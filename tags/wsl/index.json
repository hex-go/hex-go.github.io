[{"content":"ifconfig ：查询、设置网卡的相关参数;\nifup/ifdown：这两个文件是script，启动、关闭网络接口;\nroute ：查询、设定路由表 (route table)\nip：复合式的指令， 可以直接修改上述提到的功能;\nifconfig 命令修改只会临时生效，永久生效需要修改配置文件\n启动、关闭网卡 ifconfig {interface} {up|down}\n下面命令是启动eth0网卡\n1 ifconfig eth0 up 设置IP地址 不加其他参数时，系統会按照IP所在的class范围，自动计算netmask,network,broadcast等参数\n1 ifconfig eth0 192.168.100.100 或者\n1 ifconfig etho 192.168.100.100 netmask 255.255.255.128 mtu 8000 route -n 显示具体IP与PORT\n路由表说明： 排序从上到下依次是：小网段 -\u0026gt; 大网段 -\u0026gt; 默认路由。路由规则越靠前，优先级越高。\nDestination=0.0.0.0表示默认路由。即目标IP没有具体路由规则时，数据包走此路由进行转发。\nGateway=0.0.0.0表示路由直接由本地送达。即通过LAN的MAC直接通讯。如果是具体IP,则往往是具备三层路由能力的设备。\nFlag标识说明\nU: 路由是Up的 H: 目标是Host，而非一个网段 G: 通过外部设备路由数据包 R: 使用动态路由时，恢复路由信息的标识 D: 由服务或Port功能设置为动态路由 M: 路由被修改 !: 路由不被接受(拒绝不安全网段的数据包) 命令举例 增加\n1 route add -net 192.168.100.0 netmask 255.255.255.0 dev eth0 删除\n1 route del -net 169.254.0.0 netmask 255.255.0.0 dev eth0 ip ip命令整合了ifonfig和route命令的功能。\n排错命令 ping ping 探测主机192.168.1.254是否有回应。 探测仅等待一秒钟，也仅探测一次。 1 ping -c 2 -W 3 192.168.1.254 -c 执行ping的次数; -W 超时时间，单位秒\nping命令探测整个网络传输的查询最大MTU值 封包大小=MTU-28,因为IP头20字节，icmp包头8字节；-M do参数指定不允许路由器、交换机进行包重组。\n1 ping -c 2 -s 1472 -M do 192.168.1.254 -s ICMP包的大小，默认56字节; -M 主要检查MTU值( do 不让重新拆包、打包 dont 允许拆包打包)\ntraceroute 主机之间节点分析，用来判断网络环境是内部问题还是外部问题。\n原理：会针对目的IP的所有 中间node 进行 UDP 的超时等待\nnetstat 本地网络连接和端口监听\n参数说明 路由相关：-r列出路由表，等同route命令；-n显示IP/Port而非主机名\n端口相关：-aall; -n显示IP; -[tu]TCP/UDP; -l: listen; -pPID;\n查看主机所有连接状态 1 netstat -atunp 查看所有监听状态连接 1 netstat -ltunp Telnet DNS域名解析 host 1 host www.baidu.com 8.8.8.8 第二个参数为dns-server地址，可省略（使用/etc/resolv.conf）。\nnslookup 根据域名找主机 2. 根据主机找IP dig 抓包工具 1 tcpdump [-AennqX] [-i 网络接口] [-w 存储文件名称] [-c 次数] [-r 文件] [抓包的格式] 抓包格式\n网络问题排查 1 2 3 4 5 6 7 8 步骤 网卡是否正常 IP设置是否正确 LAN网络是否正常 路由信息是否正确 查看DNS 查看网络节点 查看服务状态 Selinux,防火墙 工具 lspci、dmesg ifconfig ping route -n dig、host traceroute netstat selinux,iptables 解决方案 重装驱动/更换网卡 修改配置，重启network服务 交换机、防火墙设置 修改配置，重启network服务 修改配置 等待恢复 排查问题，重启服务 iptables 规则存在顺序。 依次检查,匹配即停(LOG策略除外),没有匹配走默认。\n4表5链\nfilter: 本机进出\n- INPUT: 入本机的数据包\n- OUTPUT: 出本机的数据包\n- FORWARD: 转发数据包\nnat: 源IP:Port\\目的IP:Port之间转换\n- PREROUTING: 路由判断前执行的规则（DNAT-目的NAT/REDIRECT-重定向）\n- POSTROUTING: 路由判断后执行的规则（SNAT-源NAT/MASQUERADE-广播）\n- OUTPUT: 出本机的数据包\nmangle: 与特殊的封包的路由标识有关\n- PREROUTING、PREROUTING、OUTPUT、INPUT、FORWARD\nraw: 确定是否对数据包进行状态追踪\n- PREROUTING\n- OUTPUT\n由于 mangle 很少被使用，下图为去除mangle后的链表相关性\n规则表之间顺序: raw \u0026gt; mangle \u0026gt; nat \u0026gt; filter\n入站规则链顺序：PREROUTING \u0026gt; INPUT\n出站规则链顺序：OUTPUT \u0026gt; POSTROUTING\n转发规则链顺序：PREROUTING \u0026gt; FORWARD \u0026gt; POSTROUTING\n路径A: 数据包进入主机，路由判断是进入主机的数据包后，主要通过fileter[INPUT]链管控。\n路径B: 数据包经主机转发给其他主机，主要经过的链是 filter[FORWARD]和nat[POSTROUTING,PREROUTING]。\n路径C: 响应请求或者由主机主动发出的包。经路由判断后，通过filter[OUTPUT]和nat[OUTPUT,POSTROUTING]发出。\n命令举例 查看规则 1 iptables -t nat -L -n -t nat指定表，如果不传则为默认的filter表；-L列出目前的table规则；-n不进行IP与hostname的反查，速度快；-v显示详细信息\nUbuntu22.04,CentOS8之后，使用nf_tables作为新的内核网络过框架.具体命令参考\n1 2 # 列出所有表 nft list tables iptables-legacy: ==iptables,背后是iptables框架\nnft: 背后是nf_tables框架\niptables-nft: 使用方法与iptables兼容，背后框架是nf_tables\niptables: 软连接，可在iptables-legacy与iptables-nft之间切换\nnftables nftables是一个新式的数据包过滤框架，旨在替代现用的iptables、ip6tables、arptables和ebtables的新的包过滤框架。\nnftables旨在解决现有{ip/ip6}tables工具存在的诸多限制。相对于旧的iptables，nftables最引人注目的功能包括：改进性能、支持查询表、事务型规则更新、所有规则自动应用等等\n","description":"","id":0,"section":"posts","tags":["Linux","Network"],"title":"Linux网络-常用命令","uri":"https://hex-go.github.io/posts/bash/2024-04-23-linux%E7%BD%91%E7%BB%9C-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"content":"物理层 \u0026ndash; 数据链路层 \u0026ndash; 网络层 \u0026mdash;- 传输层 \u0026ndash; 会话层 \u0026ndash; 表达层 \u0026ndash; 应用层\n\u0026ndash; MAC,ARP \u0026ndash; IP \u0026ndash; TCP/UDP,PORT \u0026ndash;\nLAN: 区域网络(Local Area Network)\nWAN: 广域网络(Wide Area Network)\n数据链路层(MAC) MTU: 最大传输单位(Maximum Transmission Unit), 默认值为1500bytes。以太网数据包的最大大小，超出会被丢弃。\n网络层(IP) IP地址: 由两部分组成: 网络标识部分(NET_ID)和主机标识部分(Host_ID),网络部分取决于子网掩码。NET_ID用来确定网段，Host_ID用来确定主机。\n例如192.168.1.10/24,Net_ID=19.168.1 Host_ID=10\n同一网络的特点：\nNet_ID.0(网段地址NetworkIP)与Net_ID.255(广播地址)两个地址作为保留地址，不可作为主机IP(例如192.168.1.0/24，不可将192.168.1.0与192.168.1.255设置为主机IP)。 可通过广播地址向同一网络所有主机传递数据，DHCP(新主机接入网络，发现dhcp请求到广播地址，dhcp-server接收并相应可以IP给该主机)\\ARP(主机发送arp请求到广播地址，来获取某IP对应的MAC)等 不同网络则广播地址不同，则需要三层路由设备进行连接。 IP地址分类方法: 将整个IP网段分为五种等级。\nA类地址(Net_ID首位=0, 0.x.x.x~127.x.x.x)； B类地址(NET_ID开头=10, 128.x.x.x~191.x.x.x); C类地址(NET_ID开头=110, 192.x.x.x~223.x.x.x); D类地址(NET_ID开头=1110, 224.x.x.x~239.x.x.x)，群播的特殊功能，不常用 E类地址(NET_ID开头=1111, 240.x.x.x~255.x.x.x)，保留未使用 私有IP：取A类、B类、C类网络中一段作为私有IP地址\n内网进行网络规划时，严格设置私有IP,否则一旦内网需要连接公网，会与公网IP冲突。\nA类中的: 10.x.x.x B类中的: 172.[16-31].x.x C类中的: 192.168.x.x 回环地址网段: 用于主机本地测试，无网卡也可本机收发包测试服务。\nA类中的：127.0.0.0/8 网络\nCIDR(Classless Interdomain Routing, 无类域间路由选择): 使用IP地址和/子网掩码来表示一个网络地址。\nCIDR是对IP地址分类方法的进化，CIDR表示法中，子网掩码的位数可以是任意的，不再受限于传统的A类、B类、C类地址划分。\n网关,即为默认路由，负责不同网段之间的IP Forwarding的，如同值为0.0.0.0意味着直接从网口出，而不通过路由器(主机与目标网络在同一子网)\n传输层(TCP/UDP,端口) TCP: 三次握手(1.请求端发送SYN=1,状态变为; 2.回复ACK=1,SYN=1,状态更新为; 3. 回复ACK=1)\nUDP\nDNS同时提供UDP/TCP协议，优先使用UDP，当UDP无法正确获得数据时，更换为TCP传输。\n防火墙 定义：能够分析、过滤网络数据包的文件。根据实现不同又分为软件防护墙、硬件防火墙。\n软件防火墙有Netfilter(封包过滤式防火墙机制)、TCP Wrappers(根据程序分析管控)、Proxy(代理服务器)。\n封包过滤：直接分析封包表头数据，以决定该连线为放行或抵挡的机制。（二层、三层、四层）\n程序管控：透过服务器程序的插件(tcpd)，分析谁对某程序进行访问，然后通过规则去分析该程序允许谁访问。\nProxy：正向代理，面向公网的请求都由proxy发出，保护了由Proxy代理的主机。\n二层防火墙：针对源MAC、目的MAC\n三层防火墙：针对源IP、目的IP等(网络层协议)\n四层防火墙：针对TCP/UDP端口，以及TCP状态\n作用：\n拒绝数据包进入主机的哪些Port 拒绝 iptables 路由器 路由器会有两个网络接口，通过路由器本身的IP Forward功能让两个网域可以互相沟通网络封包。\n路由器：IP转发\n何时需要路由器 主机超过百台，需要划分lan，避免广播域过大带来的广播风暴； 为专有部门划分lan，放置数据广播时被同一广播域的节点抓包泄露； NAT 当路由器两端的网段分别为Public_IP、Private_IP时，需要NAT功能。\nNAT: IP转换+IP转发\nIP转换：修改数据包的IP包头数据的源IP、目的IP，将私有IP改为共有IP，实现联系外网。\n网络地址转换=路由器+IP转换。\nARP Proxy 当路由器两端的网段是同一个网段时\n让某个网络接口的MAC代理其他主机IP的对应，即让想要连接到这个IP的MAC封包由自己处理，此接口会称为所代理IP的arp代理\nDHCP服务器 客户端由广播地址，向整个网段内广播DHCP请求，有网段内的DHCP服务器响应IP参数。\nClient广播搜索DHCP服务器(UDP,目标IP=255.255.255.255) Server响应参数(根据Client-MAC在服务器登录文件中查找是否存在对应IP且无人使用) Client发送DHCP参数选择(广播) DHCP响应确认 DHCP （Dynamic Host Configuration Protocol） 可以提供网络参数给客户端电脑，使其自动配置网络的功能;\n透过 DHCP 的统一管理，在同一域当中就比较不容易出现 IP 冲突的情况发生;\nDHCP 可以通过 MAC 的比对来提供 Static IP （或称为固定 IP），否则通常提供客户端 dynamic IP （或称为动态 IP）;\nDHCP 除了 Static IP 与 Dynamic IP 之外，还可以提供租约行为之设定;\n在租约期限到期之前，客户端dhcp软件即会主动的要求更新（约0.5,0.85倍租约时间左右）;\nDHCP 可以提供的 MAC 比对、Dynamic IP 的 IP 范围以及租约期限等等，都在 dhcpd.conf 这个档案当中设定的;\n一般的情况之下，用户需要自行设定 dhcpd.leases 这个档案，不过，真正的租约档案记录是在 /var/lib/dhclient/dhclient-eth0.leases 里面;\n如果只是要单纯的 DHCP 服务，建议可以购买类似 IP 分享器的设备即可提供稳定且低耗电的网络服务。\nDHCP 服务与 DNS 服务的相关性很高;\n若 DHCP 客户端获取 IP 的速度太慢，或许可以找一下有网管 switch 的 STP 设置。\nNTP服务器 Linux 的 NAT 功能主要通过封包过滤的方式， 并使用 iptables 的 nat 表格进行 IP 伪装 （SNAT） ，让客户端自行前往互联网上的任何地方的一种方式。\nLinux 可以通过网络校时，最常见的网络校时为使用 NTP 服务器，这个服务启动在 udp port 123;\n时区档案主要放置于 /usr/share/zoneinfo/ 目录下，而本地时区则参考 /etc/localtime;\nNTP 服务器为一种阶层式的服务，所以 NTP 服务器本来就会与上层时间服务器作时间的同步化， 因此 nptd 与 ntpdate 两个指令不可同时使用;\nNTP 服务器的连接状态可以使用 ntpstat 及 ntpq -p 来查询;\nNTP 提供的客户端软件为 ntpdate 这个指令;\n在 Linux 下想要手动处理时间时，需以 date 设定时间后，以 hwclock -w 来写入 BIOS 所记录的时间。\nNTP 服务器之间的时间误差不可超过 1000 秒，否则 NTP 服务会自动关闭。\n共享文件服务器 NFS: Unix Like 依赖RPC-server\nCIFS: Windows\nSAMBA: windows+Linux 依赖NetBIOS(Network Basic Input/Output System)\n","description":"","id":1,"section":"posts","tags":["Linux","Network"],"title":"Linux-网络基础","uri":"https://hex-go.github.io/posts/bash/2024-04-23-linux%E7%BD%91%E7%BB%9C-%E5%9F%BA%E7%A1%80/"},{"content":"文件系统层次标准(FHS: Filesystem Hierarchy Standard): 核心在于确定每个特定的目录下应该放什么内容的文件和数据，并希望\nLinux 用户能够遵循该准则。\n指导用户: 1. 文件该放在哪；2. 文件该去哪里找。\nFHS根据文件系统使用的频繁与否以及是否允许用户随意改动，将目录定义为四种交互作用形态。\n可分享的：可以分享给其他系统挂载使用的目录\n不可分享的：与自身机器直接相关的设备文件等，不能分享给其他主机\n不变的：数据不常变动的文件\n可变的：经常改变的数据，如登录文件、新闻组等。\n可分享 不可分享 不变 /usr /etc /opt /boot 可变 /var/mail /var/run /var/spool/news /var/lock /bin 二进制目录，存放用户级的基本命令(软连接，指向/usr/bin)\n/boot 启动目录，存放BootLoader的静态文件(开机引导相关文件：内核、开机菜单、相关配置文件等)\n/dev 设备目录，device的缩写，存放设备文件(字符型设备文件、块设备文件、网络设备文件)\n/etc 系统配置文件目录\n/home 用户主目录\n/lib 库目录，存放系统和软件的共享库(/bin,/sbin,开机时所调用的函数)\n/media 媒体目录，可移动媒体设备的常用挂载点\n/mnt 挂载目录，临时挂载文件系统的挂载点\n/opt 可选目录，optional，存放第三方软件包和数据文件\n/proc 进程目录，现有硬件及进程信息(虚拟文件系统)\n/run 运行目录，存放系统运作的运行时数据(虚拟文件系统)\n/root root用户的主目录\n/sbin 系统二进制目录，存放系统管理员级的基本命令(开机、修复、还原系统等，软连接，指向/usr/sbin)\n/srv 服务目录，service的缩写，存放各类服务的相关文件\n/sys 系统目录，系统硬件信息的相关文件内核相关信息(虚拟文件系统，与/proc类似,更针对硬件相关参数方面)\n/tmp 临时文件\n/usr Unix Software Resource的缩写，即Unix系统软件资源。存放所有软件的数据。\n/var 可变目录，常态化变动的文件（日志、缓存、登录日志等）\n/etc目录下的常见配置 /var目录下的常见日志文件 syslogd: 是大部分Linux发行版默认的日志守护进程，默认配置文件为/etc/syslog.conf\nrsyslogd: 目前大多Linux发行版用rsyslogd替换了syslogd，默认配置文件在/etc/rsyslog.conf，了解日志存储信息。\n日志文件 说明 /var/log/message 记录了所有系统级的事件，例如启动、关机、内核错误、网络错误、程序故障等。 /var/log/cron cron 任务运行的日志 /var/log/secure 用户认证相关的安全事件信息(su\\sudo\\ssh\\passwd\\useradd等) /var/log/lastlog 用户最近一次成功+失败的登录事件，命令lastlog查看 /var/log/wtmp 用户登录、注销、系统重启等事件，命令last查看 /var/log/utmp 所有当前已登录用户的信息，命令who\\w\\users\\finger查看 /var/log/btmp 失败的登录尝试，lastb命令查看 /var/log/dmesg 系统在开机时内核自检的信息，也可以使用dmesg命令直接查看内核自检信息 ","description":"","id":2,"section":"posts","tags":["Linux"],"title":"Linux基础-FHS(文件系统层次标准)","uri":"https://hex-go.github.io/posts/bash/2024-04-22-linux%E5%9F%BA%E7%A1%80-fhs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B1%82%E6%AC%A1%E6%A0%87%E5%87%86/"},{"content":"POSIX（Portable Operating System Interface，可移植操作系统接口）是一个由IEEE（电气和电子工程师学会）制定的一系列标准，旨在定义操作系统接口的标准化。\n它的目的是使 UNIX 和类 UNIX 操作系统之间的软件在不同系统上可移植并保持兼容性。\n目前工作中涉及到的Posix标准有：\n正则表达式实现分为两种：基本正则表达式(BRE)、扩展正则表达式(ERE)\n线程之间的隔离屏障、线程内存空间大小等。\n","description":"","id":3,"section":"posts","tags":["Linux"],"title":"Linux基础-Posix","uri":"https://hex-go.github.io/posts/bash/2024-04-22-linux%E6%A0%87%E5%87%86-posix/"},{"content":"Linux系统在引导时加载Linux内核后，便由Linux内核加载init程序，由init程序完成余下的引导过程，比如加载执行级别，加载服务，启动Shell/图形化界面等等。\nLinux历史上服务管理一共出现过三种方式，init、service、systemd\ninitd Linux 最初一直采用 init 进程。\nInit（初始化的简称）是在启动计算机系统期间启动的第一个进程（initd的PID是0），其他进程都是它的子进程。\n因为init的参数全在/etc/init.d目录下，所以使用 init 启动一个服务，命令如下：\n1 /etc/init.d/nginx start service service是一个运行System V init(/etc/init.d 目录下的参数)的脚本命令。service根据/etc/init.d目录下的服务配置运行程序。可以将service理解成init的一种实现。两者的服务管理方式没有区别\n1 2 3 /etc/init.d/nginx start 或者 service nginx start service与init存在以下缺点：\n启动时间长：init进程串行启动。 启动脚本复杂：init进程有启动执行脚本，不管理其他阶段，脚本需要自行处理其他各种情况。 systemd 2015年以后(Ubuntu-15.04|RHEL-7)，为克服System V init启动时间长、脚本复杂的缺点而诞生的。提供系统启动速度。大部分Linux发行版都已采用新的systemd替代System V和Upstart，向下兼容System V。\nsystemd: 是Linux系统中最新的初始化系统(init)，为系统的启动和管理提供一套完整的解决方案。\nSystemd取代了initd成为系统的第一个进程(Systemd 的PID是1)，其他进程都是它的子进程。\n命令 Systemd是一组命令的集合，涉及系统管理的各方面。\n系统级别 systemctl是管理系统的主命令\n重启系统：systemctl reboot; 关机：systemctl poweroff; 停止CPU: systemctl halt; 暂停系统: systemctl halt等\nsystemd-analyze查看启动耗时。\n查看启动耗时: systemd-analyze; 查看每个服务的启动耗时: systemd-analyze blame; 显示瀑布状的启动过程流: systemd-analyze critical-chain; 显示指定服务的启动流: systemd-analyze critical-chain atd.service\nhostnamectl管理主机信息\n查看: hostnamectl; 设置: hostnamectl set-hostname hex\nlocalectl管理本地化设置\n查看: localectl; 设置: localectl set-locale LANG=en_GB.utf8\ntimedatectl管理时区设置\n查看: timedatectl; 设置timedatectl set-timezone America/New_York\nloginctl查看当前登录的用户\n列出当前session: loginctl list-sessions; 列出当前登录用户: loginctl list-users; 显示指定用户信息: loginctl show-user user1\nUnit Systemd 可以管理所有系统资源。不同的资源统称为 Unit（单位）。\n日志管理 Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。\n","description":"","id":4,"section":"posts","tags":["Linux"],"title":"Linux基础-服务管理","uri":"https://hex-go.github.io/posts/bash/2024-04-22-linux%E5%9F%BA%E7%A1%80-%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86-%E5%8E%9F%E7%90%86/"},{"content":"Systemd相关文件 /usr/lib/systemd/system/xx.service 配置文件 命令举例 开机自启动 1 systemctl enable httpd 启动服务 1 systemctl start httpd 查看服务状态 1 systemctl status httpd 停止服务 1 systemctl stop httpd 加载配置文件 1 systemctl daemon-reload 重启服务 1 systemctl restart httpd 列出Target包含的服务 1 2 # 查看 multi-user.target 包含的所有服务 systemctl list-dependencies multi-user.target 切换Target 1 2 3 切换到另一个 target # shutdown.target 就是关机状态 systemctl isolate shutdown.target 服务配置文件 配置文件所在目录：主要放在/usr/lib/systemd/system目录，也可能在/etc/systemd/system目录。\n以配置文件sshd.service举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID Type=simple KillMode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target [Unit]区块: 启动顺序、依赖关系 Description: 给出当前服务的简单描述\nDocumentation: 给出文档位置\nAfter: 表示如果network.target或sshd-keygen.service需要启动，那么当前服务sshd.service应该在它们之后启动。\nBefore: 定义服务应该在哪些服务之前启动。\nAfter和Before字段只涉及启动顺序，不涉及依赖关系。\nWants: 设置弱依赖关系。比如Wants=sshd-keygen.service表示服务与sshd-keygen.service之间存在\u0026quot;弱依赖\u0026quot;关系，即如果sshd-keygen.service启动失败或停止运行，不影响当前服务继续执行。\nRequires: 设置强依赖关系，即如果配置的服务启动失败或异常退出，那么当前也必须退出。\nWants字段与Requires字段只涉及依赖关系，与启动顺序无关。\n[Service]区块：启动行为 Service区块定义如何启动当前服务。\n启动命令\nEnvironmentFile：指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。\nExecStart：定义启动进程时执行的命令(参数可用$key的形式，在EnvironmentFile配置的文件中获取)。\nExecReload\\ExecStop\\ExecStartPre\\ExecStartPost\\ExecStopPost: 重启\\停止\\启动之前\\启动之后\\停止之后\n赋值是加连词号-，表示抑制错误，即发生错误时不影响其他命令执行。例如EnvironmentFile=-/etc/sysconfig/sshd\n，当文件不存在时，不影响后续ExecStart执行\n启动类型\nType: 定义启动类型。\nType字段值 说明 simple（默认值） ExecStart字段启动的进程为主进程 forking ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot 类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus 类似于simple，但会等待 D-Bus 信号后启动 notify 类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle 类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合 重启行为\nKillMode: 定义 Systemd 如何停止服务。\nKillMode字段值 说明 control-group（默认值） 当前控制组里面的所有子进程，都会被杀掉 process 只杀主进程 mixed 主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none 没有进程会被杀掉，只是执行服务的 stop 命令 Restart: 定义了服务退出后，Systemd 的重启方式。\n守护进程，推荐设置on-failure; 允许发生错误退出的服务，可设置on-abnormal\nRestart字段值 说明 no（默认值） 退出后不会重启 on-success 只有正常退出时(退出状态码为0), 才会重启 on-failure 非正常退出时(退出状态码非0), 包括被信号终止和超时, 才会重启 on-abnormal 只有被信号终止和超时，才会重启 on-abort 只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog 超时退出，才会重启 always 不管是什么退出原因，总是重启 RestartSec字段：表示 Systemd 重启服务之前，需要等待的秒数。\n[Install]区块 定义如何安装当前配置文件，即systemctl enable命令执行时，将当前配置文件拷贝至哪里(/etc/systemd/system/[Target|WantedBy设置].wants/)。\nWantedBy字段：表示该服务所在的 Target。例如WantedBy=multi-user.target指的是，服务所在的Target是multi-user.target。\n这个设置非常重要，因为执行systemctl enable sshd.service命令时，sshd.service的一个符号链接，就会放在/etc/systemd/system目录下面的multi-user.target.wants子目录之中。\nTarget Target: 表示一组服务。Systemd默认的启动Target是multi-user.target。在这个组里的所有服务，都将开机启动。\n可执行命令查看\n1 systemctl get-default 一般来说，常用的 Target 有两个：一个是multi-user.target，表示多用户命令行状态；另一个是graphical.target，表示图形用户状态，它依赖于multi-user.target。官方文档有一张非常清晰的 Target 依赖\nmulti-user.target配置文件内容如下：\n1 2 3 4 5 6 7 [Unit] Description=Multi-User System Documentation=man:systemd.special(7) Requires=basic.target Conflicts=rescue.service rescue.target After=basic.target rescue.service rescue.target AllowIsolate=yes Requires：要求basic.target一起运行。\nConflicts：冲突字段。如果rescue.service或rescue.target正在运行，multi-user.target就不能运行，反之亦然。\nAfter：表示multi-user.target在basic.target rescue.service rescue.target之后启动，如果它们有启动的话。\nAllowIsolate：允许使用systemctl isolate命令切换到当前Targetmulti-user.target。\n","description":"","id":5,"section":"posts","tags":["Linux","Systemd"],"title":"Linux基础-服务管理-实战","uri":"https://hex-go.github.io/posts/bash/2024-04-22-linux%E5%9F%BA%E7%A1%80-%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86-%E5%AE%9E%E6%88%98/"},{"content":"操作系统之前 Power-On \u0026ndash;\u0026gt; BIOS \u0026ndash;\u0026gt; 主引导记录(grub) \u0026ndash;\u0026gt; OS\n操作系统 OS \u0026ndash;\u0026gt; /boot \u0026ndash;\u0026gt; init进程 \u0026ndash;\u0026gt; 运行级别 \u0026ndash;\u0026gt; /etc/init.d \u0026ndash;\u0026gt; 用户登录 \u0026ndash;\u0026gt; login shell\n加载内核：操作系统接管硬件之后，首先读取/boot目录下的内核文件。 启动init进程：内核文件加载后，运行第一个程序/sbin/init(初始化系统环境), PID=1,其他所有进程都是他的子进程。 加载运行级别: 由init进程根据运行级别(7种/etc/inittab)，加载相应运行程序/etc/rc[0-6].d/(K01sysstat|S01cron|S01dbus|S01docker|S01rsync|S01ssh等)。 加载服务: 运行级别目录下(例如/etc/rc2.d)都是指向/etc/init.d/下的链接文件2024-04-22-Linux基础-启动流程.md。 用户登录：开机启动程序加载后，用户进行登录。命令行登录(init进程调用gtty，让用户输入name+pwd -\u0026gt; init调用login核对密码 \u0026ndash;\u0026gt; 从/etc/pwd读取指定shell并启动)、ssh登录(sshd服务取代getty和login)、图形界面登录。 打开bash：读入/etc/profile(全局)，然后读取~/.bash_profile|~/.bash_login|.profile(当前用户，这三个文件有一个存在则不会读另外两个)。 init进程在上面2、3、4阶段\n用户登录后的配置读取：/etc/profile为系统通用设置；~/.profile为个人且需要被子进程继承的设置；~/.bashrc为个人不需要继承的设置；\n","description":"","id":6,"section":"posts","tags":["Linux"],"title":"Linux基础-启动流程","uri":"https://hex-go.github.io/posts/bash/2024-04-22-linux%E5%9F%BA%E7%A1%80-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"content":"一、简述你知道的几种CNI网络插件，并详述其工作原理。K8s常用的CNI网络插件 （calico \u0026amp;\u0026amp; flannel），简述一下它们的工作原理和区别。 Flannel\n- Overlay:\n- UDP(IP in UDP: [H-Mac|H-IP|UDP])\n- VxLAN(L2 in UDP: [H-Mac|H-IP|UDP|VxLAN])\n- IPIP(IP in IP: [H-Mac|H-IP])\n- 路由：\n- host-GW(Flanneld将容器网络的路由信息写入主机的路由表，每个主机都有完整的容器网络路由信息)\nCalico\n- Overlay\n- IPIP\n- VxLAN\n- 路由\n- BGP（Brid:bgp客户端+路由反射器,分发路由+优化大量链接）\ncilium\n容器内IP地址唯一问题：\nFlannel通过中心化容器地址分配解决，使用ETCD存储节点与网段之间关系，节点内部通过Flannel配置docker网络。\n二、Worker节点宕机，简述Pods驱逐流程。 NodeLifecycleController会通grpc与每个节点的kubelet收集节点的 三、简述你知道的K8s中几种Controller控制器，并详述其工作原理。简述 ingress-controller 的工作机制\n四、简述k8s的调度机制\n原理\n请求以及调度的步骤：\n节点预先、节点优先级排序、节点择优 五、简述kube-proxy的三种工作模式和原理 KubeProxy是运行在每个worker节点的网络代理组件，使发往service的流量负载均衡到相应的POD\n监听资源：\nservice endpoint endpointslices:(启用 EndpointSlice) node(启用服务拓扑) 四种代理模式方式：\nuser_space(k8s-v1.2被淘汰) iptables(k8s-v1.2后的默认模式) ipvs kernel_space(专用windows,userspace的早期实现。略) userspace详述 实现方式：\nkube-proxy监听端口，所有访问svc的请求都转发至此端口，然后在proxy内进行转发。每多一个svc，多一个监听端口+一个iptables规则\n数据流向：\n访问服务的ClusterIP -\u0026gt; 根据iptables转发到kube-proxy -\u0026gt; kube-proxy查找注册中心，将请求发送给实例\n负载均衡算法：轮询\n优点：当某个实例请求失败，可再重试其他实例\n缺点：效率低，因为第二步涉及内核态到用户态的切换\niptables实现详述 kube-proxy将规则添加到NAT-PreRouting钩子上，以实现其NAT和负载均衡功能。\n负载均衡策略：随机选择后端（随机数），第一个Pod没有响应,则连接失败\n缺点：\niptables更新是全量更新。（service较多时，创建、更新服务会引入时延） iptables的查询为数组遍历。（查询性能增加是线性增长的） 负载均衡算法只支持随机等成本分发。 综上，1k-svc(1W-pod)以上规模时，建议选择ipvs\nipvs实现详述 ipvs是Linux内核专用于负载均衡的组件。ipvs基于hash表实现，iptables基于数组。ipvs连接处理性能恒定，不受集群规模影响。\n负载均衡策略：\nrr: round-robin(轮询) lc: least connection (最小开放连接数) dh: destination hashing(目标散列) sh: source hashing(源地址散列) sed: shortest expected delay() nq: never queue() 缺点：IPVS与iptables的数据包路径不同，如果有IPVS与其他使用iptables的程序一起使用需求，需要考虑兼容性。\n发展趋势 接口化，类似CNI(nftables作为kube-proxy后端的pr至今未被合并) 去kube-proxy, 由容器网络框架实现(cilium) 在集群中不超过1000个服务的时候，iptables 和 ipvs 并无太大的差异。而且由于iptables 与网络策略实现的良好兼容性，iptables 是个非常好的选择。\n当你的集群服务超过1000个时，而且服务之间链接大多没有开启keepalive，IPVS模式可能是一个不错的选择。\n六、k8s每个Pod中有一个特殊的Pause容器，能否去除，简述原因\n作用：\nNetNamespace隔离：pause负责创建并维护NetNS,其他容器共享此网络命名空间 进程隔离：确保其他容器停止时，Pause容器仍运行，以维护Pod生命周期。 资源隔离 IP地址维护：Pod_IP与Pod的生命周期保持一致 生命周期管理 pod创建过程 七、简述pod中readness和liveness的区别和各自应用场景\n八、Pod启动失败如何解决以及常见的原因有哪些\n九、简述K8s中label的几种应用场景\n10.简述你知道的Jenkins Pipeline中脚本语法中的几个关键字\n十一、Docker 的网络通信模式。\n十二、K8s有哪些重要组件，简述一下集群部署的流程。\n十三、你所用的到的日志分析工具有哪些以及它们如何与K8s集群通讯。\n十四、Kubelet 与 kubeproxy 作用。Kubeproxy 的三种代理模式和各自的原理以及它们的区别。\n十六、Iptables 四个表五个链\n","description":"","id":8,"section":"posts","tags":["Kubernetes","面试速记"],"title":"K8s面试-问题","uri":"https://hex-go.github.io/posts/interview/2024-04-25-k8s-%E9%9D%A2%E8%AF%95%E9%80%9F%E8%AE%B0-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98/"},{"content":"容器网络 Network Namespace包含哪些资源？ 容器所能看到的“网络栈”被Network Namespace隔离在各自的命名空间,这个“网络栈”包括：\n网卡(Network Interface) 回环设备(Loopback Device) 路由表(Routing Table) iptables规则 -net=host意味着什么？ 不开启 Network Namespace，容器使用宿主机的网络栈。容器间会发生端口冲突，像端口资源就需要提前规划。\n同主机容器间网络通信？ 路由规则 + Veth Pair设备 + 宿主机网桥\nVeth Pair: 两张虚拟网卡(Veth Peer),向其中一个网卡发出的数据包，会直接出现在另一个网卡，不受Network Namespace的影响。\n网桥：二层设备，根据MAC地址，将数据包转发到网桥的不同端口上。\n容器根据路由表找到出口网卡。 数据经过VethPair,VethPair另一端在宿主机上，名称像veth9c02e56，其又插在docker0网桥上（brctl show命令可查看） 网桥docker0负责二层转发（根据mac地址找到对应端口,此处端口==挂在docker0上的虚拟网卡） 类型： | VethPair(网线) | 网桥 | VethPair(网线) |\n包流向: eth0 \u0026mdash;\u0026mdash;\u0026ndash; veth9c02aaa \u0026gt; docker0（网桥）\u0026gt; veth9c02bbb \u0026mdash;\u0026mdash;\u0026gt; eth0\n环境 : 容器A |\u0026mdash;\u0026mdash;-| 宿主机 |\u0026mdash;\u0026mdash;| 容器B\n举例说明，\n源容器A， 目标容器B(172.17.0.3)\n根据路由规则，确定出口网卡\n路由规则 1 2 Destination Gateway Genmask Flags Metric Ref Use Iface 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0 根据目标IP匹配上面的路由规则，这条路由规则的网关（Gateway）是 0.0.0.0，这就意味着这是一条直连规则，即：凡是匹配到这条规则的 IP\n包，应该经过本机的 eth0 网卡，通过二层网络直接发往目的主机。\n此时需要知道容器B的IP对应的MAC地址（容器A向eth0网卡发arp广播，查找MAC地址）\nARP（Address Resolution Protocol），是通过三层的 IP 地址找到对应的二层 MAC 地址的协议。\n向出口网卡发arp请求，获取目标MAC\n虚拟网卡“插”在网桥上，会被剥夺处理数据包的能力，降级为网桥上的port，数据包的处理全部由网桥负责。收到arp请求后，docker0会作为二层交换机，将arp转发到其他端口（其他容器虚拟网卡），容器B的虚拟网卡收到请求后，会将自己的MAC回复给容器A。\n数据包(目的MAC)，从源容器eth0网卡发出\n源容器A将数据包发出，数据包头包含mac地址，通过Veth-Pair设备到达宿主机vethxxx网卡上，vethxxx网卡作为docker0的从设备，处理数据包的能力被剥夺，数据包直接流入docker0\ndocker0网桥转发至端口(虚拟网卡)\ndocker0承担二层交换的角色，根据目标mac，在docker0持有的CAM表中查找对应的端口（虚拟网卡），并将数据包转发至此端口\nCAM表: 即交换机通过 MAC 地址学习维护的端口和 MAC 地址的对应表\n根据veth-pair，宿主机流入目标容器。 主机访问当前主机上的容器 路由规则（指向docker0） + 网桥docker0 + Veth Pair设备\n容器网络能做到哪些，又存在什么问题？ 容器网络可以实现：\n容器访问宿主机网络 同一主机，容器之间通信 问题：\n就是跨主通信问题\n源=主机访问对端容器。 源=容器访问对端容器。 导致以上现象的原因：\n容器地址重复(每个主机的容器网络都是172.17.0。0/16) Flannel：中心化容器地址分配， 地址分配表存储在Etcd\n容器地址不可达（不同主机不知道IP容器网段的地址分配，数据包发到宿主机网络会因为无法路由被丢掉） Flannel: Overlay网络(对应udp/vxlan模式)，源主机上的flanneld在数据包添加额外包头封装（主机IP），宿主机网络根据额外包头路由到目标主机，再由目标机器上的flanneld解包。\n解决容器网络可达问题的方案有哪两种？ 解决容器网络方案两方面：\n容器网络IP唯一； 容器网络路由可达； IP地址唯一方面：\n中心化网络地址分配\n网络路由可达有两种方式：\nOverlay方式：相当于软件方式，通过每个主机上的agent实现了一个虚拟网桥\n主机路由方式：通过将容器网络路由表维护到宿主机网络，实现路由可达。\n讲一下Overlay方案的数据包流转 以Flannel-UDP举例 容器A \u0026ndash; veth-pair \u0026ndash; cni0网桥 \u0026ndash; 主机A\n路由规则：如果目标IP属于当前主机容器ip段，是直连规则；否则根据宿主机规则进行路由\n主机A \u0026ndash; 路由规则 \u0026ndash; flannel0（TUN设备） \u0026ndash; Flannel进程\nTUN是一个三层设备，在os内核，传递给用户进程（内核态 \u0026ndash; 用户态）\n主机A-Flannel进程 \u0026ndash; 查子网-主机对应关系(Etcd) \u0026ndash; 主机B-Flannel(目的主机IP:8285)\n根据目标IP \u0026ndash; 匹配对应的目标子网 \u0026ndash; 再从Etcd中找到对应主机IP；源flannel对包头封装后，以UDP包的形式发给目标主机\nVxLAN\\UDP\\calico-IPIP对包头处理后，发的都是UDP数据包\n主机B-Flannel进程 \u0026ndash; flannel0(TUN设备) \u0026ndash; 路由规则 \u0026ndash; 主机B\nflanneld 会直接把这个 IP 包发送给它所管理的 flannel0 设备。用户态 -\u0026gt; 内核态的过程，进入内核态后 Linux 内核网络栈就会负责处理这个 IP 包，就是通过本机的路由表来寻找这个 IP 包的下一步流向。\n主机B \u0026ndash; cni0网桥 \u0026ndash; veth-pair \u0026ndash; 容器B\ndocker0网桥扮演二层交换机的角色，将数据包发送给正确的端口(虚拟网卡)，进而通过 Veth Pair 设备进入到目标容器的 Network Namespace 里。\nFlannel-Vxlan 将tun设备（flannel0）+flanneld进程的组合变成了VTEP（flannel.1） VTEP: 虚拟隧道端点(VxLAN Tunnel End Point),在内核对二层数据帧进行封装和解包。VTEP设备即有IP，也有MAC。\n每个主机多条路由规则（由flanneld创建），目标IP==目标VTEP设备的IP，经过flannel.1发出，网关地址为目标VTEP设备的IP flannel-UDP模式的包头格式？ flannel自定义的包头协议\nHost-MAC | Host-IP | UDP | Real-IP | Data\nflannel-VxLAN模式的包头格式？ VxLAN是使用UDP封装技术来实现虚拟网络，但一定一定不是UDP模式。\nHost-MAC | Host-IP | UDP | vxlan | |Real-MAC | Real-IP | Data\nFlannel-hostGW模式怎样实现的？ host-GW 不是Overlay网络，采用的是 主机路由 的方案。就是一个大二层网络，flannel将划分的路由信息刷到主机的路由表，这样每个host上都有整个容器网络的路由数据。\n原理：将每个 Flannel 子网（Flannel Subnet，比如：10.244.1.0/24）的“下一跳”，设置成该子网对应的宿主机的 IP地址。\n优点: 性能 == 虚拟机直接通信（没有引入额外的封/解包操作）\n缺点：1. 必须二层可达（即，所有主机需要在一个路由设备下。因为flannel只能做到修改主机上的路由表，如果主机中间间隔了三次路由设备，数据包从源路由器出，到下一跳路由器时，由于没有下一跳至目标路由器的路由，则会在源路由器处丢掉）\n2. 规模小（二层网络节点太多，会存在arp广播风暴问题，因此规模会受限制。）\nflannel-UDP模式的优缺点？ 优点：简单，直接，易理解\n缺点：性能差。数据包头封包/解包在用户态进行，因此数据发送，需要经历两次用户态到内核态的转换（内核态封装，用户态包头解包/封包，内核态发送）。\nFlannel-UDP模式发包时，有哪三次内核态、用户态的切换？ 第一次：容器进程的数据包，经过docker0网桥进入内核态\n第二次：数据包根据路由表、tun设备，进入用户态\n第三次：udp封包后，再由tun设备进入内核态，由宿主机网卡发出\nflannel-VxLAN模式的优缺点？ 优点：速度快\n缺点：兼容性问题。\n都是UDP封包实现Overlay网络，flannel-VxLAN模式为什么就比UDP模式快？ VxLAN封包技术是Linux内核的标准协议，虽然封包结构更复杂，但因为数据封/解包的过程在内核中完成，避免了内核态、用户态的切换。\ncalico有哪些模式？ VxLAN模式：overlay方式。VxLAN封包技术，内核支持，速度快但兼容性差。\nIPinIP模式：Overlay方式。IPIP封包技术，包头更小、内置在内核，使它性能更好、但安全性更差。\nBGP模式：主机路由方式。将修改主机路由表的操作，变为BGP协议。每个节点模拟一个路由器，容器网络的路由喜喜会被广播到其他网络的路由设备。\n什么是Underlay,什么是overlay? Overlay底层依赖Underlay网络，Overlay是依托Underlay中的物理实体，软件虚拟的层级。\n延展网络(Overlay Network): 指构建在另一个网络（Underlay）上的计算机网络(虚拟)，一种网络虚拟化技术的形式。\nUnderlay:\n为什么集群要有overlay网络？ 因为要解决跨主机容器网络不通的问题，除Overlay方案外，还存在主机路由方案（flannel-hostGW/calico-BGP）\n什么是VxLAN? VxLAN: Virtual Extensible LAN(虚拟局域网扩展技术)\nVxLAN组建的Overlay网络什么样？ 通过UDP封包技术，在真实数据包的包头怎加封装|HOST-MAC|HOST-IP|UDP|VXLAN\nK8S网络演进历史 石器时代 V1.1以前 v1.1 v1.2 v1.3以后 没有标准，只有假设 只有标准，没有实现 内置实现，多种扩展 关注网络安全、策略 v1.1以前\n基本假设：每个pod一个IP，所有pod、主机在一个可以直连直通的扁平网络。 可以理解为：k8s不提供网络的实现，而是提出的部署前置要求。开源第三方方案（calico/weave/flannel等）\nv1.1\n出现了CNI标准，但没有具体实现 K8S采用CNI，而非docker出的网络标准CNM，因为CNI更开放，不强依赖docker\n一个配置文件\n一个可执行文件 （创建/销毁容器时，创建/销毁网络配置时调用）\n读取6个环境变量\n接受1个命令行参数 （执行的操作、目标网络NameSpec、容器网卡等）\n实现两个操作（ADD/DEL） （创建网络的ADD操作/删除网络的DEL操作）\nCNI各种插件不同模式的性能对比 Bare \u0026gt; Flannel(host-gw) ~ Calico(bgp) \u0026gt; Calico(ipip) ~ Flannel(vxlan) \u0026gt; Flannel(udp)\n","description":"","id":9,"section":"posts","tags":["CNI","Kubernetes","面试速记"],"title":"K8s网络CNI-概念与入门","uri":"https://hex-go.github.io/posts/interview/2024-04-12-k8s-%E9%9D%A2%E8%AF%95%E9%80%9F%E8%AE%B0-%E7%BD%91%E7%BB%9Ccni/"},{"content":"知识 规范 文件系统层次标准(FHS)：规范目录中存放的内容所指定的标准。解决两个问题：文件放哪里；文件去哪里找。\nPosix规范：\n1. 文件管理 1.1 2. 文本处理 3. 进程管理 4. 磁盘管理 5. 可观测性（日志、资源、网络） find命令 问题 1. 文件删除后，但文件空间没有被释放，原因与解决方案 原因：Linux系统中，如果有进程打开文件并持有文件句柄时，即使其他程序删除了文件，文件系统也不会立即释放磁盘空间，知道持有文件句柄的所有进程都关闭了文件才行。\nLinux系统中，文件彻底删除取决于两个计数器：磁盘引用计数器(记录文件有几个硬链接)、内存引用计数器(记录文件被几个进程打开)。只有两个计数器全部为0时，文件才会被真正删除。\n解决：\n等持有文件句柄的进程退出 可以通过命令lsof(list open files)查看打开文件的进程。\n截断文件 truncate命令可将文件缩小、扩展到指定的大小。通常用来清除日志文件，-s指定字节大小。\n1 truncate -s 0 /var/log/xx.log cat /dev/null \u0026gt; xx.log 会使文件内容为null，文件大小为0；echo '' \u0026gt; xx.log会使文件内容为空字符串，文件大小为1。\n1 cat /dev/null \u0026gt; 格式：\nfind \u0026lt;文件路径\u0026gt; \u0026lt;条件\u0026gt; \u0026lt;文件名\u0026gt;\n常用参数\n-name 匹配文件名 -nouser 匹配无所属主的文件 -perm 匹配文件权限 -nogroup 匹配无所属组的文件 -user 匹配文件所属主 -newer 匹配比指定文件更新的文件 -group 匹配文件所属组 -type 匹配文件类型 -mtime 匹配最后修改文件内容时间 -size 匹配文件大小 -atime 匹配最后读取文件内容时间 -prune 不搜索指定目录 -ctime 匹配最后修改文件属性时间 -exec…… {}; 进一步处理搜索结果 按时间查找 查找/目录下，距离现在7天之前修改过的文件\n1 find / -mtime 7 -ls|head -mtime: 文件修改时间；-ctime:改变时间（权限、属主等）；-atime: 访问时间（read）；\n-mmin,-cmin,-amin以分钟为单位，上面三个以天为单位\n时间比较参数：-mnewer: 修改时间比xxx文件更晚的文件。 还有anewer和cnewer\n7：当前时间-文件修改时间=7,即距今7天时修改的文件；-7：修改时间差\u0026lt;7的文件；+7:修改时间差\u0026gt;7的文件\n-ls：详细信息；\nhead：默认显示前10行\ngrep命令 grep: Global Regular Expression Print(全局正则表达式版本)的缩写， 文本搜索工具。\n匹配所有d开头文件中包含test的行\n1 grep \u0026#39;test\u0026#39; d* 匹配xx文件中至少包含5个连续小写字母的行\n1 grep \u0026#39;[a-z]\\{5\\}\u0026#39; xx 目录操作 默认 只搜索当前目录\n-r 搜索子目录\n-d 忽略子目录搜索\nPOSIX 全名为Portable Operating System Interface(可移植操作系统接口)，由IEEE制定的OS接口标准化的规范。保证不同Unix系统上的应用的兼容性。\nPOSIX规范将正则表达式实现分为两种：基本正则表达式(BRE)、扩展正则表达式(ERE)\nPOSIX还规定了线程之间的隔离屏障、线程内存空间大小等。\n通配符规则(glob) POSIX中对glob()函数的标准化,定义一种模式匹配规则，用于匹配文件系统中的文件名（类似Shell中的通配符，但更为灵活）。\n以下是一些常见的通配符和它们的含义：\n通配符 含义 举例 * 匹配零个或多个任意字符。 例如，*.txt 匹配所有以 .txt 结尾的文件名。 ? 匹配任意单个字符。 例如，file?.txt 匹配 file1.txt、file2.txt 等。 [] 用于指定一个字符集，可以匹配方括号中的任何单个字符。 例如，file[123].txt 匹配 file1.txt、file2.txt、file3.txt。 {} 用于指定多个可能的匹配项，以逗号分隔。 例如，{*.txt,*.pdf} 匹配所有以 .txt 或 .pdf 结尾的文件名。 ! 用于排除匹配项。 例如，!*.txt 匹配所有不以 .txt 结尾的文件名。 基本正则表达式（BRE） 类型 元字符 语法 举例 转义字符 \\ 用于转义特殊字符，使其失去其特殊含义。 \\t: 制表符;\\r: 回车;\\n: 换行;\\.: 小数点本身 字符集 \\d 一个数字。 \\d: \u0026ldquo;9\u0026rdquo;,\u0026ldquo;0\u0026rdquo;,\u0026ldquo;1\u0026rdquo; \\w 一个非空字符A-Za-z0-9_。 \\w: \u0026ldquo;A\u0026rdquo;,\u0026ldquo;a\u0026rdquo;,\u0026ldquo;0\u0026rdquo;,\u0026quot;_\u0026quot; \\s 一个空白字符。 \\s: \u0026ldquo;\\t\u0026rdquo;, \u0026ldquo;\\n\u0026rdquo; . 除\\n外的任一字符 .: \u0026ldquo;A\u0026rdquo;,\u0026ldquo;a\u0026rdquo;,\u0026ldquo;0\u0026rdquo;,\u0026quot;_\u0026quot;,\u0026quot;\\t\u0026quot;,\u0026quot;\\r\u0026quot; 自定义字符集 [] []匹配内的任一字符 [ab@#]: \u0026ldquo;a\u0026rdquo;, \u0026ldquo;b\u0026rdquo;, \u0026ldquo;@\u0026rdquo;, \u0026ldquo;#\u0026rdquo; [-] [-]范围的任一字符 [a-d]: \u0026ldquo;a\u0026quot;到\u0026quot;d\u0026quot;之间的任一字符 [^] [^]匹配之外的任一字符 [^ab@#]: 非\u0026quot;a\u0026rdquo;, \u0026ldquo;b\u0026rdquo;, \u0026ldquo;@\u0026rdquo;, \u0026ldquo;#\u0026ldquo;的任一字符 匹配次数 {n} 表达式匹配N次。 a{3}: \u0026ldquo;aaa\u0026rdquo; {m,n} M =\u0026lt; 表达式匹配次数 \u0026lt;= N。 [ab]{1,2}: \u0026ldquo;a\u0026rdquo;, \u0026ldquo;aa\u0026rdquo;, \u0026ldquo;b\u0026rdquo;, \u0026ldquo;bb\u0026rdquo; {m,} M =\u0026lt; 表达式匹配次数 \\w\\d{2,}: \u0026ldquo;a12\u0026rdquo;, \u0026ldquo;_4567\u0026rdquo;, \u0026ldquo;A12345\u0026rdquo;\u0026hellip; ? 0次或者1次，等同{0,1} a[bc]?: \u0026ldquo;a\u0026rdquo;, \u0026ldquo;ac\u0026rdquo;, \u0026ldquo;ad\u0026rdquo; + 1次以上，等同{1,} a+b: \u0026ldquo;ab\u0026rdquo;, \u0026ldquo;aab\u0026rdquo;, \u0026ldquo;aaab\u0026rdquo;\u0026hellip; * 0次以上(不出现或者任意次)，等同{0,} a*b: \u0026ldquo;b\u0026rdquo;, \u0026ldquo;ab\u0026rdquo;, \u0026ldquo;aab\u0026rdquo;\u0026hellip; 非贪婪模式 匹配次数后加?,匹配次数不定的表达式尽可能少的匹配 目标文本\u0026quot;dxxdxxxxd\u0026rdquo;: 正则d\\w+?: \u0026ldquo;dx\u0026rdquo;; 正则d\\w+?d: \u0026ldquo;dxxd\u0026rdquo; 其他 ^ 字符串开始地方匹配 ^aa: \u0026ldquo;aaxxx\u0026rdquo; $ 字符串结束地方匹配 bb$: \u0026ldquo;xxxbbb\u0026rdquo; \\d 匹配单词边界，即单词与空格之间 表达式 ` ` 或，既可匹配左表达式，又可匹配右表达式 () 1. 匹配次数时，()内被整体修饰; (ab)+: \u0026ldquo;ab\u0026rdquo;, \u0026ldquo;abab\u0026rdquo;\u0026hellip; 2. 取结果时，()中的内容可单独取到 ￥(\\d+.?\\d*): \u0026ldquo;￥ 20.5\u0026rdquo;\u0026hellip;,单独获取括号范围匹配内容为\u0026quot;20.5\u0026rdquo; \\d 匹配单词边界，即单词与空格之间 举例\n数字：^[0-9]*$\nn位的数字：^\\d{n}$\n至少n位的数字：^\\d{n,}$\n零和非零开头的数字：^(0|[1-9][0-9]*)$\n非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]{1,2})?$\n带1-2位小数的正数或负数：^(-)?\\d+(.\\d{1,2})?$\n正数、负数、和小数：^(-|+)?\\d+(.\\d+)?$\n有两位小数的正实数：^[0-9]+(.[0-9]{2})?$\n有1~3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$\n非零的正整数：^[1-9]\\d*$ 或 ^([1-9][0-9]){1,3}$ 或 ^+?[1-9][0-9]$\n非零的负整数：^-[1-9][]0-9\u0026quot;$ 或 ^-[1-9]\\d$\n非负整数：^\\d+$ 或 ^[1-9]\\d*|0$\n非正整数：^-[1-9]\\d*|0$ 或 ^((-\\d+)|(0+))$\n非负浮点数：^\\d+(.\\d+)?$ 或 ^[1-9]\\d*.\\d*|0.\\d*[1-9]\\d*|0?.0+|0$\n浮点数：^(-?\\d+)(.\\d+)?$ 或 ^-?([1-9]\\d*.\\d*|0.\\d*[1-9]\\d*|0?.0+|0)$\n4.2 检验字符\n汉字：^[\\u4e00-\\u9fa5]{0,}$\n英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]{4,40}$\n长度为3-20的所有字符：^.{3,20}$\n由26个英文字母组成的字符串：^[A-Za-z]+$\n由26个大写英文字母组成的字符串：^[A-Z]+$\n由26个小写英文字母组成的字符串：^[a-z]+$\n由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$\n由数字、26个英文字母或者下划线组成的字符串：^\\w+$ 或 ^\\w{3,20}$\n中文、英文、数字包括下划线：^[\\u4E00-\\u9FA5A-Za-z0-9_]+$\n中文、英文、数字但不包括下划线等符号：^[\\u4E00-\\u9FA5A-Za-z0-9]+$ 或 ^[\\u4E00-\\u9FA5A-Za-z0-9]{2,20}$\n可以输入含有^%\u0026amp;\u0026rsquo;,;=?$\u0026quot;等字符：[^%\u0026amp;\u0026rsquo;,;=?$\\x22]+ 12 禁止输入含有~的字符：[^~\\x22]+\n文件描述符与输出重定向 1 bash your_script.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026gt;操作符将标准输出重定向到/dev/null，2\u0026gt;\u0026amp;1将标准错误重定向到与标准输出相同的位置，也就是/dev/null，这样就会丢弃所有的输出。\n0: 标准输入；1: 标准输出; 2: 标准错误输出; 3及以上: 非默认动态创建。\u0026amp;用于将输出重定向到文件描述符，而不是文件。\nservice与systemctl的区别与联系 RHEL 5/6系统，使用service命令来管理系统服务\nRHEL 7/8系统，使用systemctl命令来管理服务\n1 systemctl start|restart|stop|reload|status httpd Bash与Shell的关系 Shell是接受用户指令，然后将指令交给系统执行的软件的统称，Bash是其中一种解释器，Bash是Sell的子集。\nLinux系统与Linux内核 Linux内核：控制计算机系统的所有软件和硬件，在必要时分配硬件。并根据需要执行软件。主要有四种功能：内存管理、软件程序管理、硬件设备管理、文件系统管理。\nLinux系统：OS是\nps命令 参数 作用 -a 显示所有进程（包括其他用户进程） -u 显示详细信息（用户信息等） -x 显示没有控制终端的进程 进程状态：\nR（运行）：进程正在运行或在运行队列中等待。\nS（中断）：进程处于休眠中，当某个条件形成后或者接收到信号时，则脱离该状态。\nD（不可中断）：进程不响应系统异步信号，即便用kill命令也不能将其中断。\nZ（僵死）：进程已经终止，但进程描述符依然存在, 直到父进程调用wait4()系统函数后将进程释放。\nT（停止）：进程收到停止信号后停止运行。\n除了上面5种常见的进程状态，还有可能是高优先级（\u0026lt;）、低优先级（N）、被锁进内存（L）、包含子进程（s）以及多线程（l）\n这5种补充形式。\nnice命令 调整进程优先级。格式 nice \u0026lt;优先级Num\u0026gt; \u0026lt;服务名称\u0026gt;\n在top命令输出的结果中，PR和NI值代表的是进程的优先级（取值范围是-20～19），数字越低，优先级越高。\n例如，将bash服务的优先级调至最高\n1 nice -20 bash pidof命令 查询指定服务进程的PID。格式：pidof \u0026lt;服务名|sshd\u0026gt;\n转义字符 参数存在空格，但需要作为一个参数传递：双引号\n双引号中的某些字符需要转义：反斜杠\n不希望出现转义：单引号\n4个最常用的转义字符如下所示：\n反斜杠（\\）：使反斜杠后面的一个变量变为单纯的字符。\n单引号（\u0026rsquo; \u0026lsquo;）：转义其中所有的变量为单纯的字符串。\n双引号（\u0026quot; \u0026ldquo;）：保留其中的变量属性，不进行转义处理。\n反引号（ ）：把其中的命令执行后返回结果。\nShell脚本参数说明 以example.sh one two three命令举例：\n$#: 参数的数量, 示例中值为3\n$*: 所有参数的值（空格分隔），示例中值为\u0026quot;one two three\u0026rdquo;\n$?: 上一次命令的返回值(交互式模式比较常用)\n$0: 脚本文件名, 示例中值为\u0026quot;example.sh\u0026quot;\n$1: 第一个参数, 示例中值为\u0026quot;one\u0026quot;\n$2: 第二个参数, 示例中值为\u0026quot;two\u0026quot;\nShell脚本控制语句 判断语句 类型 操作符 说明 文件判断 -e true: 文件存在 -d true: 目录类型 -f true: 一般文件 -r true: 文件可读 -w true: 文件可写 -x true: 文件可执行 逻辑判断 \u0026amp;\u0026amp; 与：成功才会执行后语句 || 或：失败才会执行后语句 ! 非： ! 非： 数值判断 -eq 等于 -ne 不等于 -gt 大于 -lt 小于 -le 小于等于 -ge 大于等于 字符判断 = 字符串相同 = 字符串不同 -z 字符串为空 交互式 判断当前用户，root用户打印”administer“；普通用户打印”user“ 1 [ ! $USER = root ] \u0026amp;\u0026amp; echo \u0026#34;user\u0026#34; || echo \u0026#34;root\u0026#34; 对($USER = root)的结果取反，即，当用户不为root时，打印user（前语句成功，才执行\u0026amp;\u0026amp;后语句）；当用户为root时，打印root(前语句echo user失败, 执行||语句)\n等同于[ $USER = root ] \u0026amp;\u0026amp; echo \u0026quot;root\u0026quot; || echo \u0026quot;user\u0026quot;\n查看内存可用量，如果\u0026lt;1024M，则打印\u0026quot;内存不足\u0026quot; 1 2 3 FreeM=`free -m | grep \u0026#39;Mem:\u0026#39; | awk \u0026#39;{print $4}\u0026#39;` [FreeM -lt 1024] \u0026amp;\u0026amp; echo \u0026#34;low memory\u0026#34; 批处理 格式\n单分支：\n1 2 3 4 if [条件] then echo \u0026#34;True echo\u0026#34; fi 双分支：\n1 2 3 4 5 6 if [条件] then echo \u0026#34;True\u0026#34; else echo \u0026#34;False\u0026#34; fi 多分支：\n1 2 3 4 5 6 7 8 if [条件A] then echo \u0026#34;条件A is True\u0026#34; elif [条件B] echo \u0026#34;条件B is True\u0026#34; else echo \u0026#34;条件A \u0026amp; 条件B is False\u0026#34; fi 判断主机是否在线\n1 2 3 4 5 6 7 8 ping -c 3 -i 0.2 -w 3 $1 \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 if [ $? -eq 0] then echo \u0026#34;$1 is OnLine\u0026#34; else echo \u0026#34;$1 is OffLine\u0026#34; fi ping 发送3个数据包，间隔0.2秒，超时时间3秒，目标IP从脚本第一个参数获得，并丢弃标准输出和错误输出（也可写省略写法 ping xxx \u0026amp;\u0026gt; /dev/null）\n判断上面ping命令的执行结果，等于0意味着，ping命令执行成功，服务可达；不等于0意味着，ping命令失败，服务不可达。\nfor循环 格式\n1 2 3 4 for i in $取值列表 do echo $i done while循环 死循环，可通过exit，在合适的实际退出死循环。\n格式\n1 2 3 4 while [条件] do echo ”“ done case语句 1 2 3 4 5 6 7 8 9 10 case 变量 in 模式1) echo \u0026#34;变量 in 模式1\u0026#34; ;; 模式2) echo \u0026#34;变量 in 模式1\u0026#34; ;; *) echo \u0026#34;Default\u0026#34; esac 周期任务 语法分 时 日 月 星期 命令 时间间隔*/2 时间范围，一种：1-3；另一种1,2,3 注意事项\n文件目录必须写绝对路径 分字段必须有数值，不能为空或者* 日、星期字段不能同时使用 ","description":"","id":10,"section":"posts","tags":["Linux","bash"],"title":"Linux-面试速记-bash脚本","uri":"https://hex-go.github.io/posts/interview/2024-04-15-linux-%E9%9D%A2%E8%AF%95%E9%80%9F%E8%AE%B0-bash%E8%84%9A%E6%9C%AC/"},{"content":"有哪些数据类型？ 类型 说明 语法 空值 None 整型(int) 5 -10 浮点型(float) 3.14 -0.5 字符串(str) \u0026ldquo;world\u0026rdquo; \u0026lsquo;hello\u0026rsquo; 布尔(bool) True False 列表(list) 有序集合 [1,1,3] [\u0026lsquo;a\u0026rsquo;, \u0026lsquo;b\u0026rsquo;] 元组(tuple) 不可变有序集合 (1,1,3) (\u0026lsquo;a\u0026rsquo;, \u0026lsquo;b\u0026rsquo;) 集合(set) 无序、唯一元素集合 {1,2,3}, {\u0026lsquo;a\u0026rsquo;,\u0026lsquo;b\u0026rsquo;} 字典(dict) 键值对集合 {\u0026rsquo;name\u0026rsquo;: \u0026lsquo;hex\u0026rsquo;, \u0026lsquo;age\u0026rsquo;: 18} 列表与元组的区别？ 列表ke\n使用场景：\nPython如何实现 Python哪些数据类型是线程安全的？ 基本数据类型（如整数、浮点数、布尔值等）通常是线程安全的，因为它们的操作是原子的，不会受到多线程并发操作的影响。\n复杂数据类型（如列表、字典、集合等），大部分情况下是不线程安全的，因为它们的操作可能涉及多个步骤，无法保证原子性。\nPython提供了一些线程安全的数据结构，例如：\nqueue 模块中的 Queue 类：提供了线程安全的队列实现，例如 queue.Queue 类和 queue.PriorityQueue collections 模块中的一些数据结构：例如 collections.deque 类提供了线程安全的双向队列实现 threading 模块中的 Lock 类 Python的内存管理机制(垃圾回收、内存池) ","description":"","id":11,"section":"posts","tags":["Linux","bash"],"title":"Python-面试速记-八股文","uri":"https://hex-go.github.io/posts/interview/2024-04-18-python-%E9%9D%A2%E8%AF%95%E9%80%9F%E8%AE%B0-%E5%85%AB%E8%82%A1%E6%96%87/"},{"content":"存储相关概念PV、PVC、StorageClass？ PV: 描述持久化存储数据卷（存储类型、挂载目录、远程存储服务器地址等）\nPVC: 描述Pod希望使用的持久化存储的属性（存储大小、读写权限等）\nStorageClass: 创建PV的模板，包含两方面内容：PV的属性（存储类型、大小等）；创建PV的存储插件信息（例如ceph）\nPVC与PV是如何进行绑定的？ spec字段：PV的存储大小必须满足PVC的要求； StorageClass: PV与PVC的StorageClass字段必须一样； VolumeController有哪些功能？ PersistentVolumeController: 不断监听每个PVC，如果未绑定pv,则遍历所有可用PVC与未绑定的PVC进行绑定（所谓绑定，就是将PV对象的名字填在PVC.spec.volumeName字段上） AttachDetachController: 不断检查每个Pod对应的PV,与Pod所在虚拟机的挂载情况，从而对PV执行Attach\\Detach操作。 VolumeManagerReconciler: 运行在每个节点，但独立于kubelet主循环外的Goroutine。 容器挂载持久化存储的两阶段处理 第一阶段：Attach。pod调度到节点上，当前节点的kubelet会根据Volume类型为pod创建Volume,如果是远程块存储，kubelet会调用存储接口创建远程磁盘并挂载到当前节点(/dev/sdb)。 第二阶段，Mount。kubelet格式化挂载的磁盘，并此磁盘挂载到宿主机的容器目录（/var/lib/kubelet/pods/\u0026lt;podID\u0026gt;/volumes）。 NFS较为简单，Attach的操作跳过（对于NFS来说，并无”磁盘“挂载虚拟机）\n之后，kubelet将volume目录通过CRI中的Mounts参数传递给容器运行时（如，docker）,就可以为Pod里的容器挂载持久化存储了。\n删除PV时，需要执行什么操作？ Unmount Detach StorageClass存在的意义 手动创建维护PV的工作太庞杂，因此K8S提供了自动创建PV的机制Dynamic Provisioning机制。而StorageClass就是其工作机制的核心。\n充当PV的模板，且只有StorageClass相同的PV与PVC才能绑定在一起； 指定PV的存储插件（Provisioner），当存储插件支持Dynamic Provisioning机制时，实现PV的自动创建。 LocalPath模式如何避免pv与pvc的绑定过程与Pod的调度过程冲突？ 在StorageClass的定义时，声明属性volumeBindingMode=WaitForFirstConsumer（延迟绑定），即pv与pvc的绑定延迟到pod调度之后，这样就不会与pod的调度策略冲突。\n延迟绑定为什么与Dynamic Provisioning机制冲突？ 因为Dynamic Provisioning机制会调用pvc指定的sc中的provisioner自动创建pv,一旦pv创建则固定怕node\nK8S存储方案的演进过程是？ 存储卷插件：k8s早期版本中Volume Plugins是用于提供持久化存储的主要方式，由K8S核心团队维护。\n缺点：新的存储类型、功能很难被引入和部署。\nFlexVolume: K8S-v1.8引入的一种存储插件扩展方式。外部插件以二进制文件与配置，并实现一定接口(init\\attach\\detach\\waitforattach\\isattached\\mountdevice\\unmountdevice\\mount\\unmount),kubelet通过插件在宿主机上执行接口命令。(FlexVolume仅仅是两阶段的执行者，无法管理pv的生命周期)\n缺点：1. 不支持DynamicProvisioning; 2. FlexVolume每一次对插件可执行文件的调用是独立的，mount时的上下文无法在unmount时复用。\nCSI：设计思想，**把Dynamic Provision，以及 Kubernetes 里 的一部分存储管理功能，从主干代码里剥离出来，做成了几个单独的组件。**这些组件会监听API-Server与存储相关的变化，来执行具体的存储管理动作。这些管理动作(如arrach\\mount阶段)实际是通过调用csi插件完成。\nExternal Components(由K8S社区维护): K8S项目中剥离的存储管理功能；\nDriver Register: 负责将插件注册到kubelet External Provisioner: 监听PVC对象，当PVC创建时调用CSI Controller的CreateVolume方法创建PV（公有云则调用公有云的API,）完成Provision阶段； External Attacher: 监听VolumeAttechment对象，当其创建时调用CSI Controller的ControllerPublish方法，完成对应volume的Attach阶段; 以上三个组件会作为sidecar的形式与CSI插件位于同一个Pod中\nCustom Components(CSI插件):\nCSI Identity：对外暴露插件本身的信息 CSI Controller(Master节点): 定义对 CSI Volume（对应 Kubernetes 里的 PV）的管理接口(Create\\Delete\\Attach\\Detach\\Snapshot等)，调用它的服务是 CSI Node(Node节点)：是由Kubelet的VolumeManagerReconciler 控制循环检测，并调用CSI Node的Mount完成磁盘格式化、挂载指定目录（Mount阶段）。 FlexVolume Attach(挂载虚拟机)、Mount(格式化、挂载至宿主机目录) CSI Provision(创建磁盘)、Attach 和 Mount Docker与K8S有哪几种存储类型？ Docker容器有：\nBindMount: 外部宿主机的磁盘存储到内部容器存储的映射关系。即存储位置局限在宿主机，存储介质只是物理磁盘，存储管理只有映射关系。\nVolumeMount:\nK8S容器编排存储：\n普通Volume: 只用来提供共享的存储资源，声明周期与Pod相同 PV: 生命周期与pod无关 Kubelet主循环 kubelet 主控制循环（Kubelet Sync Loop）\n设计原则：主控制循环绝对不可以被 block。\n","description":"","id":12,"section":"posts","tags":["CSI","Kubernetes","面试速记"],"title":"K8s网络CSI-面试速记","uri":"https://hex-go.github.io/posts/interview/2024-04-15-k8s-%E9%9D%A2%E8%AF%95%E9%80%9F%E8%AE%B0-%E5%AD%98%E5%82%A8csi/"},{"content":"在此之前使用网桥的方案进行网络配置，实现局域网同网段访问WSL内服务的访问。\n但最近一年左右，Windows11 出了一个更加优雅的新解决方案：“镜像网络”，利用了 Hyper-V 虚拟交换机的镜像端口技术。\n随着此次更新，WSL2 2.0版本有以下功能更新：\n自动回收空闲内存 自动回收虚拟硬盘空间 镜像网络 DNS 代理隧道 Windows 系统防火墙集成 Windows 代理设置集成\n这些功能极大的方便了对子系统服务发现和暴露管理，深度优化了在子系统进行网络开发方向的体验。 镜像网络和桥接网络，两个方案都具有无需关注端口转发，仅需关注更宏观的路由规则及防火墙设置的优势。\n版本说明 1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; wsl -v WSL 版本： 2.1.0.0 内核版本： 5.15.137.3-1 WSLg 版本： 1.0.59 MSRDC 版本： 1.2.4677 Direct3D 版本： 1.611.1-81528511 DXCore 版本： 10.0.25131.1002-220531-1700.rs-onecore-base2-hyp Windows 版本： 10.0.22631.3296 \u0026gt; wsl -l -v NAME STATE VERSION * Ubuntu-22.04 Running 2 wsl更新 Windows 11 23H2 ++\n1 wsl --update --pre-release 配置网卡路由规则、防火墙规则 允许外部路由设备进站到 WSLg/WSL2 子系统 Hyper-V默认防火墙规则会阻挡同一局域网的访问请求，参考此链接解决\n管理员权限在PowerShell窗口执行下面命令，修改Hyper-V防火墙规则，允许入站请求：\n1 Set-NetFirewallHyperVVMSetting -NXXame \u0026#39;{40E0AC32-46A5-438A-A0B2-2B479E8F2E90}\u0026#39; -DefaultInboundAction Allow 允许 WSLg/WSL2 虚拟交换机进行路由转发，主要是一些极特殊环境会用到 好像每次重启都会失效(因此重启后需要再次配置)，但是我们可以把它编写成“PowerShell 脚本”放到“本地组策略”里，实现开机自动重新配置\n本地组策略 -\u0026gt; 计算机策略 - Windows 设置 -\u0026gt; 脚本(启动/关机)\n1 2 3 Get-NetIPInterface | Where-Object {$_.InterfaceAlias -match \u0026#34;^vEthernet\\s.*(Default Switch|WSL|WSLCore|LAN).*$\u0026#34;} | Set-NetIPInterface -Forwarding Enabled -ErrorAction SilentlyContinue 防火墙放行WSL的出入站规则（没用-未设置）\n1 New-NetFirewallRule -WSL-mirror\u0026#34; -Direction Inbound -InterfaceAlias \u0026#34;vEthernet (Default Switch)\u0026#34; -Action Allow 配置~\\.wslconfig 此代码块用于创建或打开配置文件 ~.wslconfig hostAddressLoopback是实验性功能。\n默认情况下，在wsl2中开启的网络端口，会通过localhost映射到win11上，在win11宿主机通过localhost访问，但是无法通过宿主机的局域网、公网IP访问。\n当这个选项设置为true之后，就会允许wsl与宿主机通过局域网、公网IP(仅支持分配给主机的 IPv4 地址)访问两者之间的服务，且保留了localhost访问的能力。\n1 2 3 if (-not (Test-Path -Path \u0026#34;~/.wslconfig\u0026#34;)) { New-Item -ItemType File ~/.wslconfig } pushd ~ ; code .wslconfig 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 推荐的一些配置项如下 [wsl2] # 核心配置 autoProxy=false # 是否强制WSL使用 Windows 代理设置（按需启用） dnsTunneling=true # WSL DNS 代理隧道，以便由 Windows 代理转发 DNS 请求（按需启用） firewall=true #WSL的 Windows 防火墙集成，以便 Hyper-V 或者 WPF 能过滤子系统流量（按需启用） guiApplications=true # 启用 WSLg GUI 图形化程序支持 ipv6=true # 启用 IPv6 网络支持 localhostForwarding=true # 启用 localhost 网络转发支持 memory=4GB # 限制WSL的最大内存占用 nestedVirtualization=true # 启用WSL嵌套虚拟化功能支持 networkingMode=mirrored # 启用镜像网络特性支持 #pageReporting=true # 启用WSL页面文件通报，以便 Windows 回收已分配但未使用的内存 processors=8 # 设置WSL的逻辑 CPU 核心数为 8（最大肯定没法超过硬件的物理逻辑核心数） [experimental] # 实验性功能 autoMemoryReclaim=gradual # 启用空闲内存自动缓慢回收 hostAddressLoopback=true # 启用WSL和 Windows 宿主之间的本地回环互通支持 sparseVhd=true # 启用WSL虚拟硬盘空间自动回收 useWindowsDnsCache=false # 和 dnsTunneling 配合使用，决定是否使用 Windows DNS 缓存池 配置/etc/wsl.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 此配置文件不能通过 cd /etc \u0026amp;\u0026amp; ln -Ps /mnt/d/Devs/WSL/wsl.conf wsl.conf 来配置，只能通过拷贝副本 # https://docs.microsoft.com/en-us/windows/wsl/wsl-config [automount] enabled=true mountFsTab=true options=\u0026#34;metadata,dmask=0022,fmask=0077,umask=0022\u0026#34; root=/mnt/ [filesystem] umask=0022 [interop] enabled=true appendWindowsPath=false # 不添加 Windows 环境变量 Path，防止路径变量污染带来的干扰 # 其它网络配置 [network] generateHosts=true generateResolvConf=true # boot command 暂不支持 nohup 后台启动 # command=nohup service cron start \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp; [boot] # command=/root/.start.sh systemd=true 重启WSL 1 wsl --shutdown ; wsl 测试\n1 2 3 4 5 6 7 # 查询子系统的 IP Address 地址 # 你将能看到一组和 Windows 宿主一致的双栈 IPv4/IPv6 地址及 MAC 地址 # Just enjoy it! ip address show eth0 # 你可以使用 python 临时启动一个 Web 服务器测试网络连通性 python3 -m http.server -d . -b 0.0.0.0 54321 WSL镜像网络，宿主机无法访问Docker容器问题 镜像网络，win11宿主机无法访问wsl中的容器\n问题分析：\n当启用镜像网络后，本地主机转发的行为与之前的有所不同\n1 2 3 4 5 6 7 8 9 windows ---\u0026gt; linux(WSL) ---\u0026gt; Docker container localhostforwarding (until) ok 127.0.0.1 ---\u0026gt; 127.0.0.1(lo) / 172.x.x.1(br-xxx) ---\u0026gt; 172.x.x.x(eth0) ok 127.0.0.1 \u0026lt;--- 127.0.0.1(lo) / 172.x.x.1(br-xxx) \u0026lt;--- 172.x.x.x(eth0) netowrkingMode=mirrored ok 127.0.0.1 ---\u0026gt; 127.0.0.1(loopback0)/127.0.0.1(br-xxxx) ---\u0026gt; 172.x.x.x(eth0) ~~~~~~~~~ ng \u0026lt;- - - 172.x.x.x(eth0) 本地转发设置（默认）：源地址（Win11）是 docker 网络网关（=指向 linux）。\n镜像网络设置：源地址是127.0.0.1，因此，数据包会返回到127.0.0.1（wsl上的localhost），而不会到达 Win11。如果从另一个主机访问，则没有问题，因为源地址就是他的IP地址。\n方案一(简单粗暴) 禁用 iptables，使用userland-proxy(用户空间代理)\n禁用iptables后的数据流：\n本地转发（默认）：\n1 2 3 windows ---\u0026gt; linux(WSL) ok 127.0.0.1 ---\u0026gt; 127.0.0.1(lo) ok 127.0.0.1 \u0026lt;--- 127.0.0.1(lo) 镜像流量\n1 2 3 windows ---\u0026gt; linux(WSL) ok 127.0.0.1 ---\u0026gt; 127.0.0.1(loopback0) ok 127.0.0.1 \u0026lt;--- 127.0.0.1(loopback0) userland-proxy 是一种在 Docker 容器与外部网络之间进行端口转发的机制，它直接在用户空间进行网络数据包的处理，而不依赖于 iptables。\n缺点：\n性能很差，数据包在内核空间、用户空间之间切换传递。 安全性差，无法对数据包进行过滤、转发、Nat等操作。 功能受限，不支持端口映射、网络隔离等功能。\n总之，iptables禁用后，类似于所有容器启动默认设置--network=host,几个容器的简单使用可以，但影响复杂场景的使用(比如端口复用)。 在/etc/docker/daemon.json中增加以下内容\n1 2 3 { \u0026#34;iptables\u0026#34;: false } 并重启docker服务\n1 service docker restart 方案二\n增加iptables规则，在PREROUTING阶段对来自loopback0接口且目的地址为127.0.0.1的数据包进行DNAT，将目的地址转换为127.0.0.1。添加此链目的是破坏PREROUTING钩子，并禁用PREROUTING链中设置的所有 Docker 规则。 https://gist.github.com/shigenobuokamoto/b565d468541fc8be7d7d76a0434496a0\n以上两方案都是临时手段，仍等待后续官方解决方案。\n详情请见issue\n参考连接 https://learn.microsoft.com/zh-cn/windows/wsl/wsl-config#configuration-settings-for-wslconfig\nhttps://blog.gazer.win/essay/wsl2-mirrored-network.html\nhttps://github.com/microsoft/WSL/issues/10494\n","description":"","id":13,"section":"posts","tags":["WSL"],"title":"WSL网络配置-镜像网络","uri":"https://hex-go.github.io/posts/golang/2020-05-25-go-modules%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%92%8C%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/"},{"content":"重要 开发或者局域网内部服务，有时候需要模拟 https 环境。使用来自真实证书颁发机构 (CA) 的证书进行开发存在私钥泄露的风险，而且不对公网暴露的服务，也没必要申请真实证书，增加成本。因此最好的解决方案是管理在自己的CA。\n一般都是自签证书，然后在 http server 中使用自签证书。并且为了解决浏览器信任问题，需要将自签证书使用的 CA 证书添加到系统或浏览器的可信 CA 证书中。 上述过程需要操作繁琐的openssl命令实现自签证书，且需要手动信任CA。对本地开发和局域网不那么友好。本文将介绍mkcert，可简化这一过程。\nmkcert简介 mkcert是一个go语言编写的小工具，可自动在系统根存储中创建和安装本地 CA，并生成本地信任的证书。可跨平台，配置简单。\n安装 自行下载，选择合适安装包进行安装 https://github.com/FiloSottile/mkcert/releases/latest\n使用 建议以管理员运行mkcert\n生成本地CA、并导入系统根存储 1 mkcert -install mkcert 支持以下根存储：\nmacOS 系统存储 Windows 系统存储 Linux update-ca-trust （Fedora、RHEL、CentOS） update-ca-certificates （Ubuntu、Debian、OpenSUSE、SLES） trust（Arch） 火狐浏览器（仅限 macOS 和 Linux） Chrome 和 Chromium Java（需要设置JAVA_HOME） 生成证书 1 mkcert example.com \u0026#34;*.example.com\u0026#34; example.test localhost 127.0.0.1 ::1 本地开发使用 创建CA及CA私钥文件，并安装至本机 1 mkcert -install 按需生成服务证书（域名、IP、通配符） 此命令执行后，返回会显示所生成证书的存储路径\n1 mkcert example.com \u0026#34;*.example.com\u0026#34; example.test localhost 127.0.0.1 ::1 将第二步生成的证书与私钥配置给服务，tls\n此处只需要第2步生成的服务证书文件+服务证书私钥。 此时本机访问服务将不会出现问题，如需要解决其他机器此服务，证书不合法问题，再执行第四步\n解决其他主机访问证书不合法问题 1 2 3 4 5 6 7 # 1. 将第一步生成的ca文件（rootCA.pem）拷贝至当前需要配置的机器 # 注意只需要rootCA.pem文件，一定不能将私钥随意拷贝 # 2. 声明变量， export CAROOT=/xxx/rootCA.pem # 3. 执行命令，本机证书导入rootStore mkcert -install 局域网 主机（mac/linux/windows） + k8s_ingress\n根CA生成与管理 建议公司只生成一个根CA，并由公司QA进行管理，尤其是rootCA-key.pem不可泄露\n执行命令\n1 mkcert install 将生成的根CA证书提供给cert-manager 通过mkcert -CAROOT命令打印CA证书rootCA.pem的目录 根据证书及其私钥，创建ClusterIssuer(CertManager的CR) k8s集群可通过挂载cert-manager生成的证书，从而实现以下能力\nk8s对外暴露ingress tls加密 服务之间加密通信 服务之间，基于证书签名、验签机制实现服务认证。 开发、测试、演示机器配置免密访问\n将ca文件rootCA.pem拷贝至需要配置的机器，执行以下命令实现配置\n1 2 3 4 # 声明变量， export CAROOT=/xxx/rootCA.pem # 执行命令，本机证书导入rootStore mkcert -install 其他场景 a. 关于CA a.1 生成CA的存储路径 可通过mkcert -CAROOT命令打印CA证书rootCA.pem与私钥rootCA-key.pem的目录，注意私钥妥善保存\na.2 导入已有CA,而不重新生成CA 通过mkcert -CAROOT命令查找rootCA.pem文件\n复制到需要配置的机器\n将设置CAROOT指向证书文件\n执行mkcert -install\n将ca文件（rootCA.pem）拷贝至当前需要配置的机器，执行下面命令\n1 2 3 export CAROOT=/xxx/rootCA.pem mkcert -install 输出\n1 2 3 Created a new local CA 💥 The local CA is now installed in the system trust store! ⚡️ The local CA is now installed in the Firefox trust store (requires browser restart)! 🦊 a.3 只导入指定的rootStore 默认导入所有支持的根存储，也可以通过环境变量TRUST_STORES，指定只导入指定的root store。选项包括\u0026quot;system\u0026quot;、\u0026ldquo;java \u0026ldquo;和 \u0026ldquo;nss\u0026rdquo;\n1 2 export TRUST_STORES=system,java,nss mkcert -install b. 关于证书 b.1 根据CSR文件生成证书 mkcert通过创建csr的能力，但提供根据csr创建证书的能力。这样可以避免服务私钥与CA私钥共同持有的安全隐患。\n使用 OpenSSL 创建证书签名请求\n1 openssl req -out example.csr -new -newkey rsa:4096 -nodes -keyout example.pem -subj \u0026#34;/C=US/ST=College Station/L=Texas/O=Home/OU=lab/CN=*.apps.svc.com\u0026#34; 上面命令会创建以下文件:\nexample.csr - 证书签名请求csr文件. example.pem - 此csr相关的私钥文件.\n利用mkcert, 根据csr文件提供的信息，创建相应证书 1 mkcert -csr example.csr 输出为\n1 2 3 4 5 Created a new certificate valid for the following names - \u0026#34;*.apps.svc.com\u0026#34; Reminder: X.569 wildcards only go one level deep，so this won\u0026#39;t match a.b.apps.svc.com The _ certificate is at \u0026#34;./_wildcard.apps.svc.com.pem\u0026#34; It will expire on 19 January 2026 b.2 生成pk12格式证书 -pkcs12命令可以产生PKCS12格式的证书。java 程序通常不支持PEM格式的证书，但是支持PKCS12格式的证书。\n1 mkcert -pkcs12 localhost 127.0.0.1 输出示例，默认密码为\n1 2 3 4 5 6 7 8 9 10 11 Note: the local CA is not installed in the Java trust store. Run “mkcert -install\u0026#34; for certificates to be trusted automtically Created a new certificate valid for the following names - \u0026#34;Localhost\u0026#34; - \u0026#34;127.0.0.1\u0026#34; The PKCS#12 bundle is at \u0026#34;./localhost+1.p12\u0026#34; The legacy PKCS#12 encryption password is the often hardcoded default \u0026#34;changeit\u0026#34; It will expire on 15 April 2026 c. 关于证书信任 c.1 设置nodejs证书信任 Node 不使用系统根存储，因此不会自动信任mkcert证书。必须设置 NODE_EXTRA_CA_CERTS 环境变量。\n1 export NODE_EXTRA_CA_CERTS=\u0026#34;$(mkcert -CAROOT)/rootCA.pem\u0026#34; Reference 概念说明\nmkcert 源码仓库\n","description":"","id":14,"section":"posts","tags":["Devops","证书","PKI","Mkcert"],"title":"mkcert-本地、局域网自签证书解决https访问问题","uri":"https://hex-go.github.io/posts/devops/2024-03-14-mkcert-%E6%9C%AC%E5%9C%B0%E5%92%8C%E5%B1%80%E5%9F%9F%E7%BD%91%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E8%A7%A3%E5%86%B3https%E8%AE%BF%E9%97%AE%E9%97%AE%E9%A2%98/"},{"content":"1.简介 容器在主机内核上运行，从内核中获取时钟，但时区并非来自内核，而是来自用户空间。因此，在大多数情况下，它们默认使用UTC时间。虽然代码处理时间时可以考虑时区信息从而避免时区问题带来的错误，但容器日志和系统日志信息中的时间显示会影响问题定位与解决。而且有些应用程序将机器的时区作为默认时区，并希望用户设置时区。本文将系统的说明时区问题，以及解决时区问题的几种配置方法。不过，在解决方案之前，我们先来了解一下问题所在。\n2.时区说明 2.1 时区信息格式 在大多数 UNIX 系统中，不同的时区由时区信息格式（ Time Zone Information Format）定义。这是 20 世纪 80 年代推出的一种二进制文件格式。这些文件可以在IANA 时区数据库中找到（通常位于/usr/share/zoneinfo）。在大多数发行版中，这些文件都是作为发行版的一部分，默认安装。\n对于容器基础镜像而言，大部分基础镜像（Ubuntu/Debian/alpine）默认情况下并不包含这个软件包，因此需要手动安装：\n1 2 3 4 5 # debian/ubuntu apt-get install tzdata # alpine apk add tzdata # centos/fedora的基本镜像默认安装了 tzdata 软件包 2.2 如何指定时区 但仅有这些文件还不够，我们还需要在主机（或容器）中指定所需的时区。有两种方法：\n/etc/timezone文件：只有Ubuntu/debian生效，不具备通用性，不建议使用。\n2.2.1 /etc/localtime文件 /etc/localtime文件配置本地系统的全系统时区。它通常是一个指向/usr/share/zoneinfo的软链接，后面跟一个时区数据库名称，如 \u0026ldquo;Asia/Shanghai\u0026rdquo;（即 /usr/share/zoneinfo/Asia/Shanghai）。\n1 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 2.2.2 TZ 环境变量 优先级更高\n将TZ环境变量设置为时区标识符（如 TZ=Asia/Shanghai）来设置时区，通常只在程序所需时区与主机时区不同的情况下进行设置。它的优先级比/etc/localtime更高。\n1 export TZ=Asia/Shanghai 3.配置方法 以alpine:3.19.1镜像举例说明\n通过运行下面命令\n1 docker run --rm -i alpine:3.19.1 date 输出为\n1 Wed Mar 13 06:06:18 UTC 2024 可以看出，alpine:3.19.1镜像时区为UTC。Alpine基础镜像默认不包含/usr/share/zoneinfo或/etc/localtime，正如上面对时区实现的说明，这些都是设置容器时区所必需的。\n3.1 构建镜像时配置 可以在镜像构建时，安装tzdata软件包，并设置TZ环境变量来完成时区设置。具体Dockerfile内容如下：\n1 2 3 4 5 6 7 8 9 FROM alpine:3.19.1 ENV TZ=Asia/Shanghai # 国内源加速 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN apk upgrade --update \\ \u0026amp;\u0026amp; apk add -U tzdata 如果以后时区都不需要更改，且想精简镜像体积。可以使用下面的Dockerfile\n安装 tzdata 软件包 复制需要的时区信息（例如，/usr/share/zoneinfo/Asia/Shanghai） 卸载 tzdata 软件包 重新创建文件夹 /usr/share/zoneinfo/Asia/（因为卸载会删除该文件夹） 将之前复制的文件放回该目录 设置时区。可通过TZ环境变量；也可通过/etc/localtime 软连接。 1 2 3 4 5 6 7 8 9 10 11 12 13 FROM alpine:3.19.1 ENV TZ=Asia/Shanghai # 国内源加速 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN \\ apk add tzdata \u0026amp;\u0026amp; \\ cp /usr/share/zoneinfo/Asia/Shanghai /tmp \u0026amp;\u0026amp; \\ apk del tzdata \u0026amp;\u0026amp; \\ mkdir -p /usr/share/zoneinfo/Asia/ \u0026amp;\u0026amp; \\ mv /tmp/Shanghai /usr/share/zoneinfo/Asia/ 或\n1 2 3 4 5 6 7 8 9 10 11 12 FROM alpine:3.19.1 # 国内源加速 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN \\ apk add tzdata \u0026amp;\u0026amp; \\ cp /usr/share/zoneinfo/Asia/Shanghai /tmp \u0026amp;\u0026amp; \\ apk del tzdata \u0026amp;\u0026amp; \\ mkdir -p /usr/share/zoneinfo/Asia/ \u0026amp;\u0026amp; \\ mv /tmp/Shanghai /usr/share/zoneinfo/Asia/ \u0026amp;\u0026amp; \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 缺点：\n并非所有镜像都有包管理器，有些镜像只是FROM scratch 要为所有镜像（尤其是一些不重新构建的中间件镜像）维护一个 Dockerfile，增加复杂性 需要在构建时就确定时区 3.2 容器运行时配置 除了在构建时安装 tzdata 软件包，还可以在容器运行时，从宿主机上加载所需的时区文件，例如：\n1 docker run -v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime -i --rm alpine:3.19.1 date 使用 -v 将主机上的TZif文件直接挂载到容器的/etc/localtime，从而解决了容器时区问题。\n如果容器后续需要修改其他时区，建议挂在整个/usr/share/zoneinfo目录\n缺点：\n提高了运维人员的维护成本，容易出现人为失误 需要提前确定，主机是否安装tzdata 3.3 Pod中手动设置 使用hostPath将K8S节点上的时区文件挂载至容器中。创建tz-test.yaml文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 apiVersion: v1 kind: Pod metadata: name: tz-test spec: containers: - image: alpine:3.19.1 name: tz-test args: - date volumeMounts: - name: zoneinfo mountPath: /etc/localtime subPath: Asia/Shanghai readOnly: true volumes: - name: zoneinfo hostPath: path: /usr/share/zoneinfo restartPolicy: OnFailure 缺点：\n手动操作，维护成本高 无法保证集群中的所有节点都安装了 tzdata hostPath权限问题，且有安全隐患 如果使用helm chart，则需要定制化修改 3.4 通过k8tz管理 k8tz 可以将时区注入Pod和CronJobs ，只需极少的工作就能在 pod 和命名空间中自动标准化选定的时区。它可以作为手动工具，在本地自动转换部署yaml和 Pod；也可以作为准入控制器，使用annotations为创建的任何 Pod 完全自动执行流程。\nk8tz不使用hostPath，而是分配emptyDir，并注入initContainer，用 TZif 文件填充卷。然后，使用emptyDir将/etc/localtime和/usr/share/zoneinfo挂载到Pod中的每个容器。为了确保所需的时区有效，它会在所有容器中添加TZ环境变量。\n3.4.1 安装 1 2 helm repo add k8tz https://k8tz.github.io/k8tz/ helm install k8tz k8tz/k8tz --set timezone=Asia/Shanghai 运行下面命令测试：\n1 kubectl run -it ubuntu --image=alpine:3.19.1 --restart=OnFailure --rm=true --command date 3.4.2 配置 安装时全局设置 1 helm install k8tz k8tz/k8tz --set timezone=Asia/Shanghai 通过Pod注解设置 1 kubectl run -it ubuntu --image=alpine:3.19.1 --restart=OnFailure --rm=true --command date --annotations k8tz.io/timezone=Asia/Shanghai 通过Namespace注解设置(与Pod相同) 3.4.3 注解说明 Controller的行为可通过 Pod、Namespace对象上的注解进行控制。如果在两个对象中指定了相同的注解，则Pod 优先级更高。\nAnnotation 描述 默认值 k8tz.io/inject k8tz 是否注入时区 true k8tz.io/timezone 决定设置哪个时区, e.g: Asia/Shanghai UTC k8tz.io/strategy 决定使注入策略, i.e: hostPath/initContainer initContainer 缺点：\n如果容器下集群，通过docker运行时，运维人员容易失误，遗漏时区设置 4. 总结 由于国内时区不需要频繁修改，建议需要重新构建的镜像在基础镜像中将时区配置正确；k8s集群中部署k8tz，解决中间件时区设置问题；docker-run运行的中间件，单独维护，并将运行脚本版本化控制。\n5.参考 k8tz/k8tz: Kubernetes admission controller and a CLI tool to inject timezones into Pods and CronJobs (github.com)\n","description":"理解容器时区问题的根源及常见解决方法：镜像构建时配置、容器运行命令时配置、Pod通过hostPath挂载解决、k8tz解决","id":15,"section":"posts","tags":["Kubernetes","k8tz","Timezone"],"title":"理解容器时区问题的根源及常见解决方法","uri":"https://hex-go.github.io/posts/kubernetes/2024-03-13-%E7%90%86%E8%A7%A3%E5%AE%B9%E5%99%A8%E6%97%B6%E5%8C%BA%E9%97%AE%E9%A2%98%E7%9A%84%E6%A0%B9%E6%BA%90%E5%8F%8A%E5%B8%B8%E8%A7%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"content":"1.问题描述 开发同事编写Dockerfile时遇到问题，ENTRYPOINT [\u0026quot;java\u0026quot;, \u0026quot;$JAVA_OPTS\u0026quot;, \u0026quot;-jar\u0026quot;, \u0026quot;/app.jar\u0026quot;]无法实现变量替换。自己工作中涉及变量替换等操作时，都是将shell命令放到可执行文件中，虽然对同事的这种写法奇怪，但当时也确实没发现错误的原因，深入了解过EXEC格式后，吃透了这个问题。\n2.说明 Dockerfile中的ENTRYPOINT\\RUN\\CMD具备两种格式：EXEC格式和SHELL格式。\n2.1 exec格式： 示例：\nENTRYPOINT [\u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;/start.sh\u0026quot;]，\n实现：\n直接使用命令本身来执行，不需要通过Shell解释器。实际程序PID=1，可以接收、处理信号，实现优雅启停。\n优点：\n高效 安全 缺点：\n不能使用Shell语法，灵活性差 2.2 shell格式: 写法示例：\n1 2 3 4 5 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y --no-install-recommends \\ package-A \\ package-B \\ package-C \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* 实现：\n此格式是使用Shell解释器来执行命令，最终程序被执行时，类似于/bin/sh -c的方式运行了我们的程序，这样会导致/bin/sh以PID为1的进程运行，\n而实际程序是它fork/execs出来的子进程。\n优点：\n可以使用Shell语法，例如管道、重定向等，这增加了Dockerfile的灵活性；\n缺点：\nsh父进程带来额外开销； 存在安全隐患，如shell注入攻击； 无法实现优雅启停，docker stop的SIGTERM信号只是发送给容器中PID为1的进程，无法传递给子进程，实际进程实际程序无法接收、处理信号； 3.解决 想要在EXEC格式的ENTRYPOINT中引用环境变量，需要编写shell脚本。在脚本中，变量替换与反斜线转义都是生效的。然后ENTRYPOINT使用exec格式执行。\n即脚本/start.sh内容为\n1 java $JAVA_OPTS -jar /app.jar Dockerfile中的内容为\n1 ENTRYPOINT [\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;/start.sh\u0026#34;] 也可以通过 ENTRYPOINT [\u0026quot;/bin/sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;java $JAVA_OPTS -jar /app.jar\u0026quot;]实现变量替换，但java进程无法接收、处理信号，不推荐\n3.总结 一般来说，除非需要 shell 功能，否则应使用exec格式；如果需要ENTRYPOINT或CMD中的 shell 功能，则应考虑编写shell脚本，然后使用exec格式执行。\nshell格式：使用Shell解释器来执行命令，更灵活但也更复杂、更容易受到攻击。\nexec格式：直接使用命令本身来执行，更简单、更高效、更安全，推荐使用。\n名称 最佳使用场景 shell功能 是否能处理信号 程序ID shell格式 RUN 支持(可引用变量、反斜线转义) 否 1进程的子进程 exec格式 ENTRYPOINT\\CMD 不支持 是(可将信号传递给程序处理，实现优雅启停) 1 4.参考 exec-form 变量替换\n优雅的终止docker容器\n关于 Dockerfile ENTRYPOINT 需要知道的一切\n","description":"","id":16,"section":"posts","tags":["Devops"],"title":"Docker易错集锦-1: Dockerfile的ENTRYPOINT中的环境变量无法替换","uri":"https://hex-go.github.io/posts/devops/2023-11-02-docker%E6%98%93%E9%94%99%E9%9B%86%E9%94%A6-1_dockerfile%E7%9A%84entrypoint%E4%B8%AD%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"content":"Canal 完美保持Flannel原生的三种模式，扩展支持Calico的BGP、IPIP模式。并且支持网络策略。\nCanal 表示使用Flannel通过VXLAN处理主机间的pod流量，使用Calico处理同一主机内的pod流量和网络策略。\nCanal项目可以理解为同时使用Calico、Flannel的最佳实践, 通过Calico CNI和Calico 网络策略与Flannel和主机本地IPAM插件相结合，以提供具有策略执行功能的 VXLAN 网络。\n同时具备了flannel与calico的能力，但相应的也存在维护两个组件的复杂度。\ncanal项目初始是为了将两者深度集成，后来发现使用canal的用户的需求只是为了让两者更好的协同，没有将两者合一的需求。因此canal项目已不维护，只停留在部署方案上。如果熟悉两个中间件，又想同时使用calico、与flannel的能力，可以考虑canal\nPolicy IPAM CNI Overlay Routing Datastore Calico Host-local Calico VXLAN Static Kubernetes 路由：static，用于路由主机之间的pod流量。静态路由通常与主机本地 IPAM 插件结合使用，后者会为每个主机静态分配一个 /24 pod IP 地址范围。\n数据持久化：Kubernetes，即通过连接api-server进行数据的修改（不需要单独的存储管理；可通过api-server的rbac进行权限管理；可通过k8s的审计功能进行审计）\n参考链接 Canal项目地址(不维护)\nCalico解决网络策略，flannel解决网络通信(canal）\n","description":"","id":17,"section":"posts","tags":["Canal","Kubernetes"],"title":"K8s网络CNI-Canal详细说明","uri":"https://hex-go.github.io/posts/kubernetes/2023-09-02-k8s%E7%BD%91%E7%BB%9Ccni-canal%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E/"},{"content":"Calico由Tigera维护，是k8s中另一个流行的开源CNI插件。适用于网络性能、灵活性和功率等因素至关重要的环境。\n与 Flannel 不同，Calico 提供先进的网络管理安全功能，同时提供主机和 pod 之间的网络连接。\n1. calico架构 组件：\n在标准的 Kubernetes 集群上，Calico 可以作为 DaemonSet 轻松部署在每个节点上。集群中的每个节点都将安装三个 Calico 组件：Felix、BIRD和用于管理多个网络任务的confd。\nFelix作为 Calico 代理处理节点路由，而BIRD和confd则管理路由配置更改。\n原理：\nCalico的设计比较新颖，Flannel的Host-Gateway模式之所以不能跨二层网络，是因为它只能修改主机的路由，Calico把改路由表的做法换成了标准的BGP路由协议。\n相当于在每个节点上模拟出一个额外的路由器，由于采用的是标准协议，Calico模拟路由器的路由表信息就可以被传播到网络的其他路由设备中，这样就实现了在三层网络上的高速跨节点网络。\n不过在现实中的网络并不总是支持BGP路由的(部分内网和公网的局部区域不支持BGP)，因此Calico也设计了一种IPIP模式，使用Overlay的方式来传输数据。IPIP的包头非常小，而且也是内置在内核中的，因此它的速度理论上比VxLAN快一点点，但安全性更差。\n或 VXLAN 可以实现覆盖网络模式，像覆盖网络一样封装跨子网发送的数据包。\nCalico BGP 协议使用未封装的 IP 网络结构，无需用封装层封装数据包，从而提高了k8s工作负载的网络性能。\n2. 流量加密 集群内的 pod 流量使用Wireguard进行加密，它可以创建和管理节点之间的隧道，提供安全的通信。\n3. Calico后端模式 Flannel的Host-Gateway模式之所以不能跨二层网络，是因为它只能修改主机的路由，Calico把改路由表的做法换成了标准的BGP路由协议。\n但带来了新的问题：部分内网和公网的局部区域不支持BGP，因此Calico的妥协机制为IPIP模式，calico也支持vxlan模式\nbackend实现方式 适用场景 优点 限制 基于哪一层 实现方式 VxLAN 普遍适用，官方推荐 性能良好，手动干预少（易部署） 与部分内核不兼容 三层网络层 使用设备flannel.0进行封包解包，不是内核原生支持，上下文切换较大，性能非常差 IPIP 测试、在比较老的不支持VXLAN的Linux内核部署 简单、兼容性好 性能差 三层网络层 使用flannel.1进行封包解包，内核原生支持 bgp 网络性能要求比较高的场景 网络性能高 对基础网络架构有要求 二层网络 无需flannel.1这样的中间设备，直接宿主机当作子网的下一跳地址，性能最强 RR 网络性能要求比较高的场景 网络性能高 对基础网络架构有要求 二层网络 无需flannel.1这样的中间设备，直接宿主机当作子网的下一跳地址，性能最强 3.1 Pod-Node通信的网络模型 Node上每有一个Pod，则会在节点上创建一个veth pair, Calico 通过一个巧妙的方法将 Pod 的所有流量引导到一个特殊的网关 169.254.1.1，从而引流到主机的 calixxx 网络设备上，最终将二三层流量全部转换成三层流量来转发。\n在主机上通过开启代理 ARP 功能来实现 ARP 应答，使得 ARP 广播被抑制在主机上，抑制了广播风暴，也不会有 ARP 表膨胀的问题。\n选取节点node1中的容器pod-a作为实验节点，进入容器pod-a查看IP地址： 172.17.8.2/32 容器IP地址为/32位的地址，表示容器是一个单点的局域网\n1 2 3 4 5 6 7 8 9 [root@pod-a-bc2sm /]$ ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 3: eth0@if771: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u0026gt; mtu 1440 qdisc noqueue state UP link/ether 66:fb:34:db:c9:b4 brd ff:ff:ff:ff:ff:ff inet 172.17.8.2/32 scope global eth0 valid_lft forever preferred_lft forever 查看容器pod-a的默认路由: 根据以下路由表信息可以知道：169.254.1.1为容器默认网关，但没有任一网卡对应此IP地址。\n当一个数据包的目的地址不是本机时，会查询路由表，从路由表查询到网关后，会通过arp获取网关的mac地址，然后在二层网络数据包中将目标mac替换为网关的mac地址。也就是说，网关IP只是为了能找到网关的mac地址，响应arp就行。\n1 2 3 [root@pod-a-bc2sm /]$ ip route default via 169.254.1.1 dev eth0 169.254.1.1 dev eth0 scope link 查看容器的arp缓存： ip neigh: 用于查看系统上的邻居表(Neighbor Table)，通常也称为ARP缓存表。这个表存储本机与其它机器或网络设备之间的关联。\n返回信息依次为: 目标设备IP地址(169.254.1.1) 与目标设备通信的网卡(dev eth0) 目标设备mac地址(lladdr ee:ee:ee:ee:ee:ee) 与目标设备通信状态(REACHABLE)\narp获取mac地址过程：内核会对外发送arp请求，询问二层网络中拥有169.254.1.1地址的mac，拥有此ip的设备会在二层网络中响应自己的mac地址。\nmac地址为calico设置的，如何响应arp：容器和主机都没有169.254.1.1IP地址，甚至连主机上的端口 calicba2f87f6bb，MAC 地址也是一个无用的 ee:ee:ee:ee:ee:ee。按道理容器和主机网络根本就无法通信,但calico采用了网卡代理arp功能。\n1 2 [root@pod-a-bc2sm /]$ ip neigh 169.254.1.1 dev eth0 lladdr ee:ee:ee:ee:ee:ee REACHABLE 代理arp 代理ARP(Proxy ARP): 是 ARP 协议的一个变种，当 ARP 请求目标跨网段时，网关设备收到此 ARP 请求，会用自己的 MAC 地址返回给请求者。\n确认宿主机开启了代理arp:\n1 2 cat /proc/sys/net/ipv4/conf/calicba2f87f6bb/proxy_arp 1 3.2 BGP Flannel host-gw方式的改进版\n边界网关协议（Border Gateway Protocol， BGP）：是互联网上一个核心的去中心化自治路由协议。BGP不使用传统的内部网关协议（IGP）的指标。\n3.3 IPIP IPIP模式(IP in IP Overlay):即在IP报文基础上，又封装了一个IP头，和VXLAN类似（但封装头更小，比vxlan理论性能稍强）\n| HostMac | HostIP | RealIP | Data |\n把 IP 层封装到IP层的一个tunnel。作用其实基本上就相当于一个基于IP层的网桥！一般来说，普通的网桥是基于mac层的，根本不需IP，\n而这个IPIP则是通过两端的路由做一个tunnel，把两个本来不通的网络通过点对点连接起来。\n以两个node上的两个容器为例，说一下报文的流动过程。\n报文从PodA(10.244.104.14)发出，根据路由发往容器中的网关169.254.1.1\n但PodA中路由信息如下(没有)：\n1 2 3 4 5 [root@pod-a-bc2sm /]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 169.254.1.1 0.0.0.0 UG 0 0 0 eth0 169.254.1.1 0.0.0.0 255.255.255.255 UH 0 0 0 eth0 查看网关通向的二层地址(mac地址)，容器中网关arp地址为ee:ee:ee:ee:ee:ee：\n1 2 3 [root@pod-a-bc2sm /]# arp -n Address HWtype HWaddress Flags Mask Iface 169.254.1.1 ether ee:ee:ee:ee:ee:ee C eth0 集群节点上执行下面命令，查看mac地址ee:ee:ee:ee:ee:ee对应的网卡\n1 2 3 4 5 6 [root@node1 /]# ifconfig | grep -E \u0026#34;flags|ether\u0026#34; cali0a4fde325ea: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1480 ether ee:ee:ee:ee:ee:ee txqueuelen 0 (Ethernet) cali43af9e40d9b: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1480 ether ee:ee:ee:ee:ee:ee txqueuelen 0 (Ethernet) ... 容器中网卡是veth的pair虚拟网卡，一端连接容器(pod-a:eth0),一端连接宿主机(node-a:cali0a4fde325ea)。因此，执行下面命令，查看容器内网卡编号：\n1 2 3 [root@pod-a-bc2sm /]# ethtool -S eth0 NIC statistics: peer_ifindex: 14 确认宿主机编号为14的网卡\n1 2 3 4 [root@node1 /]# ip link show ... 14: cali0a4fde325ea@if4: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1480 qdisc noqueue state UP mode DEFAULT link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 4 因此容器(pod-a-bc2sm)中的报文通过cali0a4fde325ea网卡到达宿主机(node1)然后根据宿主机路由，将报文发往tunl0\n3.4 Route Reflector 模式（RR）（路由反射）： Calico维护的网络在默认是（Node-to-Node Mesh）全互联模式，Calico集群中的节点之间都会相互建立连接，用于路由交换。\n但是随着集群规模的扩大，mesh模式将形成一个巨大服务网格，连接数成倍增加。这时就需要使用 Route Reflector（路由器反射）模式解决这个问题。\n4. 网络策略 Calico 的网络策略实现了拒绝/匹配规则，这些规则可通过清单应用，为 pod 分配入口策略。用户可以定义全局范围的策略，并与 Istio 服务网格集成，以控制 pod 流量、提高安全性并管理k8s的工作负载。\n5. 实验举例 待整理\n6. 总结 calico具有以下的优点：\n高性能：Calico BGP 协议使用未封装的 IP 网络结构，无需用封装层封装数据包，从而提高了k8s工作负载的网络性能。 支持流量加密：集群内pod流量使用Wireguard创建vpn进行安全的通信。 便于跟踪调试：因为不存在操纵数据包的包装器，跟踪和调试比其他工具容易得多。开发人员和管理员可以轻松了解数据包行为，并使用策略管理和访问控制列表等高级网络功能。 支持网络策略： 总之，对于希望控制网络组件的用户来说，Calico 是一个极佳的选择。Calico 可以与不同的k8s平台（如 kops、Kubespray）轻松配合使用，也可按需向Calico Enterprise获取商业支持。\n参考链接 Calico网络策略确保CNI的安全（利用 Calico 强化 Kubernetes 网络策略）\nKubernetes 网络：使用 Calico 实现高性能\nMAC地址、IP地址以及ARP协议详细讲解\n","description":"","id":18,"section":"posts","tags":["Calico","Kubernetes"],"title":"K8s网络CNI-Calico详细说明","uri":"https://hex-go.github.io/posts/kubernetes/2023-09-01-k8s%E7%BD%91%E7%BB%9Ccni-calico%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E/"},{"content":"Flannel由CoreOS开发，是k8s最成熟的开源CNI插件之一。它提供了一个开箱即用的网络模型，旨在实现更好的容器和主机间的网络。\nFlannel使用K8S集群的现有etcd集群来使用API存储其状态信息，不需要单独配置数据存储。\nFlannel通过配置一个3层的IPv4 Overlay网络来运行。该网络是一个跨越集群中每个节点的大型内部网络，在此Overlay网络中，每个节点都有一个子网，用于在内部分配IP地址。\n每个节点会运行一个flanneld的进程，负责子网租赁和管理。\n在配置Pod时，每个节点上的网桥接口都会为每个新容器分配一个地址。\n同一主机中的Pod可以使用网桥进行通信， 不同主机上的Pod会使用flanneld配置的后端其流量封装在UDP数据包中，以便路由到适当的目标。 Flannel有几种不同类型的后端可用于封装和路由。默认和推荐使用VXLAN，因为VXLAN性能更良好并且需要的手动干预更少。\n1. Flannel的后端 Flannel通过在每一个节点上启动一个叫flanneld的进程，负责每一个节点上的子网划分，并将相关配置信息（如各节点的子网网段、外部IP等）保存到etcd中，而具体的网络报文转发交给后端实现。\nflanneld启动时通过配置文件指定不同的后端进行网络通信，目前比较成熟的后端有UDP、VxLAN(Virtual Extensible Lan)和host-gateway三种。\nbackend实现方式 适用场景 优点 限制 基于哪一层 实现方式 VxLAN 普遍适用，官方推荐 性能良好，手动干预少（易部署） 与部分内核不兼容 三层网络层 使用设备flannel.0进行封包解包，不是内核原生支持，上下文切换较大，性能非常差 UDP 测试、在比较老的不支持VXLAN的Linux内核部署 简单、兼容性好 性能差 三层网络层 使用flannel.1进行封包解包，内核原生支持 host-gateway 网络性能要求比较高的场景 网络性能高 对基础网络架构有要求 二层网络 无需flannel.1这样的中间设备，直接宿主机当作子网的下一跳地址，性能最强 1.1 VxLan模式详解 VXLAN Overlay(L2 in UDP): 采用内置在Linux内核里的标准协议，因此虽然它的封包结构比UDP模式复杂，但由于所有数据装、解包过程均在内核中完成，实际的传输速度要比UDP模式快许多。\n| HostMac | HostIP | UDP | vxlan | RealMac | RealIP | Data |\nflanneld服务为无状态服务，在每个节点启动一个flanneld服务，监听端口为8472(VXLAN)，其它节点会用一个随机端口连接到目标主机的8472端口，采用UDP协议进行发布。\n如下面一条抓包数据所示：\n源 192.168.1.1节点的pod[10.42.1.2] 中去ping 目的 192.168.1.2节点的pod[10.42.2.6]，抓取源主机 192.168.1.1 的enp0s3设备的udp包：\n1 2 3 192.168.1.215.38381 \u0026gt; 192.168.1.216.8472: [bad udp cksum 0x11bc -\u0026gt; 0x6334!] OTV, flags [I] (0x08), overlay 0, instance 1 f2:60:ca:96:7f:1f \u0026gt; 4a:02:36:26:f9:c1, ethertype IPv4 (0x0800), length 74: (tos 0x0, ttl 64, id 34781, offset 0, flags [DF], proto TCP (6), length 60) 10.42.0.0.10384 \u0026gt; 10.42.1.7.443: Flags [S], cksum 0x1589 (incorrect -\u0026gt; 0x6701), seq 1841703998, win 64240, options [mss 1460,sackOK,TS val 3365946307 ecr 0,nop,wscale 7], length 0 192.168.1.1.39338 \u0026gt; 192.168.1.2.8472: UDP 数据包的源 IP 地址是 192.168.1.1，源端口号是 39338，目标 IP 地址是 192.168.1.2，目标端口号是 8472 以太网帧信息：\nf2:60:ca:96:7f:1f \u0026gt; 4a:02:36:26:f9:c1：源 MAC 地址是 f2:60:ca:96:7f:1f[192.168.1.1 enp0s3]，目标 MAC 地址是 4a:02:36:26:f9:c1[192.168.1.2 enp0s3]。 ethertype IPv4 (0x0800)：以太网帧的类型为 IPv4。 length 98：数据包的总长度为 98 字节。 最后是 IPv4 报文的信息：\n10.42.1.2.10384 \u0026gt; 10.42.2.6.443：TCP数据包的源IP地址是10.42.1.2，源端口号是10384，目标IP地址是10.42.2.6，目标端口号是443 Flags [S]：TCP 数据包的标志字段，其中 [S] 表示该数据包是一个 TCP 连接的初始 SYN 数据包。 cksum 0x1589 (incorrect -\u0026gt; 0x6701)：TCP 数据包的校验和字段，当前显示的是错误的校验和。 seq 1841703998：TCP 数据包的序列号。 win 64240：TCP 数据包的窗口大小。 1.2 UDP模式 UDP Overlay(IP in UDP): 使用了Flannel自定义的一种包头协议，数据是在Linux的用户态进行封包\\解包，因此当数据进入主机后，需要经历两次内核态到用户态的转换。\n| HostMac | HostIP | UDP | RealIP | Data |\n1.3 host-gateway模式 与前两种模式（覆盖网络）不同，host-gw采取的是主机路由的方案\n这种方案的思路是，既然在无法进行路由是因为网络中的节点之间没有路由信息，但Flannel是知道这个信息的，Flannel把这个信息告诉网络上的节点\n| RealIP | Data |\nFlannel通过在各个节点上的Agent进程，将容器网络的路由信息刷到主机的路由表上，这样一来所有的主机就都有整个容器网络的路由数据了。\nHost-Gateway的方式没有引入像Overlay中的额外装包解包操作，完全是普通的网络路由机制，它的效率与虚拟机直接的通信相差无几。\n然而，由于Flannel只能够修改各个主机的路由表，一旦主机直接隔了个其他路由设备，比如三层路由器，这个包就会在路由设备上被丢掉。\n这样一来，Host-Gateway的模式就只能用于二层直接可达的网络，由于广播风暴的问题，这种网络通常是比较小规模的，但近年来也出现了一些专门的设备能够构建出大规模的二层网络（就是我们经常听到的“大二层”网络）。\n2. 封装流量加密 默认情况下，封装的流量是不加密的。Flannel 提供了两种加密方案，可以在 Kubernetes 集群的工作节点之间建立加密隧道：\nIPSec：使用 strongSwan 在 Kubernetes worker 之间建立加密的 IPSec 隧道。它是加密的实验性后端。 WireGuard：比 strongSwan 更快的替代方案。 3. 总结 Flannel 以其简单而有效的网络模型而闻名，这对于初学者来说是一个巨大的优势。以下是 Flannel 的主要亮点：\n简单有效的网络模型\nFlannel 提供了一个简单但高效的网络模型，特别适合那些希望迅速入门k8s网络的初学者。它使用了一种称为VXLAN（Virtual Extensible LAN）的技术，\n将容器放置在一个逻辑二层（L2）网络中，无需分配路由。这使得容器之间的通信变得非常容易管理，而无需复杂的配置。\n流量传输的无缝控制\nFlannel 的网络模型允许在主机之间实现无缝的流量传输。这对于集群管理员来说是一个关键的优势，因为它可以确保容器之间的通信顺畅，同时不会引入额外的延迟或瓶颈。\nFlannel 将网络控制平面信息交换成轻量级的 UDP 包，从而实现了对 MAC 地址的访问控制，确保了通信的安全性。\n集成和易用性\nFlannel 是一个广泛使用的 CNI 插件，因此它与各种 Kubernetes 部署环境和工具集成良好。对于初学者来说，这使得部署和管理k8s集群变得更加容易。\n而且，Flannel 不仅易于使用，还易于配置，这对于初学者来说是一个额外的好处。\n总之，对于想要入门k8s网络的初学者，Flannel 提供了一个出色的起点。其简单而高效的网络模型以及与k8s生态系统的广泛集成，使其成为学习和掌握容器网络基础的理想选择。\n通过Flannel，你可以在不陷入复杂性的情况下，快速搭建起稳定的k8s网络基础，为你的容器化应用提供可靠的网络通信支持。\n参考链接 Comparing CNI providers \u0026ndash; Flannel\n","description":"","id":19,"section":"posts","tags":["Flannel","Kubernetes"],"title":"K8s网络CNI Flannel详细说明","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-31-k8s%E7%BD%91%E7%BB%9Ccni-flannel%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E/"},{"content":"CNI(Container Network Interface)意为容器网络接口，它是一种标准的设计，为了让用户在容器创建或销毁时都能够更容易地配置容器网络。\n由Google和CoreOS联合定制的网络标准，是Kubernetes网络插件的基础。基于CNI标准，有如下常见的CNI网络插件产品。\n目前主流的网络插件是Flannel、Calico、cillium。这些插件既可以确保满足Kubernetes的网络要求，又能为Kubernetes集群管理员提供他们所需的某些特定的网络功能。\n本文讲通过Kubernetes集群中不同网络环境下，通过Pod之间流量分析来比较Flannel、Calico、cillium、canal处理网络流量的不同之处。\n1. Canal网络插件介绍 2020年废弃不再维护，项目维护者认为应该将精力放在为flannel和calico项目增加功能上，而非深度整合两者。\nCanal结合Flannel和Calico的网络功能。将Flannel叠加网络层和VXLAN封装与Calico的网络组件（如 Felix、主机代理和网络策略）集成在一起，\n使用Flannel处理节点间的流量，使用 Calico 处理节点内流量和网络策略(Calico网络策略，可以在网络方面提供项目/命名空间隔离)。\n总之，对于希望利用具有网络策略规则的覆盖网络模型来加强安全性的企业来说，Canal 是一个不错的选择。\n优点: Flannel叠加网络且支持网络策略、提供了统一部署Flannel和Calico的方法\n缺点: Flannel和Calico之间的集成度不高\nCanal 要求在节点上安装iptables或xtables-nft包。\n2. Calico网络插件介绍 基于BGP的纯三层网络方案，与OpenStack\\k8s\\aws\\gce都有良好集成，默认配置不启用任何网络策略\nCalico在每个计算节点上实现一个高效的vRouter(使用Linux Kernel)，负责数据转发。每个vRouter使用BGP协议在整个Calico网络中传播当前节点上运行的workload的路由信息。\n这确保了workload之间的数据流量通过IP路由互联，无需额外的NAT、隧道或Overlay网络。此外，Calico还基于iptables提供了丰富和灵活的网络策略，用于实现多租户隔离、安全组和其他可达性限制。\n优点： 支持网络策略、网络性能高、支持 SCTP\n缺点： 不支持组播\n3. Flannel网络插件介绍 Flannel通过给每个宿主机分配子网的方法为容器提供虚拟网络。基于Linux TUN/TAP，使用UDP封装IP包来创建overlay网络，并依靠etcd来管理网络分配数据。\nFlannel 是为 K8s 配置 L3 网络结构的简单方法。Flannel在每台主机上运行一个名为flanneld的二进制 Agent，flanneld负责从更大的预配置地址空间中为每台主机分配子网。\nFlannel 通过k8s API或直接使用etcd来存储网络配置、分配的子网、以及其他辅助数据（例如主机的公共 IP）。数据包使用某种后端机制来转发，默认封装为 VXLAN。\n默认情况下，封装的流量是不加密的。Flannel 提供了两种加密方案：\nIPSec：使用 strongSwan 在 Kubernetes worker 之间建立加密的 IPSec 隧道。它是加密的实验性后端。 WireGuard：比 strongSwan 更快的替代方案。 优点: 支持IPsec加密、单一二进制安装和配置\n缺点: 不支持网络策略、无法通过单个守护进程运行多台主机和多个网络，但可以为每台主机运行多个守护进程。\n4. Weave网络插件介绍 Weave Net是一个去中心化的容器网络方案，各个host上的wRouter间通过建立Full Mesh的TCP连接，并通过Gossip来同步控制信息。\n这种方式省去了集中式的K/V Store，一定程度上简化了部署复杂性，Weave将其称为data centric，而非Raft或者Paxos的algorithm centric。\n在数据平面上，Weave通过UDP封装实现L2 Overlay，封装支持两种模式，一种是在用户空间运行的sleeve mode（Flannel的udp），另一种是在内核空间运行的fastpath mode（Flannel的vxlan）。\nSleeve mode通过pcap设备在Linux bridge上截获数据包并由wRouter完成UDP封装，支持对L2 traffic进行加密，还支持Partial Connection，但是性能损失明显。 Fastpath mode通过OVS的odp封装VxLAN并完成转发，wRouter不直接参与转发，而是通过下发odp流表的方式控制转发，这种方式可以明显地提升吞吐量，但是不支持加密等高级功能。 fastpass相当于vxlan overlay, sleeve相当于udp overlay, 改进点在于：1. 支持网络策略；2.去除额外的中心化容器地址分配器，将配置存储功能集成至服务内部；\n优点: 内核级通信、网络策略和加密支持、提供有偿故障排除支持\n缺点: 由于基于内核的路由选择，只支持 Linux 系统、默认加密标准导致网络速度降低\n5. Cilium网络插件介绍 Cilium 在 Kubernetes 中启用网络和网络策略（L3、L4 和 L7）。默认情况下，Cilium 使用 eBPF 技术在节点内部路由数据包，并使用 VXLAN 将数据包发送到其他节点。也可以配置非封装的技术。\nCilium 推荐大于 5.2 的内核版本，从而充分利用 eBPF 的能力。Kubernetes worker 需要打开 TCP 端口 8472（VXLAN）和 TCP 端口 4240（健康检查）。此外，还必须为健康检查启用 ICMP 8/0。\n默认情况下，Cilium 不允许 Pod 与其他节点上的 Pod 通信。要解决此问题，请启用 Ingress Controller 以使用 “CiliumNetworkPolicy” 进行跨节点路由请求。\n选择 Cilium CNI 并为新集群启用项目网络隔离后，配置如下：\n1 2 3 4 5 6 7 8 9 10 apiVersion: cilium.io/v2 kind: CiliumNetworkPolicy metadata: name: hn-nodes namespace: default spec: endpointSelector: {} ingress: - fromEntities: - remote-node 各个网络插件的 CNI 功能 下表总结了 Rancher 中每个 CNI 网络插件支持的不同功能：\n提供商 网络模型 路由分发 网络策略 网格 外部数据存储 加密 加密协议 Ingress/Egress 策略 企业支持 Canal 封装(UDP/VXLAN/IPIP)、未封装（host-gw/BGP） 否 是 否 K8s API 是 IPsec、WireGuard 是 否 Flannel 封装(UDP/VXLAN)或未封装（host-gw） 否 否 否 K8s API 是 IPsec 否 否 Calico 封装(VXLAN/IPIP）或未封装(BGP) 是 是 是 Etcd 和 K8s API 是 IPsec 是 是 WeaveNet 封装(UDP/VXLAN) 是 是 是 否 是 WireGuard 是 是 Cilium 封装(VXLAN) 是 是 是 Etcd 和 K8s API 是 IPsec 是 否 网络模型：封装或未封装。如需更多信息，请参阅 CNI 中使用的网络模型。 路由分发：一种外部网关协议，用于在互联网上交换路由和可达性信息。BGP 可以帮助进行跨集群 pod 之间的网络。此功能对于未封装的 CNI 网络插件是必须的，并且通常由 BGP 完成。如果你想构建跨网段拆分的集群，路由分发是一个很好的功能。 网络策略：Kubernetes 提供了强制执行规则的功能，这些规则决定了哪些 service 可以使用网络策略进行相互通信。这是从 Kubernetes 1.7 起稳定的功能，可以与某些网络插件一起使用。 网格：允许在不同的 Kubernetes 集群间进行 service 之间的网络通信。 外部数据存储：具有此功能的 CNI 网络插件需要一个外部数据存储来存储数据。 加密：允许加密和安全的网络控制和数据平面。 Ingress/Egress策略：允许你管理 Kubernetes 和非 Kubernetes 通信的路由控制。 CNI 社区人气 下表总结了不同的 GitHub 指标，了解每个项目的受欢迎程度和活动。数据收集于 2023 年 8 月\n提供商 项目 Stars Forks Contributors Canal https://github.com/projectcalico/canal 704 104 21 Flannel https://github.com/flannel-io/flannel 8.2k 2.9k 223 Calico https://github.com/projectcalico/calico 4.9k 1.2k 320 Weave https://github.com/weaveworks/weave/ 6.5k 673 87 Cilium https://github.com/cilium/cilium 16.3k 2.4k 640 CNI 网络性能 理论上说，这些CNI工具的网络速度应该可以分为3个速度等级。\n最快的是Romana、Gateway模式的Flannel、BGP模式的Calico。\n次一级的是IPIP模式的Calico、Swarm的Overlay网络、VxLan模式的Flannel、Fastpath模式的Weave。\n最慢的是UDP模式的Flannel、Sleeve模式的Weave。\nBare \u0026gt; Flannel(host-gw) ~ Calico(bgp) \u0026gt; Calico(ipip) ~ Flannel(vxlan) \u0026gt; Flannel(udp)\n测试容器网络速度的具体方法\n引用 calico - 确定最佳联网方案(基本概念)\nCNI 网络插件(rancher)\nKubernetes CNI 插件选型和应用场景探讨\n","description":"","id":20,"section":"posts","tags":["CNI","Kubernetes"],"title":"K8s网络CNI-常见网络插件说明与横向对比","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-30-k8s%E7%BD%91%E7%BB%9Ccni-%E5%B8%B8%E8%A7%81%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E8%AF%B4%E6%98%8E%E4%B8%8E%E5%AF%B9%E6%AF%94/"},{"content":"二分查找 红蓝染色法 查找有序数组中第一个\u0026gt;=8的数的位置，如果数据全部\u0026lt;8，则返回数组长度。\n查找反转有序数组(例如 [3,4,5,1,2])中最小数的位置。\n暴力做法：依次遍历数组中每个元素\n暴力做法没有利用到数组的有序性\n高效做法：两个指针L、R，分别指向左右边界（即,闭区间[L,R]），M指向正在询问的数。当M\u0026lt;8则是false（红色）；当M\u0026gt;=8则是true（蓝色）\n第一次迭代：\nL,R := 0,n-1 // L为左边界；R为右边界\nM := (L+R)/2 // M取中间值偏左（L+R可能存在溢出问题，）\ncompare(M, 8)\n第二次迭代：（M\u0026lt;8, [0:M]区间的元素全部排除）\nL,R := M+1, n-1 // L必须为M+1，而非M；否则当数组只有一个元素时，会陷入死循环。\nM :=\n第三次迭代： （M\u0026gt;=8, [M:n-1]区间的元素全部排除）\nL,R := M+1, m-1\n出口（关键）\n循环不变量：\n最终[0:L-1]一定小于8； [r+1: n-1]一定 \u0026gt;=8\n根据循环不变量，R+1是最终答案\n循环结束后，R+1=L,所以答案也可以用L表示\n","description":"","id":21,"section":"posts","tags":["CNI","Kubernetes","面试速记"],"title":"K8s网络CNI-概念与入门","uri":"https://hex-go.github.io/posts/interview/2024-04-12-%E7%AE%97%E6%B3%95-%E9%9D%A2%E8%AF%95%E9%80%9F%E8%AE%B0-%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"content":"网络架构是 K8S 的一个复杂组件。Kubernetes 网络模型对特定网络功能提出了要求。业界已开发出许多针对特定环境和要求的网络解决方案。\n容器网络接口（CNI）可让你在创建或销毁容器时轻松配置容器网络。本文将介绍经典网络插件的工作原理以及如何使用 CNI 插件。\n1. 什么是CNI？ CNI 是 Kubernetes 中的标准网络实现接口。Kubelet 通过 CNI 调用不同的网络插件，以实现不同的网络配置方法。常见的CNI插件有Calico、Flannel、Terway、Weave Net 和 Contiv 等。\n2. K8S中的CNI调用链 在群集中创建 Pod 时，API-Server会将 Pod 配置写入群集。API-Server的某些控制组件（如scheduler）被调度到特定节点。Kubelet 监听该 Pod 的创建后，会在当前节点执行一些创建操作。\n创建网络时，Kubelet 会读取配置目录（/etc/cni/net.d/）中的配置文件。配置文件声明了要使用的插件。Kubelet 执行 CNI 插件的二进制文件。\nCNI 插件会进入 Pod 的网络空间，配置 Pod 网络。Pod 网络配置完成后，Kubelet 将创建 Pod 并将其上线。\n上述过程中的配置文件、cni插件的可执行文件，都在cni插件安装时进行了配置和安装。\n3. CNI插件选型 3.1 后端模式 CNI 插件分为三种后端模式：Overlay(覆盖)、Routing(路由)、Underlay(底层)。\nOverlay模式: 容器的CIDR地址与主机的 IP 地址范围无关。在跨主机通信期间，主机之间会建立隧道，容器CIDR中的所有数据包都会封装为底层物理网络中主机之间交换的数据包。这种模式消除了对底层网络的依赖。\nRouting模式: 主机和容器属于不同的 CIDR 块。跨主机通信通过路由实现。不同主机之间不建立用于数据包封装的隧道。不过，路由互连部分取决于底层网络。例如，从底层网络到第 2 层必须有可到达的路由。\nUnderlay模式: 容器和主机位于同一网络层，共享同一位置。容器之间的网络互联取决于底层网络。因此，这种模式高度依赖底层能力。\n3.2 环境限制 不同的环境分别会有不同的限制以及能力。\n虚拟机环境：像OpenStack，施加了许多网络限制。1. 机器之间不能通过第2层协议直接访问，只能转发具有第3层特征（如 IP 地址）的数据包，主机只能使用指定的 IP 地址。因此只能选择Overlay模式下的插件，如 Flannel-VXLAN、Calico-IPIP、Weave等。\n物理机环境：对底层网络的限制很少。因此，可以选择Underlay模式或Routing模式的插件。在Underlay模式模式下，可以将多个网络接口控制器（NIC）直接插入物理机，或在 NIC 上虚拟硬件。在Routing模式下，路由是通过 Linux 路由协议建立的。这避免了 VXLAN 封装造成的性能下降。在这种环境下，可以选择 Calico-BGP、Flannel-HostGW 和 Sriov 等插件。\n公有云环境：是一种虚拟环境，对底层功能有许多限制。不过，每个公共云都会调整容器以提高性能，并可能提供 API 以配置额外的网卡或路由功能。公有云环境建议选择公有云供应商提供的 CNI 插件，以获得兼容性和最佳性能。\n3.3 功能要求 安全要求\n通过配置网络策略(NetworkPolicy)以支持是否允许节点间访问等策略。并非每个CNI插件都支持网络策略。如果需要 NetworkPolicy 支持，可以选择 Calico 或 Weave。\n集群内外资源互连\n部署在虚拟机（VM）或物理机上的应用程序无法一次性迁移到容器化环境。因此，有必要在虚拟机或物理机和容器之间配置 IP 地址互连，将它们互连或部署在同一层。\n这种情况下，可以选择 Underlay 模式下的插件。例如，Sriov 插件允许 Pod 和传统虚拟机或物理机在同一层运行。还可以使用 Calico-BGP 插件。虽然容器与传统虚拟机或物理机处于不同的 CIDR 块中，但可以使用 Calico-BGP 向原始路由器宣传 BGP 路由，从而实现虚拟机和容器之间的互联。\nK8S服务发现和负载均衡\n服务发现和负载平衡是k8s的一种Service资源。并非所有 CNI 插件都能提供这两项功能。对于处于 Underlay 模式的许多插件来说，Pod 的网卡是 Underlay 硬件，或者是通过硬件虚拟化并插入容器的。因此，NIC 流量无法路由到主机所在的命名空间。因此，无法应用 kube-proxy 在主机上配置的规则。\n在这种情况下，插件无法访问 Kubernetes 的服务发现功能。如果需要服务发现和负载平衡，请选择支持这两种功能的 Underlay 模式插件。\n3.4 性能要求 设计两个方面：POD创建速度，POD网络性能\nPod创建速度 在Pod创建时，CNI插件创建和配置相应的网络资源。Overlay与Routing模式可以快速创建Pod，插件可在机器上实现虚拟化，因此您只需调用内核接口即可创建Pod。\n如果选择 Underlay 模式的插件，则需要创建底层网络资源，这会减慢Pod创建过程。因此，需要快速扩展Pod、创建许多Pod时建议选择 Overlay 或 Routing 模式的插件。\nPod网络性能 Pod 的网络性能是通过 Pod 间网络转发、网络带宽和每秒脉冲 (PPS) 延迟等指标来衡量的。\nOverlay模式下的插件性能将低于Underlay和Routing模式下的插件，因为前者在节点上实现了虚拟化并对数据包进行了封装。这种封装会导致数据包头丢失和 CPU 消耗。\n因此，如果您在机器学习和大数据等场景中需要较高的网络性能，请不要选择 Overlay 模式的插件。建议选择 Underlay 或 Routing 模式的 CNI 插件。\n4. 如何开发一个CNI插件 社区提供的插件可能无法满足特定要求。例如，阿里云只能使用覆盖模式下的 VXLAN 插件。该插件性能相对较差，无法满足阿里云的某些业务需求。为此，阿里云开发了 Terway 插件。\n如果社区中的插件都不适合当前环境，可以开发一个 CNI 插件。\nCNI 插件的实现方法如下：\n二进制 CNI 插件用于配置 Pod 的网卡和IP地址。这相当于将一根网线连接到 Pod，而Pod有一个IP地址和网卡。 一个守护进程用于管理 Pod 之间的网络连接。这一步将 Pod 连接到网络，使它们能够相互通信。 4.1 为Pod配置网卡和IP 为Pod准备虚拟网卡\n创建veth虚拟网卡 一端连接到Pod的网络空间，另一端连接到主机的网络空间(Pod和主机的网络命名空间就连接起来了) 为Pod分配IP地址(为Pod分配一个集群唯中一的IP地址)\n根据节点为Pod分配CIDR区块(创建集群时,如下图创建了172.16.0.0/16段，每个节点分别分配了24位掩码的172.16.0.0/24段和172.16.1.0/24段，从而避免了节点间的IP地址冲突) 从节点的CIDR区块中为Pod分配IP地址(当前节点的IP地址分配既可以DHCP,也可以按序分配) 配置Pod的IP地址和路由\n为Pod网卡配置IP地址 为Pod网卡配置路由(入pod流量：在host上配置流向此POD-IP的路由指向此pod在主机上的veth1; 出pod的流量: 在Pod内的eth0网卡配置路由，pod访问集群外部)以便将指向此 pod 的流量路由到其 NIC。此外，在此 NIC 上配置默认路由的 CIDR 块，以便将通向 Internet 的流量路由到此 NIC。 4.1.1 为Pod准备NIC 可以将veth虚拟网卡的一端连接到Pod的网络空间，另一端连接到主机的网络空间。这样，pod 和主机的命名空间就连接起来了。\n4.1.2 为Pod分配IP地址 4.2 5. 总结 在环境中部署K8S集群时，如何选择合适的 CNI 插件。 当社区中可用的CNI插件无法满足需求时，如何开发 CNI 插件。 术语 底层网络（underlay network）：底层网络可使用传统的基于硬件的网络连接方式，或组合使用硬件和软件，将虚拟机或物理机连接起来。\n叠加网络（overlay network）：大多数编排系统都会包含一个软件定义的网络连接组件，称为叠加网络。它叠加于底层之上，在容器和主机的生命周期中提供网络连接能力，例如IP地址和端口。叠加还可以在使用同一物理网络的应用之间隔离通信。叠加技术包括Flannel\\calico等。\n参考链接 KubeBuilder 简明教程\n白话K8S网络\n浅谈Kubernetes Service负载均衡实现机制\n","description":"","id":22,"section":"posts","tags":["CNI","Kubernetes"],"title":"K8s网络CNI-概念与入门","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-30-k8s%E7%BD%91%E7%BB%9Ccni-%E6%A6%82%E5%BF%B5%E4%B8%8E%E4%BB%8B%E7%BB%8D/"},{"content":" Flannel 是 Kubernetes 中常用的 CNI 插件之一，用于为容器提供网络连接。然而，在某些情况下，特定版本的\nFlannel 可能与某些内核版本不兼容，导致 \u0026ldquo;bad udp checksum\u0026rdquo; 错误，从而影响了跨节点的 Pod 通信。在本篇博客中，将详细介绍如何逐步排查和定位这个问题。\n当排查 Kubernetes 网络问题，特别是与 CNI（容器网络接口）有关的问题时，需要考虑以下方面：\n防火墙 iptables 规则 路由规则 cni中间件（本文为flannel）状态 以下是一步步排查防火墙、iptables 规则、route 路由规则并通过抓包定位 \u0026ldquo;bad udp checksum\u0026rdquo; 错误的过程\n环境说明 为简单定位问题，将节点缩减为2台，master: 192.168.1.10 worker: master: 192.168.1.11\nrke配置文件举例()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 cluster_name: general nodes: - address: 192.168.1.10 role: - controlplane - etcd - worker - address: 192.168.1.11 role: - worker ssh_key_path: /home/tgde/.ssh/id_ed25519 kubernetes_version: v1.19.8-rancher1-1 # Specify network plugin-in (canal, calico, flannel, weave, or none) network: plugin: canal private_registries: - url: reg.paas.org is_default: true dns: provider: coredns ingress: provider: none services: kubelet: extra_binds: - \u0026#34;/data:/data\u0026#34; 操作系统: Ubuntu 22.04.3 LTS os内核: 5.15.0-79-generic rke: v1.2.6 k8s安装包：v1.19.8-rancher1-1 flannel版本：v0.13.0-rancher1 network-plugin: canal 1. 确认错误现象 rke up 创建集群后，部署cert-manager后，创建ClusterIssuer时，cert-manager组件之间无法通过svc.ns访问\n节点名称 节点角色 node_IP node网卡 子网 子网网卡 node-1 master 192.168.1.1 ens160 10.42.0.0/24 flannel.1 node-2 worker 192.168.1.2 ens160 10.42.1.0/24 flannel.1 pod\npod名称 所属节点 集群内部IP dnstools node-1[192.168.1.1] 10.42.0.5 coffee-85cvd node-1[192.168.1.1] 10.42.0.6 coffee-mrj6s node-2[192.168.1.2] 10.42.1.3 测试结果为:\nk8s集群内部:\npod dnstools 可以ping通pod coffee-85cvd（同节点pod）,无法ping通pod coffee-mrj6s(跨节点pod)\n宿主机节点:\n宿主机可以 ping 通部署在当前主机上的pod ，去ping 部署在其他宿主机pod ip 不通\n期望的正常结果为:\nk8s集群内部pod可以与集群内部任意pod通信; 宿主机可以ping集群内所有pod的IP; 2. 排查防火墙 同时在 node-1[192.168.1.1] node-2[192.168.1.2]执行命令检查防火墙，确认状态已关闭\n1 systemctl status ufw.service 3. 确认节点之间没有安全组规则 机器部署在云服务器，检查安全组设置，排除安全组规则设置导致通信异常的问题。\n4. 排查iptables规则 -L: 列出当前的iptables规则\n-S: 查看当前的iptables规则的详细信息\n1 sudo iptables -L 4. 检查路由规则 1 route -n 5. 检查vxlan配置 6. 抓包 tcpdump \u0026lt;参数\u0026gt; -i \u0026lt;网卡\u0026gt; \u0026lt;过滤条件: udp|icmp\u0026gt;\nX: 输出数据包的内容，以十六进制和 ASCII 文本的形式。这允许你查看数据包的实际内容。 e: 在输出中显示以太网帧的详细信息，包括源和目标 MAC 地址以及帧类型。 n: 使用数字形式显示IP地址和端口号，而不进行 DNS 解析。（性能优化、隐私保护） i: 指定要捕获数据包的网络接口。 v/vv/vvv: 增加输出的详细程度，以便查看更多的信息。 源端网络\n1 sudo tcpdump -vvvenX -i ens160 udp 目的端网络\nflannel节点之间通过udp通信，需要将协议改为udp\n1 sudo tcpdump -vvvenX -i ens160 udp 总结 checksum-offload 指定了内核不做校验和，交给网卡去做，当使用VXLAN时，由于某些原因(参考连接1和2)，校验值计算错误导致Bad udp cksum错误，所以会丢弃。\n而canal中节点中间通信通过flannel 的vxlan实现，节点内部通讯通过calico，因此出现跨节点pod无法通信，同一节点pod通信正常的现象。\n解决 关闭 CNI VXLAN 网卡的 checksum offload 升级内核版本 什么是 checksum offload Checksum Offload 是网卡的一个功能选项。如果该选项开启，则网卡层面会计算需要发送或者接收到的消息的校验和，从而节省 CPU 的计算开销。此时，在需要发送的消息到达网卡前，系统会在报头的校验和字段填充一个随机值。但是，尽管校验和卸载能够降低 CPU 的计算开销，但受到计算能力的限制，某些环境下的一些网络卡计算速度不如主频超过 400MHz 的 CPU 快。\nReference 1. 内核缺陷触发的NodePort服务63秒延迟问题\n2. k8s vxlan 作为 cni 后端引发的 63 秒延迟\n3. 63 秒延迟的触发原因定位-张浩\n4. Disable tx and rx offloading on VXLAN interfaces #1282\n","description":"","id":23,"section":"posts","tags":["Flannel","Kubernetes"],"title":"K8s部署实录-6-Flannel版本与5.15内核不兼容导致跨节点pod无法通信问题","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-29-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-6-flannel%E7%89%88%E6%9C%AC%E4%B8%8E5.15%E5%86%85%E6%A0%B8%E4%B8%8D%E5%85%BC%E5%AE%B9%E5%AF%BC%E8%87%B4%E8%B7%A8%E8%8A%82%E7%82%B9pod%E6%97%A0%E6%B3%95%E9%80%9A%E4%BF%A1%E9%97%AE%E9%A2%98/"},{"content":"部署集群后出现异常，想重新进行部署，需要在 Kubernetes 集群中清理节点，以确保不影响重新部署。\n在本篇博客中，将详细介绍如何使用 RKE（Rancher Kubernetes Engine）进行节点清理，以及确保节点重新部署的平稳进行。\n引言 在 Kubernetes 集群中，节点清理是一个关键步骤，它需要在保证应用程序的稳定运行的前提下，清理节点以进行重新部署。\nRKE（Rancher Kubernetes Engine）是一个用于部署和管理 Kubernetes 集群的强大工具。\n在本篇博客中，将深入探讨如何使用 RKE 来清理节点，以确保重新部署过程能够顺利进行。\nrke版本：v1.2.6\nk8s离线包版本：v1.19.6\n步骤 以下是执行节点清理操作的详细步骤：\n0. 预检查 该节点不应再是任何群集的成员。 清理脚本具备 root/sudo 访问权限。 检查该节点正在运行的容器或Pod，这些容器或Pod将在以下步骤中被强制删除（如果想保持业务应用的连续性，参考下面步骤1）。 确认在正确的节点上，并准备好继续清理所有容器以及 Kubernetes 和 Rancher/RKE 特有的所有数据（如有必要，可提前备份）。 1. Drain 节点 在清理节点之前，使用 kubectl drain 命令将节点上的工作负载（Pod）驱逐到其他节点上。 确保应用程序在节点清理过程中不会受到影响。\n1 kubectl drain \u0026lt;node-name\u0026gt; --ignore-daemonsets 2. 移除节点 编辑 cluster.yml 文件，将要清理的节点从 nodes 列表中删除。然后运行以下命令，使用 RKE 将节点从集群中移除。\n1 rke remove --config cluster.yml 3. 清理节点 此脚本不适用于rke2和k3s（这两者使用部署时生成的uninstall脚本）\n该脚本将删除与 Rancher 和 Kubernetes 有关的所有容器、卷、映像、网络接口和目录。还可以选择刷新所有 iptables 规则并删除容器镜像。\n登录到要清理的节点，并执行以下清理操作：\n清理脚本: extended-cleanup-rancher2.sh\n执行下面命令\n1 sudo bash extended-cleanup-rancher2.sh 如果需要，可以同时或单独使用可选的 -f 和 -i 标志来刷新 iptables (-f) 和删除容器映像 (-i)。\n1 sudo bash extended-cleanup-rancher2.sh -f -i 4. 重启节点 重启节点以应用清理和配置更改。\n5. 重新部署节点 更新 cluster.yml 文件，将节点重新添加到 nodes 列表中。然后使用 RKE 进行重新部署。\n注意事项 始终在执行节点清理之前备份重要数据。 仔细阅读 RKE 和 Kubernetes 的文档，以确保了解每个步骤的影响和细节。 执行节点清理操作时，要确保其他节点正常运行以避免服务中断。 结论 节点清理是 Kubernetes 部署过程中的关键步骤，它需要谨慎操作以确保重新部署的成功进行。通过使用 RKE 和以上步骤，可以有效地清理节点并确保应用程序的稳定运行。\n在执行节点清理操作之前，始终要备份数据并确保了解每个步骤的细节，以保证整个过程的顺利进行。\n可以了解如何使用 RKE 进行节点清理，以及如何在保持应用程序稳定性的前提下，重新部署节点。有利于在 Kubernetes 部署过程中更加灵活地管理节点，并确保系统的连续运行。\n","description":"","id":24,"section":"posts","tags":["RKE","Kubernetes"],"title":"k8s部署实录-5-RKE节点清理指南：确保节点重新部署的顺利进行","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-5-rke%E8%8A%82%E7%82%B9%E6%B8%85%E7%90%86%E6%8C%87%E5%8D%97/"},{"content":"当你在 Linux 系统中尝试使用 sudo 命令执行操作时，可能会遇到一些令人困惑的问题。其中之一是，为什么在某些情况下，即便使用 sudo 作为超级用户权限，仍然会报告权限拒绝错误。在本篇博客中，我们将探讨这个问题，并为您解释为什么在执行类似 sudo echo 的命令时，会遇到权限问题，同时提供解决方法。\n背景 在 Linux 终端中，sudo 是一种以超级用户（root）权限执行命令的方式。然而，一些情况下可能会让人感到困惑，尤其是当在 sudo 后面使用 echo 命令并附加重定向操作时，可能会遇到权限拒绝错误。让我们深入探讨一下为什么会出现这种情况。\n原因 问题的核心在于重定向操作符（\u0026gt;\u0026gt;）的工作方式。在 Linux 中，重定向操作符会在命令执行之前打开文件，而不是在命令执行期间。这意味着，即使您使用 sudo 作为超级用户来执行 echo 命令，重定向操作符在打开文件时仍然以普通用户权限进行。因此，如果您尝试执行以下命令：\n1 sudo echo \u0026#34;192.168.1.218 reg.paas.org\u0026#34; \u0026gt;\u0026gt; /etc/hosts sudo 作用于 echo 命令本身，但由于重定向操作符的权限与当前用户一致，你可能会看到 \u0026ldquo;权限拒绝\u0026rdquo; 错误。\n解决方法 要解决这个问题，可以使用以下方法之一：\n使用特权执行重定向：为了确保重定向操作以超级用户权限进行，您可以使用以下方法：\n1 echo \u0026#34;192.168.1.218 reg.paas.org\u0026#34; | sudo tee -a /etc/hosts 这会将输出通过管道传递给 tee 命令，然后使用 sudo 权限将数据追加到 /etc/hosts 文件中。\n使用 sudo -i：您可以通过使用 sudo -i 切换到超级用户环境，然后执行多个命令，其中包括重定向。但要小心在超级用户环境中执行命令。\n总结 在 Linux 中，sudo echo 后使用重定向操作符可能会导致权限拒绝错误。这是因为重定向操作符在执行命令之前以当前用户权限打开文件。通过使用管道和 tee 命令，或者在超级用户环境中执行命令，您可以解决这个问题。在处理权限问题时，始终要谨慎，确保您了解您正在执行的操作以及其潜在的影响。\n","description":"","id":25,"section":"posts","tags":["Sudo"],"title":"k8s部署实录-4-\"sudo echo '192.168.1.218 reg.paas.org' \u003e\u003e /etc/hosts\" 报权限拒绝错误","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-4-sudo%E6%8F%90%E6%9D%83echo%E5%90%8E%E7%9A%84%E9%87%8D%E5%AE%9A%E5%90%91%E6%93%8D%E4%BD%9C%E7%AC%A6%E4%BC%9A%E6%8A%A5%E6%9D%83%E9%99%90%E6%8B%92%E7%BB%9D%E9%94%99%E8%AF%AF/"},{"content":"重要 前因：\n由于客户现场不给root权限，docker-ce为客户自行安装，版本为24.0.5, 与准备的安装包不兼容（rke版本为v1.2.6, k8s版本为v1.19,兼容的docker版本为v1.13.x - v20.10.x）\n报错信息如下： 1 2 3 4 5 INFo[0000] [dialer] Setup tunnel for host [192.168.1.215] INFo[0000] [dialer] Setup tunnel for host [192.168.1.228] WARN[0000] [state] can\u0026#39;t fetch legacy cluster state from Kubernetes: Unsupported Docker version found [24.0.5] on host [192.168.1.227], supported versions are [1.13.x 17.03.x 17.06.x 17.09.x 18.06.x 18.09.x 19.03.x 20.10.x] INFO[0000] [certificates] Generating CA kubernetes certificates INFO[0000] [certificates] Generating Kubernetes API server aggregation layer requestheader client CA certificates 现状：\nrke up默认校验docker版本，docker-ce v24.0.5版本与rke-v1.2.6不兼容，导致安装失败\n原因分析：\n由于本身为开发环境部署，只为调研。打算将rke的docker版本校验忽略，继续安装\n处理方案：\nconfig.yml文件中的ignore_docker_version: true配置无效，rke的参数--ignore-docker-version有效\n1 rke up --ignore-docker-version Reference Docker version not supported even with ignore_docker_version: true\n","description":"","id":26,"section":"posts","tags":["Kubernetes","RKE"],"title":"k8s部署实录-3-rke部署集群忽略docker版本校验","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-3-rke%E9%83%A8%E7%BD%B2%E9%9B%86%E7%BE%A4%E5%BF%BD%E7%95%A5docker%E7%89%88%E6%9C%AC%E6%A0%A1%E9%AA%8C/"},{"content":"重要 前因：\n免密是由客户进行操作，出于安全的考虑，生成ssh-key-gen时选用的加密算法为ed25519, 而非默认的rsa, 从而生成的私钥文件目录为~/.ssh/id_ed25519\n现状：\n执行rke up命令，报错 ~/.ssh/id_rsa 文件不存在，集群安装失败。\n1 2 3 4 5 6 7 8 9 10 11 INFO[0000] Building Kubernetes cluster INFO[0000] [dialer] Setup tunnel for host [10.0.0.1] WARN[0000] Failed to set up SSH tunneling for host [10.0.0.1]: Can’t establish dialer connection: Error while reading SSH key file: open /root/.ssh/id_rsa: no such file or directory INFO[0000] [dialer] Setup tunnel for host [10.0.0.2] WARN[0000] Failed to set up SSH tunneling for host [10.0.0.2]: Can’t establish dialer connection: Error while reading SSH key file: open /root/.ssh/id_rsa: no such file or directory INFO[0000] [dialer] Setup tunnel for host [10.0.0.3] WARN[0000] Failed to set up SSH tunneling for host [10.0.0.3]: Can’t establish dialer connection: Error while reading SSH key file: open /root/.ssh/id_rsa: no such file or directory WARN[0000] Removing host [10.0.0.1] from node lists WARN[0000] Removing host [10.0.0.2] from node lists WARN[0000] Removing host [10.0.0.3] from node lists FATA[0000] Cluster must have at least one etcd plane host: failed to connect to the following etcd host(s) [10.0.0.1] 原因分析：\n配置ssh免密时，使用的key为ed25519加密算法生成的，而rke工具从操作机寻找文件~/.ssh/id_rsa，从而检查ssh免密，需要查找rke官方配置，从而指定ssh key的路径，替换默认值\n处理方案：\n修改配置文件cluster.yaml\n1 ssh_key_path: ~/.ssh/id_ed25519 如果在群集级别和节点级别都定义了ssh_key_path，则节点级别的密钥优先。\n集群级别设置：\n1 2 3 cluster_name: mycluster ssh_key_path: ~/.ssh/id_ed25519 nodes: 节点级别设置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cluster_name: mycluster nodes: - address: 1.1.1.1 user: ubuntu role: - controlplane - etcd - worker ssh_key_path: ~/.ssh/id_ed25519 - address: 1.1.1.2 user: ubuntu role: - controlplane - etcd - worker ssh_key_path: ~/.ssh/id_ed25519 Reference RKE配置参数-ssh_key_path\nRKE配制文件-full-example\n","description":"","id":27,"section":"posts","tags":["Kubernetes","RKE"],"title":"k8s部署实录-2-rke指定ssh_key_path配置从而替换默认路径","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-2-rke%E6%8C%87%E5%AE%9Assh_key_path%E9%85%8D%E7%BD%AE%E4%BB%8E%E8%80%8C%E6%9B%BF%E6%8D%A2%E9%BB%98%E8%AE%A4%E8%B7%AF%E5%BE%84/"},{"content":"重要 前因：\n客户现场只提供JumpServer的web-client方式连接，root密码甚至是普通用户的密码也不提供。导致只能通过web-client进行环境部署操作。\n现状：\n使用JumpServer的WebClient方式进行vim编辑文件时，发现Vim的编辑模式无法Esc退出\n原因分析：\nEsc会触发浏览器的Esc热键，导致Vim无法推出编辑模式\n处理方案\n将 jj 替代 Esc, 通过jj退出编辑模式\n在~/.vimrc下添加映射 \u0026ldquo;inoremap jj \u0026rdquo;\n1 2 3 # $vimrc_path文件存在时，向文件中追加\u0026#34;inoremap jj \u0026lt;Esc\u0026gt;\u0026#34;,否则新建文件并增加以上内容 vimrc_path=\u0026#34;$HOME/.vimrc\u0026#34; content_to_append=\u0026#34;inoremap jj \u0026lt;Esc\u0026gt;\u0026#34;; if [ -f \u0026#34;$vimrc_path\u0026#34; ]; then echo \u0026#34;$content_to_append\u0026#34; \u0026gt;\u0026gt; \u0026#34;$vimrc_path\u0026#34;; else echo \u0026#34;$content_to_append\u0026#34; \u0026gt; \u0026#34;$vimrc_path\u0026#34;; fi Reference 在 Vim 编辑器中，.vimrc 文件是用于配置 Vim 的设置和行为的配置文件。\n其中，inoremap 是 Vim 配置文件中的一个命令，用于定义插入模式（Insert Mode）下键盘映射。\n键盘映射允许您将按键序列映射为其他按键、命令或字符串，以改变编辑器的行为。\n具体来说，inoremap 是 \u0026ldquo;Insert Normal Mode Mapping\u0026rdquo; 的缩写，它会在插入模式下将一个按键序列映射为另一个按键序列。\n常见的用例是将短按键序列映射为更长或更方便的按键序列，以提高编辑效率。\ninoremap jj \u0026lt;Esc\u0026gt; 将按下两个连续的 j 键映射为按下\u0026lt;Esc\u0026gt;键，而 键用于从插入模式返回到普通模式。\n解释一下具体含义：\ninoremap: 表示在插入模式下进行键盘映射。\njj: 指定按键序列，即按两次 j 键。\n\u0026lt;Esc\u0026gt;: 是特殊字符表示 键，它在 Vim 中表示退出插入模式，返回到普通模式。\n这样，每当在插入模式中按下两次 j 键，Vim 将会识别为按下了一个 键，从而退出插入模式。\n","description":"","id":28,"section":"posts","tags":["Vim"],"title":"k8s部署实录-1-web控制台Esc快捷键与vim的热键冲突无法推出编辑模式","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-1-web%E6%8E%A7%E5%88%B6%E5%8F%B0esc%E5%BF%AB%E6%8D%B7%E9%94%AE%E4%B8%8Evim%E7%9A%84%E7%83%AD%E9%94%AE%E5%86%B2%E7%AA%81%E6%97%A0%E6%B3%95%E6%8E%A8%E5%87%BA%E7%BC%96%E8%BE%91%E6%A8%A1%E5%BC%8F/"},{"content":"1.简介 Linux查漏补缺，还剩：\n4-安装包管理[rpm/dpkg] 5-proc程序查看说明 6-磁盘格式化 7-mount说明 8-LVM 9-账号管理与ACL 2.说明 Linux系统将硬件设备当成特殊文件，成文设备文件，存储在/dev目录下。设备文件分为3类\n字符型设备文件: 指每次只能处理一个字符的设备（终端、调制解调器）。 块设备文件: 能处理大块数据的设备(硬盘)。 网络设备文件: 数据包发送、接收设备(网卡、回环设备) 3.总结 4.参考 Base\nhttps://www.cnblogs.com/chengmo/archive/2010/10/25/1857775.html\nKernel - all /dev\nhttps://www.kernel.org/doc/html/v4.20/admin-guide/devices.html\n关于 /dev/tcp/${HOST}/${PORT}\nhttps://www.jianshu.com/p/f10736931b93\nhttps://ithelp.ithome.com.tw/articles/10221819\n4-安装包管理[rpm/dpkg]\n第二十二章、软件安装 RPM, SRPM 与 YUM\n5-proc程序查看说明\n16.3 程序管理\n6-磁盘格式化与逻辑卷管理\n7.3 磁盘的分区、格式化、检验与挂载\n8-LVM\n14.3 逻辑卷轴管理员 （Logical Volume Manager）\n7-mount说明\n所谓的“挂载”就是利用一个目录当成进入点，将磁盘分区的数据放置在该目录下； 也就是说，进入该目录就可以读取该分区的意思。这个动作我们称为“挂载”，那个进入点的目录我们称为“挂载点”。\n目录树与文件系统的关系：通过挂载，实现目录树的架构与磁盘内的数据(文件系统)结合。\n7.1.7 挂载点的意义 （mount point）\n7.3.5 文件系统挂载与卸载： mount, umount\n8-账号管理与ACL\n第十三章、Linux 帐号管理与 ACL 权限设置\n","description":"","id":29,"section":"posts","tags":["Bash","Linux","特殊/dev"],"title":"Linux查漏补缺-3-特殊设备文件[loop,null,zero,full,random,tcp..]","uri":"https://hex-go.github.io/posts/bash/2022-10-27-linux%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA-3-%E7%89%B9%E6%AE%8A%E8%AE%BE%E5%A4%87%E6%96%87%E4%BB%B6loopnullzerofullrandomtcp../"},{"content":"1.简介 ​ 在kubernetes中部署mariadb服务,挂载local-storage时，binlog目录赋予777\n权限，仍权限不足导致服务无法启动，后执行chmod 1777 binlog/ 解决问题。没有系统研究过linux的权限，以为rwx\n是就是所有权限，缺少对特殊权限s和t权限的理解。\n2.说明 s权限：强制位权限。可执行的文件搭配这个权限，便能得到特权，任意存取该文件的所有者能使用的全部系统资源。\n请注意具备SUID/SGID权限的文件，黑客经常利用这种权限，以SUID/SGID配上root帐号拥有者，无声无息地在系统中开扇后门，供日后进出使用。\n例如：\nSUID举例 /usr/bin/passwd SGID举例 /usr/bin/locate t权限：粘滞位权限。一般只用在目录上，在具备此权限的目录下，任何用户可写入文档，又不让用户删除这个目录下他人的文档。\n例如：\n/tmp和/var/tmp目录 2.1 SUID Set UID：简称为SUID，s的权限是在用户。\n把此进程的有效用户ID设置为此文件拥有者的用户ID，程序在执行过程中拥有文件拥有者的权限。仅可用在可执行二进制文件。\n场景举例：\n账号与密码的存放文件其实是/etc/passwd与 /etc/shadow)。而/etc/shadow文件的权限如下\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp$ stat /etc/shadow File: /etc/shadow Size: 1427 Blocks: 8 IO Block: 4096 regular file Device: 10302h/66306d Inode: 21758432 Links: 1 Access: (0640/-rw-r-----) Uid: ( 0/ root) Gid: ( 42/ shadow) Access: 2022-10-26 10:30:01.647835420 +0800 Modify: 2022-09-21 15:42:07.468201547 +0800 Change: 2022-09-21 15:42:07.472201579 +0800 Birth: 2022-09-21 15:42:07.468201547 +0800 shadow文件所有者是root，权限为0640。在这个权限中，仅有root可以存储，其他人是连看都不行的。\n现有普通用户hex也有更新自身密码的需求，即使用/usr/bin/passwd命令，存取/etc/shadow密码文件。\n这是因为/usr/bin/passwd的文件权限如下\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp$ stat /usr/bin/passwd File: /usr/bin/passwd Size: 59976 Blocks: 120 IO Block: 4096 regular file Device: 10302h/66306d Inode: 49283913 Links: 1 Access: (4755/-rwsr-xr-x) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2022-09-19 15:45:14.219152977 +0800 Modify: 2022-03-14 16:59:13.000000000 +0800 Change: 2022-09-19 02:49:39.597789775 +0800 Birth: 2022-09-19 02:49:39.597789775 +0800 passwd文件所有者是root，权限为4755。\nother位有x权限说明普通用户具备此文件的可执行权限； user位有s权限说明当其他用户执行passwd时会获得文件passwd的拥有者root的权限。 有s权限的帮助，当普通用户hex执行/usr/bin/passwd时，会“暂时”得到passwd文件拥有者root的权限。\n2.2 SGID Set GID: 简称为SGID，s的权限是在group。\n把此进程的有效用户组ID设置为此文件的组ID，程序在执行过程中拥有文件所属组的权限。\n可以用在两个方面：\n文件：如果SGID设置在二进制文件上，则不论用户是谁，在执行该程序的时候，它的有效用户组(effective group)\n将会变成该程序的用户组所有者(group id)。\n举例来说，/usr/bin/locate 可以读取 /var/lib/mlocate/mlocate.db 这个文件的内容 ， mlocate.db 的权限如下：\n1 2 3 root@hex-PC:/tmp# ll /usr/bin/plocate /var/lib/plocate/plocate.db -rwxr-sr-x 1 root plocate 313904 Feb 17 2022 /usr/bin/plocate* -rw-r----- 1 root plocate 70159347 Oct 26 19:14 /var/lib/plocate/plocate.db 与 SUID 类似，如果使用普通用户去执行 locate ，那 普通用户 将会取得 slocate 组的支持，\n因此就能够去读取 mlocate.db 文件\n目录：如果SGID设置在A目录上，则用户在A目录下新建的文件的群组都会与A目录的群组名称相同。\n用户若对于此目录具有 r 与 x 的权限时，该用户能够进入此目录； 用户在此目录下的有效群组（effective group）将会变成该目录的群组； 用途：若用户在此目录下具有 w 的权限（可以新建文件），则用户所创建的新文件，该新文件的群组与此目录的群组相同。 2.3 SBIT Sticky Bit: 简称为SBit，只针对目录有效，对文件没有效果。\nSBIT 对于目录的作用是：用户在该目录下建立文件或目录时，只有自己与root才有权力删除。\n用户需要对SBIT标记的目录具备以下权限：\nx权限：用户具备此权限才能进入目录； r权限：用户具备此权限才能查看文件属性和内容(ls 与 cat)； w权限：用户具备此权限才能创建、修改、删除文件和子目录； 举例来说，/tmp本身的权限是“drwxrwxrwt”，在这样的权限内容下，任何人都可以在/tmp内新增、修改文件，但仅有该文件/目录的建立者与root能够删除自己的目录或文件。\n以root登入系统，并且进入 /tmp中。\ntouch test，并且更改test权限成为777.\n以一般用户登入，并进入 /tmp.\n尝试删除test文件。\n2.4 设置特殊权限 通常使用 chmod xyz filename 方式来设置filename的权限时，是假设没有SUID、SGID及SBIT。而在三位前增加一位用来表示这些特殊权限：\n4为SUID\n2为SGID\n1为SBIT\n3=SGID+SBIT; 5=SUID+SBIT; 6=SUID+SGID; 7=SUID+SGID+SBIT;\n例如：test文件权限为默认权限-rw-rw-r--\n1 2 3 4 5 hex@hex-PC:/tmp/perm-test$ ls -alh total 4K drwxrwxr-x 2 hex hex 4.0K Oct 26 18:53 . drwxrwxrwt 40 root root 4.0K Oct 26 17:29 .. -rw-rw-r-- 1 hex hex 0 Oct 26 18:53 test 为此文件test设置SUID权限，即设置s在用户权限中。因此，在原先的664之前还要加上4。命令如下：\n1 chmod 4664 test 查看修改后文件权限为\n1 2 3 4 5 hex@hex-PC:/tmp/perm-test$ ls -alh total 4K drwxrwxr-x 2 hex hex 4.0K Oct 26 18:53 . drwxrwxrwt 40 root root 4.0K Oct 26 17:29 .. -rwSrw-r-- 1 hex hex 0 Oct 26 18:53 test 2.5 延伸 2.5.1 SUID是否可用于bash脚本？否 不能用在批处理文件(shell脚本)上。这是因为shell脚本只是将很多二进制执行文件调进来执行而已。所以SUID的权限部分，还是要看shell脚本调用进来的程序设置，而不是shell脚本本身。\n2.5.2 大写S与大写T说明 chmod命令不进行必要的完整性检查，即使不设置x权限就设置s权限，chmod也不会报错。当ls -l时看到rwS，大写S说明s权限未生效。\nS_ISUID的表示方式。所属用户的S_IXUSR(x位)为S_ISUID所共用： 当S_IXUSR和S_ISUID共存时，用小写s表示； 当只设置了S_ISUID时，用大写S表示（权限未生效）； S_ISGID的表示方式。所属用户的S_IXGRP(x位)为S_ISGID所共用： 当S_IXGRP和S_ISGID共存时，用小写s表示； 当只设置了S_ISGID时，用大写S表示（权限未生效）： S_ISVTX的表示方式。所属用户的S_IXOTH(x位)为S_ISVTX所共用： 当S_IXOTH和S_ISVTX共存时，用小写t表示； 当只设置了S_ISVTX时，用大写T表示（权限未生效）： 综上：大写字母意味着该位[u|g|o]没有x权限，小写字母意味着该位[u|g|o]有x权限。因为特殊权限都必须具备x权限，所以：\n大写意味着权限一定未生效； 小写意味着权限不一定生效；(比如，SUID设置在目录；SBIT设置在文件等，仍小写但无效) 2.5.3 区别 S_UID S_GID T 权限号(rwx set 755) 4755 2755 1755 文件对象 二进制、可执行文件 二进制、可执行文件；目录 目录 生效条件 文件属主必须先设置x权限 文件属组必须先设置x权限 - 目录具备w权限，可新建文件\n- 目录具备rx权限，才能进入目录 设置命令 chmod u+s \u0026lt;bin-exec文件\u0026gt; chmod g+s \u0026lt;bin-exec文件\u0026gt; chmod o+t \u0026lt;目录\u0026gt; 移除命令 chmod u-s \u0026lt;bin-exec文件\u0026gt; chmod g-s \u0026lt;bin-exec文件\u0026gt; chmod o-t \u0026lt;目录\u0026gt; 权限显示 (4755/-rwsr-xr-x) (2755/-rwxr-sr-x) (1755/-rwxr-xr-t) 生命周期 仅在该程序的执行过程中有效 同 S_UID 文件读写 3.总结 文件具有SUID的特殊权限时，代表用户执行此二进制程序时，在执行过程中用户会暂时具有程序拥有者的权限。 目录具有SGID的特殊权限时，代表用户在这个目录下新建的文件的群组都会与该目录的群组名称相同。 目录具有SBIT的特殊权限时，代表用户在该目录下创建的文件只有自己与root能够删除。 设置权限时，了解cat、ls、执行文件等操作所需的基本权限也很重要。可参考 注2：鸟哥-常见指令需要的基本权限\n4.参考 [注1]： 鸟哥-特殊权限SUID说明\n[注2]： 鸟哥-常见指令需要的基本权限\n","description":"","id":30,"section":"posts","tags":["Bash","Linux","特殊权限"],"title":"Linux查漏补缺-2-特殊权限[s·t]","uri":"https://hex-go.github.io/posts/bash/2022-10-26-linux%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA-2-%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90st/"},{"content":"1.简介 操作机某软件异常，进行重装时。对软链接理解存在偏差导致误删除目录问题详细参考 2.3.5 删除目录的软链。\n因为未移除感觉软链接，导致安装失败；\n尝试删除软链接/root/bin -\u0026gt; /bin。\n执行命令rm /root/bin/时，报错Is a directory。\n想当然的执行rm -rf /root/bin/ 导致将其link的目录/bin删除。\n目录软链接的删除，应为rm /root/bin，而非rm -rf /root/bin/。\n本文详细记录由链接引伸出来的一系列概念。\n2.说明 2.0 基础知识 inode的相关说明：注1\n跨文件系统（磁盘分区），inode不唯一； 每个文件都会占用一个 inode ，文件内容由 inode 来指向blok获取； inode与文件名为一对多关系； 系统内部读取文件步骤：注1\n系统找到文件名对应的inode 通过 inode 号码，获取inode信息 根据 inode 信息，找到文件数据所在的 block，读出数据。 链接: UNIX文件系统提供的一种将不同文件链接至同一个文件的机制；实际上是一种文件共享的方式，是 POSIX 中的概念，主流文件系统都支持链接文件。\n查看文件信息的命令\nls命令\n示例：\n1 2 3 4 hex@hex-PC:/tmp/ln-test$ ls -li total 4 60822147 -rw-rw-r-- 1 hex hex 12 Oct 25 17:36 test 60822175 lrwxrwxrwx 1 hex hex 4 Oct 25 17:36 test-sl -\u0026gt; test 参数：\n-i 查看inode 输出：\n第一列：inode号 第二列：文件权限 第三列：链接数目，指一共多少个文件名指向这个inode 第四列：文件拥有者 第五列：文件所属group 第六列：文件大小 第七列：文件内容上一次变动的时间 第八列：文件名 stat命令\n示例：\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp/ln-test$ stat test-sl File: test-sl -\u0026gt; test Size: 4 Blocks: 0 IO Block: 4096 symbolic link Device: 10302h/66306d Inode: 60822175 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-25 17:36:18.216885854 +0800 Modify: 2022-10-25 17:36:16.184873570 +0800 Change: 2022-10-25 17:36:16.184873570 +0800 Birth: 2022-10-25 17:36:16.184873570 +0800 参数： 无\n输出：\nFile：显示文件名\nSize：显示文件大小\nBlocks：文件使用的数据块总数\nIO Block：IO块大小\nsymbolic link：文件类型（软链接）\nInode：inode 号\nLinks：链接数，即有多少文件名指向这个 inode\nUid：文件拥有者的 Uid\nGid：文件所属group的 Gid\nAccess：文件的读、写、执行权限\n文件的时间戳，共有三个：\nChange：简写为ctime，文件状态(链接数、大小、权限、Blocks数)改变时间。 Modify：简写为mtime，文件内容的修改时间，文件内容被修改时更新。 Access：简写为atime，文件内容的访问时间。文件内容被访问时更新。 Birth: 文件创建时间。 2.1 软链接、硬链接区别 功能项 软链接 硬链接 使用对象 文件、目录 文件 inode是否相同 不同 相同 是否跨文件系统(磁盘分区) 是 否 原文件删除 软链接不可用 不受影响 与原文件的关联项 执行命令时，原文件名参数 原文件inode 原文件是否必须存在 否 是 执行命令 ln -s \u0026lt;src\u0026gt; \u0026lt;file-sl\u0026gt; ln \u0026lt;src\u0026gt; \u0026lt;file-hl\u0026gt; 2.2 软链接 软链接只是一个符号链接，其实就是新建立一个文件，这个文件就是专门用来指向别的文件。大小很小，权限是777，而真正的信息是由指向的原文件决定；\n删除软链接文件，不影响原文件； 删除原文件，则相应的软链接不可用（cat那个软链接文件，则提示“没有该文件或目录“）； 2.3 硬链接 硬链接实际上是为文件建一个别名，指向同一个inode。\n创建硬链接时，不会建立inode，只是在原文件的inode link count域再增加1； 删除硬链接时，在原文件的inode link count域再减1； 系统调用会检查inode link count的数值，如果\u0026gt;=1，那么inode不会被回收，文件的内容不会被删除。\n2.4 引申问题 2.4.1 软链接跳转靠的是文件名而非inode 验证思路：设置软链接时，原文件参数传递为相对路径；再将软链接移动到其他目录下；如果报错Not Found则说明成立\n软链接查找使用的文件名，为ln执行命令时传入的原文件，如果是相对路径，则根据软链接路径进行查找。\n准备测试环境\n1 2 3 4 5 # 创建测试目录 mkdir /tmp/ln-test/ cd /tmp/ln-test/ # 生成测试 原文件 echo \u0026#34;source file\u0026#34; \u0026gt; test 设置软链接\n1 ln -s test test-sl 查看文件状态\n执行命令ls -li(i参数为查看文件inode)\n1 2 3 4 hex@hex-PC:/tmp/ln-test$ ls -li total 4 60822147 -rw-rw-r-- 1 hex hex 12 Oct 25 17:36 test 60822175 lrwxrwxrwx 1 hex hex 4 Oct 25 17:36 test-sl -\u0026gt; test 执行命令stat \u0026lt;filename\u0026gt;\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp/ln-test$ stat test-sl File: test-sl -\u0026gt; test Size: 4 Blocks: 0 IO Block: 4096 symbolic link Device: 10302h/66306d Inode: 60822175 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-25 17:36:18.216885854 +0800 Modify: 2022-10-25 17:36:16.184873570 +0800 Change: 2022-10-25 17:36:16.184873570 +0800 Birth: 2022-10-25 17:36:16.184873570 +0800 移动软链接至其他目录\n1 mv test-sl ../ 通过软链接cat文件内容\nstat 查看软链接属性，File: test-sl -\u0026gt; test 显示软链接指向当前目录test文件，但test文件不存在。\n1 2 3 4 5 6 7 8 9 10 11 12 hex@hex-PC:/tmp/ln-test$ cd ../ hex@hex-PC:/tmp$ stat test-sl File: test-sl -\u0026gt; test Size: 4 Blocks: 0 IO Block: 4096 symbolic link Device: 10302h/66306d Inode: 60822175 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-25 17:40:57.608602008 +0800 Modify: 2022-10-25 17:36:16.184873570 +0800 Change: 2022-10-25 17:40:34.131967367 +0800 Birth: 2022-10-25 17:36:16.184873570 +0800 hex@hex-PC:/tmp$ cat test-sl cat: test-sl: No such file or directory 软链接所在新目录创建新的test文件，再查看\n1 2 3 4 5 6 hex@hex-PC:/tmp$ echo \u0026#34;Other test file\u0026#34; \u0026gt; test hex@hex-PC:/tmp$ ls -li test* 60822202 -rw-rw-r-- 1 hex hex 16 Oct 25 17:47 test 60822175 lrwxrwxrwx 1 hex hex 4 Oct 25 17:36 test-sl -\u0026gt; test hex@hex-PC:/tmp$ cat test-sl Other test file 软链接移动前后，inode为60822175，未改变；但前后的原文件test的inode已发生改变60822147 -\u0026gt; 60822202。说明软链接是通过File: test-sl -\u0026gt; test记录所跳转的原文件，而非inode。\n2.4.2 硬链接无法跨分区，而软链接可以的原因 硬盘格式化的时候，操作系统自动将硬盘分为两个区域：\n数据区：存放文件内容\ninode 区：存放 inode 包含的信息，也叫作 inode table\n硬链接通过与原文件共用同一inode访问blok读取文件内容。跨分区无法共享inode，所以硬链接无法跨分区。\n软链接记录的是原文件的文件名， 而非inode。可以跨分区。\n延伸个问题：Linux是如何跨分区寻找inode的\n2.4.3 硬链接不支持目录的原因 系统限制对目录进行硬链接只是一个硬性规定，并不是逻辑上不允许、技术上不可行。\n其实使用 ln -d 命令也允许 root 用户尝试建立目录硬链接，且.与..都是目录的硬链接。\n由于 Linux 操作系统中的目录是以 / 为节点的树状结构，对目录的硬链接有可能破坏这种结构，甚至形成循环如： /usr/bin -\u0026gt; /usr/ ，在使用遍历目录的命令时（如： ls -R ）系统就会陷入无限循环中。\n如果使用 hard link 链接到目录时， 链接的数据需要连同被链接目录下面的所有数据都创建链接。因此造成环境相当大的复杂度。\n举例来说，如果要将 /etc 使用实体链接创建一个 /etc_hd 的目录时，那么在 /etc_hd 下面的所有文件名同时都与 /etc 下面的文件名要创建 hard link 的，而不是仅链接到 /etc_hd 与 /etc 而已。 并且，未来如果需要在 /etc_hd 下面创建新文件时，连带的， /etc 下面的数据又得要创建一次 hard link。\n2.3.4 .与..是目录的硬链接，特殊在哪里 创建目录时，默认会生成两个目录项： . 和 .. 。\n. 相当于当前目录的硬链接； .. 相当于父目录的硬链接。 目录硬链接总数：\n空目录的硬链接总数，等于2（.和\u0026lt;file-name\u0026gt;）； 目录的硬链接总数，等于 2 + 它的子目录总数（子目录的 ..）； 2.3.5 目录软链接删除，注意区分 软链接/ 与 软链接 目录的软链接=文件，而非目录文件；例如\n目录文件：/tmp/ln-test/test-dir 等同于 /tmp/ln-test/test-dir/\n目录的软链接：/tmp/ln-test/test-dir-sl \u0026lt;不等于\u0026gt; /tmp/ln-test/test-dir-sl/\n​\trm 前者 == 删除软链接； rm后者 == 删除原目录。\n验证：\n准备环境\n1 2 3 4 # 创建目录 mkdir -p /tmp/ln-test/test-dir cd /tmp/ln-test/test-dir 设置软链接\n1 ln -s test-dir/ test-dir-sl 查看文件状态\n1 2 3 4 hex@hex-PC:/tmp/ln-test$ ls -li total 4 60822338 drwxrwxr-x 2 hex hex 4096 Oct 26 10:22 test-dir 60822339 lrwxrwxrwx 1 hex hex 9 Oct 26 10:23 test-dir-sl -\u0026gt; test-dir/ 软链接 stat\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp/ln-test$ stat test-dir-sl File: test-dir-sl -\u0026gt; test-dir/ Size: 9 Blocks: 0 IO Block: 4096 symbolic link Device: 10302h/66306d Inode: 60822339 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-26 10:23:12.046192861 +0800 Modify: 2022-10-26 10:23:06.810155908 +0800 Change: 2022-10-26 10:23:06.810155908 +0800 Birth: 2022-10-26 10:23:06.810155908 +0800 软链接/ 的stat\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp/ln-test$ stat test-dir-sl/ File: test-dir-sl/ Size: 4096 Blocks: 8 IO Block: 4096 directory Device: 10302h/66306d Inode: 60822338 Links: 2 Access: (0775/drwxrwxr-x) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-26 10:23:12.046192861 +0800 Modify: 2022-10-26 10:22:18.821817214 +0800 Change: 2022-10-26 10:22:18.821817214 +0800 Birth: 2022-10-26 10:22:18.821817214 +0800 可尝试执行stat test-dir和stat test-dir/，会发现与stat test-dir-sl/的inode一致。\n测试删除\n通过上一步stat查看软链接/和软链接已足够说明问题，通过删除再二次验证\n删除软链接/\n1 2 hex@hex-PC:/tmp/ln-test$ rm test-dir-sl/ rm: cannot remove \u0026#39;test-dir-sl/\u0026#39;: Is a directory 删除软链接\n1 2 3 4 hex@hex-PC:/tmp/ln-test$ rm test-dir-sl hex@hex-PC:/tmp/ln-test$ ls -li total 4 60822338 drwxrwxr-x 2 hex hex 4096 Oct 26 10:22 test-dir 2.3.6 应用场景 软链接：\n灵活切换不同版本的目标程序\n在开发的过程中，对于同一个工具软件，可能要安装多个不同的版本，例如：Python2 和 Python3。\n当在终端窗口中输入：python 时，启动的是 python2.7 版本。\n如果有一天需要使用 python3.5 版本，只需要把软链接 python 指向 python3.5 即可。\n动态库版本管理\n场景描述： 想象这样一个情景，一个程序需要使用 foo_1.1 文件中的共享资源，由于 foo 经常改变版本号。每次升级后都得将使用 foo_1.1 的所有程序更新到 foo_1.2 文件，那么每次更新 foo 版本后，都要重复上边的工作。\n解决方案：创建一个 foo 的软链接指向 foo_1.2。这时，当一个程序访问 foo 时，实际上是访问 foo_1.2。当升级到 foo_1.3 时，只需要更新软链接指向。这不仅解决了版本升级问题，而且还允许在系统中保存两个不同的版本，如果 foo_1.3 有错误，再更新回原来的 foo_1.2 链接就可以。\n快捷方式，将目录层次较深的文件链接到一个更易访问的目录中。\n硬链接：\n不同角度对文件进行分类 文件多人共享 文件备份 3.总结 目录的软链接比较特殊，尤其删除时注意区分带与不带的/的区别。\u0026lt;软链接\u0026gt;/是原目录本身，后\u0026lt;软链接\u0026gt;是软链接文件； 硬链接无法跨分区是实现机制决定的，无法创建目录的硬链接是硬性规定（.与..都是目录的硬链接）； 硬链接共用同一inode，增加硬链接相当于文件inode的新的别名； 软链接通过创建时的原文件参数查找原文件，而非原文件inode（原文件参数==绝对路径，软链接可到处移动。否则不可以）； 4.参考 [注1]： linux-inode说明\n[注2]： \u0026ldquo;醉卧沙场：计算机专业性文章及回答总索引-存储和文件系统\u0026rdquo;\n[注3]：Linux是如何跨分区寻找inode\n[注4]： \u0026ldquo;鸟哥私房菜-链接ln说明\u0026rdquo;\n","description":"","id":31,"section":"posts","tags":["Bash","Linux"],"title":"Linux查漏补缺-1-链接","uri":"https://hex-go.github.io/posts/bash/2022-10-25-linux%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA-1-%E9%93%BE%E6%8E%A5/"},{"content":"1. 简介 本博客站使用hugo引擎，使用zzo主题并略作调整搭建起来。本文记录hugo的概念说明以及使用备忘。\n2. 说明 2.1 目录结构 1 2 3 4 5 6 7 8 9 10 11 12 13 hex-go.github.io ├── archetypes/ # 博客模板目录 │ └── default.md ├── config/ # 配置文件 ├── content/ # 博客主要内容，也是网站资源的顶层 ├── public/ # 默认存放hugo构建后的编译文件(gitignore) ├── resources/ # 缓存一些文件以加快生成速度(gitignore) ├── static/ # 静态文件 ├── themes/ # 主题（git add submodule） ├── .gitignore # 不进行版本控制的文件和目录 ├── .gitmodules # 记录主题submodule信息 ├── Makefile # make 命令 └── README.md # 本文档 2.2 内容管理 hugo的顶层为./content/\u0026lt;DIRECTORIES\u0026gt;，是用于确定布局等的内容类型。 要了解有关部分的更多信息，包括如何嵌套它们，请参阅部分。\nPage bundles: Hugo 通过Page bundles来表示页面相关的图像和其他资源。 _index.md 在 Hugo 中具有特殊作用。它允许你在列表模板中添加前置内容和内容。这些模板包括章节模板、分类模板、分类术语模板和主页模板。\n1 2 3 4 5 6 7 8 9 10 11 12 . └── content └── about | └── index.md // \u0026lt;- https://example.org/about/ ├── posts | ├── firstpost.md // \u0026lt;- https://example.org/posts/firstpost/ | ├── happy | | └── ness.md // \u0026lt;- https://example.org/posts/happy/ness/ | └── secondpost.md // \u0026lt;- https://example.org/posts/secondpost/ └── quote ├── first.md // \u0026lt;- https://example.org/quote/first/ └── second.md // \u0026lt;- https://example.org/quote/second/ 2.1 配置 配置文件\n1 2 3 4 5 ./config/ └── _default ├── config.toml ├── menus.toml └── params.toml 2.1.1 内容宽度 如果想增大博客屏幕尺寸，只需更改params.toml文件中的viewportSizeref-1值即可。一共5个选项，对应尺寸为：\n选项 对应宽度 naroow 800px normal 960px（默认） wide 1280px wider 1440px widest 1600px 2.1.2 目录设置(Toc) config.toml中关于博客目录Toc的设置 \u0026ndash; 设置博客目录以Hx起始，以及截止Hx：\n1 2 3 4 [markup.tableOfContents] endLevel = 4 ordered = false startLevel = 2 必须设置此配置参数，否则 toc 将无法运行。以上面配置为例，startLevel和endLevel意味着最多使用 h2 标签，最少使用 h4 标签作为文章标题。而 h1、h5、h6 标签不会包含在 TOC 元素中。\n博客目录可以在params.toml（全局生效）中设置，也可以在单一博客的Front-Matters(当前博客)中设置。\nparams.toml配置举例:\n1 2 3 4 5 6 7 # 博客目录 enableToc = true # 目录是否启用 hideToc = false # 目录是否隐藏 enableTocSwitch = true # 是否启用 目录隐藏\\显示 按钮 tocFolding = false # 目录是否动态显示 tocPosition = \u0026#34;outer\u0026#34; # 文档目录结构位置: 内联(inner)、外嵌(outer)。 tocLevels = [\u0026#34;h2\u0026#34;, \u0026#34;h3\u0026#34;, \u0026#34;h4\u0026#34;] # 目录所包含的标题，还受config.toml中的markup.tableOfContents配置影响 参数 说明 enableToc 在所有文章中是否显示目录，true: 显示；false: 不显示 toc 在所有文章中完全取消提示。这是 enableToc 的别名 enableTocSwitch 开启目录隐藏\\显示按钮，true: 开启；false: 隐藏 hideToc 隐藏toc(搭配enableTocSwitch=true时,默认隐藏目录)。true: 隐藏; false: 不隐藏 enableTocContent 在主文章中显示提示，不在侧边栏中显示。 tocPosition oneof [inner outer]。 inner: toc将位于边框内;；outer: Toc将位于边框之外。 tocFolding 是否动态显示目录, 默认折叠,查看至相应内容时展开当前目录 tocLevels 标题是否在目录中显示，优先级没有config.toml中的高 minimum h2, maximum h4 in your article 2.1.3 侧边栏设置 参数 说明 enableBio Bio(biography),生平 enableBioImage enableSidebar 侧边栏显示 enableSidebarTags enableSidebarSeries 侧边栏 - 系列显示 enableSidebarCategories 侧边栏 - 分类显示 enableHomeSidebarTitles 启用主页侧边栏字幕 enableListSidebarTitles itemsPerCategory enableSidebarPostsByOrder sidebarPosition 2.2 博客结构 2.2.1 调整sidebar顺序 如何修改\nzzo主题关于sidebar的标签、分类、系列的排序，未设置配置项，需要找到关于sidebar的内容部分进行调整。\nsidebar关于这些的内容在在themes/zzo/layouts/partials/sidebar目录下，分别为sidebar-home.html与sidebar-list.html\n如何生效\n由于使用git 子模块引用的主题文件，需要执行以下操作，引用最新提交的zzo主题文件\n首先,进入包含子模块的父仓库的根目录。\n使用以下命令来更新子模块内容：\n添加 --init 选项, 可在更新子模块的同时，初始化子模块\n1 git submodule update --remote --init 在父仓库中提交子模块变更\n1 2 git add path/to/submodule # 将子模块的路径添加到父仓库的暂存区 git commit -m \u0026#34;Update submodule to latest commit\u0026#34; 2.3 博客编写 2.3.1 Archetype(模板) Hugo提供Archetypes(原型)能力，定义通用的模板, 一是为了保证博客内容和数据的一致性; 二是为了快速生成,提高效率。\n如何创建\narchetype需要以类型为名称,并将模板文件保存至archetypes/目录下,以golang模板举例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 --- title: \u0026#39;{{ replace (replaceRE `\\d{4}-\\d{2}-\\d{2}-` \u0026#34;\u0026#34; .Name) \u0026#34;_\u0026#34; \u0026#34;: \u0026#34; |title}}\u0026#39; categories: - Golang tags: - Go subtitle: \u0026#34;\u0026#34; description: date: {{ .Date }} toc: true --- ## 1.简介 ## 2.说明 ## 3.总结 ## 4.参考 方法\nreplaceRE: 根据正则替换,将符合正则表达式的内容替换为指定字符, 上面模板将.Name中的日期前缀置为空;\nreplace: 将字符串中的某些字符替换为特定字符, 此处将去除日期前缀的.Name中的_字符替换为: 变量Page variables\n.Name: 当前页面名称\n.Date: 返回给定页面的日期\n如何使用\n根据指定类型,创建博客\nkind: 博客类型, 需要与archetypes目录下的模板名称保持一致, 此处以golang举例;\ntarget_file_path: 博客生成位置, 此处以content/posts/golang/2020-05-25-Go-Modules版本控制和依赖管理.md举例;\n1 hugo new --kind \u0026lt;kind|golang\u0026gt; \u0026lt;target_file_path|content/posts/golang/2020-05-25-Go-Modules版本控制和依赖管理.md\u0026gt; 2.3.2 Front-Matters Hugo将每个博客的开头区块定义为Front Matter(扉页)，定义一些当前博客相关的内容、设置。\n2.3.3 引用 在 Hugo 中，通过ref 和 relref创建链接引用或获取其他页面的元数据。根据hugo文档与源码注释，ref 用于获取相对于 Hugo 根目录的页面路径，\nrelref 用于获取相对于当前页面的页面路径。但经过翻阅源码、测试，两者没有区别，建议选用ref即可\nHeading IDs hugo会自动给文档标题增加Head_ID, 可以通过此引用具体的小节。但部分字符会被转义，因此点击目标标题的索引查看，便于确认转义后的Head_ID\n举例说明：\n文章路径中的.md后缀可带、可不带；\n示例目录结构\n1 2 3 4 5 6 7 8 9 10 11 12 . └── content ├── page | ├── about.md // \u0026lt;- https://example.org/posts/about/ | ├── friend.md // \u0026lt;- https://example.org/posts/friend/ | └── share.md // \u0026lt;- https://example.org/posts/share/ └── posts ├── kubernetes | └── 2019-12-13-k8s小技巧.md // \u0026lt;- https://example.org/posts/kubernetes/2019-12-13-k8s小技巧/ └── 个人工具 ├── 2019-06-22-hexo--常用命令备忘录.md // \u0026lt;- https://example.org/posts/个人工具/2019-06-22-hexo--常用命令备忘录/ └── 2022-09-30-博客迁移-1_调研hugo框架zzo主题.md // \u0026lt;- https://example.org/posts/个人工具/2022-09-30-博客迁移-1_调研hugo框架zzo主题/ base 页面为 content/posts/个人工具/2022-09-30-博客迁移-1_调研hugo框架zzo主题.md\n1 2 [friend](https://hex-go.github.io/page/friend/) [about](https://hex-go.github.io/page/about/) 相对引用文章\n相对引用示例-引用文章 相对引用文章，标题\n相对引用示例-异文章引用标题 当前文章，引用标题\n相对引用示例-当前文章引用标题 绝对引用标题\n绝对引用-标题示例 2.3.3 相关内容 此配置影响博客结尾的相关文章，由于相关文章设置最大显示5条(zzo主题中已写死)\n自定义相关内容算法中不同因素的权重，结合threshold=80，相关文章最大5条\n相同系列的文章，也必定为相关文章（合理） 文章\u0026gt;3个相同关键字，则为相关文章（合理） 文章\u0026gt;3个相同tag，则为相同文章(合理) 日期不纳入相关性计算（合理） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 [related] # 相关内容设置 includeNewer = false # 包括更新日期比当前文章新的相关文章 threshold = 80 # 定义两篇文章之间标签匹配的阈值。标签匹配度高于阈值的文章将被视为相关文章。 toLower = false # 将标签、关键字转换成小写进行匹配，即 false：区分大小写 [[related.indices]] # 相关性 - 系列 name = \u0026#39;series\u0026#39; # 名称，series(系列) weight = 90 # 权重，在相关性计算中的权重，范围为正整数，值越大相关性越强，0：不进行相关性计算 type = \u0026#39;basic\u0026#39; # 相关性类型， basic基本类型 applyFilter = false # 是否应用过滤器，false：不应用 cardinalityThreshold = 0 # 关键字的基础阈值，0：没有基础阈值 pattern = \u0026#39;\u0026#39; # 正则表达式模式，可用正则进行过滤 toLower = false # 转小写 [[related.indices]] # 相关性 - 关键字 name = \u0026#39;keywords\u0026#39; # 名称，keywords(关键字) weight = 30 # 权重，30：标签在相关性计算中 权重较低 type = \u0026#39;basic\u0026#39; applyFilter = false cardinalityThreshold = 0 pattern = \u0026#39;\u0026#39; toLower = false [[related.indices]] # 相关性 - 标签 name = \u0026#39;tags\u0026#39; # 名称，tag(标签) weight = 30 # 权重，30：标签在相关性计算中 权重较低 type = \u0026#39;basic\u0026#39; applyFilter = false cardinalityThreshold = 0 pattern = \u0026#39;\u0026#39; toLower = false [[related.indices]] # 相关性 - 日期 name = \u0026#39;date\u0026#39; # 名称，date(日期) weight = 0 # 权重，0：日期不进行相关性计算 type = \u0026#39;basic\u0026#39; applyFilter = false cardinalityThreshold = 0 pattern = \u0026#39;\u0026#39; toLower = false 2.3.4 代码块 代码块增加文件路径作为标题\n1 echo hello! 将行号替换为指定字符, 比如 \u0026gt;或$, 以\u0026gt;举例：\n1 echo hello! 多语言代码块\njava javascript 1 System.out.println(\u0026#39;Hello World!\u0026#39;); 1 console.log(\u0026#39;Hello World!\u0026#39;); 3.总结 4.参考 Viewport Size – Z Themes Documentation (zzo-docs.vercel.app) ","description":"","id":32,"section":"posts","tags":["个人工具","Hugo"],"title":"博客迁移-1：调研hugo框架zzo主题","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-09-30-%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB-1_%E8%B0%83%E7%A0%94hugo%E6%A1%86%E6%9E%B6zzo%E4%B8%BB%E9%A2%98/"},{"content":"前言 PipeWire开发工作最早可以追溯到2015年，最初被认为是 “视频领域的 PulseAudio\u0026quot;，但后来也扩展到了音频领域。2021年4月发布的 Fedora34 成为了第一个默认采用了这项技术的发行版，其他桌面 Linux 发行版之后也很快跟进。相比之下，Ubuntu 进度远远落后于其竞争对手。 PipeWire 的优点： - 首先 PipeWire 的实现方式更新，开发也更加积极，bug 相对也就更少； - 其次 PipeWire 有更好的硬件兼容性(PulseAudio 不支持很多新的蓝牙耳机)，还减少了 CPU 的使用，代码基础更现代化； - 与PulseAudio相比，对现代蓝牙音频设备（例如，Apple Air Pods）的支持更好； WirePlumber, 一个流行的PipeWire会话和策略管理器。 Ubuntu 22.04 LTS 的默认镜像会同时安装 PipeWire 和 PulseAudio。 PipeWire 只用于视频，PulseAudio 处理音频。需要手动将 PipeWire 设为默认的音频服务器。 Ubuntu 22.10（代号 \u0026quot;Kinetic Kudu\u0026quot;）开发版本的日常构建中，Pipewire已经取代了 PulseAudio，成为了 Ubuntu 的默认音频服务器，不再需要任何设置。 配置PipeWire为默认音频服务器 Ubuntu 22.04部分安装并启用了PipeWire。启用剩余的部分，并使用PipeWire进行音频和蓝牙，而不是PulseAudio。\n安装 检查环境\nPipewire预先安装，并自动作为后台服务运行。在终端运行下面的命令来进行确认\n1 systemctl --user status pipewire pipewire-session-manager 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ● pipewire.service - PipeWire Multimedia Service Loaded: loaded (/usr/lib/systemd/user/pipewire.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-09-29 14:21:51 CST; 8min ago TriggeredBy: ● pipewire.socket Main PID: 2657 (pipewire) Tasks: 2 (limit: 75541) Memory: 6.6M CPU: 142ms CGroup: /user.slice/user-1000.slice/user@1000.service/session.slice/pipewire.service └─2657 /usr/bin/pipewire Sep 29 14:21:51 hex-Pad systemd[2650]: Started PipeWire Multimedia Service. Sep 29 14:21:51 hex-Pad pipewire[2657]: Cannot connect to server socket err = 没有那个文件或目录 Sep 29 14:21:51 hex-Pad pipewire[2657]: Cannot connect to server request channel Sep 29 14:21:51 hex-Pad pipewire[2657]: jack server is not running or cannot be started Sep 29 14:21:51 hex-Pad pipewire[2657]: JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock Sep 29 14:21:51 hex-Pad pipewire[2657]: JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock Sep 29 14:21:51 hex-Pad pipewire[2657]: jack-device 0x5595b2c0bd58: can\u0026#39;t open client: 拒绝连接 ● pipewire-media-session.service - PipeWire Media Session Manager Loaded: loaded (/usr/lib/systemd/user/pipewire-media-session.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-09-29 14:21:51 CST; 8min ago Main PID: 2658 (pipewire-media-) Tasks: 2 (limit: 75541) Memory: 4.9M CPU: 108ms CGroup: /user.slice/user-1000.slice/user@1000.service/session.slice/pipewire-media-session.service └─2658 /usr/bin/pipewire-media-session Sep 29 14:21:51 hex-Pad systemd[2650]: Started PipeWire Media Session Manager. 安装客户端包\n默认情况下，音频输出并。运行命令安装客户端库：\n1 sudo apt install pipewire-audio-client-libraries libspa-0.2-bluetooth libspa-0.2-jack 安装WirePlumber作为会话管理器：\n1 sudo apt install pipewire-media-session- wireplumber 注意\u0026rsquo;pipe - wire-media-session\u0026rsquo;后面的\u0026rsquo;-\u0026rsquo;。这是为了在同一个命令中删除它，因为将使用\u0026rsquo;wireplumber\u0026rsquo;代替。\n1 systemctl --user --now enable wireplumber.service 安装蓝牙编码器 AAC/LDAC/AptX:\n1 2 3 4 sudo apt install \\ libfdk-aac2 \\ libldacbt-{abr,enc}2 \\ libopenaptx0 配置 Wireplumber使事情变得非常容易！如果只想用PipeWire替换Pulseaudio，则启用媒体会话服务和重新启动，仅此而已！\nALSA客户端配置PipeWire输出\n将PipeWire示例中的配置文件复制到ALSA配置目录中：\n1 sudo cp /usr/share/doc/pipewire/examples/alsa.conf.d/99-pipewire-default.conf /etc/alsa/conf.d/ JACK客户端配置PipeWire输出:\n1 sudo cp /usr/share/doc/pipewire/examples/ld.so.conf.d/pipewire-jack-*.conf /etc/ld.so.conf.d/ sudo ldconfig\nBluetooth客户端\n只需删除此包装，蓝牙将由PipeWire处理：\n1 sudo apt remove pulseaudio-module-bluetooth 检查 通过客户端工具pactl检查： 1 LANG=C pactl info | grep \u0026#39;^Server Name\u0026#39; 返回值\n1 Server Name: PulseAudio (on PipeWire 0.3.32) 通过systemctl检查pipewire服务状态 1 systemctl --user status pipewire pipewire-session-manager 配置返回值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 ● pipewire.service - PipeWire Multimedia Service Loaded: loaded (/usr/lib/systemd/user/pipewire.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-09-29 14:21:51 CST; 13min ago TriggeredBy: ● pipewire.socket Main PID: 2657 (pipewire) Tasks: 2 (limit: 75541) Memory: 7.7M CPU: 245ms CGroup: /user.slice/user-1000.slice/user@1000.service/session.slice/pipewire.service └─2657 /usr/bin/pipewire Sep 29 14:21:51 hex-Pad systemd[2650]: Started PipeWire Multimedia Service. Sep 29 14:21:51 hex-Pad pipewire[2657]: Cannot connect to server socket err = 没有那个文件或目录 Sep 29 14:21:51 hex-Pad pipewire[2657]: Cannot connect to server request channel Sep 29 14:21:51 hex-Pad pipewire[2657]: jack server is not running or cannot be started Sep 29 14:21:51 hex-Pad pipewire[2657]: JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock Sep 29 14:21:51 hex-Pad pipewire[2657]: JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock Sep 29 14:21:51 hex-Pad pipewire[2657]: jack-device 0x5595b2c0bd58: can\u0026#39;t open client: 拒绝连接 ● wireplumber.service - Multimedia Service Session Manager Loaded: loaded (/usr/lib/systemd/user/wireplumber.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-09-29 14:33:58 CST; 1min 26s ago Main PID: 10292 (wireplumber) Tasks: 4 (limit: 75541) Memory: 7.2M CPU: 170ms CGroup: /user.slice/user-1000.slice/user@1000.service/session.slice/wireplumber.service └─10292 /usr/bin/wireplumber Sep 29 14:33:58 hex-Pad systemd[2650]: Started Multimedia Service Session Manager. Sep 29 14:33:58 hex-Pad wireplumber[10292]: Failed to set scheduler settings: Operation not permitted Sep 29 14:33:59 hex-Pad wireplumber[10292]: \u0026lt;WpSiAudioAdapter:0x55ae534170e0\u0026gt; Object activation aborted: proxy destroyed Sep 29 14:33:59 hex-Pad wireplumber[10292]: \u0026lt;WpSiAudioAdapter:0x55ae534170e0\u0026gt; failed to activate item: Object activation aborted: proxy destroyed 检查已安装deb包\n1 2 3 4 5 apt list --installed | grep libldac apt list --installed | grep pipewire apt show pipewire-pulse 其他问题 1. systemctl \u0026ndash;user status 执行失败 ubuntu22.04 登录会出现问题，导致出现报错\n1 process org.freedesktop.systemd1 exited with status 1 原因是：缺少环境变量XDG_RUNTIME_DIR， 怀疑之前将18.04$HOME目录下内容覆盖了22.04下的内容，导致~/.profile或~/.bashrc的内容出现问题。目前通过下面命令进行屏蔽\n1 echo \u0026#34;export XDG_RUNTIME_DIR=/run/user/$(id -u)\u0026#34; \u0026gt;\u0026gt; /$HOME/.profile 2. wireplumber在pipewire-media-session未卸载之前，为masked状态无法enable mask 是个比disable更彻底的状态。\n使用disable会删除服务相关的unit-file；\n使用mask则会将其link至/dev/null，其对比disable的优势是防止任何形式的激活，包括手动\nsystemctl list-unit-files命令来显示unit-files的状态，(static, enabled, disabled, masked, indirect)\nsystemctl list-units命令来显示服务的状态\n3. 恢复pulseaudio为音频处理 要撤消更改，首先删除客户端库：\n1 sudo apt remove pipewire-audio-client-libraries libspa-0.2-bluetooth libspa-0.2-jack 删除WirePlumber并安装以前的pipewire-media-session\n1 sudo apt install pipewire-media-session wireplumber- 最后，重新启用PipeWire-Media-Session服务：\n1 2 rm -f ~/.config/systemd/user/pipewire-session-manager.service systemctl --user --now enable pipewire-media-session 如果声音仍无法正常工作，尝试通过命令禁用PipeWire-Pulse服务：\n1 2 3 4 # 当前用户 systemctl --user --now disable pipewire-pulse.service pipewire-pulse.socket # 全局 sudo systemctl --global --now disable pipewire-pulse.service pipewire-pulse.socket 重新启用re-enable pulseaudio服务：\n1 2 3 4 # 当前用户 systemctl --user --now reenable pulseaudio.service pulseaudio.socket # 全局 sudo systemctl --global --now reenable pulseaudio.service pulseaudio.socket 重启\n1 2 3 systemctl --user restart pulseaudio reboot Reference 上下文：\nPipeWire is the default audio server in Ubuntu 22.10.\nPipeWire\nwireplumber\n配置：\nEnable PipeWire on Ubuntu 22.04\nHow to Use PipeWire to replace PulseAudio in Ubuntu 22.04\n其他\nWhy are some systemd services in the \u0026ldquo;masked\u0026rdquo; state?\nUnmask a Masked Service in Systemd\n","description":"","id":33,"section":"posts","tags":["个人工具"],"title":"Ubuntu22.04: 声卡驱动相关","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-09-28-ubuntu22.04_%E5%A3%B0%E5%8D%A1%E9%A9%B1%E5%8A%A8%E7%9B%B8%E5%85%B3/"},{"content":"重要 记录Ubuntu工作机中，一些自定义系统配置所在目录。方便备份和恢复开发环境。\ninstall Ubuntu-22.04 登录选择 ubuntu xorg apt update apt upgrade dpkg -i # 运行APPImage的依赖sudo dpkg -i $HOME/apps/packages/libfuse2_2.9.9-5ubuntu3_amd64.deb bash get-docker.sh install sougou install chrome; restart computer 拷贝个人配置cp -r -p \u0026lt;硬盘/home/hex/\u0026gt; /home/hex/ 重启检查 1.简介 1.1 文件夹书签(Nautilus Add Bookmarks) 配置文件所在目录 cat /home/hex/.config/gtk-3.0/bookmarks，内容如下：\n1 2 3 4 file:///home/hex/WeChatFiles/hexiang3941/FileStorage/File file:///home/hex/Desktop/github file:///home/hex/workspace file:///home/hex/Documents/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/%E5%85%AC%E5%8F%B8-4-%E8%BD%A6%E7%99%BE%E6%96%87%E6%A1%A3 注意：\n需要填绝对路径 先后顺序为目录显示顺序 文件保存退出，配置即生效 1.2 用户目录(xdg-user-dirs) 详细信息,请参考man xdg-user-dirs-update\n配置文件所在目录$HOME/.config/user-dirs.dirs，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # This file is written by xdg-user-dirs-update # If you want to change or add directories, just edit the line you\u0026#39;re # interested in. All local changes will be retained on the next run. # Format is XDG_xxx_DIR=\u0026#34;$HOME/yyy\u0026#34;, where yyy is a shell-escaped # homedir-relative path, or XDG_xxx_DIR=\u0026#34;/yyy\u0026#34;, where /yyy is an # absolute path. No other format is supported. # XDG_DESKTOP_DIR=\u0026#34;$HOME/Desktop\u0026#34; XDG_DOWNLOAD_DIR=\u0026#34;$HOME/Downloads\u0026#34; XDG_TEMPLATES_DIR=\u0026#34;$HOME/Templates\u0026#34; XDG_PUBLICSHARE_DIR=\u0026#34;$HOME/Public\u0026#34; XDG_DOCUMENTS_DIR=\u0026#34;$HOME/Documents\u0026#34; XDG_PICTURES_DIR=\u0026#34;$HOME/Pictures\u0026#34; XDG_Apps_DIR=\u0026#34;$HOME/apps\u0026#34; XDG_WORKSPACE_DIR=\u0026#34;$HOME/workspace\u0026#34; XDG_MUSIC_DIR=\u0026#34;$HOME/Music\u0026#34; XDG_VIDEOS_DIR=\u0026#34;$HOME/Videos\u0026#34; 以上内容，为命令xdg-user-dirs-update生成。通常在用户会话开始时自动执行，来根据语言环境更新用户dirs。此逻辑由下面配置文件/etc/xdg/user-dirs.conf控制\n1 2 3 4 5 6 7 8 9 10 11 # This controls the behaviour of xdg-user-dirs-update which is run on user login # You can also have per-user config in ~/.config/user-dirs.conf, or specify # the XDG_CONFIG_HOME and/or XDG_CONFIG_DIRS to override this # enabled=True # This sets the filename encoding to use. You can specify an explicit # encoding, or \u0026#34;locale\u0026#34; which means the encoding of the users locale # will be used filename_encoding=UTF-8 有些目录像Music\\Vedio不会经常使用，不想让系统自动创建，可以讲上面配置文件设置为enabled=False。但这样会导致部分问题\n比如Nautilus文件工具通过$HOME/Template目录中文件，显示新建文件时的选项。删除此目录会导致鼠标右键无新建文件选项。\n(但其他文件管理系统Thunar[xfce默认]、Nemo[cinnamon默认]没有这个问题)\n隐藏不需要目录方法：\n一种：删除目录，并执行命令xdg-user-dirs-update 另一种：改变位置 最后一种：手动修改文件，并讲设置为false，禁止自动更新 简单操作举例：\n1 2 3 4 5 6 # 1. 创建默认目录 xdg-user-dirs-update # 2. 创建自定义目录 xdg-user-dirs-update --set DOWNLOAD ~/Internet # 3. 查询 xdg-user-dir TEMPLATES 1.3 本地Desktop存储目录 配置文件目录$HOME/.local/share/applications/， 配置文件jetbrains-goland.desktop示例如下：\n1 2 3 4 5 6 7 8 9 10 [Desktop Entry] Version=1.0 Type=Application Name=GoLand Icon=/home/hex/apps/GoLand-2021.1.3/bin/goland.svg Exec=\u0026#34;/home/hex/apps/GoLand-2021.1.3/bin/goland.sh\u0026#34; %f Comment=Cross-platform IDE built specially for Go developers Categories=Development;IDE; Terminal=false StartupWMClass=jetbrains-goland 1.4 快捷键存储目录(keyboard) 1.5 运行appImage失败 原因：Ubuntu 22.04 不再默认安装 libfuse2，导致运行appImage时报错如下\n1 2 3 4 5 AppImages require FUSE to run. You might still be able to extract the contents of this AppImage if you run it with the --appimage-extract option. See https://github.com/AppImage/AppImageKit/wiki/FUSE for more information 需要安装libfuse2\n1.5 截图工具flameshot无法使用(Gnome4.1+) 在登录时，选择ubuntu xorg则解决问题\n1 sudo apt install libfuse2 或者离线安装\n1 sudo dpkg -i $HOME/apps/packages/libfuse2_2.9.9-5ubuntu3_amd64.deb 1.6 压缩包安装Typora 解压安装包\n1 2 3 mkdir /tmp/typora tar -zxvf /home/hex/apps/packages/办公软件/Typora-linux-x64.tar.gz -C /tmp/typora mv /tmp/typora/bin/Typora-linux-x64 $HOME/apps/Typora 创建软连接\n是为了在命令行执行 typora \u0026lt;/md/file/path\u0026gt;, 打开命令行工具\n1 ln -s /home/hex/apps/Typora/Typora /usr/local/bin/typora 创建Desktop\n将以下内容拷贝至文件/home/hex/.local/share/applications/self-typora.desktop\n1 2 3 4 5 6 [Desktop Entry] Name=typora Exec=/home/hex/apps/Typora/Typora Icon=/home/hex/apps/Typora/resources/app/asserts/icon/icon_512x512.png Type=Application StartupNotify=true 文件保存即生效\n1.7 卸载软件 1 2 3 sudo apt-get remove --purge libreoffice* sudo apt clean sudo apt-get autoremove 1.8 个性化设置 点击最小化\n1 gsettings set org.gnome.shell.extensions.dash-to-dock click-action \u0026#39;minimize\u0026#39; 执行后即时生效\n显示电池电量百分比\nSettings - Power - Show Battery Percentage 点击开启\n改变图标大小\nSettings - Appearance - Dock Icon size 设置值 48 Settings - Appearance - Dock Icon size 设置值 48 显示设置\nUbuntu一般会自动识别HI-DPI屏幕并适当扩展。如果没有，需要手动进行调整。\nSettings -\u0026gt; Displays -\u0026gt; enable Fractional scaling -\u0026gt; 选择合适地比例\ndocker-run 地微信显示出现问题，调整DPI环境变量。此值计算方式为分别率/英寸，例如200\n安装字体、编解码器\n微软字体、主流媒体格式\n1 sudo apt install ubuntu-restricted-extras 1.9 声音 检查pulseaudio状态\n1 pulseaudio --check 它通常不打印输出，只需退出代码即可。0表示运行。\n停止\n1 2 3 pulseaudio -k # or killall pulseaudio 后台期待\n1 pulseaudio -D Reference ","description":"","id":34,"section":"posts","tags":["个人工具"],"title":"Ubuntu: 个性化配置及保存路径","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-09-19-ubuntu_%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BF%9D%E5%AD%98%E8%B7%AF%E5%BE%84/"},{"content":"重要 最重要的事:\n1.简介 Reference vimium进阶篇：高级技巧,高手必知\n知乎-vimium常见问题及处理方式\n","description":"","id":35,"section":"posts","tags":["个人工具"],"title":"浏览器插件: vimium使用和配置","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-08-23-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%8F%92%E4%BB%B6-vimium_%E4%BD%BF%E7%94%A8%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"content":"重要 环境说明 问题 1. Implicit memory aliasing in for loop 报错意思是：在循环中重复使用变量的地址 参考链接\n因为for语句中变量是被重用的，即变量内存地址不变，但值发生变化。当取消引用指针时，值可能发生改变，所以静态检查报错\n1.1 错误写法 1 2 3 4 for i, v := range versions { res := createWorkerFor(\u0026amp;v) ... } 1.2 正确写法 for循环中使用元素的实际地址i,而非迭代变量取值（推荐） 1 2 3 for i := range versions { res := createWorkerFor(\u0026amp;versions[i]) } 在每次循环时重新初始化迭代变量 1 2 3 4 for _, v := range versions { v := v res := createWorkerFor(\u0026amp;v) // this is now the address of the inner v } 使用闭包 1 2 3 4 5 for _, v := range versions { go func(arg ObjectDescription) { x := \u0026amp;arg // safe }(v) } 2. commentFormatting: put a space between // and comment text 注释后面需要加空格\n2.1 错误写法 1 //UpdatePatch update patch - edit qlet`s information, and generate a new version patch 2.2 正确写法 1 // UpdatePatch update patch - edit qlet`s information, and generate a new version patch 2.3 IDE配置 goland中，可以点击File - Settings - Editor - Code Style - Go -Other下，勾选Add a leading space to comments。可以实现注释代码时自动在//后加空格。\n3. Consider preallocating (prealloc) lint 考虑 预先分配问题 参考链接\n使用make预先分配合理的内存空间，能减少复制和扩展。\n3.1 错误写法 1 2 3 4 var to []string for i := range s.To { to = append(to, s.To[i].String()) } 3.2 正确写法 1 2 3 4 to := make([]string, 0, len(s.To)) for i := range s.To { to = append(to, s.To[i].String()) } 或者干脆使用append，直接对切片对象赋值\n1 2 3 4 to := make([]string, len(s.To)) for i, t := range s.To { to[i] = t.String() } 4. should replace errors.New(fmt.Sprintf(…)) with fmt.Errorf(…) go 1.13之后，推荐使用fmt.Errof(\u0026quot;%w\u0026quot;,err)来生成error\n4.1 错误写法 1 errors.New(fmt.Sprintf(\u0026#34;error is %s\u0026#34;, err.Error())) 4.2 正确写法 1 fmt.Errorf(\u0026#34;error is %w\u0026#34;, err) 5. error strings should not be capitalized or end with punctuation or a newline error 信息不应该: 以大写字母开头 或 以标点符号\\换行结尾。\n6. don’t use MixedCaps in package name 包的名称不能大小写混写，应全小写\n6.1 错误写法 1 package fileUtils 6.2 正确写法 1 package fileutils 7. exported type T should have comment or be unexported 暴露出去的结构体或方法，应该加注释或不对外暴露。\n8. comment on exported type U should be of the form \u0026ldquo;U ..\u0026rdquo; 暴露出去的类型U的注释，应该为这种格式// U xxx。即以变量名开头\n9. 使用errors.Is方法替代 使用errors.Is方法替换错误信息校验\n###　9.1 错误写法\n1 2 3 4 5 6 7 8 9 if fieldErr, ok := err.(validator.ValidationErrors); ok { var tagErrorMsg []string for key, value := range fieldErr.Translate(validate.Trans) { tagErrorMsg = append(tagErrorMsg, fmt.Sprintf(\u0026#34;%s: %s\u0026#34;, key, value)) } respErr := errors.New(strings.Join(tagErrorMsg, \u0026#34;,\u0026#34;)) return respErr } 9.2 正确写法 1 2 3 4 5 6 7 8 9 10 var fieldErr validator.ValidationErrors if errors.Is(err, fieldErr) { var tagErrorMsg []string for key, value := range fieldErr.Translate(validate.Trans) { tagErrorMsg = append(tagErrorMsg, fmt.Sprintf(\u0026#34;%s: %s\u0026#34;, key, value)) } respErr := errors.New(strings.Join(tagErrorMsg, \u0026#34;,\u0026#34;)) return respErr } Reference golint错误检查以及 min-confidence 不同等级的错误提示 ","description":"","id":36,"section":"posts","tags":["Go"],"title":"golangci-lint常见报错说明及修复建议","uri":"https://hex-go.github.io/posts/golang/2022-08-04-golangci-lint%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99%E8%AF%B4%E6%98%8E%E5%8F%8A%E4%BF%AE%E5%A4%8D%E5%BB%BA%E8%AE%AE/"},{"content":"重要 最重要的事:\n1.简介 1.2 本地模式 WindTerm有两种模式:\n远程模式\nWindTerm的远程模式是默认的模式。 在远程模式下,每个键按下发送到服务器就像其他终端。\n本地模式\n本地模式主要用于浏览文本。 在本地模式下,每个键按下将解析本地,而不是发送到服务器。\n支持大多数本地模式 导航 ， 滚动 ， 搜索 ， 复制和粘贴 ， 选择 和 折叠 Vim的捷径。\n当WindTerm在本地模式下,它就像一个只读的文本编辑器,这是非常方便的文本浏览。 特别是,快速滚动,不断输出时,切换到本地模式可以输出的立即停止滚动,方便阅读。\n快捷方式 行动 Alt + Enter 远程和本地模式切换（Toggle the remote and local mode） i 切换回远程模式（Switch back to remote mode from local mode） p 粘贴、切换回远程模式（Paste and switch back to remote mode from local mode） Ctrl + v 粘贴、切换回远程模式（Paste and switch back to remote mode from local mode） 本地模式Vim导航键说明\nShortcut Action h 左移（Move left） j 下移（Move down） k 上移（Move up） l 右移（Move right） 0 行首（Move to the begining of the line） $ 行尾（Move to the end of the line） ^ 行首非空字符（Move to the first non-blank character of the line） w 下一个单词（Move to next word） W 下一个空白分隔词（Move to next blank delimited word） b 词首（Move to the beginning of the word） B 空白分隔词首（Move to the beginning of the blank delimted word） e 词尾（Move to the end of the word） E 空白分隔词尾（Move to the end of the blank delimited word） 1G 首行（Move to the first line of the session） nG N行（Move to nth line of the session） G 尾行（Move to the last line of the session） gg 开头（move to the beginning of the session） ge 行尾单词，词首（Move to the end of the previous word） gE Move to the end of the previous Blank delimited word - 非空句首（Move to the previous non-blank sentence） + 非空句尾（Move to the next non-blank sentence） ( 句首（Move to the previous sentence） ) 句尾（Move to the next sentence） { 段首（Move to the previous paragraph） } 段尾（Move to the next paragraph） 本地模式Vim文本复制说明\n在本地模式下，可以使用y{motion}复制，其中{motion}是上面导航快捷键或搜索快捷键。例如，yw 复制下一个单词的开头。其他有用的副本命令包括：\n快捷键 动作 yy 复制当前行，包括换行符、新行起始字符（如hex@hex-ThinkPad:~$）；复制选中内容 y$ 复制当前行，不包括换行符、新行起始字符 yw 复制到下一个单词开头 ytx 当前光标位置向后复制至字符x,不包括x yfx 当前光标位置向后复制至字符x, 包括x p 粘贴、并返回Remote模式 P 粘贴、并保留Local模式(Vim文本) “xy{motion} 复制内容、并注册给变量x “xp 黏贴变量x中的内容、并返回Remote模式 “xP 黏贴变量x中的内容、并保留Local模式(Vim文本) “+y{motion} 复制内容、至系统粘贴板 “+p 从系统粘贴板粘贴、并返回Remote模式 “+P 从系统粘贴板粘贴、并保留Local模式(Vim文本) 1.2 快捷键记录 快捷键 动作 Ctrl+Shift+W 关闭页签（Close tab） Ctrl+Shift+T 回复页签（Restore tab） Ctrl+Shift+Left 转至前提示行（Goto the previous prompt line） Ctrl+Shift+Right 转至后提示行（Goto the next prompt line） Ctrl+Alt+L 锁屏 Alt+1 选择1页签 Alt+O 打开页签 Alt+S 搜索页签 批量发送（Sender Pane）快捷键 快捷键 动作 Alt+Enter 发送（Send） Alt+Q 停止（Stop） Alt+= 增加新的发送记录（Add Sender） Alt+- 删除发送（Remove Sender） Alt+X 清空（Clear Sender） 文件传输（Sftp）快捷键 快捷键 动作 Alt+Enter 发送（Send） Alt+Q 停止（Stop） Alt+= 增加新的发送记录（Add Sender） Alt+- 删除发送（Remove Sender） Alt+X 清空（Clear Sender） 快捷键 动作 F2 文件重命名（Rename） F3 文件下载 （Download） F4 文件上传 （Upload） F5 目录刷新 （Refresh） F6 移动至 （Move to） Del 删除 （Remove） Return 打开 （Open） Backspace 返回上一层（Cdup） Alt+D 选中地址栏（Select the address bar） Alt+Left 向前回滚 （Go backward） Alt+Right 向后回滚 （Go forward） Alt+Return 属性 （Show property） Ctrl+A 全选 （Select all items） Ctrl+Shift+N 新建文件夹（Create a folder） Ctrl+N 新建文件 （Create a file） Ctrl+L 新建软链 （Create a link） Ctrl+C 复制名称 （Copy names） Ctrl+Shift+C 复制路径 （Copy paths） Ctrl+P 复制名称至终端（Copy names to terminal） Ctrl+Shift+P 复制名称至终端（Copy paths to terminal） 自动补全 自动补全会提示当前可用的命令、子命令、命令选项、命令参数、历史命令、快捷命令。\n自动补全-快捷命令 自动补全支持快捷栏（Alt+w-\u0026gt;Alt+Q在底部启用）中快速命令的补全。需要先在快捷命令中创建命令，自动补全索引的是快捷命令的名字。\n自动补全-历史命令 历史命令包含同一系统（如 Linux 系统）所有会话的命令历史记录,默认最大数量为 10000 条(30天)。\n在Session窗口，可以通过下面两种方式实现历史命令的自动补全：\n在行首输入! 或者，通过快捷键Ctrl+R 自由键入模式 自由键入模式：键入shell命令、使用VIM应用程序时，可以使用鼠标移动光标、选择文本、拖放文本。\n按住Alt后，在需要的位置点击左键鼠标，即可将游标移动至任意位置（当会话-终端为xterm、xterm-256color时，只需要点击鼠标即可）； 修改默认快捷键 目前没有自定义快捷键的功能，可以通过手动修改配置文件{应用程序目录}\\global\\wind.keymaps的方式设置issue-403\n修改复制快捷键（注意设置action，防止全局生效导致无法发送取消信号）参考此issue\n原配置内容为\n1 2 3 4 { \u0026#34;keys\u0026#34;: \u0026#34;\u0026lt;Ctrl+C\u0026gt;\u0026#34;, \u0026#34;modes\u0026#34;: \u0026#34;normal, local\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;Text.Copy\u0026#34; } 修改为\n1 2 3 4 5 { \u0026#34;keys\u0026#34;: \u0026#34;\u0026lt;Ctrl+C\u0026gt;\u0026#34;, \u0026#34;modes\u0026#34;: \u0026#34;normal, command, local, remote\u0026#34;, \u0026#34;when\u0026#34;: \u0026#34;window.activeText.isSelectionEmpty() == false\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;Text.Copy\u0026#34; } 修改粘贴快捷键\n原配置为：\n1 2 3 4 { \u0026#34;keys\u0026#34;: \u0026#34;\u0026lt;Shift+Ins\u0026gt;\u0026#34;, \u0026#34;modes\u0026#34;: \u0026#34;normal, command, local, remote\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;Text.Paste\u0026#34; } 修改为：\n1 2 3 4 { \u0026#34;keys\u0026#34;: \u0026#34;\u0026lt;Ctrl+V\u0026gt;\u0026#34;, \u0026#34;modes\u0026#34;: \u0026#34;normal, command, local, remote\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;Text.Paste\u0026#34; } 上面的json对象都是平级，功能取并集。而页面显示的靠后设置的json，可以将需要显示的配置放到文件末尾，让其在页面显示。只影响显示，不影响功能。\n本地操作kubectl最佳实践 目前wsl会出现乱码问题，因此不推荐在windows下使用。如果在linux下，通过以下配置\n通过不同环境创建不同目录，并在不同目录下保存相应的kubeconfig文件，在shell设置中，将工作目录与环境变量进行设置\nshell设置如下图\n目录结构仅供参考\n1 2 3 4 5 6 kube dev core .kubeconfig paas .kubeconfig 待解决问题：\n修改稿默认粘贴快捷键为ctrl+c后，导致无法发送取消信号，目前改回默认配置，参考此issue后修改\n打开wsl窗口后，使用vim会出现乱码ESC[0%m。目前通过ssh 127.0.0.1的方式操作wsl.此issue-232、issue-1544出现的乱码不同，且也为解决。暂时记录等后续再跟进\nReference ","description":"","id":37,"section":"posts","tags":["个人工具"],"title":"终端工具WindTerm使用","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-07-29-%E7%BB%88%E7%AB%AF%E5%B7%A5%E5%85%B7windterm%E4%BD%BF%E7%94%A8/"},{"content":"重要 最重要的事:\n1.简介 1.1 从LastPass迁移至Bitwarden import-from-lastpass\nlastPass导出 - Web端 左下角 Advanced Options - Export\nlastPass导出 - 浏览器插件 navigate to Account Options → Advanced → Export → LastPass CSV File\nBitwarden导入 Tools - Import Data - 选择文件格式(lastPass CSV) - 导入\n1.2 设置浏览器自动填充 auto-fill-browser\n快捷键 Windows: Ctrl + Shift + L\nMacOS: Cmd + Shift + L\nLinux: Ctrl + Shift + L\n页面加载时 浏览器插件图标，点击左键。Setting - Options - Enable Auto-fill on Page Load\n1.3 Web端设置中文显示 账号设置 - 偏好设置 - 语言\nACCOUNT SETTINGS - Preferences - Language\n1.4 Web端创建多层级文件夹 举例：\n创建 个人， 再创建个人/生活\n1.5 URI说明 URI匹配说明\n如果子域名相同(*.icos.city)，尽量不选择默认规则，否则无法区分。\n规则间关系是且，而非或， 所以可以通过正则实现多个域名用一个用户名密码访问。\n正则 只保证有唯一秘钥被匹配，下面正则并不严谨，但够用。这样自动填充就能、也只能填充唯一一个正确秘钥，节省时间。\nURI规则： ^(http|https)://((gitlab|zentao|jenkins).icos.city|(nextcloud|icoswiki).chebai.org)\n可匹配项：\n- https://zentao.icos.city\n- https://gitlab.icos.city\n- https://jenkins.icos.city\n- http://icoswiki.chebai.org\n- http://nextcloud.chebai.org\n1.6 Web修改未同步至浏览器插件 手动同步\n左键点击插件图标，点击右下角Setting - 点击上方 Sync按钮 手动同步\nReference Web端访问地址\n官方说明文档\nBitwarden 帮助中心中文版\n","description":"","id":38,"section":"posts","tags":["个人工具"],"title":"密码管理工具Bitwarden使用","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-07-28-%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7bitwarden%E4%BD%BF%E7%94%A8/"},{"content":"重要 最重要的事:\n1. 命令行快捷键 参见 man readline 来查看 Bash 中所有默认的键盘绑定, 可以使用 set -o vi 使用 vi 风格的键盘绑定。\n命令行编辑：光标移动\n##　1.1 行首、行尾\nCtrl + a: 转到行的开头。 == Home键 == alt + shift + b\nCtrl + e: 转到行的结尾。 == End键 == alt + shift + f\n##　1.2 前移、后移 1字符\nCtrl + b: 左移动1个字符。 == 方向左键\u0026lt;-\nCtrl + f: 右移动1个字符。 == 方向右键-\u0026gt;\n##　1.3 前移、后移 1单词\nCtrl + 方向左键\u0026lt;-: 左移动1个单词。== alt + b(back)\nCtrl + 方向左键-\u0026gt;: 右移动1个单词。== alt + f(forward)\n命令行编辑：快捷删除\n1.4 删除至行首、删除至行尾 Ctrl + u删除至行首，Ctrl + k删除至行尾。\n1.5 删除前一项 Ctrl + w删除删除光标处左边一个单词，或至单词首的内容。\n1.6 删除后一项 Alt + d: 删除光标处右边一个单词，或至单词末的内容\n1.7 删除前一字符 Ctrl + h: 删除删除光标处左边一个字符。\n1.8 删除后一字符 Ctrl + d: 删除光标处右边一个字符。\n1.9 插入上次删除的内容 Ctrl + y: 将上一次删除的内容插入到光标处。(光标不移动，等同于撤销操作)。\n命令行编辑：撤销\n1.10 撤销修改 Ctrl+shift+-：撤销，即恢复上一次操作，可撤销多次。\n注意，这个快捷根据自己系统设定不一样，有的Ctrl+shift+-是撤销，Ctrl+-是命令行字体变小，而有的系统设置刚好相反。\n命令行编辑：屏幕调整\n1.11 字体变小 Ctrl+-：命令行字体变小，注意看上面撤销修改Ctrl+shift+-的说明。\n1.12 字体变大 Ctrl+shift++：命令行字体变大。有的系统设置是Ctrl++，ctrl和+的组合是命令行字体变大。\n1.13 清屏 Ctrl+l: 清屏，但是当前命令行内容保留\n1.14 锁定 Ctrl+s: 锁定命令行\n1.14 解锁 Ctrl+Q: 解锁命令行\n命令行编辑：快捷输入\n1.15 使用上个命令最后一项 参数: !$ 或者 快捷键: alt+.\n1 ls /home/hex/ 1 cd !$ 等同于 cd /home/hex/\n1.16 使用上一个命令 参数: !!\n权限不足时 sudo !!\n1 2 3 vi /etc/hosts sudo !! 1.17 使用上次删除的内容 Ctrl + y: 将上一次删除的内容插入到光标处。(光标不移动，等同于撤销操作)。\n2. vim快捷键 3. bash常用命令 3.1 文件擦除数据 1 \u0026gt; /root/test.md 或者\n1 echo \u0026#39;\u0026#39; \u0026gt; /root/test.md 3.2 读取日志文件 3.2.1 实时读取日志文件 1 tail -F linuxidc_log 3.2.2 less读取文件 1 less -N linuxidc.txt //按下v键来编辑文件\n//退出编辑器后，可以继续用less浏览\n可以在更少的范围内搜索字词，按页移动，高亮与行号等。\n###　3.2.3 读取压缩日志而不解压缩\n使用zless，zcat，zgrep等z命令查看压缩包的内容，甚至不必显式提取压缩文件\n1 zcat linuxidc_log.zip | more 3.3 文件查找 3.3.1 查找包含特定文本的文件 1 grep -Pri 要搜索的字符串 路径 3.3.2 精通find命令 如何使用find命令在Linux中查找文件\n3.4 输出查看-表格 1 mount |column -t 3.5 SSH客户端配置优化 ~/.ssh/config 包含了\n避免在特定网络环境中连接被断掉的情况的设置 TCPKeepAlive=yes ServerAliveInterval=15 ServerAliveCountMax=6 使用压缩（这对于通过低带宽连接使用 scp 很有用） Compression=yes 使用一个本地控制文件来开启到同一台服务器的多通道 ControlMaster auto ControlPath /tmp/%r@%h:%p ControlPersist yes 1 2 3 4 5 6 7 TCPKeepAlive=yes ServerAliveInterval=15 ServerAliveCountMax=6 Compression=yes ControlMaster auto ControlPath /tmp/%r@%h:%p ControlPersist yes 文件传输 python2\ncaddy\n操作不被history记录 关闭history 1 history -c 操作命令前，加一个空格 清除指定history记录 1 history -d \u0026lt;num\u0026gt; 进程相关 查看运行时间 通过 -o 参数，指定只显示具体的某个字段，会得到更清晰的结果。\n通过 -o etime 获取该进程的运行时间(etime格式 = %d-%h:%m:%s etimes格式 = %s)\n1 ps -p 10167 -o etimes,etime -o rss 可以只获取该进程的内存信息\n资源使用率排序 内存使用率 排序 1 ps aux | sort -rnk 4 CPU使用率 排序 1 ps aux | sort -nk 3 网络相关 查看本机公网IP 1 2 3 curl ip.sb # 或 curl ifconfig.me Reference Linux常用命令行小技巧: 全面+有深度, 有点乱\n80%的人都不会的，15个Linux实用技巧: 清晰，量少\n30个高效的Linux命令技巧: Bash语法\n","description":"","id":39,"section":"posts","tags":["个人工具"],"title":"Linux常用快捷键","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-07-08-linux%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"content":"重要 最重要的事:\n1.简介 dd指令是一个简单的复制指令，它不管源和目标的编码、格式、数据结构，简单粗暴的把二进制数据从A复制到B。\n所以恢复的目标硬盘甚至不需要提前分区，因为dd会把分区信息也写入。\n不管源数据是文件、分区、磁盘还是光盘，都可以进行数据备份。\n优点：\n操作简单 缺点：\n速度慢 硬盘大小必须比源大 2. 操作 2.1 整盘复制 目标磁盘需要比源磁盘大。\nif=表示源磁盘，of=表示目标磁盘\n1 dd if=/dev/sda of=/dev/sdb 2.2 磁盘备份成文件再恢复 2.2.1 磁盘-\u0026gt;文件 bs参数: 一次拷贝的字节数。如：bs=4096。合理使用bs参数可优化dd执行速度，bs的合理范围要参考本机的性能进行具体设置。\n单备份 1 dd if=/dev/sda of=/home/sda.img bs=4096 备份并压缩 1 dd if=/dev/sda | gzip \u0026gt; /home/sda.img 2.2.2 文件-\u0026gt;磁盘 单备份 1 dd if=sdadisk.img of=/dev/sdb 从压缩文件恢复 1 gzip -dc /home/sda.img | dd of=/dev/sda 2.3 分区备份 把分区直接备份到另一个分区，就需要生成一个新的分区，这个分区的大小不能比源分区小，只能和源分区大小一致或比它大。\n查看磁盘sdb的分区表，查看所有分区uuid，此时各分区uuid各不相同。\n1 2 df -h blkid 备份\n1 dd if=/dev/sda1 of=/dev/sdb1 恢复\n1 dd if=/dev/sdb1 of=/dev/sda1 修复还原到大小不一样的分区时的设置：\n1 2 3 sudo dd if=/dev/sda1 of=/dev/sdb1 sudo e2fsck -f /dev/sdb1 sudo resize2fs /dev/sdb1 2.4 查看进度 watch 1 watch -n 5 killall -USR1 dd 2.5 销毁磁盘数据 原磁盘包含有敏感数据，因为所有删除甚至格式化的内容都有可能使用技术手段进行还原。使用dd命令即可完全抹盘。\n使用0填充整个硬盘：\n1 dd if=/dev/zero of=/dev/sda1 或者，使用随机数填充整个硬盘，效果更佳：\n1 dd if=/dev/urandom of=/dev/sda1 2.6 磁盘测速 1 2 dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file dd if=/root/1Gb.file bs=64k | dd of=/dev/null 2.7 磁盘修复 1 dd if=/dev/sda of=/dev/sda 或dd if=/dev/hda of=/dev/hda 2.8 制作系统盘 1 dd if=ubuntu-server-amd64.iso if=/dev/sdb 2.0 写指定大小文件 如大文件测试上传或下载的速度。下面命令生成一个文件名为 file.img 大小为 1G 的文件。\n1 dd if=/dev/zero of=file.img bs=1M count=1024 参考链接 Ubuntu 备份与恢复系统\nlinux使用dd命令备份系统\n","description":"","id":40,"section":"posts","tags":["个人工具","Disk"],"title":"Ubuntu系统dd命令备份和恢复系统","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-07-08-ubuntu_dd%E5%91%BD%E4%BB%A4%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D%E7%B3%BB%E7%BB%9F/"},{"content":"重要 目前主流的网盘系统都支持WebDAV连接方式，在windows系统下链接WebDAV以及是很常见的事情，如果能在Linux下链接WebDAV变成本地磁盘，那么可以把部分文件放置在WebDAV空间，甚至还可以通过网页转成外链链接。\n1.简介 常用的文件共享协议有三种：FTP、Samba、WebDAV\nWebDAV 基于 HTTP 协议的通信协议，在广域网上共享文件有天然的优势，移动端文件管理APP也大多支持WebDAV协议。使用HTTPS还能保安全性。Apache和Nginx支持WebDAV，可作为WebDAV文件共享服务器软件。也可以使用专门的WebDAV软件部署。\nwebdav 是 GitHub 上开源的项目，基于 Go 语言实现，不仅跨平台，还支持 ARM 架构，可在㠌入式设备中部署 WebDAV 服务器。\n2. 操作 2.1 运行阿里云盘-webDAV 环境准备 1. 参数说明 变量名称 描述 示例 ALIYUNPAN_REFRESH_TOKEN RefreshToken 024534dbe2384807b24abfd1ab84fd7d ALIYUNPAN_AUTH_USER webdav登录用户名，随意设置，磁盘挂载的时候使用 admin ALIYUNPAN_AUTH_PASSWORD webdav登录密码，随意设置，磁盘挂载的时候使用 admin ALIYUNPAN_PAN_DIR 网盘文件夹的webdav服务根目录 / ALIYUNPAN_TRANSFER_URL_TYPE 上传下载链接类型：1-默认 2-阿里ECS环境(ECS必须是经典网络类型) 1 ALIYUNPAN_BLOCK_SIZE 上传数据块大小，单位为KB，默认为1024KB，建议范围1024KB~10240KB 10240 2. 获取refresh-token 3. https配置(可选) nginx配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 server { listen 443; server_name your.host.com; ssl on; root html; index index.html index.htm; ssl_certificate /path/to/your/file.pem; ssl_certificate_key /path/to/your/file.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; # webdav server location /{ root html; proxy_pass http://127.0.0.1:23077; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_redirect off; } } 部署 1. docker-run部署 1 2 3 4 5 6 7 docker run -d --name=aliyundisk \\ --restart=always -p 23077:23077 \\ -e TZ=\u0026#34;Asia/Shanghai\u0026#34; \\ -e ALIYUNPAN_REFRESH_TOKEN=\u0026#34;024534dbe2384807b24abfd1ab84fd7d\u0026#34; \\ -e ALIYUNPAN_AUTH_USER=\u0026#34;admin\u0026#34; \\ -e ALIYUNPAN_AUTH_PASSWORD=\u0026#34;admin\u0026#34; \\ -e ALIYUNPAN_PAN_DIR=\u0026#34;/\u0026#34; tickstep/aliyunpan-webdav:v0.1.4 2. docker-compose部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 version: \u0026#39;3\u0026#39; services: webdav: image: tickstep/aliyunpan-webdav:\u0026lt;tag\u0026gt; container_name: aliyunpan-webdav restart: always ports: - 23077:23077 environment: - TZ=Asia/Shanghai # refresh token用于登录 - ALIYUNPAN_REFRESH_TOKEN=b9123...13e66a1 # webdav 登录用户名 - ALIYUNPAN_AUTH_USER=admin # webdav 登录密码 - ALIYUNPAN_AUTH_PASSWORD=admin # 指定网盘文件夹作为webdav服务根目录 - ALIYUNPAN_PAN_DIR=/ # 上传下载链接类型：1-默认 2-阿里ECS环境(ECS必须是经典网络类型) - ALIYUNPAN_TRANSFER_URL_TYPE=1 # 上传数据块大小，单位为KB，默认为1024KB，建议范围1024KB~10240KB - ALIYUNPAN_BLOCK_SIZE=10240 2.2 挂载webdav 1. 安装davfs2工具 centos\n1 yum install davfs2 ubuntu\n1 apt install davfs2 2. 挂载磁盘 执行命令后，按提示输入用户名密码（ALIYUNPAN_AUTH_USER和ALIYUNPAN_AUTH_PASSWORD的值）\n1 2 mkdir /aliyun-disk mount -t davfs https://pan.cloud.com/dav /aliyun-disk 3. 设置开机自动挂载 编辑davfs2.conf配置文件，将use_locks的1改为0 1 vim /etc/davfs2/davfs2.conf 修改secrets文件，添加账号信息 普通用户可以修改此文件~/.davfs2/secrets\n1 vim /etc/davfs2/secrets 在底部添加账号信息，如\n1 https://pan.cloud.com/dav user password 添加开机挂载命令 在 /etc/rc.d/rc.local文件或者/etc/profile.d/aliyundisk.sh中追加下面内容\n开机自动运行的几种方法：\n/etc/rc.d/rc.local： 文件会在 Linux 系统各项服务都启动完毕之后再被运行\ncrontab @rebot: 任务在系统重启之后自动运行某个命令\nsystemd：适用systemd系统\n/etc/profile.d/xx.sh: /etc/profile会遍历/etc/profile.d/*.sh\n/etc/profile： 此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行. 并从/etc/profile.d目录的配置文件中搜集shell的设置。 /etc/bashrc: 为每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取（即每次新开一个终端，都会执行bashrc）。 ~/.bash_profile: 每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次。默认情况下,设置一些环境变量,执行用户的.bashrc文件。 ~/.bashrc: 该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该文件被读取。你可以在这里设置你的个性化终端了. ~/.bash_logout: 当每次退出系统(退出bash shell)时,执行该文件. 另外,/etc/profile中设定的变量(全局)的可以作用于任何用户,而~/.bashrc等中设定的变量(局部)只能继承 /etc/profile中的变量,他们是**”父子”关系**。 ~/.bash_profile: 是交互式、login 方式进入 bash 运行的。~/.bashrc 是交互式 non-login 方式进入 bash 运行的通常二者设置大致相同，所以通常前者会调用后者。 1 mount -t davfs http://127.0.0.1:23077 /aliyundisk/ 4. 避坑 不能通过/etc/fstab的auto选项, 实现开机自动挂载\n1 http://127.0.0.1:23077 /aliyundisk/ davfs noauto,user 0 0 因为/etc/fstab在网络初始化之前执行，只有在建立网络连接之后才能装载webDAV共享，所以不能auto在/etc/fstab文件中使用该选项。自动挂载将失败。\n3. 可视化管理工具推荐 阿里云盘可视化管理工具-小白羊版\nReference 网络存储文件共享之WebDAV\nLinux配置WebDAV-server为共享存储\n阿里云盘命令行客户端，支持webdav文件服务\n阿里云盘可视化管理工具-小白羊版\n","description":"","id":41,"section":"posts","tags":["个人工具"],"title":"阿里云盘-WebDAV开机自动挂载","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-05-17-%E9%98%BF%E9%87%8C%E4%BA%91%E7%9B%98_webdav%E5%BC%80%E6%9C%BA%E8%87%AA%E5%8A%A8%E6%8C%82%E8%BD%BD/"},{"content":"重要 由于生产环境的函数服务需要编译go包，但内网无法访问互联网。所以需要搭建代理私仓，缓存第三方包。主要考虑的技术选型有两种: nexus和goproxy.\nnexus是能满足需求，但太重,并且go不支持认证,必须开启nexus的匿名模式。go-proxy功能比较简单。下面分别介绍nexus和goproxy的搭建方式，针对不同场景进行选择。\nnexus搭建go私仓库 待整理\ngoproxy搭建go私仓库 goproxy.io 是全球最早的Go modules镜像代理服务之一，采用CDN加速服务为开发者提供依赖下载, 该服务由一批热爱开源, 热爱 Go 语言的年轻人开发维护。从 Go 1.11 开始 Go 语言开始支持 Go modules 来解决大家长久以来诟病的依赖管理问题，目前 Go modules 功能已经符合生产环境标准。\ngoproxy命令介绍：\n参数 说明 默认值 示例 -listen 服务监听端口 \u0026ldquo;0.0.0.0:8081\u0026rdquo; -listen=0.0.0.0:80 -cacheDir 指定Go Module的缓存目录 \u0026ldquo;$GOPATH/pkg/mod/cache/download\u0026rdquo; -cacheDir=/tmp/test -proxy 指定上游 proxy server，推荐 goproxy.io \u0026quot;\u0026quot; -proxy https://goproxy.io -exclude proxy 模式下指定哪些 path 不经过上游服务器(例如内网仓库等) \u0026quot;\u0026quot; -exclude \u0026ldquo;git.example.com,rsc.io/private\u0026rdquo; 1 docker run -d -p80:8081 --name goproxy goproxy/goproxy -listen=0.0.0.0:8081 -cacheDir=/tmp/test -proxy https://goproxy.io -exclude \u0026#34;git.corp.example.com,rsc.io/private\u0026#34; 测试 在本地开发机上，通过环境变量将 proxy server 指定到你刚部署的服务器：\n1 2 3 export GO111MODULE=on export GOPROXY=http://[goproxy所在的机器IP]:80 export GOPATH=/tmp/go 接着运行下面命令，查看是否成功。\ngo get -v github.com/pkg/errors\n观察服务器日志输出是否正常\n执行命令docker logs -f goproxy\n1 2 3 4 5 6 7 8 9 10 11 12 goproxy.io: ------ --- /github.com/pkg/errors/@v/v0.9.1.mod [cached] goproxy.io: 0.000s 200 /github.com/pkg/errors/@v/v0.9.1.mod goproxy.io: ------ --- /github.com/@v/list [proxy] goproxy.io: ------ --- /github.com/pkg/errors/@v/list [proxy] goproxy.io: ------ --- /github.com/pkg/@v/list [proxy] goproxy.io: 0.684s 404 /github.com/@v/list goproxy.io: 0.846s 404 /github.com/pkg/@v/list goproxy.io: 1.315s 200 /github.com/pkg/errors/@v/list goproxy.io: ------ --- /github.com/pkg/errors/@v/v0.9.1.info [cached] goproxy.io: 0.000s 200 /github.com/pkg/errors/@v/v0.9.1.info goproxy.io: ------ --- /github.com/pkg/errors/@v/v0.9.1.zip [cached] goproxy.io: 0.000s 200 /github.com/pkg/errors/@v/v0.9.1.zip Reference nexus搭建\ngoproxy 官方文档\n","description":"","id":42,"section":"posts","tags":["Go","Proxy","Nexus"],"title":"内网搭建goproxy私仓","uri":"https://hex-go.github.io/posts/golang/2022-05-07-%E5%86%85%E7%BD%91%E6%90%AD%E5%BB%BAgoproxy%E7%A7%81%E4%BB%93/"},{"content":"重要 最重要的事:\n1.简介 set 命令是 Bash 脚本的重要环节，却常常被忽视，导致脚本的安全性和可维护性出问题。此处记录基本用法。\n2.使用 set命令用来修改 Shell 环境的运行参数，也就是定制环境。\n顺便提一下，如果命令行下不带任何参数，直接运行set，会显示所有的环境变量和 Shell 函数\n常用的四个命令如下\nu, 忽略空变量 x, 调试 结果前打印命令 e, 发生错误，立即终止 o pipefail, 管道子命令发生错误，立即终止 2.1 忽略不存在变量 忽略 执行脚本 中 不存在的变量。\n1 set -u 等同于\n1 set -o nounset 2.2 在打印结果之前，先打印命令。 在运行结果之前，先输出执行的命令。\n1 set -x 等同于\n1 set -o xtrace 2.3 错误处理 Bash 命令执行失败，默认会继续执行后面的命令。\n通过下面写法，当command有非零返回值，脚本就会停止执行。防止错误累积\n1 command || exit 1 退出时，执行额外操作\n1 command || { echo \u0026#34;command failed\u0026#34;; exit 1; } 等同于\n1 if ! command; then echo \u0026#34;command failed\u0026#34;; exit 1; fi 等同于\n1 if [ \u0026#34;$?\u0026#34; -ne 0 ]; then echo \u0026#34;command failed\u0026#34;; exit 1; fi 2.4 命令依赖 command1执行成功，再执行command2。\n1 command1 \u0026amp;\u0026amp; command2 2.5 发生错误，立即终止 脚本只要发生错误，就终止执行。但对|管道失效，具体原因看 2.6 小节\n1 set -e 等同于\n1 set -o errexit 脚本后续命令，非空返回为执行成功。则需要临时关闭set -e，来让命令正常执行\n1 2 3 4 5 6 7 8 9 #!/usr/bin/env bash set -e echo \u0026#34;初始设置 set -e 并执行命令\u0026#34; ## 临时关闭 set -e set +e echo \u0026#34;执行正常返回为非空的命令\u0026#34; # 重新打开 set -e set -e 也可以通过command || true的方式解决\n1 2 3 4 5 6 #!/bin/bash set -e command || true echo bar 2.6 子命令失败，整个管道命令就失败，脚本就会终止执行。 管道命令，就是多个子命令通过管道运算符|组合成为一个大的命令。Bash会把最后一个子命令的返回值，作为整个命令的返回值。\n也就是说，只要最后一个子命令不失败，管道命令总是会执行成功，因此它后面命令依然会执行，set -e 就失效了。\n例如\n1 2 3 4 5 #!/usr/bin/env bash set -e # 由于下面`echo \u0026#34;test\u0026#34;`成功，命令永远不会中断 mc | echo \u0026#34;test\u0026#34; echo bar 改为如下写法，解决管道问题\n1 2 3 4 5 #!/usr/bin/env bash set -eo pipefail foo | echo a echo bar 总结 上面参数总会一起使用\nu, 忽略空变量 x, 调试 结果前打印命令 e, 发生错误，立即终止 o pipefail, 管道子命令发生错误，立即终止 比如\n1 set -euxo pipefail 等同于\n1 2 set -eux set -o pipefail 等同于\n1 bash -euxo pipefail script.sh Reference 官方手册\nBash脚本set命令教程-阮一峰\n","description":"","id":43,"section":"posts","tags":["Bash"],"title":"bash脚本set命令说明","uri":"https://hex-go.github.io/posts/bash/2022-03-30-bash%E8%84%9A%E6%9C%ACset%E5%91%BD%E4%BB%A4%E8%AF%B4%E6%98%8E/"},{"content":"重要 Featmap是一个用户故事映射工具，用于构建，计划和传达产品积压。\nFeatmap Picture\n环境说明 服务依赖 Postgresql\n个人部署记录\n安装 目录结构\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . ├── charts │ └── featmap │ ├── Chart.yaml │ ├── config │ │ └── conf.json # 配置文件： chart部署时， 运行环境的真实配置 │ ├── templates │ │ ├── configmap.yaml │ │ ├── deployment.yaml │ │ ├── _helpers.tpl │ │ ├── ingress.yaml │ │ └── svc.yaml │ └── values.yaml # chart值配置文件 ├── conf.json # 配置文件： 构建镜像时， 打进镜像的默认配置 ├── Dockerfile ├── Makefile └── README.md 1. 构建Docker镜像 1.1 Dockerfile 内容如下: 1 2 3 4 5 6 7 8 9 10 FROM self.registry.com/ubuntu:20.04 WORKDIR /opt/featmap COPY conf.json . ADD https://github.com/amborle/featmap/releases/download/v2.1.0/featmap-2.1.0-linux-amd64 /usr/local/bin/featmap RUN chmod 775 /usr/local/bin/featmap EXPOSE 5000 ENTRYPOINT [\u0026#34;featmap\u0026#34;] 其中配置文件内容conf.json如下:\n不支持环境变量，只能通过此配置文件修改环境配置\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;appSiteURL\u0026#34;: \u0026#34;https://localhost:5000\u0026#34;, \u0026#34;dbConnectionString\u0026#34;: \u0026#34;postgresql://gitea:gitea@pgsql-host:5432/postgres?sslmode=disable\u0026#34;, \u0026#34;jwtSecret\u0026#34;: \u0026#34;ChangeMeForProductionXXX\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;5000\u0026#34;, \u0026#34;emailFrom\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;smtpServer\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;smtpPort\u0026#34;: \u0026#34;587\u0026#34;, \u0026#34;smtpUser\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;smtpPass\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;environment\u0026#34;: \u0026#34;development\u0026#34; } 1.2 构建镜像 命令 镜像地址: self.registry.com/featmap:2.1.0\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 TAG := 2.1.0 IMAGE_PATH := self.registry.com/featmap IMAGE := $(IMAGE_PATH):$(TAG) .PHONY: docker-clean docker-clean: @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;docker clean\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; for i in $$(docker ps -a |grep $(IMAGE_PATH) |awk \u0026#39;{print$$1}\u0026#39;) ; do docker rm -f $$i ; done for i in $$(docker images |grep $(IMAGE_PATH) |awk \u0026#39;{print$$3}\u0026#39;) ; do docker rmi -f $$i ; done .PHONY: build build: docker-clean @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;docker build\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; docker build -t $(IMAGE) . 2. 部署 安装命令\n线上配置通过charts/featmap/config/conf.json修改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 TAG := 2.1.0 IMAGE_PATH := hub.icos.city/icos/icospaas/featmap IMAGE := $(IMAGE_PATH):$(TAG) INSTANCE := featmap CHART := charts/featmap NAMESPACE := default KUBECONFIG := /home/hex/.kube/config .PHONY: push push: build @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;docker push \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; docker push $(IMAGE) .PHONY: helm-uninstall helm-uninstall: @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;helm uninstall\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; helm --kubeconfig=$(KUBECONFIG) -n $(NAMESPACE) uninstall $(INSTANCE) .PHONY: helm-install helm-install: push @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;helm install\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; helm --kubeconfig=$(KUBECONFIG) -n $(NAMESPACE) install $(INSTANCE) $(CHART) ","description":"","id":44,"section":"posts","tags":["Devops","Featmap","Dockerfile","Chart"],"title":"FeatMap-UserStory地图服务配置和搭建","uri":"https://hex-go.github.io/posts/devops/2022-03-25-featmap-userstory%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%E5%92%8C%E6%90%AD%E5%BB%BA/"},{"content":"简介 算法（Algorithm）是指用来操作数据、解决程序问题的一组方法。对于同一个问题，\n使用不同的算法，也许最终得到的结果是一样的，但在过程中消耗的资源和时间却会有很大的区别。\n衡量算法性能优劣的度量：\n时间维度：是指执行当前算法所消耗的时间，我们通常用「时间复杂度」来描述。 空间维度：是指执行当前算法需要占用多少内存空间，我们通常用「空间复杂度」来描述。 大O符号表示法\n1. 时间复杂度 算法基本操作的重复执行次数为问题规模n的某个函数，也就是用时间频度T(n)表示。\n如果存在某个函数f(n)，使得当n趋于无穷大时，T(n)/f(n)的极限值是不为零的常数，\n那么f(n)是T(n)的同数量级函数，记作T(n)=O(f(n))，称O(f(n))为算法的渐进时间复杂度，简称为时间复杂度。\n1.1 概述 算法的渐进时间复杂度: T(n) = O(f(n))\nT(n): 表示时间频度\nf(n): 表示每行代码执行次数之和\nn : 表示着问题的规模\nO : 表示正比例关系\n常见的算法时间复杂度由小到大依次为：Ο(1)＜Ο(log n)＜Ο(n)＜Ο(nlog n)＜Ο(n2)＜Ο(n3)＜…＜Ο(2^n)＜Ο(n!)\n1.2 求解算法复杂度 求解算法复杂度分以下几个步骤：\n找出算法中的基本语句：算法中执行次数最多的语句就是基本语句，通常是最内层循环的循环体。 计算基本语句的执行次数的数量级：只需计算基本语句执行次数的数量级，即只要保证函数中的最高次幂正确即可，可以忽略所有低次幂和最高次幂的系数。这样能够简化算法分析，使注意力集中在最重要的一点上：增长率。 用大Ο表示算法的时间性能：将基本语句执行次数的数量级放入大Ο记号中。 其中用大O表示法通常有三种规则：\n用常数1取代运行时间中的所有加法常数； 只保留时间函数中的最高阶项； 如果最高阶项存在，则省去最高阶项前面的系数； 1.3 举例说明 常数阶O(1) 1 2 3 4 5 int i = 1; int j = 2; ++i; j++; int m = i + j; 线性阶O(n) 1 2 3 4 5 for(i=1; i\u0026lt;=n; ++i) { j = i; j++; } 对数阶O(logN) 1 2 3 4 5 int i = 1; while(i\u0026lt;n) { i = i * 2; } 线性对数阶O(nlogN) 1 2 3 4 5 6 7 8 for(m=1; m\u0026lt;n; m++) { i = 1; while(i\u0026lt;n) { i = i * 2; } } 平方阶O(n²) 1 2 3 4 5 6 7 8 for(x=1; i\u0026lt;=n; x++) { for(i=1; i\u0026lt;=n; i++) { j = i; j++; } } 立方阶O(n³)、K次方阶O(n^k) 1 三层、k层for循环嵌套 2. 空间复杂度 算法的渐进空间复杂度: S(n)=O(f(n))\nS(n): 表示空间复杂度\nf(n): 表示一个算法所需的存储空间\nn : 表示问题的规模\nO : 表示正比例关系\nO(1) 1 2 3 int i = 1; int j = 2; int k = 1 + 2; O(n) 1 2 3 4 5 6 int j = 0; int[] m = new int[n]; for (int i = 1; i \u0026lt;= n; ++i) { j = i; j++; } Reference 算法的时间与空间复杂度\nLeetCode0：学习算法必备知识：时间复杂度与空间复杂度的计算\n","description":"","id":45,"section":"posts","tags":["LeetCode"],"title":"算法的时间和空间复杂度说明","uri":"https://hex-go.github.io/posts/leetcode/2021-11-09-%E7%AE%97%E6%B3%95%E7%9A%84%E6%97%B6%E9%97%B4%E5%92%8C%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E8%AF%B4%E6%98%8E/"},{"content":"重要 环境说明 部署的external-dns包括以下组件:\nexternal-dns: k3s集群内部，kube-system命名空间 下载 etcd : k3s集群内部，paas命名空间 下载 coredns : k3s集群内部，paas命名空间 下载 external-dns 可以将ingress和external-service对象存储至etcd中，CoreDNS使用此etcd作为后端，解析所注册的服务。\n例如它解决了 registry，openldap、cassandra(headless) 、keycloak(loadbalancer) 这些服务的域名注册问题。\nexternal-dns可以通过设置coredns前缀,同时为不通的域名提供解析服务.\n部署 1. 部署 etcd 1.1 边缘使用local storage部署 在运行etcd的节点创建本地目录 1 mkdir \u0026#34;/opt/etcd-dns\u0026#34; 创建pv pv创建修改详情，参考etcd/chart/etcd-pv/README.md\n1 kubectl apply -f etcd/chart/etcd-pv/pv.yaml 部署etcd auth.rbac.enabled 设置为false, 不启用认证\nservice.type 设置为 LoadBalancer\nservice.loadBalancerIP 设置为\u0026quot;192.168.83.10\u0026quot;\npersistence.enable 设置为 true\npersistence.storageClass 设置为 paas-storage , 值与上一步创建pv时的sc一致\npersistence.size 设置为 8Gi , 值与上一步创建的pv大小一致\n1 helm install etcd etcd/chart/etcd -n paas 检测是否组成集群 1 etcdctl endpoint status --cluster -w table 2. 部署coredns 2.1 部署 chart配置说明 部署配置：\nservice.loadBalancerIP 设置dns服务的loadBalanceIP, 默认为 \u0026ldquo;192.168.83.5\u0026rdquo;\ncorefile相关配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 servers: - zones: - zone: . port: 53 plugins: # bugsize 由默认 512 设置为 1232 (loadBalance 只能代理TCP或UDP一种，此处coredns设置为UDP. # 为防止大数据记录数据超过512，走TCP协议,故将默认大小调大) - name: bufsize parameters: 1232 - name: errors # health 会启动一个监听 :8080/health 的服务 , 此chart中的 livenessProbe 检查此端口 - name: health configBlock: |- lameduck 5s # ready 会启动一个监听 :8181/ready 的服务 , 此chart中的 readinessProbe 检查此端口 - name: ready # # prometheus 会启动一个监听 :9153/metrics 的服务 , 此chart中的 serviceMonitor 检查此端口 - name: prometheus parameters: 0.0.0.0:9153 # 转发，配置上游DNS地址 - name: forward parameters: . 114.114.114.114 - name: log # 自定义 zone 配置，需要与下面 zonefile 对应 - name: file parameters: /etc/coredns/example.db deploy.org # adp租户 zone 配置， # 1. 设置 bufsize; 2. path 设置 /edge 取决与external-dns启动的设置，如果多个external-dns，则通过此处区分 # 2. endpoint 设置的地址为ETCD的LoadBalance IP和端口号 - zones: - zone: adp.icos.city port: 53 bufsize: 1232 plugins: - name: errors - name: log - name: etcd configBlock: |- path /edge endpoint http://192.168.83.10:2379 自定义zone配置\n1 2 3 4 5 6 7 zoneFiles: - filename: example.db domain: deploy.org contents: | deploy.org. IN SOA ns.deploy.org. root.deploy.org. 2015082541 7200 3600 1209600 3600 deploy.org. IN NS ns.deploy.org. license.deploy.org. IN TXT \u0026#34;QClDmn9IdX50gDN59UXNpb4oR733jsk05zLuCAkj0=\u0026#34; 部署 1 helm install coredns coredns/chart/coredns -n paas 3. 部署external-dns Deployment中的配置\nspec.template.spec.containers.[0].args\n--coredns-prefix=/edge/参数决定数据存储在etcd的目录前缀，此处不同可区分不同集群内的external-dns;\n而集群内部不同租户的服务，通过ingress中的租户名可以区分开\n部署\n1 kubectl apply -f external-dns.yaml 禁用节点DNS缓存 所有节点执行一下操作，注意IP地址设置正确\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 systemctl disable systemd-resolved systemctl stop systemd-resolved echo \u0026#39; network: bonds: bond0: addresses: - 192.168.82.11/23 gateway4: 192.168.82.1 interfaces: - ens3f0 - ens3f1 nameservers: addresses: - 192.168.83.5 search: [] parameters: mode: balance-rr ethernets: ens3f0: {} ens3f1: {} version: 2\u0026#39; \u0026gt; /etc/netplan/01-netcfg.yaml rm -rf /etc/resolv.conf echo \u0026#34;nameserver 192.168.83.5\u0026#34; \u0026gt; /etc/resolv.conf netplan apply 常用修改说明 license配置DNS-TXT记录说明 在zone为.的域的plugins参数增加name为file的参数，值为/etc/coredns/example.db deploy.org 1 2 3 4 5 6 7 servers: - zones: - zone: . port: 53 plugins: - name: file parameters: /etc/coredns/example.db deploy.org 在zoneFiles增加如下配置，license.deploy.org. IN TXT行的值为从QA获取的由私钥签名过的ou名Signature 1 2 3 4 5 6 7 zoneFiles: - filename: example.db domain: deploy.org contents: | deploy.org. IN SOA ns.deploy.org. root.deploy.org. 2015082541 7200 3600 1209600 3600 deploy.org. IN NS ns.deploy.org. license.deploy.org. IN TXT \u0026#34;QCUEsCx70xK2u9pdrm6y0hf4up8C9S44tvekF9LVODBPHbryRQGqh9dUyb8VcN11IlPXcl7hVdqC3qsIgYUo5/KBdNCX+edFYquOeKEyEfnkHRzoi8hjR6NIzOQoHh518EJClDmn9IdX50gDN59UXNpb4oR733jsk05zLuCAkj0=\u0026#34; 冒烟测试 集群中创建external-svc 1 2 3 4 5 6 7 8 9 10 11 12 echo \u0026#39; apiVersion: v1 kind: Service metadata: annotations: external-dns.alpha.kubernetes.io/hostname: reg.chebai.org name: reg-chebai-org namespace: paas spec: externalName: 10.90.0.11 type: ExternalName\u0026#39; \u0026gt; test-svc.yaml kubectl apply -f test-svc.yaml 检查 ETCD 中是否有正确写入的数据 1 2 etcdctl --prefix --keys-only=true get / # etcdctl --user=\u0026#34;root\u0026#34; --password=\u0026#34;OH4dQD4Cww\u0026#34; --prefix --keys-only=true get / 检查各个节点的测试数据域名解析 1.如果etcd中能查询到数据，但解析出错；则检查CoreDNS是否配置域adp.icos.city\n2.注意仔细看存储路径的prefix, 是否与CoreDNS中配置的保持一致\n1 nslookup reg.chebai.org \u0026lt;NODEIP\u0026gt; 或\n1 dig @192.168.83.5 reg.chebai.org Reference DNS相关 DNS之BIND使用小结(Forward转发)\nLinux系统解析域名的先后顺序files(/etc/hosts)OR dns(/etc/resolv.conf)\nresolv.conf(5) — Linux manual page\n/etc/resolv.conf 中的第二个nameserver未被 wget 拾取\n","description":"","id":46,"section":"posts","tags":["Kubernetes"],"title":"跨级群DNS方案-解析各集群ingress与custom-dns记录","uri":"https://hex-go.github.io/posts/kubernetes/2021-11-08-%E8%B7%A8%E7%BA%A7%E7%BE%A4dns%E6%96%B9%E6%A1%88-%E8%A7%A3%E6%9E%90%E5%90%84%E9%9B%86%E7%BE%A4ingress%E4%B8%8Ecustom-dns%E8%AE%B0%E5%BD%95/"},{"content":"重要 最重要的事:\n1.简介 seq: 序号，TCP连接中传送的字节流中的每个字节都按顺序编号。\nack: 确认号，是期望收到对方下一个报文的第一个数据字节的序号。\nSYN: 同步SYN，在连接建立时用来同步序号。当SYN=1，ACK=0，表明是连接请求报文，若同意连接，则响应报文中应该使SYN=1，ACK=1\nACK: 确认ACK，仅当ACK=1时，确认号字段才有效。TCP规定，在连接建立后所有报文的传输都必须把ACK置1；\nFIN: 终止FIN，用来释放连接。当FIN=1，表明此报文的发送方的数据已经发送完毕，并且要求释放；\n三次握手 过程：\nx= 随机生成序列号\ny= 随机生成序列号\n客户端[SYN_SENT ]\u0026mdash;-SYN=1,seq=x (请求连接)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt;[ ]服务端\n客户端[ ]\u0026lt;\u0026mdash;SYN=1,ACK=1,ack=x+1,seq=y(应答客户端SYN，并请求建立连接)\u0026ndash;\u0026gt;[SYN_RCVD ]服务端\n客户端[ESTABLISHED]\u0026ndash;ACK=1,ack=Y+1 (应答服务端SYN)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;[ESTABLISHED]服务端\n三次握手而非两次的原因：\n如果客户端发送请求连接-1，由于网络原因超时，客户端重试再次发出请求连接-2，此时正常建立连接并完成通信；\n之后网络回复请求连接-1再次送达服务端, 此时服务端响应的应答客户端SYN请求被返回客户端，此时客户端不会再\n发出应答服务端端SYN请求，server收不到确认请求，则不会建立连接。\n四次挥手 过程：\n断开过程由客户端或服务端任一方执行close来触发。TCP连接是全双工的，因此，每个方向都必须要单独进行关闭\nx=等于前面已经传送过来的数据的最后一个字节的序号加1\ny=自身序列号\nz=服务端释放的报文可能携带数据\n客户端[FIN_WAIT_1]\u0026mdash;-FIN=1,seq=x (client请求释放)\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;[ ]服务端\n客户端[FIN_WAIT_1]\u0026lt;\u0026mdash;ACK=1,ack=x+1,seq=y (释放确认报文)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;[CLOSE-WAIT ]服务端\n客户端[FIN_WAIT_2]\u0026lt;\u0026mdash;FIN=1,ACK=1,ack=y+1,seq=z (server请求释放)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;[LAST-ACK ]服务端\n客户端[TIME-WAIT ]\u0026mdash;-ACK=1,ack=z+1,seq=y+1 (最终释放确认报文)\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;[CLOSE ]服务端\n2∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。\n客户端[CLOSE]\n为什么客户端最后还要等待2MSL？\nMSL（Maximum Segment Lifetime）, 报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。\n第一，保证TCP协议的全双工连接能够可靠关闭保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，\n站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，\n应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，\n而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。\n第二，保证这次连接的重复数据段从网络中消失 防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。\n客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。\n这样新的连接中不会出现旧连接的请求报文。\n为什么建立连接是三次握手，关闭连接确是四次挥手呢？\n建立连接的时候，服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。\n而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，\n所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，\n因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。\nReference 两张动图-彻底明白TCP的三次握手与四次挥手\n","description":"","id":47,"section":"posts","tags":["计算机原理","面试","TCP"],"title":"TCP三次握手四次挥手备忘","uri":"https://hex-go.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/2021-11-05-tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E5%A4%87%E5%BF%98/"},{"content":"重要 最重要的事:\n1.简介 单向TLS加密\n流程： 浏览器 \u0026ndash;(request.明文)\u0026ndash;\u0026gt; 服务器 服务器 \u0026ndash;(response.明文)\u0026ndash;\u0026gt; 浏览器 服务器 \u0026ndash;(公钥.server)\u0026ndash;\u0026gt; 浏览器 浏览器 \u0026ndash;(request.密文-公钥加密)\u0026ndash;\u0026gt; 服务器 缺点：\n服务器发出的请求仍然是明文，即使用私钥加密，公钥是公开的，也相当于是明文 双向TLS加密\n流程： 浏览器 \u0026ndash;(request.明文)\u0026raquo;\u0026gt; 服务器 浏览器 \u0026laquo;(response.明文)\u0026ndash; 服务器 浏览器 \u0026laquo;(公钥.server)\u0026mdash;- 服务器 浏览器 \u0026ndash;(公钥.client)\u0026raquo;\u0026raquo; 服务器 浏览器 \u0026ndash;(request.密文-公钥.server加密)\u0026raquo;\u0026gt; 服务器 浏览器 \u0026laquo;(request.密文-公钥.client加密)\u0026mdash; 服务器 缺点：\n非对称机密给服务端和客户端性能带来巨大影响（加解密费时，费资源） 对称加密+非对称加密结合 随机数1= client random\n随机数2= server random\n随机数3= premaster secret\n流程：\n[ ]浏览器[随机数1 ] \u0026ndash;(随机数1.明文)\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt; [ ]服务器[私+公钥.server] [ ]浏览器[随机数1 ] \u0026laquo;(随机数2.明文)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- [随机数1+2 ]服务器[私+公钥.server] [ ]浏览器[随机数1+2 ] \u0026laquo;(公钥.server)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- [随机数1+2 ]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026ndash;(随机数3.密文-公钥.server加密)\u0026raquo;\u0026raquo; [随机数1+2 ]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026ndash;(finish.密文-随机数计算秘钥)\u0026raquo;\u0026raquo;\u0026raquo; [随机数1+2+3]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026laquo;(finish.密文-随机数计算秘钥)\u0026mdash;\u0026mdash; [随机数1+2+3]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026ndash;(request.密文-随机数计算秘钥)\u0026raquo;\u0026raquo;\u0026gt; [随机数1+2+3]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026laquo;(response.密文-随机数计算秘钥)\u0026mdash;- [随机数1+2+3]服务器[私钥.server] 缺点：\n中间人攻击 数字证书 服务器上传公钥+名字 ca用这些信息计算hash,办法证书给服务器 服务器将证书发给浏览器验证 剩余证书签名、验证过程待完善\nReference 为了一个HTTPS，浏览器操碎了心\u0026hellip;\n","description":"","id":48,"section":"posts","tags":["计算机原理","面试","待完善"],"title":"Https流程说明","uri":"https://hex-go.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/2021-11-05-https%E6%B5%81%E7%A8%8B%E8%AF%B4%E6%98%8E/"},{"content":"重要 ChirpStack是一个开源的lora设备管理平台，其中ApplicationServer是设备管理页面，\n支持简单认证，也支持oauth2认证，但oauth2认证与正常的不太一样，可以简单总结为\n依靠sso做统一认证 本地数据库存储用户信息进行鉴权 优点： 依靠本地鉴权管理体系，更好跟local模式兼容。\n缺点： 无法统一在sso中进行权限分配。\nReference ","description":"","id":49,"section":"posts","tags":["Source Code"],"title":"ChirpStack-ApplicationServer[源码]-oidc认证流程","uri":"https://hex-go.github.io/posts/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/2021-03-01-chirpstack-applicationserver%E6%BA%90%E7%A0%81-oidc%E8%AE%A4%E8%AF%81%E6%B5%81%E7%A8%8B/"},{"content":"重要 入口函数 nuclio: pkg/processor/trigger/kafka/trigger.go k.consumerGroup.Consume函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func (k *kafka) Start(checkpoint functionconfig.Checkpoint) error { var err error k.consumerGroup, err = k.newConsumerGroup() if err != nil { return errors.Wrap(err, \u0026#34;Failed to create consumer\u0026#34;) } k.shutdownSignal = make(chan struct{}, 1) // start consumption in the background go func() { for { k.Logger.DebugWith(\u0026#34;Starting to consume from broker\u0026#34;, \u0026#34;topics\u0026#34;, k.configuration.Topics) // start consuming. this will exit without error if a rebalancing occurs err = k.consumerGroup.Consume(context.Background(), k.configuration.Topics, k) if err != nil { k.Logger.WarnWith(\u0026#34;Failed to consume from group, waiting before retrying\u0026#34;, \u0026#34;err\u0026#34;, errors.GetErrorStackString(err, 10)) time.Sleep(1 * time.Second) } else { k.Logger.DebugWith(\u0026#34;Consumer session closed (possibly due to a rebalance), re-creating\u0026#34;) } } }() return nil } sarama consume 函数sarama:consumer_group.go c.newSession函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 // Consume implements ConsumerGroup. func (c *consumerGroup) Consume(ctx context.Context, topics []string, handler ConsumerGroupHandler) error { // Ensure group is not closed select { case \u0026lt;-c.closed: return ErrClosedConsumerGroup default: } c.lock.Lock() defer c.lock.Unlock() // Quick exit when no topics are provided if len(topics) == 0 { return fmt.Errorf(\u0026#34;no topics provided\u0026#34;) } // Refresh metadata for requested topics if err := c.client.RefreshMetadata(topics...); err != nil { return err } // Init session sess, err := c.newSession(ctx, topics, handler, c.config.Consumer.Group.Rebalance.Retry.Max) if err == ErrClosedClient { return ErrClosedConsumerGroup } else if err != nil { return err } // loop check topic partition numbers changed // will trigger rebalance when any topic partitions number had changed go c.loopCheckPartitionNumbers(topics, sess) // Wait for session exit signal \u0026lt;-sess.ctx.Done() // Gracefully release session claims return sess.release(true) } 安装 使用 Reference ","description":"","id":50,"section":"posts","tags":["Source Code","Nuclio","待完善"],"title":"Nuclio[源码]-kafka-trigger流程","uri":"https://hex-go.github.io/posts/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/2021-02-23-nuclio%E6%BA%90%E7%A0%81-kafka-trigger/"},{"content":"重要 Kubernetes: 1.20.2\nPod 安全策略 1. 什么是PodSecurityPolicy？ Pod 安全策略（Pod Security Policy） 是集群级别的资源，它能够控制 Pod 规约 中与安全性相关的各个方面。 PodSecurityPolicy 对象定义了一组 Pod 运行时必须遵循的条件及相关字段的默认值，只有 Pod 满足这些条件 才会被系统接受。 Pod 安全策略允许管理员控制如下方面：\n2. 启用PodSecurityPolicy Pod 安全策略实现为一种可选（但是建议启用）的 准入控制器(admission-controllers)。 启用了准入控制器 即可强制实施 Pod 安全策略，不过如果没有授权认可策略之前即启用 准入控制器 将导致集群中无法创建任何 Pod。\n由于 Pod 安全策略 API（policy/v1beta1/podsecuritypolicy）是独立于准入控制器(admission-controllers)来启用的，对于现有集群而言，建议在启用准入控制器之前先添加策略并对其授权。\n3. 配置PodSecurityPolicy举例 3.1 创建PSP(PodSecurityPolicy) rke部署的集群会默认创建部分psp资源，比如default-psp\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 apiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: name: default-psp annotations: seccomp.security.alpha.kubernetes.io/allowedProfileNames: \u0026#39;*\u0026#39; spec: allowPrivilegeEscalation: true allowedCapabilities: - \u0026#39;*\u0026#39; fsGroup: rule: RunAsAny hostIPC: true hostNetwork: true hostPID: true hostPorts: - max: 65535 min: 0 privileged: true runAsUser: rule: RunAsAny seLinux: rule: RunAsAny supplementalGroups: rule: RunAsAny volumes: - \u0026#39;*\u0026#39; 3.2 RBAC授权 1 2 3 4 5 6 7 8 9 10 11 12 # 0. `default-psp`会在rke创建集群的时候自动创建 # 1. 创建role, 此角色可访问 `default-psp` 的psp # kubectl -n \u0026lt;namespace\u0026gt; create role \u0026lt;role-name\u0026gt; --verb=use --resource=podsecuritypolicy --resource-name=default-psp kubectl -n kube-ops create role psp:unprivileged --verb=use --resource=podsecuritypolicy --resource-name=default-psp # 2. 创建`rolebinding` # 在Namespace下会有一个默认账户`default` # Deployment创建的pod, 不指定`serviceAccountName`时，使用`default`账户，需要将`default`账户与创建的角色关联（特定用户声明参考Ingress-Nginx部署举例） # kubectl -n \u0026lt;Namespace\u0026gt; create rolebinding \u0026lt;Rolebinding-name\u0026gt; --role=\u0026lt;Role-name\u0026gt; --serviceaccount=\u0026lt;Namespace\u0026gt;:\u0026lt;ServiceAccount\u0026gt; kubectl -n kube-ops create rolebinding default:psp:unprivileged --role=psp:unprivileged --serviceaccount=kube-ops:default 3.3 创建Deployment 1 2 3 4 5 6 7 8 # 创建Deployment测试，一切正常 # kubectl create deployment \u0026lt;Deployment-name\u0026gt; --image=\u0026lt;ImagePath\u0026gt; -n \u0026lt;Namespace\u0026gt; kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 -n kube-ops # 查看，pod正常创建 root@hex-0001:~/# kubectl get pod -n kube-ops NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-57978f5f5d-dbkcm 0/1 ContainerCreating 0 12s 3.4 调试方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 创建失败时通过`Deployment`和`event`查看状态 # 1. describe Deployment root@lab-rke-hex-0001:~/bkp# kubectl describe deployment kubernetes-bootcamp -n kube-ops Name: kubernetes-bootcamp Namespace: kube-ops Selector: app=kubernetes-bootcamp Replicas: 1 desired | 0 updated | 0 total | 0 available | 1 unavailable StrategyType: RollingUpdate RollingUpdateStrategy: 25% max unavailable, 25% max surge Pod Template: Labels: app=kubernetes-bootcamp Containers: kubernetes-bootcamp: Image: gcr.io/google-samples/kubernetes-bootcamp:v1 Volumes: \u0026lt;none\u0026gt; Conditions: Type Status Reason ---- ------ ------ Progressing True NewReplicaSetCreated Available False MinimumReplicasUnavailable ReplicaFailure True FailedCreate OldReplicaSets: \u0026lt;none\u0026gt; NewReplicaSet: kubernetes-bootcamp-57978f5f5d (0/1 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 25s deployment-controller Scaled up replica set kubernetes-bootcamp-57978f5f5d to 1 # 2. get event root@lab-rke-hex-0001:~/bkp# kubectl get event -n kube-ops LAST SEEN TYPE REASON OBJECT MESSAGE 3m11s Warning FailedCreate replicaset/kubernetes-bootcamp-57978f5f5d Error creating: pods \u0026#34;kubernetes-bootcamp-57978f5f5d-\u0026#34; is forbidden: PodSecurityPolicy: unable to admit pod: [] 8m39s Normal ScalingReplicaSet deployment/kubernetes-bootcamp Scaled up replica set kubernetes-bootcamp-57978f5f5d to 1 4. IngressNginx部署举例 serviceAccount: ingress-nginx-admission 创建job:ingress-nginx-admission-patch和job: ingress-nginx-admission-create等 serviceAccount: ingress-nginx 创建Deployment:ingress-nginx-controller 所以需要将PodSecurityPolicy: default-psp给到两个账户serviceAccount: ingress-nginx和serviceAccount: ingress-nginx-admission\n操作如下：\n4.1 关联 PodSecurityPolicy: default-psp与serviceAccount: ingress-nginx Deployment中声明的serviceAccount如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: apps/v1 kind: Deployment metadata: labels: app.kubernetes.io/name: ingress-nginx name: ingress-nginx-controller spec: template: metadata: name: ingress-nginx-admission-create labels: app.kubernetes.io/name: ingress-nginx spec: containers: - name: create image: reg.chebai.org/kubernetes-ingress-controller/kube-webhook-certgen:v1.0.0 serviceAccountName: ingress-nginx-admission 创建rbac, 关联ServiceAccount与PodSecurityPolicy。\n1 2 3 4 5 6 7 8 9 10 # 0. `default-psp`会在rke部署集群的时候自动创建 # 1. 创建role `psp:unprivileged`, 此角色可访问psp `default-psp` # kubectl -n \u0026lt;namespace\u0026gt; create role \u0026lt;role-name\u0026gt; --verb=use --resource=podsecuritypolicy --resource-name=default-psp kubectl -n ingress-nginx create role psp:unprivileged --verb=use --resource=podsecuritypolicy --resource-name=default-psp # 2. 创建rolebinding `ingress-nginx:psp:unprivileged` # ingressNginx的Deployment创建的pod时，指定`serviceAccountName`为`ingress-nginx`。需要将`ingress-nginx`账户与创建的角色关联 # kubectl -n \u0026lt;Namespace\u0026gt; create rolebinding \u0026lt;Rolebinding-name\u0026gt; --role=\u0026lt;Role-name\u0026gt; --serviceaccount=\u0026lt;Namespace\u0026gt;:\u0026lt;ServiceAccount\u0026gt; kubectl -n ingress-nginx create rolebinding ingress-nginx:psp:unprivileged --role=psp:unprivileged --serviceaccount=ingress-nginx:ingress-nginx 4.2 关联 PodSecurityPolicy: default-psp与serviceAccount: ingress-nginx Job中声明的serviceAccount如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 apiVersion: batch/v1 kind: Job metadata: name: ingress-nginx-admission-patch annotations: \u0026#34;helm.sh/hook\u0026#34;: post-install,post-upgrade \u0026#34;helm.sh/hook-delete-policy\u0026#34;: before-hook-creation,hook-succeeded labels: app.kubernetes.io/name: ingress-nginx spec: template: metadata: name: ingress-nginx-admission-patch labels: app.kubernetes.io/name: ingress-nginx spec: containers: - name: patch image: reg.chebai.org/kubernetes-ingress-controller/kube-webhook-certgen:v1.0.0 serviceAccountName: ingress-nginx-admission 创建rbac, 关联ServiceAccount与PodSecurityPolicy。\n1 2 3 4 5 6 7 8 # 0. `default-psp`会在rke部署集群的时候自动创建 # 1. `psp:unprivileged`在上一步已创建 # 2. 创建rolebinding `ingress-nginx-admission:psp:unprivileged` # ingressNginx的Job创建的pod时，指定`serviceAccountName`为`ingress-nginx-admission`。需要将`ingress-nginx-admission`账户与创建的角色关联 # kubectl -n \u0026lt;Namespace\u0026gt; create rolebinding \u0026lt;Rolebinding-name\u0026gt; --role=\u0026lt;Role-name\u0026gt; --serviceaccount=\u0026lt;Namespace\u0026gt;:\u0026lt;ServiceAccount\u0026gt; kubectl -n ingress-nginx create rolebinding ingress-nginx-admission:psp:unprivileged --role=psp:unprivileged --serviceaccount=ingress-nginx:ingress-nginx-admission 4.2 helm 部署ingress-nginx 1 helm install ingress-nginx ingress-nginx/ -n ingress-nginx Reference Pod 安全策略\n","description":"","id":51,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes[PodSecurityPolicy]-使用说明","uri":"https://hex-go.github.io/posts/kubernetes/2021-02-18-kubernetespodsecuritypolicy-%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"},{"content":"重要 Kubernetes API弃用策略\nKubernetes 升级， 主要的API变化在v1.16\\v1., 具体说明如下：\nv1.16 变化\nv1.16版本将停止提供以下不推荐使用的API版本，而支持更新和更稳定的API版本：\nNetworkPolicy资源: 由extensions/v1beta1迁移至v1.8以来可用的networking.k8s.io/v1API。 PodSecurityPolicy资源: 由extensions/v1beta1迁移至v1.10以来可用的policy/v1beta1API。 DaemonSet资源: 由extensions/v1beta1和apps/v1beta2迁移至v1.9以来可用的apps/v1API。 spec.templateGeneration字段被删除。 spec.selector为必填项, 且在创建后是不变的。使用现有的tmplate labels作为selector无缝升级 spec.updateStrategy.type默认值为RollingUpdate（extensions/v1beta1默认值为OnDelete) Deployment资源: 由extensions/v1beta1 apps/v1beta1 apps/v1beta2迁移至v1.9以来可用的apps/v1API。 spec.rollbackTo字段被删除 spec.selector为必填项, 且在创建后是不变的。使用现有的tmplate labels作为selector无缝升级 spec.progressDeadlineSeconds默认值为600s(extensions/v1beta1默认值没有截止日期） spec.revisionHistoryLimit默认值为10(apps/v1beta1默认值为2，extensions/v1beta1中默认值为保留所有) maxSurge和maxUnavailable默认值为25％(extensions/v1beta1默认值为1) Statefulset资源: 由apps/v1beta1和apps/v1beta2迁移至v1.9以来可用的apps/v1API。 spec.selector为必填项, 且在创建后是不变的。使用现有的tmplate labels作为selector无缝升级 spec.updateStrategy.type默认值为RollingUpdate（extensions/v1beta1默认值为OnDelete) ReplicaSet资源: 由extensions/v1beta1 apps/v1beta1 apps/v1beta2迁移至v1.9以来可用的apps/v1API。 spec.selector为必填项, 且在创建后是不变的。使用现有的tmplate labels作为selector无缝升级 v1.22变化\nMutatingWebhookConfiguration和ValidatingWebhookConfiguration资源: 由admissionregistration.k8s.io/v1beta1迁移至v1.16以来可用的admissionregistration.k8s.io/v1 API\nwebhooks[*].failurePolicy 默认值 from Ignore to Fail webhooks[*].matchPolicy 默认值 from Exact to Equivalent webhooks[*].timeoutSeconds 默认值 from 30s to 10s webhooks[*].sideEffects 变为必填项 oneof None and NoneOnDryRun webhooks[*].admissionReviewVersions 变为必填项 webhooks[*].name 名称必须唯一 CustomResourceDefinition资源: 由apiextensions.k8s.io/v1beta1 迁移至v1.16以来可用的apiextensions.k8s.io/v1API。\nspec.scope 去除默认值 Namespaced，变为必须指定。 spec.version 去除，由 spec.versions 替换。 spec.validation 去除，由spec.versions[*].schema 替换。 spec.subresources 去除，由spec.versions[*].subresources 替换。 spec.additionalPrinterColumns 去除，由spec.versions[*].additionalPrinterColumns 替换。 spec.conversion.webhookClientConfig迁移至spec.conversion.webhook.clientConfig。 spec.conversion.conversionReviewVersions迁移至spec.conversion.webhook.conversionReviewVersions spec.versions[*].schema.openAPIV3Schema 为必填项, 并且必须为结构化schema。 spec.preserveUnknownFields: true 不被允许，必须通过schema中指定 x-kubernetes-preserve-unknown-fields: true additionalPrinterColumns 中, JSONPath 字段改为jsonPath (fixes #66531) APIService资源: 由apiregistration.k8s.io/v1beta1 迁移至v1.10以来可用的apiregistration.k8s.io/v1API。\nTokenReview资源: 由authentication.k8s.io/v1beta1 迁移至v1.6以来可用的authentication.k8s.io/v1API。\nLocalSubjectAccessReview、SelfSubjectAccessReview、SubjectAccessReview\n由authentication.k8s.io/v1beta1 迁移至v1.6以来可用的authentication.k8s.io/v1API。\nspec.group字段重命名为spec.groups(fix #32709) CertificateSigningRequest资源: 由certificates.k8s.io/v1beta1 迁移至v1.19以来可用的certificates.k8s.io/v1API。\n请求证书： spec.signerName为必填项(请参阅Kubernetes signers), 并且不允许通过。certificate.k8s.io/v1API创建对kubernetes.io/legacy-unknown的请求。 spec.usages为必填项、不可重复，并且只能包含已知用法。 颁发证书： status.condition不可重复。 status.conditions[*].status为必填项。 status.certificate 必须为PEM-encoded, 并且仅包含CERTIFICATE 块。 Lease资源: 由coordination.k8s.io/v1beta1 迁移至v1.14以来可用的coordination.k8s.io/v1API。\nIngress资源: 由extensions/v1beta1迁移至v1.19以来可用的networking.k8s.io/v1beta1API。\nspec.backend 字段名变为 spec.defaultBackend spec.rules[*].http.paths[*].backend.serviceName 字段变为 spec.rules[*].http.paths[*].backend.service.name spec.rules[*].http.paths[*].backend.servicePort 字段，值为数字变为 spec.rules[*].http.paths[*].backend.service.port.number spec.rules[*].http.paths[*].backend.servicePort 字段，值为字符串变为 spec.rules[*].http.paths[*].backend.service.port.name spec.rules[*].http.paths[*].pathType 为必填项，oneofPrefix, Exact, and ImplementationSpecific. ImplementationSpecific用来对应v1beta1. spec.rules[*].http.paths[*].backend.path为必填项，匹配所有路径值设置为/。 IngressClass资源: 由networking.k8s.io/v1beta1迁移至v1.19以来可用的networking.k8s.io/v1API。\nClusterRole, ClusterRoleBinding, Role, and RoleBinding 资源由rbac.authorization.k8s.io/v1beta1迁移至v1.8以来可用的rbac.authorization.k8s.io/v1API\nPriorityClass资源由scheduling.k8s.io/v1beta1迁移至v1.14以来可用的scheduling.k8s.io/v1API\nCSIDriver, CSINode, StorageClass, and VolumeAttachment 资源由storage.k8s.io/v1beta1迁移至storage.k8s.io/v1API\nCSIDriver在v1.19可用 CSINode在v1.17可用 StorageClass在v1.6可用 VolumeAttachment在v1.13可用 1.25变化\nEvent资源: 由events.k8s.io/v1beta1迁移至v1.19以来可用的events.k8s.io/v1API\ntype 仅限于 Normal 、 Warning involvedObject 被重命名为 regarding action, reason, reportingComponent, and reportingInstance 为必填项 eventTime 替换废弃的字段firstTimestamp series.lastObservedTime 替换废弃的字段lastTimestamp series.count 替换废弃的字段count reportingComponent 替换废弃的字段source.component reportingInstance 替换废弃的字段source.host RuntimeClass资源: 由node.k8s.io/v1beta1迁移至v1.20以来可用的node.k8s.io/v1API\nReference Kubernetes API弃用策略\n启用API迁移指南\n","description":"","id":52,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes[Release]-弃用API迁移说明(持续更新)","uri":"https://hex-go.github.io/posts/kubernetes/2021-02-18-kubernetesrelease-%E5%BC%83%E7%94%A8api%E8%BF%81%E7%A7%BB%E8%AF%B4%E6%98%8E/"},{"content":"重要 最重要的事: 主机换风扇，想尝试不装cpu散热使用。结果温度巨高。cpu使用率长时间标满（估计差一点就要断电保护了）。\n想查看温度，记录一下。\n1.简介 使用GUI工具Psensor，它允许你在Linux中监控硬件温度。用Psensor你可以：\n监控cpu和主板的温度 监控NVidia GPU的文档 监控硬盘的温度 监控风扇的速度 监控CPU的利用率 Psensor最新的版本同样提供了Ubuntu中的指示小程序，这样使得在Ubuntu中监控温度变得更加容易。你可以选择在面板的右上角显示温度。它还会在温度上过阈值后通知\n2. 安装 在安装Psensor前，你需要安装和配置lm-sensors，这是一个用于硬件监控的命令行工具。如果你想要测量磁盘温度，你还需要安装hddtemp。要安装这些工具，运行下面的这些命令:\n1 sudo apt-get install lm-sensors hddtemp 安装Psensor：\n1 sudo apt-get install psensor 3. 配置 在面板显示温度 1 # 启动 点击psensor, 进入Sensor Preferences. 在Application Indicator菜单下，选择你想要显示温度的组件并勾上Display sensor in the label选项。\n设置开机自启 进入Preferences-\u0026gt;Startup并选择Launch on session startup使每次启动时启动Psensor。\nReference pensor\n","description":"","id":53,"section":"posts","tags":["个人工具","Ubuntu"],"title":"Ubuntu--18.04-安装cpu温度显示工具","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2021-02-04-ubuntu18.04_%E5%AE%89%E8%A3%85cpu%E6%B8%A9%E5%BA%A6%E6%98%BE%E7%A4%BA%E5%B7%A5%E5%85%B7/"},{"content":"重要 阅读nuclio源码，分析nuclio平台中java由源码到服务启动的全过程。\n环境说明 nuclio: 1.4.17\nkubernetes: 1.15.3\n源码： 构建过程 有nuctl的build command往下查看调用\npkg/nuctl/command/build.go文件下，newBuildCommandeer函数内部调用了rootCommandeer.platform.CreateFunctionBuild\n走platform接口pkg/platform/platform.go，因为platform类型为kube，所以调用pkg/platform/kube/platform.go。\n其中kube的NewPlatform继承了pkg/platform/abstract/platform.go的实例，CreateFunctionBuild就在abstract/中具体定义的。\npkg/platform/abstract/platform.go文件下，CreateFunctionBuild函数内部，实例化了一个builder，并执行builder.Build函数。\npkg/processor/build/builder.go文件下：\nBuild 函数调用buildProcessorImage函数\nbuildProcessorImage 函数调用createProcessorDockerfile函数\ncreateProcessorDockerfile 函数调用getRuntimeProcessorDockerfileInfo函数\ngetRuntimeProcessorDockerfileInfo 函数调用resolveProcessorDockerfileInfo函数\nresolveProcessorDockerfileInfo 函数调用runtime.GetProcessorDockerfileInfo函数\n走runtime接口pkg/processor/build/runtime/runtime.go，\n因为runtime类型为java，所以调用pkg/processor/build/runtime/java/runtime.go。\npkg/processor/build/runtime/java/runtime.go中，有具体的GetProcessorDockerfileInfo定义（包含onbuild信息）。 resolveProcessorDockerfileInfo 函数调用GenerateDockerfileContents函数\nGenerateDockerfileContents 函数调用platform.GetOnbuildStages函数\nplatform接口pkg/platform/platform.go，GetOnbuildStages 具体定义在 pkg/platform/abstract/platform.go。\npkg/platform/abstract/platform.go文件下：\nGetOnbuildStages 函数内部调用ContainerBuilder.GetOnbuildStages函数。\nBuilderPusher接口pkg/containerimagebuilderpusher/containerimagebuilder.go，\n因为kind为kaniko，所以调用pkg/containerimagebuilderpusher/kaniko.go\npkg/containerimagebuilderpusher/kaniko.go文件下：\nGetOnbuildStages函数主要做以下操作\n将onbuildArtifacts转换为\u0026quot;FROM %s(artifact.Image) AS %s(artifact.Name)\u0026quot; \\n ARG NUCLIO_LABEL \\n ARG NUCLIO_ARCH\nGenerateDockerfileContents 函数调用platform.TransformOnbuildArtifactPaths函数\nplatform接口pkg/platform/platform.go，GetOnbuildStages 具体定义在 pkg/platform/abstract/platform.go。\nTransformOnbuildArtifactPaths 函数内部调用ContainerBuilder.GetOnbuildStages函数。\nBuilderPusher接口pkg/containerimagebuilderpusher/containerimagebuilder.go，\nTransformOnbuildArtifactPaths 具体定义在 pkg/containerimagebuilderpusher/kaniko.go\npkg/containerimagebuilderpusher/kaniko.go文件下：\nTransformOnbuildArtifactPaths 函数主要做以下操作\n将onbuildArtifacts转换为--from=%s(artifact.Name) %s(artifat.Path[x]) 从后向前推，构建function函数最终镜像的Dockerfile在pkg/processor/build/builder.go, 函数GenerateDockerfileContents。\n内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 // GenerateDockerfileContents return function docker file func (b *Builder) GenerateDockerfileContents(baseImage string, onbuildArtifacts []runtime.Artifact, imageArtifactPaths map[string]string, directives map[string][]functionconfig.Directive, healthCheckRequired bool) (string, error) { // now that all artifacts are in the artifacts directory, we can craft a Dockerfile dockerfileTemplateContents := `# Multistage builds {{ range $onbuildStage := .OnbuildStages }} {{ $onbuildStage }} {{ end }} # From the base image FROM {{ .BaseImage }} # Old(er) Docker support - must use all build args ARG NUCLIO_LABEL ARG NUCLIO_ARCH ARG NUCLIO_BUILD_LOCAL_HANDLER_DIR {{ if .PreCopyDirectives }} # Run the pre-copy directives {{ range $directive := .PreCopyDirectives }} {{ $directive.Kind }} {{ $directive.Value }} {{ end }} {{ end }} # Copy required objects from the suppliers {{ range $localArtifactPath, $imageArtifactPath := .OnbuildArtifactPaths }} COPY {{ $localArtifactPath }} {{ $imageArtifactPath }} {{ end }} {{ range $localArtifactPath, $imageArtifactPath := .ImageArtifactPaths }} COPY {{ $localArtifactPath }} {{ $imageArtifactPath }} {{ end }} {{ if .HealthcheckRequired }} # Readiness probe HEALTHCHECK --interval=1s --timeout=3s CMD /usr/local/bin/uhttpc --url http://127.0.0.1:8082/ready || exit 1 {{ end }} # Run the post-copy directives {{ range $directive := .PostCopyDirectives }} {{ $directive.Kind }} {{ $directive.Value }} {{ end }} # Run processor with configuration and platform configuration CMD [ \u0026#34;processor\u0026#34; ] ` onbuildStages, err := b.platform.GetOnbuildStages(onbuildArtifacts) if err != nil { return \u0026#34;\u0026#34;, errors.Wrap(err, \u0026#34;Failed to transform retrieve onbuild stages\u0026#34;) } // Transform `onbuildArtifactPaths` depending on the builder being used onbuildArtifactPaths, err := b.platform.TransformOnbuildArtifactPaths(onbuildArtifacts) if err != nil { return \u0026#34;\u0026#34;, errors.Wrap(err, \u0026#34;Failed to transform onbuildArtifactPaths\u0026#34;) } dockerfileTemplate, err := template.New(\u0026#34;singleStageDockerfile\u0026#34;). Parse(dockerfileTemplateContents) if err != nil { return \u0026#34;\u0026#34;, errors.Wrap(err, \u0026#34;Failed to create onbuildImage template\u0026#34;) } var dockerfileTemplateBuffer bytes.Buffer err = dockerfileTemplate.Execute(\u0026amp;dockerfileTemplateBuffer, \u0026amp;map[string]interface{}{ \u0026#34;BaseImage\u0026#34;: baseImage, \u0026#34;OnbuildStages\u0026#34;: onbuildStages, \u0026#34;OnbuildArtifactPaths\u0026#34;: onbuildArtifactPaths, \u0026#34;ImageArtifactPaths\u0026#34;: imageArtifactPaths, \u0026#34;PreCopyDirectives\u0026#34;: directives[\u0026#34;preCopy\u0026#34;], \u0026#34;PostCopyDirectives\u0026#34;: directives[\u0026#34;postCopy\u0026#34;], \u0026#34;HealthcheckRequired\u0026#34;: healthCheckRequired, }) if err != nil { return \u0026#34;\u0026#34;, errors.Wrap(err, \u0026#34;Failed to run template\u0026#34;) } dockerfileContents := dockerfileTemplateBuffer.String() return dockerfileContents, nil } b.platform.GetOnbuildStages(onbuildArtifacts)调用了platform接口下的功能。\nplatform说明如下:\npkg\\platform\\platform.go中定义接口 pkg\\platform\\types.go中定义数据结构 pkg\\platform\\factory\\factory.go为工厂函数，根据platform参数 local： 调用pkg\\platform\\local\\platform.go中的NewPlatform创建platform 实例 kube： 调用pkg\\platform\\kube\\platform.go中的NewPlatform创建platform 实例 pkg\\platform\\abstract\\platform.go为具体创建platform实例的。被local和kube下的NewPlatform调用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 pkg/platform ├── abstract │ ├── platform.go ├── config │ └── types.go ├── errors.go ├── factory │ └── factory.go ├── kube │ ├── platform.go │ ├── types.go ├── local │ ├── platform.go │ └── types.go ├── platform.go └── types.go 根据上面说明，函数执行了kube/下的platform.go，之后调用abstract/platform.go下的\n函数GetProcessorDockerfileInfo, pkg/processor/build/runtime/目录下，java/runtime.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (j *java) GetProcessorDockerfileInfo(onbuildImageRegistry string) (*runtime.ProcessorDockerfileInfo, error) { processorDockerfileInfo := runtime.ProcessorDockerfileInfo{} processorDockerfileInfo.BaseImage = \u0026#34;openjdk:9-jre-slim\u0026#34; // fill onbuild artifact artifact := runtime.Artifact{ Name: \u0026#34;java-onbuild\u0026#34;, Image: fmt.Sprintf(\u0026#34;%s/nuclio/handler-builder-java-onbuild:%s-%s\u0026#34;, onbuildImageRegistry, j.VersionInfo.Label, j.VersionInfo.Arch), Paths: map[string]string{ \u0026#34;/home/gradle/bin/processor\u0026#34;: \u0026#34;/usr/local/bin/processor\u0026#34;, \u0026#34;/home/gradle/src/wrapper/build/libs/nuclio-java-wrapper.jar\u0026#34;: \u0026#34;/opt/nuclio/nuclio-java-wrapper.jar\u0026#34;, }, } processorDockerfileInfo.OnbuildArtifacts = []runtime.Artifact{artifact} return \u0026amp;processorDockerfileInfo, nil } 调用关系\ncreateProcessorDockerfile: 调用 getRuntimeProcessorDockerfileInfo函数，生成content和DockerfilePath getRuntimeProcessorDockerfileInfo函数: 调用resolveProcessorDockerfileInfo函数收集processor的dockerfile信息 获取用户输入的指令FunctionConfig.Spec.Build.Directives，如果设置了command参数，则获取FunctionConfig.Spec.Build.Commands转换为指令并与构建过程的合并。 调用GenerateDockerfileContents函数，将第一步获取的内容转换为DockerfileContent。 resolveProcessorDockerfileInfo函数： 调用GetProcessorDockerfileInfo函数，获取默认的runtime。 调用getProcessorDockerfileBaseImage函数，a. 第一优先级FunctionConfig.Spec.Build.BaseImage；b. GetProcessorDockerfileInfo函数中格式为fmt.Sprintf(\u0026quot;%s/nuclio/handler-builder-java-onbuild:%s-%s\u0026quot;。 调用函数renderDependantImageURL 调用函数getProcessorDockerfileOnbuildImage 增加health-check组件 GetProcessorDockerfileInfo函数(meige)： 指定BaseImage和OnbuildArtifacts，其中OnbuildArtifacts包含onbuildImage和path。 GetProcessorDockerfileInfo -\u0026gt; resolveProcessorDockerfileInfo -\u0026gt; getRuntimeProcessorDockerfileInfo -\u0026gt; createProcessorDockerfile\n源码： 部署过程 Reference nuclio github\n","description":"","id":54,"section":"posts","tags":["Source Code","Nuclio","待完善"],"title":"Nuclio[源码]-java构建部署流程","uri":"https://hex-go.github.io/posts/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/2021-02-02-nuclio%E6%BA%90%E7%A0%81-java%E6%9E%84%E5%BB%BA%E9%83%A8%E7%BD%B2%E6%B5%81%E7%A8%8B/"},{"content":"重要 配置 Deployment中配置举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 spec: selector: matchLabels: app: {{ template \u0026#34;common.name\u0026#34; . }} replicas: {{ .Values.deploymentReplicas }} template: metadata: name: {{ template \u0026#34;common.name\u0026#34; . }} annotations: container.security.alpha.kubernetes.io/{{- template \u0026#34;common.name\u0026#34; . -}}: \u0026#34;runtime/default\u0026#34; labels: app: {{ template \u0026#34;common.name\u0026#34; . }} release: \u0026#34;{{ .Release.Name }}\u0026#34; spec: containers: {{- if .Values.filebeatSidecar }} - name: filebeat image: {{ $.Values.filebeat.image | quote }} volumeMounts: - name: log-data mountPath: /var/logs/app {{- if .Values.configMapEnable }} {{- range $i,$map := .Values.configMapList }} - name: {{ $map.name }} mountPath: {{ $map.mountPath | quote }} {{- if $map.subPath }} subPath: {{ $map.subPath }} {{- end }} {{- end }} {{- end }} {{- end }} - name: {{ template \u0026#34;common.containers.name\u0026#34; . }} image: \u0026#34;{{ .Values.global.imageRepositoryName }}/{{ .Values.imageRepository }}:{{.Chart.AppVersion}}\u0026#34; imagePullPolicy: {{ .Values.imagePullPolicy | quote }} Reference ","description":"","id":55,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes-使用sidecar配置filebeat收集容器日志","uri":"https://hex-go.github.io/posts/kubernetes/2021-01-27-kubernetes-%E4%BD%BF%E7%94%A8sidecar%E9%85%8D%E7%BD%AEfilebeat%E6%94%B6%E9%9B%86%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97/"},{"content":"重要 配置 Deployment中配置举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 spec: selector: matchLabels: app: {{ template \u0026#34;common.name\u0026#34; . }} replicas: {{ .Values.deploymentReplicas }} template: metadata: name: {{ template \u0026#34;common.name\u0026#34; . }} annotations: container.security.alpha.kubernetes.io/{{- template \u0026#34;common.name\u0026#34; . -}}: \u0026#34;runtime/default\u0026#34; labels: app: {{ template \u0026#34;common.name\u0026#34; . }} release: \u0026#34;{{ .Release.Name }}\u0026#34; spec: {{- if .Values.persistenceEnabled}} initContainers: - name: volume-permissions image: reg.chebai.org/paas/busybox:latest command: [\u0026#39;sh\u0026#39;, \u0026#39;-c\u0026#39;, \u0026#39;chmod -R 777 {{ .Values.volumeMounts.mountPath | quote }}\u0026#39;] volumeMounts: - mountPath: {{ .Values.volumeMounts.mountPath | quote }} name: {{ $.Values.serviceName }}-nfs {{- end }} Reference ","description":"","id":56,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes-使用初始化容器修改挂卷的权限","uri":"https://hex-go.github.io/posts/kubernetes/2021-01-27-kubernetes-%E4%BD%BF%E7%94%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%B9%E5%99%A8%E4%BF%AE%E6%94%B9%E6%8C%82%E5%8D%B7%E7%9A%84%E6%9D%83%E9%99%90/"},{"content":"重要 内网搭建nexus, 供nuclio构建go语言服务使用。\n由于go-proxy不支持认证，必须nexus启用匿名访问。\ngo1.14之后，引入sumdb验证。这个校验的概念是所有公共的包都会在官方的sumdb中存有一份校验值，以防止一些恶意劫持篡改的情况发生。\n但官方的sumdb地址为sum.golang.org(需要翻墙)，构建时连到这个地址去校验包会超时。\n配置 1. sumdb超时问题 配置国内sumdb库，export GOSUMDB=\u0026quot;sum.golang.google.cn\u0026quot;\n构建过程需要连接外网。\n关闭sumdb校验，export GOSUMDB=off\n不推荐，sumdb校验对安全来说，还是比较重要。\n2. GOPRIVATE跳过私有库 `go env -w GOPRIVATE=*.gitlab.com,*.gitee.com` 后续 由于nexus比较重，使用其搭建私仓又必需启用匿名访问。所以后期可以研究goproxy搭建私仓。\nGit-Hub goproxy\n搭建私有goproxy\nathens 搭建golang私有仓库\nReference Blog-go1.12与1.14之私服使用的差异与变化\nNexus-Document go repositories\n","description":"","id":57,"section":"posts","tags":["Persistence"],"title":"Nexus-搭建go私仓内网使用.md","uri":"https://hex-go.github.io/posts/persistence/2021-01-27-nexus-%E6%90%AD%E5%BB%BAgo%E7%A7%81%E4%BB%93%E5%86%85%E7%BD%91%E4%BD%BF%E7%94%A8.md/"},{"content":"重要 最重要的事: 通过postman的tests模块解析jwt，从而在Console查看claim的值。\n配置 在请求access-token的请求中，添加Tests脚本。请求示例如下\n1 2 3 4 5 6 7 curl --location --request POST \u0026#39;https://sso.icos.city/auth/realms/icos/protocol/openid-connect/token\u0026#39; \\ --header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ --data-urlencode \u0026#39;grant_type=password\u0026#39; \\ --data-urlencode \u0026#39;username=hexiang\u0026#39; \\ --data-urlencode \u0026#39;password=xxxxxx\u0026#39; \\ --data-urlencode \u0026#39;client_id=\u0026lt;client-id\u0026gt;\u0026#39; \\ --data-urlencode \u0026#39;client_secret=\u0026lt;client-secret\u0026gt;\u0026#39; 增加的Test脚本如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 let jsonData = pm.response.json(); // use whatever key in the response contains the jwt you want to look into. This example is using access_token let jwtContents = jwt_decode(jsonData.access_token); // Now you can set a postman variable with the value of a claim in the JWT pm.variable.set(\u0026#34;someClaim\u0026#34;, jwtContents.payload.someClaim); function jwt_decode(jwt) { var parts = jwt.split(\u0026#39;.\u0026#39;); // header, payload, signature let tokenContents={}; tokenContents.header = JSON.parse(atob(parts[0])); tokenContents.payload = JSON.parse(atob(parts[1])); tokenContents.signature = atob(parts[2]); // this just lets you see the jwt contents in the postman console. console.log(\u0026#34;Token Contents:\\n\u0026#34; + JSON.stringify(tokenContents, null, 2)); return tokenContents; } Reference Issue - 在Tests中解析jwt并显示claim\nStack Overflow - 在Tests中解析jwt并修改claim值\nStack Exchange - decoding-jwt-and-testing-results-in-postman\nPostman 文档 - Write Tests\n","description":"","id":58,"section":"posts","tags":["个人工具","Postman"],"title":"Postman使用Test解析jwt验证claim","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2021-01-27-postman%E4%BD%BF%E7%94%A8test%E8%A7%A3%E6%9E%90jwt%E9%AA%8C%E8%AF%81claim/"},{"content":"重要 最重要的事: PostgreSQL已安装postgis插件，给开发提供服务时，创建了数据库，并创建新的用户，用户只有关联数据库的所有权限。导致出现如下报错\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 登录 postgresql 客户端 psql -h \u0026#34;\u0026lt;PostgreSQL-Host|NoPort\u0026gt;\u0026#34; -U \u0026#34;\u0026lt;PostgreSQL-User\u0026gt;\u0026#34; -d \u0026#34;\u0026lt;PostgreSQL-Database\u0026gt;\u0026#34; # 查看支持的数据库类型, 未发现postgis支持的类型 \u0026gt; \\dT List of data types Schema | Name | Description --------+---------------+----------------------------------------------------------------------------------------- public | agg_count | public | box2df | public | gidx | public | spheroid | public | valid_detail | # 查看此数据库支持的插件 \u0026gt;\\dx List of installed extensions Name | Version | Schema | Description ---------+---------+------------+--------------------------------------------------------------------- plpgsql | 1.0 | pg_catalog | PL/pgSQL procedural language (1 rows) # 执行建库命令，报错类型不支持 \u0026gt;DROP TABLE IF EXISTS \u0026#34;public\u0026#34;.\u0026#34;test\u0026#34;; \u0026gt;CREATE TABLE \u0026#34;public\u0026#34;.\u0026#34;test\u0026#34; ( \u0026#34;id\u0026#34; varchar(50) COLLATE \u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34; NOT NULL, \u0026#34;name\u0026#34; varchar(255) COLLATE \u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;, \u0026#34;geometry\u0026#34; \u0026#34;public\u0026#34;.\u0026#34;geometry\u0026#34;, \u0026#34;type\u0026#34; int4, \u0026#34;parent_id\u0026#34; varchar(50) COLLATE \u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34; ); ERROR: type \u0026#34;public.geometry\u0026#34; does not exist LINE 4: \u0026#34;geometry\u0026#34; \u0026#34;public\u0026#34;.\u0026#34;geometry\u0026#34;, 原因 因为数据库没有启用postgis插件，需要执行以下命令\n1 CREATE EXTENSION postgis; 但由于启用插件需要全局管理员权限，因此需要用admin用户登录postgis, 并启用\u0026quot;\u0026ldquo;数据库的postgis插件\n1 2 3 4 5 # 赋予超级管理员权限 alter role user_name superuser; # 打开一个新的pgsql,执行命令`CREATE EXTENSION postgis;` # 收回超级管理员权限 alter role user_name nosuperuser Reference StackOverflow-只能用superuser创建extension\nStackOverflow-ERROR: type \u0026ldquo;public.geometry\u0026rdquo; does not exist\n","description":"","id":59,"section":"posts","tags":["Persistence"],"title":"PostgreSQL使用postgis插件涉及权限问题","uri":"https://hex-go.github.io/posts/persistence/2021-01-26-postgresql%E4%BD%BF%E7%94%A8postgis%E6%8F%92%E4%BB%B6%E6%B6%89%E5%8F%8A%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98/"},{"content":"重要 虽然louketo-proxy停止开发，转向oauth2proxy。但由于oauth2proxy功能太弱。不适用此场景。继续选用louketo-proxy实现。\n部署配置， 一共有三个组件（以nuclio举例）：\nkeycloak: 提供oauth2的认证源。在此处配置client、redirect_url、scope等 louketo-proxy: 作为proxy，代理所有走向nuclio的流量。与keycloak集成，没有权限的请求将被proxy拦截。 nuclio: 没有登录、授权的应用（一种faas平台）。 环境说明 keycloak: 10.0.2\nlouketo-proxy: v2.3.0\nnuclio: 1.5.12\n安装 louketo-proxy启动的ingress地址对用户开放，名字应为proxy后面服务的真实地址，如代理proxy服务，则需设置为faas.icos.city。\n1. 配置louketo-proxy client-id: 配置为keycloak服务中创建的client-name\nclient-secret: 配置为keycloak服务中创建的client, 点击credentials获取。\ndiscovery-url: 注意修改keycloak地址和realm名。\u0026lt;keycloak-address\u0026gt;/auth/realms/\u0026lt;realm-name\u0026gt;\nredirection-url: 认证完成后，返回的访问地址，即louketo-proxy的ingress地址。注意，不带oauth/callback。\nupstream-url: louketo-proxy 后面的真实应用地址。\nenable-refresh-tokens: 允许refresh-token刷新token。\n用户访问应用，会重定向到Keycloak。 那里获得授权代码。 前端louketo-proxy将此授权代码交换为access token、refresh token，\n这些token放在前端的cookie中。 当使用过期的access token调用后端时，refresh token将被解密并用于获取新的access token。\nrefresh token可以过期或无效。 当返回401时，前端应刷新页面，以便将用户重定向到Keycloak。\n更安全的做法是将token存储在redis中, 而不是存储在前端Cookie中。\nskip-upstream-tls-verify: 跳过证书校验\nskip-openid-provider-tls-verify: 跳过证书校验\nproxy的chart value.yaml如下：(proxy-chart文件)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #【----------------全局变量--------------------】 global: # # 镜像仓库名称 imageRepositoryName: reg.chebai.org #【----------------镜像配置--------------------】 # 镜像 imageRepository: paas/louketo-proxy #版本要求3位数,不写默认从.Chart.appVersion拿 #imageTag: 5.6.10 # 拉取镜像策略 imagePullPolicy: Always #容器启动命令和参数 containersCommand: {} containersArgs: \u0026#39;[ \u0026#34;--client-id=\u0026lt;client-id\u0026gt;\u0026#34;, \u0026#34;--client-secret=\u0026lt;client-secret\u0026gt;\u0026#34;, \u0026#34;--discovery-url=\u0026lt;keycloak-address\u0026gt;/auth/realms/\u0026lt;realm-name\u0026gt;\u0026#34;, \u0026#34;--enable-default-deny=true\u0026#34;, \u0026#34;--secure-cookie=false\u0026#34;, \u0026#34;--encryption-key=AgXa7xRcoClDEU0ZDSH4X0XhL5Qy2Z2j\u0026#34;, \u0026#34;--enable-json-logging=true\u0026#34;, \u0026#34;--enable-logging=true\u0026#34;, \u0026#34;--enable-request-id=true\u0026#34;, \u0026#34;--enable-security-filter=true\u0026#34;, \u0026#34;--http-only-cookie=true\u0026#34;, \u0026#34;--listen=0.0.0.0:8080\u0026#34;, \u0026#34;--preserve-host=true\u0026#34;, \u0026#34;--enable-logging\u0026#34;, \u0026#34;--redirection-url=http://faas.example.com\u0026#34;, \u0026#34;--upstream-url=http://nuclio-dashboard:8070\u0026#34;, \u0026#34;--skip-openid-provider-tls-verify\u0026#34;, \u0026#34;--skip-upstream-tls-verify\u0026#34;, \u0026#34;--resources=uri=/*|methods=GET,POST,DELETE,PUT,HEAD|roles=nuclio:viewer\u0026#34; ]\u0026#39; #【----------------服务配置--------------------】 #是否启动服务 serviceEnabled: true # 服务映射端口类型ClusterIP、NodePort serviceType: NodePort # 服务 serviceName: nuclio-proxy servicePorts: # 容器内端口 - port: 8080 protocol: \u0026#34;TCP\u0026#34; ingressEnabled: true ingressAnnotations: kubernetes.io/ingress.class: nginx ingressAddns: false ingressHosts: - host: faas domain: example.com paths: - path: / servicePort: 8080 2. 配置keycloak 配置client\n配置Scope\n也可以直接通过Mappers配置audience, ClientScope只是多封装了一层，好处是便于多个client共用。\n2.1 选择icosrealm \u0026ndash; 点击Client Scopes \u0026ndash; 点击Settings\nname: 设置名字为nuclio-service Protocol: 设置名字为openid-connect\n2.2 在Client Scope页面 \u0026ndash; 点击Mappers\nname: 设置名字为nuclio-audience Mapper Type: 设置为Audience Included Client: 输入nuclio，选择所要关联的client Add to access token: 将状态设置为ON 2.3 返回Clients页面 \u0026ndash; 点击nuclio client \u0026ndash; 选择Client Scopes标签页 \u0026ndash; 选择Setup\n在Available Client Scopes 中选择刚创建的nuclio-service \u0026ndash; 点击Add selected\n创建用户 并将\n3. 部署nuclio 将nuclio的集群外部访问都删除，比如ingress、nodeport等，用户只能通过代理访问nuclio-dashboard:8070服务。\n使用 遇到问题 error redirect_url报错： keycloak-client配置redirect_url 缺少oauth/callback,导致出现报错（keycloak端报错）\nkeycloak中需要设置为http://\u0026lt;nuclio.acme.com\u0026gt;/oauth/callback（也可以直接使用通配符，配置为http://\u0026lt;nuclio.acme.com\u0026gt;/*） louketo-proxy启动时配置为http://\u0026lt;nuclio.acme.com\u0026gt;/。 登录成功，但由于未配置audience字段aud，claim中的字段无法对应\n导致如下报错(louketo-proxy 端报错) 1 \u0026#39;aud\u0026#39; claim and \u0026#39;client_id\u0026#39; do not match 使用镜像supervisor启动，导致针对role的鉴权一直失败。 换成reg.chebai.org/paas/louketo-proxy:v1.0.0之后一切正常。\nkeycloak服务端，注销session，需要重新无痕模式打开新的窗口生效。 过期时间在生成accessToken时被服务端根据配置生成（服务端默认5分钟过期），并保存在cookie中。\n在无refreshToken干预的条件下，只有等过期时间（默认5分钟）结束才会过期，返回keycloak登录页面。\nnuclio会在请求header中x-nuclio-project-namespace: \u0026lt;namespace: eg. nuclio\u0026gt;,来区分不同命名空间下的function, 后期可以结合User Group，来进行租户划分和授权管理。 后续 nuclio使用louketo-proxy进行鉴权，多租户管理。\nReference gatekeeper git 仓库\ngatekeeper 用户手册\nKeycloak-gatekeeper: \u0026lsquo;aud\u0026rsquo; claim and \u0026lsquo;client_id\u0026rsquo; do not match\nKeycloak 文档 - Audience support\n参考，理解类似gatekeepr、oauth2proxy这类工具的实现\nOpen Policy Agent 文档\n","description":"","id":60,"section":"posts","tags":["Devops"],"title":"Keycloak-配置gatekeeper保护没有认证授权的应用功能","uri":"https://hex-go.github.io/posts/devops/2021-01-25-keycloak-%E9%85%8D%E7%BD%AEgatekeeper%E4%BF%9D%E6%8A%A4%E6%B2%A1%E6%9C%89%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83%E7%9A%84%E5%BA%94%E7%94%A8%E5%8A%9F%E8%83%BD/"},{"content":"重要 ingress controller 启用证书透传需要做两步操作\n部署IngressController时，需要增加参数--enable-ssl-passthrough 在ingress对象中设置annotation，值为nginx.ingress.kubernetes.io/ssl-redirect: \u0026quot;false\u0026quot; --enable-ssl-passthrough标志启用SSLPassthrough功能，​​此功能默认情况下处于禁用状态。\n环境说明 kubernetes 1.15.6\nnginx-ingress-controller:3.21.0\n配置 1. 获取chart 离线备份\n1 2 3 4 5 6 7 8 9 10 11 helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo update # 拉取 最新 版本chart # 建议拉取chart,而不是在线安装 helm pull ingress-nginx/ingress-nginx --version=3.21.0 # helm install helm install --name ingress-nginx --namespace ingress-nginx ingress-nginx-3.21.0.tgz helm install ingress-nginx ingress-nginx/ingress-nginx 2. 配置ingress-nginx,增加参数--enable-ssl-passthrough ingress-nginx的未在values文件中分离变量控制透传，需要改动template/controller-deployment.yaml#77： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 {{- if or (eq .Values.controller.kind \u0026#34;Deployment\u0026#34;) (eq .Values.controller.kind \u0026#34;Both\u0026#34;) -}} {{- include \u0026#34;isControllerTagValid\u0026#34; . -}} apiVersion: apps/v1 kind: Deployment metadata: name: {{ include \u0026#34;ingress-nginx.controller.fullname\u0026#34; . }} spec: revisionHistoryLimit: {{ .Values.revisionHistoryLimit }} minReadySeconds: {{ .Values.controller.minReadySeconds }} template: metadata: {{- if .Values.controller.podAnnotations }} annotations: {{- range $key, $value := .Values.controller.podAnnotations }} {{ $key }}: {{ $value | quote }} {{- end }} {{- end }} labels: {{- include \u0026#34;ingress-nginx.selectorLabels\u0026#34; . | nindent 8 }} app.kubernetes.io/component: controller {{- if .Values.controller.podLabels }} {{- toYaml .Values.controller.podLabels | nindent 8 }} {{- end }} spec: dnsPolicy: {{ .Values.controller.dnsPolicy }} containers: - name: controller {{- with .Values.controller.image }} image: \u0026#34;{{.repository}}:{{ .tag }}{{- if (.digest) -}} @{{.digest}} {{- end -}}\u0026#34; {{- end }} imagePullPolicy: {{ .Values.controller.image.pullPolicy }} {{- if .Values.controller.lifecycle }} lifecycle: {{ toYaml .Values.controller.lifecycle | nindent 12 }} {{- end }} args: - /nginx-ingress-controller - --enable-ssl-passthrough 3. 配置 ingress-object 的注解 创建的需要透传的ingress对象举例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: extensions/v1beta1 kind: Ingress metadata: annotations: nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; kubernetes.io/ingress.class: nginx creationTimestamp: \u0026#34;2020-08-18T07:35:48Z\u0026#34; name: paas-sample-ingress spec: rules: - host: paassample.icos.city http: paths: - backend: serviceName: paas-sample-svc servicePort: 80 path: / Reference IngressNginx设置SSL Passthrough\n","description":"","id":61,"section":"posts","tags":["Kubernetes","IngressController"],"title":"部署组件--IngressController启用证书透传","uri":"https://hex-go.github.io/posts/kubernetes/2021-01-22-%E9%83%A8%E7%BD%B2%E7%BB%84%E4%BB%B6--ingresscontroller%E5%90%AF%E7%94%A8%E8%AF%81%E4%B9%A6%E9%80%8F%E4%BC%A0/"},{"content":"重要 由于领导想通过代码量衡量外包的工作量，需要每周提供当前周的代码增量。\n规程中遇到以下问题：\n使用什么工具，cloc 如何统计最近一周代码增量 解决中文文件名导致cloc报错 环境说明 Ubuntu 18.04\n安装 版本较老，如果想使用最新版，参考此处安装\n1 sudo apt install cloc 使用 git 获取距今一周的 Commit ID --reverse : 将git log 倒序 -1 : 只取一行日志 --pretty=format:\u0026quot;%h\u0026quot;: 日志只输出commit-id 1 2 3 4 5 6 7 8 9 # 获取最近一周日志 date_str=$(date --date=\u0026#34;1 weeks ago\u0026#34; +\u0026#34;%Y-%m-%d\u0026#34;) logs=$(git log --after=\u0026#34;${date_str}\u0026#34; --pretty=format:\u0026#34;%h\u0026#34;) # --reverse 与 --pretty 一起使用未反转日志。以下命令会取最新的一次commit-id # commit_id=$(git log --after=\u0026#34;${date_str}\u0026#34; --reverse -1 --pretty=format:\u0026#34;%h\u0026#34;) # 获取最后一条commit-id 与 HEAD的差异 cloc --git --diff \u0026#34;${logs##*$\u0026#39;\\n\u0026#39;}\u0026#34; HEAD 如果git仓库中，存在中文，则有可能遇到以下报错 1 2 3 $ cloc --git --diff c9df9mf09df HEAD fatal: pathspec \u0026#39;\u0026#34;road/Road/\\346\\265\\213\\350\\257\\225\\345\\234\\271\\2.sql\u0026#34;\u0026#39; did not match any files Failed to create tarfile of files from git. at /usr/bin/cloc line 3811. 将中文名显示乱码问题解决，则能正常统计\n1 git config --global core.quotepath false Reference bash-date\ncloc\ngit中文显示乱码问题\n","description":"","id":62,"section":"posts","tags":["Devops","Cloc","Git","Date"],"title":"Git--中文名乱码导致cloc统计代码量出错","uri":"https://hex-go.github.io/posts/devops/2021-01-22-git--%E4%B8%AD%E6%96%87%E5%90%8D%E4%B9%B1%E7%A0%81%E5%AF%BC%E8%87%B4cloc%E7%BB%9F%E8%AE%A1%E4%BB%A3%E7%A0%81%E9%87%8F%E5%87%BA%E9%94%99/"},{"content":"重要 最重要的事: 操作记录\n1.简介 nuclio平台部署，需要一个镜像仓库提供两个功能\n构建时，提供build-base-image; 存储每个function构建后的结果镜像。 所以需要： 1. 部署带认证的registry； 2. 将基础依赖镜像(包括各个语言的build-handler镜像等)推送registry\n2.环境准备 获取, 基于\n此chart 修改的registry。\n离线chart\n3.部署 参数说明 prebaked-registry/values.yaml：\n变量 说明 secrets.htpasswd kaniko pull prebaked-registry时认证用的密码 生成prebaked-registry认证密码 1 docker run --entrypoint htpasswd registry:2 -Bbn icos 123456 部署prebaked-registry 把上一步生成的密码粘贴到 prebaked-registry/values.yaml secrets.htpasswd\n执行命令部署服务：\n1 2 kubectl create ns nuclio helm install prebaked-registry ./prebaked-registry/ -n nuclio 创建registry credentials secret 1 2 3 4 5 6 7 # 输入registry密码，同prebaked-registry保持一致 read -s mypassword # 注意修改 \u0026lt;user\u0026gt; kubectl -n nuclio create secret docker-registry registry-credentials --docker-username icos --docker-password $mypassword --docker-server prebaked-registry.nuclio:5000 --docker-email admin@icos.city # 注销变量 unset mypassword 4.使用 参考chart的Note内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 1. Get the application URL by running these commands: {{- if .Values.ingress.enabled }} {{- range .Values.ingress.hosts }} http{{ if $.Values.ingress.tls }}s{{ end }}://{{ . }}{{ $.Values.ingress.path }} {{- end }} {{- else if contains \u0026#34;NodePort\u0026#34; .Values.service.type }} export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services {{ template \u0026#34;docker-registry.fullname\u0026#34; . }}) export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT {{- else if contains \u0026#34;LoadBalancer\u0026#34; .Values.service.type }} NOTE: It may take a few minutes for the LoadBalancer IP to be available. You can watch the status of by running \u0026#39;kubectl get svc -w {{ template \u0026#34;docker-registry.fullname\u0026#34; . }}\u0026#39; export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ template \u0026#34;docker-registry.fullname\u0026#34; . }} -o jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].ip}\u0026#39;) echo http://$SERVICE_IP:{{ .Values.service.externalPort }} {{- else if contains \u0026#34;ClusterIP\u0026#34; .Values.service.type }} export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l \u0026#34;app={{ template \u0026#34;docker-registry.name\u0026#34; . }},release={{ .Release.Name }}\u0026#34; -o jsonpath=\u0026#34;{.items[0].metadata.name}\u0026#34;) echo \u0026#34;Visit http://127.0.0.1:8080 to use your application\u0026#34; kubectl -n {{ .Release.Namespace }} port-forward $POD_NAME 8080:5000 {{- end }} Reference Blog-private-docker-registry\nBlog-在k8s中部署registry\n","description":"","id":63,"section":"posts","tags":["Persistence","Registry","Kubernetes"],"title":"Registry--部署至k8s集群并使用","uri":"https://hex-go.github.io/posts/persistence/2021-01-22-registry--%E9%83%A8%E7%BD%B2%E8%87%B3k8s%E9%9B%86%E7%BE%A4%E5%B9%B6%E4%BD%BF%E7%94%A8/"},{"content":"重要 记同事一次奇葩问题拍错过程。\n环境说明 presto 服务部署在k8s集群内部，并与集成了集群外的kerbos认证。\n现象：\n集群内部访问presto一切正常，但集群外部访问会阻塞5分钟，之后访问正常。\n排错过程：\n抓包，抓client与kerbos之间包。发现客户端像DNS-Server发起了对域``的解析，返回的解析结果中包含36个主机IP,包大小超过了512字节，导致消息被截断，\n然后重新发起了TCP请求，但DNS-Server的TCP-53端口没有开放，客户端重试5分钟，超时。但presto还继续了后面正常的逻辑。\n造成问题原因：\n1. 集群外部使用DNS-Server,安全组中中开放了TCP-53，未开放UDP-53端口。\n导致问题难以定位原因：\n1. 之前主机较少，解析的包未超过512。集群内外状态皆正常。\n2. 集群内部使用的CoreDNS，TCP-53与UDP-53端口开放；但集群外部使用的外部的DNS-Server,安全组中只开放了TCP-53。\n3. 以为presto服务存在问题，只抓了客户端与presto之间的网路包。后期观察presto日志发现阻塞时，日志停留在与kerbos认证过程中。\n4. presto处理机制存在问题，即dns解析异常未做处理(比如抛错或退出)；未收到期望的解析结果仍走了后面正常逻辑，导致只是等待5分钟，但后续逻辑正常。\nReference 抓取的包文件可从此处获取\n包通过wireshark打开，如下：\nDNS使用TCP和UDP的53端口\n","description":"","id":64,"section":"posts","tags":["Kubernetes"],"title":"故障排查--ExternalDNS只开放UDP53不开放TCP53导致网络超时","uri":"https://hex-go.github.io/posts/kubernetes/2021-01-21-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5--externaldns%E5%8F%AA%E5%BC%80%E6%94%BEudp53%E4%B8%8D%E5%BC%80%E6%94%BEtcp53%E5%AF%BC%E8%87%B4%E7%BD%91%E7%BB%9C%E8%B6%85%E6%97%B6/"},{"content":"重要 1.简介 EOF是（END Of File）的缩写，表示自定义终止符。既然自定义，那么EOF就不是固定的，可以随意设置别名，在linux按ctrl-d 就代表EOF。\nEOF一般会配合cat能够多行文本输出。\n2. 用法说明 其用法如下：\n1 2 3 \u0026lt;\u0026lt;EOF #开始 .... #输入内容 EOF #结束 还可以自定义，比如自定义：\n1 2 3 4 5 #开始 \u0026lt;\u0026lt;ABC .... ## 结束 ABC 通过cat配合重定向能够生成文件并追加操作，在它之前先熟悉几个特殊符号\n\u0026lt;: 输入重定向\n\u0026gt;: 输出重定向\n\u0026gt;\u0026gt;: 输出重定向,进行追加,不会覆盖之前内容\n\u0026lt;\u0026lt;: 标准输入来自命令行的一对分隔号的中间内容\n例子1：\n1 2 3 cat \u0026lt;\u0026lt;EOF hello EOF 输出为：\n1 hello cat的操作对象是文件，上面例子中cat的操作对象是用户输入；用户输入是文件描述符0对应的特殊文件。标准输入0中保存了“Hello”，再用cat命令输出其中的内容。\n\u0026ldquo;\u0026laquo;EOF EOF\u0026quot;的作用就是在执行命令过程中用户自定义输入，类似于一个临时文件。\n再结合重定向，可以\u0026rdquo;\u0026laquo;EOF EOF\u0026quot;的内容写入文件中。\n例子2：\n1 2 3 4 5 6 7 8 9 10 11 12 ## 1. 创建1.txt文件，文件中有字段`abc` echo \u0026#34;abc\u0026#34; \u0026gt; 1.txt ## 2. 向文件1.txt输入覆盖内容（也可以：cat \u0026gt; 1.txt \u0026lt;\u0026lt;EOF） cat \u0026lt;\u0026lt;EOF \u0026gt; 1.txt 11 aa bb lol EOF ## \u0026#34;\u0026lt;\u0026lt; EOF EOF\u0026#34; 的作用是在命令执行过程中用户自定义输入，它类似于起到一个临时文件的作用，只是比使用文件更方便灵活。 3. cat \u0026lt;\u0026lt;EOF 与 cat \u0026lt;\u0026lt;-EOF 的区别 两个都是获取stdin，并在EOF处结束stdin，输出stdout。\n使用cat \u0026lt;\u0026lt;EOF时，输入完成后，需要在一个新的一行输入EOF结束stdin的输入。EOF必须顶行写，前面不能用制表符或者空格。\n使用cat \u0026lt;\u0026lt;-EOF时，分界符（EOF）所在行的开头部分的制表符（Tab）都将被去除。这可以解决由于脚本中的自然缩进产生的制表符。\n对应两种正确示例写法如下：\ncat \u0026lt;\u0026lt;EOF，EOF顶行写 1 2 3 4 5 6 7 8 ## 最后的EOF不能包含制表符和空格，否则无法识别为结束分界符，无法表示stdin的结束。 #!/bin/bash cat \u0026lt;\u0026lt;EOF 你好，EOF！ EOF cat \u0026lt;\u0026lt;-EOF，EOF前可加空格 1 2 3 4 5 6 7 8 #!/bin/bash ## 虽然最后的EOF前面有多个制表符和空格，但仍然会被当做结束分界符，表示stdin的结束。 cat \u0026lt;\u0026lt;-EOF 你好，EOF！ EOF 如果使用cat \u0026lt;\u0026lt;EOF，但结束分界符EOF前面有制表符或者空格，无法将EOF识别为结束分界符，只会继续被当做stdin来输入。所以会报如下报错\n1 2.sh: line 5: warning: here-document at line 1 delimited by end-of-file (wanted `EOF\u0026#39;) 脚本内容如下：\n1 2 3 4 5 #!/bin/bash cat \u0026lt;\u0026lt;EOF 你好，EOF！ EOF how-can-i-write-a-heredoc-to-a-file-in-bash-script\nHere Documents\n","description":"","id":65,"section":"posts","tags":["Bash"],"title":"shell基础之EOF的用法","uri":"https://hex-go.github.io/posts/bash/2021-01-14-shell%E5%9F%BA%E7%A1%80%E4%B9%8Beof%E7%9A%84%E7%94%A8%E6%B3%95/"},{"content":"重要 实现的状态\ngithub仓库走代理 内网仓库不走代理 1.简介 由于github仓库拉取缓慢，所以配置了代理； 但内网仓库拉取也走了代理，导致出现以下报错\n1 2 hex@hex-pc:~/example-repo$ git pull fatal: unable to access \u0026#39;https://git.service.rd/plugins/git/example-repo.git/\u0026#39;: gnutls_handshake() failed: The TLS connection was non-properly terminated. 解决办法(推荐) git是可以根据环境变量的配置，声明代理并将内网地址配置不走代理，实现此功能，但要注意格式。\n1 2 3 4 5 6 7 export https_proxy=http://127.0.0.1:10800/ export http_proxy=http://127.0.0.1:10800/ export all_proxy=socks://127.0.0.1:1088/ export ftp_proxy=http://127.0.0.1:10800 # 声明内网不走proxy的服务 声明域名作为通配，以空格分隔。 export no_proxy=\u0026#34;.service.rd .icos.city 127.0.0.1 localhost\u0026#34; 修改本地库-local配置 也可以针对仓库设置git config。可以设置本地库全局配置，也可以只设置单一远端。\n已有仓库,进入仓库目录下，并添加一个“空”代理（仓库级别）。 1 git config --local --add http.proxy \u0026#34;\u0026#34; 在仓库目录下\u0026lt;repo_path\u0026gt;/.git/config，会出现以下内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \u0026#34;origin\u0026#34;] url = https://git.service.rd/plugins/git/example.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \u0026#34;master\u0026#34;] remote = origin merge = refs/heads/master [http] proxy = 已有仓库，进入仓库目录下，添加一个”空“代理（固定remote级别）。 1 git config --local --add remote.\u0026lt;name\u0026gt;.proxy \u0026#34;\u0026#34; 执行下面命令查看\n1 git config --local --get remote.\u0026lt;name\u0026gt;.proxy 修改全局配置（只能针对单库） 修改 ~/.gitconfig文件，增加以下内容\n1 2 3 4 5 [http] sslVerify = true [http \u0026#34;https://git.service.rd/plugins/git/example-repo.git\u0026#34;] sslVerify = false ptoxy = ","description":"","id":66,"section":"posts","tags":["个人工具","Git"],"title":"GIT-配置proxy并忽略内网仓库","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-12-28-git-%E9%85%8D%E7%BD%AEproxy%E5%B9%B6%E5%BF%BD%E7%95%A5%E5%86%85%E7%BD%91%E4%BB%93%E5%BA%93/"},{"content":"重要 s3fs使用fuse挂载s3 bucket到Linux或Mac系统,并且支持在Docker容器内部以非特权用户挂载s3 bucket。\n安装s3fs 在容器内使用s3fs,需要在Docker镜像中安装s3fs,以下是主流发行版安装方法:\nDebian 9 and Ubuntu 16.04 or newer:\n1 sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL:\n1 2 sudo yum install epel-release sudo yum install s3fs-fuse 参数说明 /etc/fuse.conf文件中配置说明\nParameter Description Default user_allow_other 允许非root用户使用allow_other 挂载选项 no value 挂载选项说明\nParameter Description Default use_path_request_style 非AWS实现的S3服务,设置此参数,配合url使用 no value url S3服务的URL http://obs.cn-north-4.myhuaweicloud.com allow_other 允许非root用户挂载 no vaule 部署服务 通过fstab挂载\n1 2 3 4 echo ACCESS_KEY_ID:SECRET_ACCESS_KEY \u0026gt; ~/.passwd-s3fs sed -i \u0026#39;s/\\#user_allow_other/user_allow_other/g\u0026#39; /etc/fuse.conf mkdir /mnt/s3 rke-test /mnt/s3 fuse.s3fs _netdev,allow_other,use_path_request_style,url=http://obs.cn-north-4.myhuaweicloud.com / 0 0 通过命令挂载\n1 2 3 4 echo ACCESS_KEY_ID:SECRET_ACCESS_KEY \u0026gt; ~/.passwd-s3fs sed -i \u0026#39;s/\\#user_allow_other/user_allow_other/g\u0026#39; /etc/fuse.conf mkdir /mnt/s3 s3fs rke-test /mnt/s3 -o _netdev -o allow_other -o use_path_request_style -o url=http://obs.cn-north-4.myhuaweicloud.com 容器内命令挂载\n1 2 3 4 5 6 docker run -d --name ranger --cap-add mknod --cap-add sys_admin --security-opt apparmor:unconfined --device=/dev/fuse reg.chebai.org/paas/ranger:latest docker exec -it -u 1000 ranger bash echo ACCESS_KEY_ID:SECRET_ACCESS_KEY \u0026gt; ~/.passwd-s3fs sed -i \u0026#39;s/\\#user_allow_other/user_allow_other/g\u0026#39; /etc/fuse.conf mkdir /mnt/s3 s3fs rke-test /mnt/s3 -o _netdev -o allow_other -o use_path_request_style -o url=http://obs.cn-north-4.myhuaweicloud.com 测试 确定已成功挂载 1 mount | grep s3 复制文件到挂载点 1 cp file /mnt/s3 在华为云控制台检查bucket中是否存在该文件 常见问题 fuse: device not found, try \u0026lsquo;modprobe fuse\u0026rsquo; first\nk8s中，容器需要设置特权模式。否则会引起此报错\n启用此功能需要节点安装fuse组件么\n不需要，只需要容器安装s3fs，调用容器内的fuse组件。fuse是user-space的组件，只需要容器内安装。之后需要特权模式sys-admin。则能正常使用。\n用户空间文件系统FUSE工作原理\ns3fs: credentials file /root/.passwd-s3fs should not have others permissions.\n文件权限问题，为是s3认证信息保密，将权限由644改为600。chmod 600 ～/.passwd-s3fs。\n文件只读性能还可以，但一点有写操作，性能很差。\na服务修改了文件，会重新上传文件至s3，其他节点则是从s3同步下修改的文件。\nreference s3fs-fuse github\nfuse 概念扫盲\n","description":"","id":67,"section":"posts","tags":["Persistence"],"title":"S3fs-利用s3作为弹性文件存储方案","uri":"https://hex-go.github.io/posts/persistence/2020-11-18-s3fs-%E5%88%A9%E7%94%A8s3%E4%BD%9C%E4%B8%BA%E5%BC%B9%E6%80%A7%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88/"},{"content":"重要 trivy用来扫描镜像的安全漏洞。如果用于生产环境，需要将漏洞库离线，安全人员将镜像的基础镜像或者buildpack的stack进行升级。之后再升级安全漏洞。\n将安全漏洞修复变成可计划，分期实施的过程。如果一直使用在线库，则不能采取存在漏洞立即删除的策略。\n环境说明 trivy version 0.4.4\n安装 使用 扫描镜像的命令\n采用server-client模式启动服务 trivy采取server-client模式，server端将漏洞库离线打在镜像内\n1. 获取离线漏洞库 在trivy版本Release时，会发布漏洞库\n下载连接\n参考issue\n或者选择执行命令下载\n1 trivy --download-db-only 2. 启动server端 server端命令如下\n\u0026ndash;token用于客户端与server连接时，认证使用。\n\u0026ndash;skip-update 跳过漏洞库更新\n1 trivy server -d --listen 0.0.0.0:4954 --skip-update --token mail2Uyu 3. 启动client端 client端命令如下\n\u0026ndash;cache-dir 声明缓存的路径\n\u0026ndash;severity 扫描的漏洞安全级别\n\u0026ndash;vuln-type 扫描的漏洞类型\n\u0026ndash;format 声明报告格式\n\u0026ndash;output 输出的日志位置\n\u0026ndash;ignore-unfixed 忽略未修复的漏洞\n1 2 3 4 5 6 7 8 trivy client --remote http://trivy-server.svc.com:4954 --token mail2Uyu \\ --cache-dir /root/.cache/trivy \\ --severity UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL \\ --vuln-type os \\ --ignore-unfixed \\ --format json \\ --output /root/.cache/reports/scan_report_984890059.json \\ ubuntu:20.04 使用 trivy 直接扫描 1 2 3 4 5 6 trivy --cache-dir /root/.cache/trivy \\ --severity CRITICAL \\ --vuln-type os \\ --format json \\ --output /root/.cache/reports/18.04.json \\ centos:centos7.8.2003 trivy 跳过 误报漏洞 在trivy命令执行的同级目录下， 创建.trivyignore文件。以类似下面内容配置忽略的漏洞\n1 2 3 4 5 6 $ cat .trivyignore # Accept the risk CVE-2018-14618 # No impact in our settings CVE-2019-1543 Reference 获取trivy漏洞库\n忽略特定的漏洞\ntrivy支持的os\nbug-使用厂商(比如. Redhat)提供的危险等级\nissue-不能使用非官方源装包(包括自制的包or国内源装包)\n","description":"","id":68,"section":"posts","tags":["Devops"],"title":"DevOps-trivy-镜像扫描汇总","uri":"https://hex-go.github.io/posts/devops/2020-11-06-devops-trivy-%E9%95%9C%E5%83%8F%E6%89%AB%E6%8F%8F%E6%B1%87%E6%80%BB/"},{"content":"重要 ingress-nginx对于暴露grpc的服务，要求必须tls加密。所以，要么ingress配置grpcs,在服务端自己管理证书；要么ingress配置grpc,在ingress配置统一管理证书。\n为便于运维管理证书，此处采用cert-manager统一在ingress配置中。自动生成证书，发布https服务。\n环境说明 使用 生成自签发CA证书，并保存在secret中(供cert-manager签发证书使用)； 配置cluster-issuer,和certificate，使生成Secret，保存证书、ca和私钥； 创建pod,service,ingress, ingress的tls配置使用第二步生成的Secret； 执行命令测试grpc端口是否暴露成功； 1 grpcurl -insecure test.icos.city:443 build.stack.fortune.FortuneTeller/Predict Reference 以上1.2步参考cert-manager相关内容\ncert-manager hex-博客\ncert-manager hex-github-示例项目\n第3,4部参考ingress-nginx的官方示例，\nIngressNginx官房GRPC示例\n第3,4部也可参考cert-manager的示例代码测试\ncert-manager hex-github-示例项目\n其他关于grpc的内容，需要参考此链接\ngrpc_github\ngrpc_go_quick_start\ngrpc python quick-start\ngrpc_java_quick-start\ningress-nginx-grpcExample\ningress-nginx-grpc-DOC\ningress-nginx-grocExampleImage\n","description":"","id":69,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes-ingress-nginx配置grpc服务","uri":"https://hex-go.github.io/posts/kubernetes/2020-11-06-kubernetes-ingress-nginx%E9%85%8D%E7%BD%AEgrpc%E6%9C%8D%E5%8A%A1/"},{"content":"重要 由于需要配置ingress-grpc,nginx-ingress要求tls加密。实现的方式有两种：一种在ingress注解grpcs,之后在pod控制证书；另一种在ingress配置tls。\n生产环境证书都是运维统一维护，舍弃第一种。所以调研cert-manager用来维护证书。\n此处cert-manager用来使用已给的ca为需要证书的服务生成证书、并使用.\n环境说明 K8S：1.15.6\nCertManager: 1.0.4\n部署cert-manager 两种方式：\n一种资源清单部署（install with regular manifests）\n另一种是helm-chart部署（install with helm）\n注意, 默认配置在certificate删除时,它所创建的secret不会被删除; 如果想要Secret同步被删除,需要在部署时指定参数--enable-certificate-owner-ref=true.\n1. 资源清单部署 由于工作环境使用的k8s环境版本为1.15.6，\u0026lt;1.16.\n1 2 # Kubernetes \u0026lt;1.16 kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.0.4/cert-manager-legacy.yaml 2. helm-chart部署 创建CRD资源 由于工作环境使用的k8s环境版本为1.15.6，创建crd时使用最新版本.\n1 kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.0.4/cert-manager.crds.yaml 获取chart部署 1 2 3 4 5 6 7 8 # 添加 chart-repo helm repo add jetstack https://charts.jetstack.io # 拉取 v1.0.4 版本chart # 建议拉取chart,而不是在线安装 helm pull jetstack/cert-manager --version=v1.0.4 # helm install helm install --name cert-manager --namespace cert-manager cert-manager-v1.0.4.tgz 检查安装 1 2 3 4 5 6 $ kubectl get pods --namespace cert-manager NAME READY STATUS RESTARTS AGE cert-manager-5c6866597-zw7kh 1/1 Running 0 2m cert-manager-cainjector-577f6d9fd7-tr77l 1/1 Running 0 2m cert-manager-webhook-787858fcdb-nlzsq 1/1 Running 0 2m 使用 cert-manager 可以从各种证书颁发机构获取证书，包括Let\u0026rsquo;s Encrypt、HashiCorp Vault、Venafi 和 私人PKI。\n由于服务不需要暴露公网，此处选用自签发CA(即私人PKI)方式签发证书：\n1. 创建ca并保存进集群，Secret:cert-manager:ca-key-pair 此处配置的是自签发证书，如果环境中需要更换成合法证书，需要运维在第二步时，根据真实证书创建Secret。\n生成自签发证书(ca.crt)和key(ca.key) 1 2 3 4 5 # Generate a CA private key openssl genrsa -out ca.key 2048 # Create a self signed Certificate, valid for 10yrs with the \u0026#39;signing\u0026#39; option set openssl req -x509 -new -nodes -key ca.key -subj \u0026#34;/CN=ICOS.CITY\u0026#34; -days 3650 -reqexts v3_req -extensions v3_ca -out ca.crt 创建Secret保存证书(命名空间: cert-manager; 资源类型: secret; 资源名称: ca-key-pair.)。 如果使用cluster-issuer，则需要将此secret保存至cert-manager命名空间；\n如果使用issuer,则需要在每个issuer所在命名空间创建此secret.\n此处以 cluster-issuer 配置\n1 kubectl create secret tls ca-key-pair --cert=ca.crt --key=ca.key --namespace=cert-manager 2. 创建 cluster-issuer, 内容如下(cluster-issuer.yaml)： 1 2 3 4 5 6 7 apiVersion: cert-manager.io/v1 kind: ClusterIssuer metadata: name: ca-clusterissuer spec: ca: secretName: ca-key-pair 执行下面命令创建\n1 kubectl create -f cluster-issuer.yaml 3. 创建certificate测试，内容如下(example-ca.yaml)： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 apiVersion: cert-manager.io/v1 kind: Certificate metadata: name: example-ca namespace: mars spec: # 创建名为`example-secret`的secret,保存`ca`与签发的证书. secretName: example-secret issuerRef: name: ca-clusterissuer kind: ClusterIssuer # 此处放的是服务集群内部访问地址， commonName: example.mars organization: - Example CA dnsNames: # 同namespace访问的服务地址 - example # 集群外部访问地址 - example.mars.icos.city 执行命令kubectl create -f example-ca.yaml\n查看证书和Secret\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 $ kubectl -n mars get certificate # 证书的状态 READY 为 True。 NAME READY SECRET AGE example-ca True example-secret 5d20h $ kubectl -n mars get secrets example-secret -o yaml # 回显的secret的 data.ca.crt, data.tls.crt, data.tls.key 都有证书或秘钥base64值。 apiVersion: v1 data: ca.crt: LS0tLS1C...EUtLS0tLQo= tls.crt: LS0tLS1C...RFLS0tLS0K tls.key: LS0tLS1C...0tLS0tCg== kind: Secret metadata: annotations: cert-manager.io/alt-names: test-cert.mars,test-cert.icos.city cert-manager.io/certificate-name: test-cert-ca cert-manager.io/common-name: icos.city cert-manager.io/issuer-kind: ClusterIssuer cert-manager.io/issuer-name: ca-clusterissuer # 在certificate中指定的 `spec.secretName` name: example-secret namespace: mars type: kubernetes.io/tls 4. 容器使用 集群中使用证书的场景有以下几个诉求：\n非https容器访问https容器，需要信任此自签证书。所以需要将ca.crt挂载到非https容器内部； 储存各个服务自身证书的secret中包含三部分，ca.crt,tls.crt,tls.key。 统一的平台部署应用到多个k8s集群，需要每个集群均部署cert-manager,并使用同一个ca。 所以采取以下实现。\n为每个服务均生成证书，至少包含同一集群内部访问和同一Namespace访问的证书。并挂载在/opt/tls/目录下。 如果服务有对外暴露，多加一个dnsName 为集群外部访问地址。 每个服务在固定的容器目录下，均有ca.crt,tls.crt,tls.key文件，只是访问https服务，则只使用ca.crt文件。 ca.crt是公用、一致的； tls.crt,tls.key是根据每个服务的服务名、ingress签发的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # Source: icossense-icosgrpc-service-xadit-001/templates/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: example-001 labels: app: example-001 chart: example-001-1.0.0 release: \u0026#34;RELEASE-NAME\u0026#34; heritage: \u0026#34;Helm\u0026#34; spec: selector: matchLabels: app: example-001 replicas: 1 template: metadata: name: example-001 labels: app: example-001 release: \u0026#34;RELEASE-NAME\u0026#34; spec: containers: - name: example-001 image: \u0026#34;hexpy/example-grpc:latest9\u0026#34; imagePullPolicy: \u0026#34;Always\u0026#34; securityContext: allowPrivilegeEscalation: true runAsNonRoot: true capabilities: drop: [\u0026#34;NET_ADMIN\u0026#34;, \u0026#34;SYS_TIME\u0026#34;,\u0026#34;CHOWN\u0026#34;,\u0026#34;SYS_ADMIN\u0026#34;] ports: - name: containerport-0 protocol: \u0026#34;TCP\u0026#34; containerPort: 7070 volumeMounts: - name: example-secret-mount mountPath: \u0026#34;/etc/tls\u0026#34; readOnly: true volumes: # 在此`deployment`中, `volumeMounts`中的`name`一致 - name: example-secret-mount secret: # 在`certificate`中`spec.secretName`设置的. secretName: example-secret Reference 官方文档\nchart\ngithub\n当证书被删除，Secret会被留下\n当证书被删除，Secret会被留下2\ngithub-示例项目\nAutomatic TLS certificates with cert-manager and ingress-nginx\n","description":"","id":70,"section":"posts","tags":["Kubernetes","CertManager"],"title":"Kubernetes-CertManager解决ingress-tls证书问题","uri":"https://hex-go.github.io/posts/kubernetes/2020-11-05-kubernetes-certmanager%E8%A7%A3%E5%86%B3ingress-tls%E8%AF%81%E4%B9%A6%E9%97%AE%E9%A2%98/"},{"content":"前言 Go 语言中Struct声明包含三部分: field_name, field_type, field_tag.\nfield_tag的作用:\n可以作为字段后额外的注释或者说明\n在反射场景下, reflect包中提供了操作tag的方法, tag的写法需要遵循一定规则.\n使用 Tag 书写规则 tag是一串字符串, 以空格分隔的key:\u0026quot;value\u0026quot;对.\nkey: 为非空字符串, 字符串不含控制字符\\空格\\引号\\冒号. value: 以双引号标记的字符串. 以:分隔,并且冒号前后不能有空格. 1 2 3 4 type Server struct { ServerName string `json: \u0026#34;server_name\u0026#34; gorm:\u0026#34;serverName\u0026#34; default:\u0026#34;example\u0026#34;` ServerIP string `json: \u0026#34;server_ip\u0026#34;` } reflect获取Tag值 StructTag提供了Get(key string) string方法来获取Tag，示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;reflect\u0026#34; \u0026#34;fmt\u0026#34; ) type Server struct { ServerName string `json: \u0026#34;server_name\u0026#34; gorm:\u0026#34;serverName\u0026#34; default:\u0026#34;example\u0026#34;` ServerIP string `json: \u0026#34;server_ip\u0026#34;` } func main() { s := Server{} st := reflect.TypeOf(s) fieldServerName := st.Field(0) fmt.Printf(\u0026#34;TAG-key=\u0026gt;json TAG-value=\u0026gt;%v\\n\u0026#34;, fieldServerName.Tag.Get(\u0026#34;json\u0026#34;)) fmt.Printf(\u0026#34;TAG-key=\u0026gt;default TAG-value=\u0026gt;%v\\n\u0026#34;, fieldServerName.Tag.Get(\u0026#34;default\u0026#34;)) fieldServerIp := st.Field(1) fmt.Printf(\u0026#34;TAG-key=\u0026gt;json TAG-value=\u0026gt;%v\\n\u0026#34;, fieldServerIp.Tag.Get(\u0026#34;json\u0026#34;)) } 程序输出如下：\n1 2 3 TAG-key=\u0026gt;json TAG-value=\u0026gt;server_name TAG-key=\u0026gt;default TAG-value=\u0026gt;example TAG-key=\u0026gt;json TAG-value=\u0026gt;server_ip Tag的作用 使用反射可以动态的给结构体成员赋值，正是因为有tag，在赋值前可以使用tag来决定赋值的动作。 比如，官方的encoding/json包，可以将一个JSON数据Unmarshal进一个结构体，此过程中就使用了Tag. 该包定义一些规则，只要参考该规则设置tag就可以将不同的JSON数据转换成结构体。\n总之：正是基于struct的tag特性，才有了诸如json数据解析、orm映射等等的应用。理解这个关系是至关重要的。或许，你可以定义另一种tag规则，来处理你特有的数据。\nTag使用举例 包 包中关于tag的规则 full example json https://godoc.org/encoding/json#Marshal \u0026ldquo;my_name,omitempty\u0026rdquo; 声明名字+可省略\n\u0026quot;,omitempty\u0026quot; 值为空则省略此字段\n\u0026ldquo;my_name\u0026rdquo; 在json中此字段的键\n\u0026quot;-\u0026quot; 字段始终省略 default https://github.com/creasty/defaults#usage gorm https://godoc.org/github.com/jinzhu/gorm https://www.cnblogs.com/zisefeizhu/p/12788017.html#%E7%BB%93%E6%9E%84%E4%BD%93%E6%A0%87%E8%AE%B0tags yaml https://godoc.org/gopkg.in/yaml.v2 xml https://godoc.org/encoding/xml Reference Go struct tag深入理解(华为)\nGo语言中的struct tag(知乎)\nWell known struct tags(golang wiki)\ngorm 结构体的相关标记\n","description":"","id":71,"section":"posts","tags":["Go"],"title":"Go-Struct-tag深入理解[一]StructTag规则说明","uri":"https://hex-go.github.io/posts/golang/2020-10-21-go-struct-tag%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E4%B8%80structtag%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"content":"重要 1. 目录操作 1.1 删除目录 删除目录下所有内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // Golang program to illustrate how to // remove all the files and directories // from the default directory package main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { // Remove all the directories and files // Using RemoveAll() function err := os.RemoveAll(\u0026#34;/Users/hex/Documents/go\u0026#34;) if err != nil { log.Fatal(err) } } 1.2 创建目录 级联创建所有目录 1 os.MkdirAll(\u0026#34;/tmp/\u0026#34;,FileMode) 1.3 创建临时目录 方法：\n调用io.ioutil包的 ioutil.TempDir方法 == == os包的 os.MkdirTemp方法\n作用：\n创建全局唯一的临时目录。但在使用完成后，需要自行删除此目录。\n参数：\n第一个dir参数如果不指定，则为os.TempDir()目录。如Linux下取$TMPDIR变量，变量空值则为/tmp目录。 ioutil.TempDir方法调用过程说明：\n在目录/tmp目录中创建一个名称以prefix开头的新目录 并返回新创建目录的路径 1 2 3 4 5 6 7 dir, err := ioutil.TempDir(\u0026#34;/tmp\u0026#34;, \u0026#34;prefix-\u0026#34;) if err != nil { log.Fatal(err) } defer os.RemoveAll(dir) fmt.Println(dir) // 例如目录名为 \u0026#34;/tmp/prefix-054003078/\u0026#34; 1.3.1 创建时间目录 1 2 3 // logsDir := os.path.Join(\u0026#34;/tmp\u0026#34;, time.Now().Format(\u0026#34;2006/01/02\u0026#34;)) logsDir := filepath.Join(\u0026#34;/tmp\u0026#34;, time.Now().Format(\u0026#34;2006/01/02\u0026#34;)) err := os.MkdirAll(logsDir, 666) 1.4 检查路径是否为目录 1 2 3 4 5 6 func IsDir(name string) bool { if info, err := os.State(name); err == nil { return info.IsDir() } return false } 1.5 打印当前目录 1 os.Getwd() //获取当前目录 1.6 文件目录拼接 1 2 os.path.join(\u0026#34;/tmp\u0026#34;, \u0026#34;/text.md\u0026#34;) 1.7 目录复制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 func CopyDir(srcPath, desPath string) error { //检查目录是否正确 if srcInfo, err := os.Stat(srcPath); err != nil { return err } else { if !srcInfo.IsDir() { return errors.New(\u0026#34;源路径不是一个正确的目录！\u0026#34;) } } if desInfo, err := os.Stat(desPath); err != nil { return err } else { if !desInfo.IsDir() { return errors.New(\u0026#34;目标路径不是一个正确的目录！\u0026#34;) } } if strings.TrimSpace(srcPath) == strings.TrimSpace(desPath) { return errors.New(\u0026#34;源路径与目标路径不能相同！\u0026#34;) } err := filepath.Walk(srcPath, func(path string, f os.FileInfo, err error) error { if f == nil { return err } //复制目录是将源目录中的子目录复制到目标路径中，不包含源目录本身 if path == srcPath { return nil } //生成新路径 destNewPath := strings.Replace(path, srcPath, desPath, -1) if !f.IsDir() { CopyFile(path, destNewPath) } else { if !FileIsExisted(destNewPath) { return MakeDir(destNewPath) } } return nil }) return err } 1.8 遍历目录下所有文件(不包含子目录) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /* 获取指定路径下的所有文件，只搜索当前路径，不进入下一级目录，可匹配后缀过滤（suffix为空则不过滤）*/ func ListDir(dir, suffix string) (files []string, err error) { files = []string{} _dir, err := ioutil.ReadDir(dir) if err != nil { return nil, err } suffix = strings.ToLower(suffix) //匹配后缀 for _, _file := range _dir { if _file.IsDir() { continue //忽略目录 } if len(suffix) == 0 || strings.HasSuffix(strings.ToLower(_file.Name()), suffix) { //文件后缀匹配 files = append(files, path.Join(dir, _file.Name())) } } return files, nil } 1.9 遍历目录下所有文件(包含子目录) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* 获取指定路径下以及所有子目录下的所有文件，可匹配后缀过滤（suffix为空则不过滤）*/ func WalkDir(dir, suffix string) (files []string, err error) { files = []string{} err = filepath.Walk(dir, func(fname string, fi os.FileInfo, err error) error { if fi.IsDir() { //忽略目录 return nil } if len(suffix) == 0 || strings.HasSuffix(strings.ToLower(fi.Name()), suffix) { //文件后缀匹配 files = append(files, fname) } return nil }) return files, err } 2. 文件操作 2.1 文件创建或追加内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { // ioutil包 创建文件 err := ioutil.WriteFile(\u0026#34;temp.txt\u0026#34;, []byte(\u0026#34;first line\\n\u0026#34;), 0644) if err != nil { log.Fatal(err) } // os包 Create方法 创建文件 f1, _ := os.Create(\u0026#34;./temp.txt\u0026#34;) defer f1.close() // os包 Openfile 读写打开文件 f2, _ := os.Openfile(\u0026#34;./temp.txt\u0026#34;, os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0666) defer f2.close() // 追加文件内容 file, err := os.OpenFile(\u0026#34;temp.txt\u0026#34;, os.O_APPEND|os.O_WRONLY, 0644) defer file.close() if err != nil { log.Println(err) } if _, err := file.WriteString(\u0026#34;second line\u0026#34;); err != nil { log.Fatal(err) } //Print the contents of the file data, err := ioutil.ReadFile(\u0026#34;temp.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(string(data)) } 2.2 创建临时文件 方法：\n调用io.ioutil包的 ioutil.TempFile方法[Go-旧版] == os包的 os.CreateTemp方法[ Go 1.17以上版本]\n作用：\n创建全局唯一的临时文件。但在使用完成后，需要自行删除此文件。\n参数：\n第一个dir参数如果不指定，则为os.TempDir()目录。如Linux下取$TMPDIR变量，变量空值则为/tmp目录。\n第二个参数pattern，在Go-1.11以后支持使用*占位符来制定随机串的位置，没有*则保持默认，再最后追加随机串。\nioutil.TempFile方法调用过程说明：\n在目录/tmp目录中以prefix开头的名称创建一个新文件 打开文件进行读写操作 并返回新创建临时文件对象*os.File 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 不指定随机串位置 file, err := ioutil.TempFile(\u0026#34;/tmp\u0026#34;, \u0026#34;prefix-\u0026#34;) if err != nil { log.Fatal(err) } defer os.Remove(file.Name()) fmt.Println(file.Name()) // 例如文件名为: \u0026#34;/tmp/prefix-054003078\u0026#34; // 指定随机串位置 file2, err2 := ioutil.TempFile(\u0026#34;/tmp\u0026#34;, \u0026#34;myname.*.go\u0026#34;) if err2 != nil { log.Fatal(err2) } defer os.Remove(file2.Name()) fmt.Println(file2.Name()) // 例如文件名为: \u0026#34;/tmp/myname.054003078.bat\u0026#34; 2.3 检查文件是否存在 1 2 3 4 5 6 7 func FileIsExisted(filename string) bool { existed := true if _, err := os.Stat(filename); os.IsNotExist(err){ existed = false } return existed } 2.4 重命名文件 1 os.Rename(\u0026#34;/tmp/1.md\u0026#34;, \u0026#34;tmp/2.md\u0026#34;) 2.5 复制文件 复制文件过程中一定要注意将原始文件的权限也要复制过去，否则可能会导致可执行文件不能执行等问题。\n2.5.1 使用io.Copy 方法简单，但是缺少灵活性。如果文件太大，不是一种很好的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func copy(src, dst string) (int64, error) { // 获取文件权限 sourceFileStat, err := os.Stat(src) if err != nil { return 0, err } perm := sourceFileStat.Mode() // 判断文件状态 if !perm.IsRegular() { return 0, fmt.Errorf(\u0026#34;%s is not a regular file\u0026#34;, src) } // 打开源文件 source, err := os.Open(src) if err != nil { return 0, err } defer source.Close() // 创建目标文件 // destination, err := os.Create(dst)\t//无法复制源文件的所有权限 //复制源文件的所有权限 destination, err := os.OpenFile(des, os.O_RDWR|os.O_CREATE|os.O_TRUNC, perm) if err != nil { return 0, err } defer destination.Close() // 拷贝 nBytes, err := io.Copy(destination, source) return nBytes, err 2.5.2 使用ioutil包WriteFile() 和 ReadFile() 一次性读取输入文件，然后再一次性写入目标文件。依然不是很高效的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func CopyFile(src, des string) (written int64, err error) { // 打开源文件 srcFile, err := os.Open(src) if err != nil { return 0, err } defer srcFile.Close() // 获取源文件的权限 fi, _ := srcFile.Stat() perm := fi.Mode() // 打开并读取源文件 input, err := ioutil.ReadFile(src) if err != nil { fmt.Println(err) return 0, err } // 创建并写入目标文件 err = ioutil.WriteFile(des, input, perm) if err != nil { fmt.Println(\u0026#34;Error creating\u0026#34;, destinationFile, err) return 0, err } return int64(len(input)), nil 2.5.3 使用os包Read() 和 Write() 使用buffer一块块地复制文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 func CopyFile(src string, des string, bufSize int) (written int64, err error) { if bufSize \u0026lt;= 0 { bufSize = 1*1024*1024 // buf大小1M } buf := make([]byte, bufSize) // 打开源文件 srcFile, err := os.Open(src) if err != nil { return 0, err } defer srcFile.Close() // 获取文件权限 fileInfo, _ := srcFile.Stat() perm := fileInfo.Mode() // 打开目标文件+原权限 destFile, err := os.OpenFile(des, os.O_RDWR|os.O_CREATE|os.O_TRUNC, perm) if err != nil { return 0, err } defer destFile.Close() count := 0 for { n, err := srcFile.Read(buf) if err != nil \u0026amp;\u0026amp; err != io.EOF { return err } if n == 0 { break } if wn, err := destFile.Write(buf[:n]); err != nil { return err } else{ count += wn } } return int64(count), nil } Reference path/filepath — 兼容操作系统的文件路径操作\nAppend to an existing file in Go (Golang)\n","description":"","id":72,"section":"posts","tags":["Go"],"title":"Go-Path-文件路径操作汇总","uri":"https://hex-go.github.io/posts/golang/2020-09-22-go-path-%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E6%93%8D%E4%BD%9C%E6%B1%87%E6%80%BB/"},{"content":"重要 删除切片中元素 Fast版本,改变顺序 此代码复制单个元素，元素长度增加, 运行时间不变。仍是复制单个元素的时间。\n1 2 3 4 5 6 7 8 9 a := []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;} i := 2 // Remove the element at index i from a. a[i] = a[len(a)-1] // Copy last element to index i. a[len(a)-1] = \u0026#34;\u0026#34; // Erase last element (write zero value). a = a[:len(a)-1] // Truncate slice. fmt.Println(a) // [A B E D] Slow版本,保持顺序 此代码复制len(a) - i - 1元素，元素长度增加, 运行时间呈线性增长。\n1 2 3 4 5 6 7 8 9 a := []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;} i := 2 // Remove the element at index i from a. copy(a[i:], a[i+1:]) // Shift a[i+1:] left one index. a[len(a)-1] = \u0026#34;\u0026#34; // Erase last element (write zero value). a = a[:len(a)-1] // Truncate slice. fmt.Println(a) // [A B D E] Reference Slice中删除元素的两种方式\nHow to delete an element from a Slice in Golang\n","description":"","id":73,"section":"posts","tags":["Go"],"title":"Go-Slice-切片操作汇总","uri":"https://hex-go.github.io/posts/golang/2020-09-22-go-slice-%E5%88%87%E7%89%87%E6%93%8D%E4%BD%9C%E6%B1%87%E6%80%BB/"},{"content":"重要 最重要的事:\n1.简介 Reference ubuntu出现\u0026quot;/dev/disk/by-uuid/xxxxxxxxx does not exist. Dropping to a shell \u0026ldquo;的恢复之路\nALERT! UUID=xxxxxxxxx does not exist. Dropping to a shell!\n卸载不能用的grub image\nhttps://askubuntu.com/questions/1273121/ubuntu-20-04-does-not-boot-after-kernel-grub-update\nhttps://askubuntu.com/questions/1273758/kernel-panic-after-update-from-16-04-lts-to-18-04-lts-virtual-machine-lubuntu\nhttps://www.reddit.com/r/zfs/comments/ilthfp/zfs_zvols_and_lvm_partitions_created_thru_libvirt/\n","description":"","id":74,"section":"posts","tags":["个人工具","Ubuntu"],"title":"Go-Ubuntu18.04-grub导致开机异常","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-09-22-ubuntu18.04_grub%E5%AF%BC%E8%87%B4%E5%BC%80%E6%9C%BA%E5%BC%82%E5%B8%B8/"},{"content":"重要 打算依托Tekton,作为工作流工具，将以下业务场景用task实现：\n镜像部署 源码构建+镜像部署 源码文件上传hdfs 微服务依赖关系 环境说明 k8s集群：\n安装 Tekton安装，通过官方GitHub仓库中的release.yaml文件部署服务。\n1 kubectl apply -f https://github.com/tektoncd/pipeline/releases/download/v0.16./release.yaml 使用 需要检查这几项, workspace\nReference 官方文档入口-select-version\nnuctl nuctl 是nuclio的客户端, nuctl使用时需要访问docker-daemon,\n1 2 3 4 $ nuctl get project --verbose 20.10.20 16:53:48.316 nuctl.platform (D) Using kubeconfig {\u0026#34;kubeconfigPath\u0026#34;: \u0026#34;/home/hex/.kube/config\u0026#34;} 20.10.20 16:53:48.324 tl.platform.docker.runner (D) Executing {\u0026#34;command\u0026#34;: \u0026#34;docker version\u0026#34;} 20.10.20 16:53:48.388 tl.platform.docker.runner (D) Command executed successfully {\u0026#34;output\u0026#34;: \u0026#34;Client: Docker Engine - Community\\n Version: 19.03.4\\n API version: 1.40\\n Go version: go1.12.10\\n Git commit: 9013bf583a\\n Built: Fri Oct 18 15:54:09 2019\\n OS/Arch: linux/amd64\\n Experimental: false\\n\\nServer: Docker Engine - Community\\n Engine:\\n Version: 19.03.4\\n API version: 1.40 (minimum version 1.12)\\n Go version: go1.12.10\\n Git commit: 9013bf583a\\n Built: Fri Oct 18 15:52:40 2019\\n OS/Arch: linux/amd64\\n Experimental: false\\n containerd:\\n Version: 1.2.10\\n GitCommit: b34a5c8af56e510852c35414db4c1f4fa6172339\\n runc:\\n Version: 1.0.0-rc8+dev\\n GitCommit: 3e425f80a8c931f88e6d94a8c831b9d5aa481657\\n docker-init:\\n Version: 0.18.0\\n GitCommit: fec3683\\n\u0026#34;, \u0026#34;stderr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;exitCode\u0026#34;: 0} 所以需要创建docker-in-docker的服务\ntask docker-in-docker\ndind issue\n构建镜像(kaniko) task kaniko\ntask之间传递数据(通过 result 配置) 传出result\n传出result \u0026ndash; task级别\n传出result \u0026ndash; pipe级别\n传入result \u0026ndash; task级别\n使用when做任务编排 任务编排 \u0026ndash; when\n使用runAfter做任务编排 任务编排 \u0026ndash; runAfter\nworkspace 工作空间使用\nauth Authorization at RunTime\n","description":"","id":75,"section":"posts","tags":["Go"],"title":"Go-Tekton使用-使用示例以及遇坑小记","uri":"https://hex-go.github.io/posts/golang/2020-09-16-go-tekton%E4%BD%BF%E7%94%A8-%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%E4%BB%A5%E5%8F%8A%E9%81%87%E5%9D%91%E5%B0%8F%E8%AE%B0/"},{"content":"引言 由于GitHub访问需要通过科学上网，因此需要配置git客户端通过proxy与github通信；但公司内网的git仓库不能走proxy，否则访问不通。因此需要查找git配置实现如下状态：\n所有github仓库走代理 所有内网仓库不走代理 现状 由于github仓库拉取缓慢，所以配置了代理； 但内网仓库拉取也走了代理，导致出现以下报错\n1 2 hex@hex-pc:~/example-repo$ git pull fatal: unable to access \u0026#39;https://git.service.rd/plugins/git/example-repo.git/\u0026#39;: gnutls_handshake() failed: The TLS connection was non-properly terminated. 办法一(推荐) git是可以根据环境变量的配置，声明代理并将内网地址配置不走代理，实现此功能，但要注意格式。\n1 2 3 4 5 6 7 export https_proxy=http://127.0.0.1:10800/ export http_proxy=http://127.0.0.1:10800/ export all_proxy=socks://127.0.0.1:1088/ export ftp_proxy=http://127.0.0.1:10800 # 声明内网不走proxy的服务 声明域名作为通配，以空格分隔。 export no_proxy=\u0026#34;.service.rd .local.domain 127.0.0.1 localhost\u0026#34; 方法二：修改本地库-local配置 也可以针对仓库设置git config。可以设置本地库全局配置，也可以只设置单一远端。\n进入仓库目录下，为当前仓库，添加一个“空”代理（仓库级别）。 1 git config --local --add http.proxy \u0026#34;\u0026#34; 在仓库目录下\u0026lt;repo_path\u0026gt;/.git/config，会出现以下内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \u0026#34;origin\u0026#34;] url = https://git.service.rd/plugins/git/example.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \u0026#34;master\u0026#34;] remote = origin merge = refs/heads/master [http] proxy = 进入仓库目录下，为名称为\u0026lt;name\u0026gt;的远端，添加一个”空“代理。 1 git config --local --add remote.\u0026lt;name\u0026gt;.proxy \u0026#34;\u0026#34; 执行下面命令查看\n1 git config --local --get remote.\u0026lt;name\u0026gt;.proxy 方法三：修改全局配置（只能针对单库） 修改 ~/.gitconfig文件，增加以下内容\n1 2 3 4 5 [http] sslVerify = true [http \u0026#34;https://git.service.rd/plugins/git/example-repo.git\u0026#34;] sslVerify = false ptoxy = ","description":"","id":76,"section":"posts","tags":["个人工具","Git"],"title":"科学上网（2） GIT配置proxy并忽略内网仓库","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-09-05-%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91-2_git%E9%85%8D%E7%BD%AEproxy%E5%B9%B6%E5%BF%BD%E7%95%A5%E5%86%85%E7%BD%91%E4%BB%93%E5%BA%93/"},{"content":"重要 defer语句是Go中一个非常有用的特性，可以将一个方法延迟到包裹defer的方法返回时执行，在实际应用中，defer可以充当其他语言中try…catch…的角色，\n也可以用来处理关闭文件句柄等收尾操作。\n1. defer使用 1.1 defer触发的时机 A \u0026ldquo;defer\u0026rdquo; statement invokes a function whose execution is deferred to the moment the surrounding function returns, either because the surrounding function executed a return statement, reached the end of its function body, or because the corresponding goroutine is panicking.\n官方文档指出，执行defer的时机为：\n包裹defer的函数返回时 包裹defer的函数执行到末尾时 所在的goroutine发生panic时 1.2 defer执行顺序 当一个方法中有多个defer时， defer会将要延迟执行的方法压栈，当defer被触发时，将所有压栈的方法出栈并执行。\n所以defer的执行顺序是LIFO的。\n例如\n1 2 3 4 5 6 7 8 9 10 11 func stackingDefers() { defer func() { fmt.Println(\u0026#34;1\u0026#34;) }() defer func() { fmt.Println(\u0026#34;2\u0026#34;) }() defer func() { fmt.Println(\u0026#34;3\u0026#34;) }() } 结果为：\n1 2 3 3 2 1 2. 坑 2.1 返回值是否匿名表现不同 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 匿名返回值 (int)，输出 0 func returnValues() int { var result int defer func() { result++ fmt.Println(\u0026#34;defer\u0026#34;) }() return result } // 命名返回值（result int）， 输出 1 // 因为return与defer是同时触发。 func namedReturnValues() (result int) { defer func() { result++ fmt.Println(\u0026#34;defer\u0026#34;) }() return result } 匿名返回执行顺序为：\n将result赋值给返回值(相当于， returnValue=result=0)；\n检查到defer，执行defer的语句，变量result值+1(result=1)；\n返回函数返回值，returnValue(returnValue=0)。\n命名返回值执行顺序为：\n返回值被声明为result； 检查到defer，执行defer的语句，变量result值+1(result=1)； 返回函数返回值，result(result=1)。 注意与python的浅拷贝区分开\n2.2 for循环中使用可能导致的性能问题 比如：\n1 2 3 4 5 6 func deferInLoops() { for i := 0; i \u0026lt; 100; i++ { f, _ := os.Open(\u0026#34;/etc/hosts\u0026#34;) defer f.Close() } } 此处defer f.Close()在创建文件对象后声明，看起来没有什么问题。但是和直接调用f.Close()相比，defer的执行存在着额外的开销。\ndefer会存在两方面的资源开销：\ndefer对其后需要的参数进行内存拷贝； 还需要对defer结构进行压栈出栈操作。 可以将f.Close()语句前的defer去掉，直接调用f.close()来减少大量defer导致的额外资源消耗。\n2.3 必须判断执行成功，再defer释放资源 如果获取资源的操作返回err参数：\n不使用defer, 可以选择忽略返回的err参数;\n使用defer进行延迟释放, 在使用defer之前先判断是否存在err。\n资源没有获取成功，对资源执行释放操作会导致释放方法执行报错。必须判断是否获取成功，再释放资源。\n正确写法：\n1 2 3 4 5 6 7 resp, err := http.Get(url) // 先判断操作是否成功 if err != nil { return err } // 如果操作成功，再进行Close操作 defer resp.Body.Close() 2.4 调用os.Exit时defer不会被执行 当发生panic时，所在goroutine的所有defer会被执行，但是当调用os.Exit()方法退出程序时，defer不会执行。\n下面例子中defer不会输出：\n1 2 3 4 5 6 func deferExit() { defer func() { fmt.Println(\u0026#34;defer\u0026#34;) }() os.Exit(0) } Reference Go语言中defer的一些坑\n","description":"","id":77,"section":"posts","tags":["Go"],"title":"Go-Defer说明","uri":"https://hex-go.github.io/posts/golang/2020-09-03-go-defer%E8%AF%B4%E6%98%8E/"},{"content":"字符串常见操作有：\n字符串长度；\n求子串；\n是否存在某个字符或子串；\n子串出现的次数（字符串匹配）；\n字符串分割（切分）为[]string；\n字符串是否有某个前缀或后缀；\n字符或子串在字符串中首次出现的位置或最后一次出现的位置；\n通过某个字符串将[]string 连接起来；\n字符串重复几次；\n字符串中子串替换；\n大小写转换；\nTrim 操作；\n\u0026hellip;\nstring 类型可以看成是一种特殊的 slice 类型，因此获取长度可以用内置的函数 len；同时支持 切片 操作，因此，子串获取很容易。\n说明：这里说的String，指得是 rune 类型，即一个 UTF-8 字符（Unicode 代码点）。\n1. 正文 1.1 字符串长度 string 类型可以看成是一种特殊的 slice 类型，因此获取长度可以用内置的函数 len；同时支持 切片 操作，因此，子串获取很容易。\n1.2 字符串比较 1 2 3 4 5 // Compare 函数，用于比较两个字符串的大小，如果两个字符串相等，返回为 0。如果 a 小于 b ，返回 -1 ，反之返回 1 。不推荐使用这个函数，直接使用 == != \u0026gt; \u0026lt; \u0026gt;= \u0026lt;= 等一系列运算符更加直观。 func Compare(a, b string) int // EqualFold 函数，计算 s 与 t 忽略字母大小写后是否相等。 func EqualFold(s, t string) bool 示例：\n1 2 3 4 5 6 7 8 a := \u0026#34;gopher\u0026#34; b := \u0026#34;hello world\u0026#34; fmt.Println(strings.Compare(a, b)) fmt.Println(strings.Compare(a, a)) fmt.Println(strings.Compare(b, a)) fmt.Println(strings.EqualFold(\u0026#34;GO\u0026#34;, \u0026#34;go\u0026#34;)) fmt.Println(strings.EqualFold(\u0026#34;壹\u0026#34;, \u0026#34;一\u0026#34;)) 输出结果：\n1 2 3 4 5 -1 0 1 true false 1.3. 是否存在某个字符或子串 有三个函数做这件事：\n1 2 3 4 5 6 // 子串 substr 在 s 中，返回 true func Contains(s, substr string) bool // chars 中任何一个 Unicode 代码点在 s 中，返回 true func ContainsAny(s, chars string) bool // Unicode 代码点 r 在 s 中，返回 true func ContainsRune(s string, r rune) bool 这里对 ContainsAny 函数进行一下说明，看如下例子：\n1 2 3 4 5 fmt.Println(strings.ContainsAny(\u0026#34;team\u0026#34;, \u0026#34;i\u0026#34;)) fmt.Println(strings.ContainsAny(\u0026#34;failure\u0026#34;, \u0026#34;u \u0026amp; i\u0026#34;)) fmt.Println(strings.ContainsAny(\u0026#34;in failure\u0026#34;, \u0026#34;s g\u0026#34;)) fmt.Println(strings.ContainsAny(\u0026#34;foo\u0026#34;, \u0026#34;\u0026#34;)) fmt.Println(strings.ContainsAny(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;)) 输出结果：\n1 2 3 4 5 false true true false false 说明，第二个参数 chars 中任意一个字符（Unicode Code Point）如果在第一个参数 s 中存在，则返回 true。\n查看这三个函数的源码，发现它们只是调用了相应的 Index 函数（子串出现的位置），然后和 0 作比较返回 true 或 fale。如，Contains：\n1 2 3 func Contains(s, substr string) bool { return Index(s, substr) \u0026gt;= 0 } 关于 Index 相关函数的实现，我们后面介绍。\n1.3. 子串出现次数 ( 字符串匹配 ) 在数据结构与算法中，可能会讲解以下字符串匹配算法：\n朴素匹配算法 KMP 算法 Rabin-Karp 算法 Boyer-Moore 算法 \u0026hellip; 在 Go 中，查找子串出现次数(字符串模式匹配)，是通过 Rabin-Karp 算法实现的。Count 函数的签名如下：\n1 func Count(s, sep string) int 在 Count 函数中，处理了几种特殊情况，属于字符匹配预处理的一部分。要注意：当 sep 为空时，Count 的返回值是：utf8.RuneCountInString(s) + 1\n1 2 3 fmt.Println(strings.Count(\u0026#34;cheese\u0026#34;, \u0026#34;e\u0026#34;)) fmt.Println(len(\u0026#34;谷歌中国\u0026#34;)) fmt.Println(strings.Count(\u0026#34;谷歌中国\u0026#34;, \u0026#34;\u0026#34;)) 输出：\n1 2 3 3 12 5 Count 是计算子串在字符串中出现的无重叠的次数，比如：\n1 fmt.Println(strings.Count(\u0026#34;fivevev\u0026#34;, \u0026#34;vev\u0026#34;)) 输出：\n1 1 1.4. 字符串分割为[]string Strings包提供了六个三组函数：Fields 和 FieldsFunc、Split 和 SplitAfter、SplitN 和 SplitAfterN。\n1.4.1 Fields 和 FieldsFunc 这两个函数的签名如下：\n1 2 func Fields(s string) []string func FieldsFunc(s string, f func(rune) bool) []string Fields 用一个或多个连续的空格分隔字符串 s，返回子字符串的数组（slice）。如果字符串 s 只包含空格，则返回空列表 ([]string 的长度为 0）。其中，空格的定义是 unicode.IsSpace。\n常见间隔符包括：\u0026rsquo;\\t\u0026rsquo;, \u0026lsquo;\\n\u0026rsquo;, \u0026lsquo;\\v\u0026rsquo;, \u0026lsquo;\\f\u0026rsquo;, \u0026lsquo;\\r\u0026rsquo;, \u0026rsquo; \u0026lsquo;, U+0085 (NEL), U+00A0 (NBSP)\n由于是用空格分隔，因此结果中不会含有空格或空子字符串，例如：\n1 fmt.Printf(\u0026#34;Fields are: %q\u0026#34;, strings.Fields(\u0026#34; foo bar baz \u0026#34;)) 输出结果：\n1 Fields are: [\u0026#34;foo\u0026#34; \u0026#34;bar\u0026#34; \u0026#34;baz\u0026#34;] FieldsFunc 用这样的 Unicode 代码点 c 进行分隔：满足 f(c) 返回 true。该函数返回[]string。如果字符串 s 中所有的代码点 (unicode code points) 都满足 f(c) 或者 s 是空，则 FieldsFunc 返回空 slice。\n也就是说，我们可以通过实现一个回调函数来指定分隔字符串 s 的字符。比如上面的例子，我们通过 FieldsFunc 来实现：\n1 fmt.Println(strings.FieldsFunc(\u0026#34; foo bar baz \u0026#34;, unicode.IsSpace)) 实际上，Fields 函数就是调用 FieldsFunc 实现的：\n1 2 3 func Fields(s string) []string { return FieldsFunc(s, unicode.IsSpace) } 1.4.2. Split 和 SplitAfter、 SplitN 和 SplitAfterN 四个函数通过调用同一个内部函数实现：\n1 2 3 4 func Split(s, sep string) []string { return genSplit(s, sep, 0, -1) } func SplitAfter(s, sep string) []string { return genSplit(s, sep, len(sep), -1) } func SplitN(s, sep string, n int) []string { return genSplit(s, sep, 0, n) } func SplitAfterN(s, sep string, n int) []string { return genSplit(s, sep, len(sep), n) } 都调用了 genSplit 函数。\n这四个函数都是通过 sep 进行分割，返回[]string。如果 sep 为空，相当于分成一个个的 UTF-8 字符，如 ：\nSplit(\u0026quot;abc\u0026quot;,\u0026quot;\u0026quot;)，得到的是[a b c]。\nSplit(s, sep) 和SplitN(s, sep, -1)等价；\nSplitAfter(s, sep) 和 SplitAfterN(s, sep, -1) 等价。\nSplit 和 SplitAfter的区别是 Split 会将 s 中的 sep 去掉，而 SplitAfter 会保留 sep。\n1 2 fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;foo,bar,baz\u0026#34;, \u0026#34;,\u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.SplitAfter(\u0026#34;foo,bar,baz\u0026#34;, \u0026#34;,\u0026#34;)) 输出：\n1 2 [\u0026#34;foo\u0026#34; \u0026#34;bar\u0026#34; \u0026#34;baz\u0026#34;] [\u0026#34;foo,\u0026#34; \u0026#34;bar,\u0026#34; \u0026#34;baz\u0026#34;] 带 N 的方法可以通过最后一个参数 n 控制返回的结果中的 slice 中的元素个数：\n当 n \u0026lt; 0 时，返回所有的子字符串；\n当 n == 0 时，返回的结果是 nil；\n当 n \u0026gt; 0 时，表示返回的 slice 中最多只有 n 个元素；\n其中，最后一个元素不会分割，比如：\n1 fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.SplitN(\u0026#34;foo,bar,baz\u0026#34;, \u0026#34;,\u0026#34;, 2)) 输出：\n1 [\u0026#34;foo\u0026#34; \u0026#34;bar,baz\u0026#34;] 官方文档提供的例子，输出结果：\n1 2 3 4 fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;a,b,c\u0026#34;, \u0026#34;,\u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;a man a plan a canal panama\u0026#34;, \u0026#34;a \u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34; xyz \u0026#34;, \u0026#34;\u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;\u0026#34;, \u0026#34;Bernardo O\u0026#39;Higgins\u0026#34;)) 输出：\n1 2 3 4 [\u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34;] [\u0026#34;\u0026#34; \u0026#34;man \u0026#34; \u0026#34;plan \u0026#34; \u0026#34;canal panama\u0026#34;] [\u0026#34; \u0026#34; \u0026#34;x\u0026#34; \u0026#34;y\u0026#34; \u0026#34;z\u0026#34; \u0026#34; \u0026#34;] [\u0026#34;\u0026#34;] 1.5. 字符串是否有某个前缀或后缀 两个函数HasPrefix和HasSuffix：\n1 2 3 4 5 6 7 8 // s 中是否以 prefix 开始 func HasPrefix(s, prefix string) bool { return len(s) \u0026gt;= len(prefix) \u0026amp;\u0026amp; s[0:len(prefix)] == prefix } // s 中是否以 suffix 结尾 func HasSuffix(s, suffix string) bool { return len(s) \u0026gt;= len(suffix) \u0026amp;\u0026amp; s[len(s)-len(suffix):] == suffix } 如果 prefix 或 suffix 为 \u0026quot;\u0026quot; , 返回值总是 true。\n示例：\n1 2 3 4 5 6 fmt.Println(strings.HasPrefix(\u0026#34;Gopher\u0026#34;, \u0026#34;Go\u0026#34;)) fmt.Println(strings.HasPrefix(\u0026#34;Gopher\u0026#34;, \u0026#34;C\u0026#34;)) fmt.Println(strings.HasPrefix(\u0026#34;Gopher\u0026#34;, \u0026#34;\u0026#34;)) fmt.Println(strings.HasSuffix(\u0026#34;Amigo\u0026#34;, \u0026#34;go\u0026#34;)) fmt.Println(strings.HasSuffix(\u0026#34;Amigo\u0026#34;, \u0026#34;Ami\u0026#34;)) fmt.Println(strings.HasSuffix(\u0026#34;Amigo\u0026#34;, \u0026#34;\u0026#34;)) 输出结果：\n1 2 3 4 5 6 true false true true false true 1.6. 字符或子串在字符串中出现的位置 Index函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 在 s 中查找 sep 的第一次出现，返回第一次出现的索引 func Index(s, sep string) int // 在 s 中查找字节 c 的第一次出现，返回第一次出现的索引 func IndexByte(s string, c byte) int // chars 中任何一个 Unicode 代码点在 s 中首次出现的位置 func IndexAny(s, chars string) int // 查找字符 c 在 s 中第一次出现的位置，其中 c 满足 f(c) 返回 true func IndexFunc(s string, f func(rune) bool) int // Unicode 代码点 r 在 s 中第一次出现的位置 func IndexRune(s string, r rune) int // 有三个对应的查找最后一次出现的位置 func LastIndex(s, sep string) int func LastIndexByte(s string, c byte) int func LastIndexAny(s, chars string) int func LastIndexFunc(s string, f func(rune) bool) int 1.3小节Contain 相关的函数内部调用的是响应的 Index 函数。\nIndexFunc 举例：\n1 2 3 4 5 han := func(c rune) bool { return unicode.Is(unicode.Han, c) // 汉字 } fmt.Println(strings.IndexFunc(\u0026#34;Hello, world\u0026#34;, han)) fmt.Println(strings.IndexFunc(\u0026#34;Hello, 世界\u0026#34;, han)) 输出：\n1 2 -1 7 1.7. 字符串 JOIN 操作 Join函数 实现 字符串或数组连接 ：\n1 func Join(a []string, sep string) string 自己实现：\n使用了 bytes 包的 Buffer 类型，避免大量的字符串连接操作（因为 Go 中字符串是不可变的）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func Join(str []string, sep string) string { // 特殊情况应该做处理 if len(str) == 0 { return \u0026#34;\u0026#34; } if len(str) == 1 { return str[0] } buffer := bytes.NewBufferString(str[0]) for _, s := range str[1:] { buffer.WriteString(sep) buffer.WriteString(s) } return buffer.String() } 标准库的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func Join(a []string, sep string) string { if len(a) == 0 { return \u0026#34;\u0026#34; } if len(a) == 1 { return a[0] } n := len(sep) * (len(a) - 1) for i := 0; i \u0026lt; len(a); i++ { n += len(a[i]) } b := make([]byte, n) bp := copy(b, a[0]) for _, s := range a[1:] { bp += copy(b[bp:], sep) bp += copy(b[bp:], s) } return string(b) } 标准库的实现没有用 bytes 包，当然也不会简单的通过 + 号连接字符串。Go 中是不允许循环依赖的，标准库中很多时候会出现代码拷贝，而不是引入某个包。这里 Join 的实现方式挺好，我个人猜测，不直接使用 bytes 包，也是不想依赖 bytes 包（其实 bytes 中的实现也是 copy 方式）。\n简单使用示例：\n1 fmt.Println(Join([]string{\u0026#34;name=xxx\u0026#34;, \u0026#34;age=xx\u0026#34;}, \u0026#34;\u0026amp;\u0026#34;)) 输出结果:\n1 name=xxx\u0026amp;age=xx 1.8. 字符串重复几次 函数签名如下：\n1 func Repeat(s string, count int) string 将 s 重复 count 次，如果 count 为负数或返回值长度 len(s)*count 超出 string 上限会导致 panic，这个函数使用很简单：\n1 fmt.Println(\u0026#34;ba\u0026#34; + strings.Repeat(\u0026#34;na\u0026#34;, 2)) 输出结果：\n1 banana 1.9. 字符替换 1 func Map(mapping func(rune) rune, s string) string Map 函数，将 s 的每一个字符按照 mapping 的规则做映射替换，如果 mapping 返回值 \u0026lt;0 ，则舍弃该字符。该方法只能对每一个字符做处理，但处理方式很灵活，可以方便的过滤，筛选汉字等。\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 mapping := func(r rune) rune { switch { case r \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; r \u0026lt;= \u0026#39;Z\u0026#39;: // 大写字母转小写 return r + 32 case r \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; r \u0026lt;= \u0026#39;z\u0026#39;: // 小写字母不处理 return r case unicode.Is(unicode.Han, r): // 汉字换行 return \u0026#39;\\n\u0026#39; } return -1 // 过滤所有非字母、汉字的字符 } fmt.Println(strings.Map(mapping, \u0026#34;Hello你#￥%……\\n（\u0026#39;World\\n,好Hello^(\u0026amp;(*界gopher...\u0026#34;)) 输出结果：\n1 2 3 4 hello world hello gopher 1.10. 字符串子串替换 进行字符串替换时，考虑到性能问题，能不用正则尽量别用，应该用这里的函数。\n字符串替换的函数签名如下：\n1 2 3 4 5 // 用 new 替换 s 中的 old，一共替换 n 个。 // 如果 n \u0026lt; 0，则不限制替换次数，即全部替换 func Replace(s, old, new string, n int) string // 该函数内部直接调用了函数 Replace(s, old, new , -1) func ReplaceAll(s, old, new string) string 使用示例：\n1 2 3 fmt.Println(strings.Replace(\u0026#34;oink oink oink\u0026#34;, \u0026#34;k\u0026#34;, \u0026#34;ky\u0026#34;, 2)) fmt.Println(strings.Replace(\u0026#34;oink oink oink\u0026#34;, \u0026#34;oink\u0026#34;, \u0026#34;moo\u0026#34;, -1)) fmt.Println(strings.ReplaceAll(\u0026#34;oink oink oink\u0026#34;, \u0026#34;oink\u0026#34;, \u0026#34;moo\u0026#34;)) 输出：\n1 2 3 oinky oinky oink moo moo moo moo moo moo 如果我们希望一次替换多个，比如我们希望替换 This is \u0026lt;b\u0026gt;HTML\u0026lt;/b\u0026gt; 中的 \u0026lt; 和 \u0026gt; 为 \u0026amp;lt; 和 \u0026amp;gt;;，可以调用上面的函数两次。但标准库提供了另外的方法进行这种替换。\n1.11 大小写转换 1 2 3 4 func ToLower(s string) string func ToLowerSpecial(c unicode.SpecialCase, s string) string func ToUpper(s string) string func ToUpperSpecial(c unicode.SpecialCase, s string) string 大小写转换包含了 4 个相关函数，ToLower和ToUpper 用于大小写转换。ToLowerSpecial和ToUpperSpecial 可以转换特殊字符的大小写。 举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 fmt.Println(strings.ToLower(\u0026#34;HELLO WORLD\u0026#34;)) fmt.Println(strings.ToLower(\u0026#34;Ā Á Ǎ À\u0026#34;)) fmt.Println(strings.ToLowerSpecial(unicode.TurkishCase, \u0026#34;壹\u0026#34;)) fmt.Println(strings.ToLowerSpecial(unicode.TurkishCase, \u0026#34;HELLO WORLD\u0026#34;)) fmt.Println(strings.ToLower(\u0026#34;Önnek İş\u0026#34;)) fmt.Println(strings.ToLowerSpecial(unicode.TurkishCase, \u0026#34;Önnek İş\u0026#34;)) fmt.Println(strings.ToUpper(\u0026#34;hello world\u0026#34;)) fmt.Println(strings.ToUpper(\u0026#34;ā á ǎ à\u0026#34;)) fmt.Println(strings.ToUpperSpecial(unicode.TurkishCase, \u0026#34;一\u0026#34;)) fmt.Println(strings.ToUpperSpecial(unicode.TurkishCase, \u0026#34;hello world\u0026#34;)) fmt.Println(strings.ToUpper(\u0026#34;örnek iş\u0026#34;)) fmt.Println(strings.ToUpperSpecial(unicode.TurkishCase, \u0026#34;örnek iş\u0026#34;)) 输出结果:\n1 2 3 4 5 6 7 8 9 10 11 12 hello world ā á ǎ à 壹 hello world önnek iş önnek iş HELLO WORLD Ā Á Ǎ À // 汉字拼音有效 一 // 汉字无效 HELLO WORLD ÖRNEK IŞ ÖRNEK İŞ // 有细微差别 1.12. 标题处理 1 2 3 func Title(s string) string func ToTitle(s string) string func ToTitleSpecial(c unicode.SpecialCase, s string) string 标题处理包含 3 个相关函数，其中 Title 会将 s 每个单词的首字母大写，不处理该单词的后续字符。ToTitle 将 s 的每个字母大写。ToTitleSpecial 将 s 的每个字母大写，并且会将一些特殊字母转换为其对应的特殊大写字母。\n举个例子：\n1 2 3 4 5 6 7 8 9 fmt.Println(strings.Title(\u0026#34;hElLo wOrLd\u0026#34;)) fmt.Println(strings.ToTitle(\u0026#34;hElLo wOrLd\u0026#34;)) fmt.Println(strings.ToTitleSpecial(unicode.TurkishCase, \u0026#34;hElLo wOrLd\u0026#34;)) fmt.Println(strings.Title(\u0026#34;āáǎà ōóǒò êēéěè\u0026#34;)) fmt.Println(strings.ToTitle(\u0026#34;āáǎà ōóǒò êēéěè\u0026#34;)) fmt.Println(strings.ToTitleSpecial(unicode.TurkishCase, \u0026#34;āáǎà ōóǒò êēéěè\u0026#34;)) fmt.Println(strings.Title(\u0026#34;dünyanın ilk borsa yapısı Aizonai kabul edilir\u0026#34;)) fmt.Println(strings.ToTitle(\u0026#34;dünyanın ilk borsa yapısı Aizonai kabul edilir\u0026#34;)) fmt.Println(strings.ToTitleSpecial(unicode.TurkishCase, \u0026#34;dünyanın ilk borsa yapısı Aizonai kabul edilir\u0026#34;)) 输出结果：\n1 2 3 4 5 6 7 8 9 HElLo WOrLd HELLO WORLD HELLO WORLD Āáǎà Ōóǒò Êēéěè ĀÁǍÀ ŌÓǑÒ ÊĒÉĚÈ ĀÁǍÀ ŌÓǑÒ ÊĒÉĚÈ Dünyanın Ilk Borsa Yapısı Aizonai Kabul Edilir DÜNYANIN ILK BORSA YAPISI AIZONAI KABUL EDILIR DÜNYANIN İLK BORSA YAPISI AİZONAİ KABUL EDİLİR 1.13. 修剪 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 将 s 左侧和右侧中匹配 cutset 中的任一字符的字符去掉 func Trim(s string, cutset string) string // 将 s 左侧的匹配 cutset 中的任一字符的字符去掉 func TrimLeft(s string, cutset string) string // 将 s 右侧的匹配 cutset 中的任一字符的字符去掉 func TrimRight(s string, cutset string) string // 如果 s 的前缀为 prefix 则返回去掉前缀后的 string , 否则 s 没有变化。 func TrimPrefix(s, prefix string) string // 如果 s 的后缀为 suffix 则返回去掉后缀后的 string , 否则 s 没有变化。 func TrimSuffix(s, suffix string) string // 将 s 左侧和右侧的间隔符去掉。常见间隔符包括：\u0026#39;\\t\u0026#39;, \u0026#39;\\n\u0026#39;, \u0026#39;\\v\u0026#39;, \u0026#39;\\f\u0026#39;, \u0026#39;\\r\u0026#39;, \u0026#39; \u0026#39;, U+0085 (NEL) func TrimSpace(s string) string // 将 s 左侧和右侧的匹配 f 的字符去掉 func TrimFunc(s string, f func(rune) bool) string // 将 s 左侧的匹配 f 的字符去掉 func TrimLeftFunc(s string, f func(rune) bool) string // 将 s 右侧的匹配 f 的字符去掉 func TrimRightFunc(s string, f func(rune) bool) string 包含了 9 个相关函数用于修剪字符串。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 x := \u0026#34;!!!@@@你好,!@#$ Gophers###$$$\u0026#34; fmt.Println(strings.Trim(x, \u0026#34;@#$!%^\u0026amp;*()_+=-\u0026#34;)) fmt.Println(strings.TrimLeft(x, \u0026#34;@#$!%^\u0026amp;*()_+=-\u0026#34;)) fmt.Println(strings.TrimRight(x, \u0026#34;@#$!%^\u0026amp;*()_+=-\u0026#34;)) fmt.Println(strings.TrimSpace(\u0026#34; \\t\\n Hello, Gophers \\n\\t\\r\\n\u0026#34;)) fmt.Println(strings.TrimPrefix(x, \u0026#34;!\u0026#34;)) fmt.Println(strings.TrimSuffix(x, \u0026#34;$\u0026#34;)) f := func(r rune) bool { return !unicode.Is(unicode.Han, r) // 非汉字返回 true } fmt.Println(strings.TrimFunc(x, f)) fmt.Println(strings.TrimLeftFunc(x, f)) fmt.Println(strings.TrimRightFunc(x, f)) 输出结果：\n1 2 3 4 5 6 7 8 9 你好,!@#$ Gophers 你好,!@#$ Gophers###$$$ !!!@@@你好,!@#$ Gophers Hello, Gophers !!@@@你好,!@#$ Gophers###$$$ !!!@@@你好,!@#$ Gophers###$$ 你好 你好,!@#$ Gophers###$$$ !!!@@@你好 1.14. Replacer 类型 这是一个结构，没有导出任何字段，实例化通过 func NewReplacer(oldnew \u0026hellip;string) *Replacer 函数进行，其中不定参数 oldnew 是 old-new 对，即进行多个替换。如果 oldnew 长度与奇数，会导致 panic.\n示例：\n1 2 r := strings.NewReplacer(\u0026#34;\u0026lt;\u0026#34;, \u0026#34;\u0026amp;lt;\u0026#34;, \u0026#34;\u0026gt;\u0026#34;, \u0026#34;\u0026amp;gt;\u0026#34;) fmt.Println(r.Replace(\u0026#34;This is \u0026lt;b\u0026gt;HTML\u0026lt;/b\u0026gt;!\u0026#34;)) 输出结果：\n1 This is \u0026amp;lt;b\u0026amp;gt;HTML\u0026amp;lt;/b\u0026amp;gt;! 另外，Replacer 还提供了另外一个方法，它在替换之后将结果写入 io.Writer 中。\n1 func (r *Replacer) WriteString(w io.Writer, s string) (n int, err error) 1.15. Reader 类型 看到名字就能猜到，这是实现了 io 包中的接口。它实现了 io.Reader（Read 方法），io.ReaderAt（ReadAt 方法），io.Seeker（Seek 方法），io.WriterTo（WriteTo 方法），io.ByteReader（ReadByte 方法），io.ByteScanner（ReadByte 和 UnreadByte 方法），io.RuneReader（ReadRune 方法） 和 io.RuneScanner（ReadRune 和 UnreadRune 方法）。\nReader 结构如下：\n1 2 3 4 5 type Reader struct { s string // Reader 读取的数据来源 i int // current reading index（当前读的索引位置） prevRune int // index of previous rune; or \u0026lt; 0（前一个读取的 rune 索引位置） } 可见 Reader 结构没有导出任何字段，而是提供一个实例化方法：\n1 func NewReader(s string) *Reader 该方法接收一个字符串，返回的 Reader 实例就是从该参数字符串读数据。在后面学习了 bytes 包之后，可以知道 bytes.NewBufferString 有类似的功能，不过，如果只是为了读取，NewReader 会更高效。\n其他方法不介绍了，都是之前接口的实现，有兴趣的可以看看源码实现，大部分都是根据 i、prevRune 两个属性来控制。\n1.16. Builder 类型 1 2 3 4 type Builder struct { addr *Builder // of receiver, to detect copies by value buf []byte } 该类型实现了 io 包下的 Writer, ByteWriter, StringWriter 等接口，可以向该对象内写入数据，Builder 没有实现 Reader 等接口，所以该类型不可读，但提供了 String 方法可以获取对象内的数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 该方法向 b 写入一个字节 func (b *Builder) WriteByte(c byte) error // WriteRune 方法向 b 写入一个字符 func (b *Builder) WriteRune(r rune) (int, error) // WriteRune 方法向 b 写入字节数组 p func (b *Builder) Write(p []byte) (int, error) // WriteRune 方法向 b 写入字符串 s func (b *Builder) WriteString(s string) (int, error) // Len 方法返回 b 的数据长度。 func (b *Builder) Len() int // Cap 方法返回 b 的 cap。 func (b *Builder) Cap() int // Grow 方法将 b 的 cap 至少增加 n (可能会更多)。如果 n 为负数，会导致 panic。 func (b *Builder) Grow(n int) // Reset 方法将 b 清空 b 的所有内容。 func (b *Builder) Reset() // String 方法将 b 的数据以 string 类型返回。 func (b *Builder) String() string Builder 有 4 个与写入相关的方法，这 4 个方法的 error 都总是为 nil.\nBuilder 的 cap 会自动增长，一般不需要手动调用 Grow 方法。\nString 方法可以方便的获取 Builder 的内容。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 b := strings.Builder{} _ = b.WriteByte(\u0026#39;7\u0026#39;) n, _ := b.WriteRune(\u0026#39;夕\u0026#39;) fmt.Println(n) n, _ = b.Write([]byte(\u0026#34;Hello, World\u0026#34;)) fmt.Println(n) n, _ = b.WriteString(\u0026#34;你好，世界\u0026#34;) fmt.Println(n) fmt.Println(b.Len()) fmt.Println(b.Cap()) b.Grow(100) fmt.Println(b.Len()) fmt.Println(b.Cap()) fmt.Println(b.String()) b.Reset() fmt.Println(b.String()) 输出结果：\n1 2 3 4 5 6 7 8 3 12 15 31 32 31 164 7夕Hello, World你好，世界 Reference Go语言标准库\u0026ndash;strings\n","description":"","id":78,"section":"posts","tags":["Go"],"title":"Go-Strings-字符串操作汇总","uri":"https://hex-go.github.io/posts/golang/2020-09-02-go-strings-%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%93%8D%E4%BD%9C%E6%B1%87%E6%80%BB/"},{"content":"重要 原理说明 kubernetes集群并采用Coredns进行解析，集群内部的服务都能通过内部域名进行访问。但是集群内部的coredns与物理机的dns解析不完全统一，\ncoredns不能解析物理机的hostname。k8s-coredns默认配置从本机/etc/resolv.conf获取上游DNS服务器的地址。\n有两种方式解决这个问题：\n搭建解析物理机地址的dns服务器，并作为上游dns服务配置给k8s的coredns。 通过coredns自带的hosts插件，手动添加自定义解析记录 配置 1. 配置外部dns服务器 搭建coredns服务参考coredns官网，此处只介绍k8s中dns服务器修改上游dns配置，有两种方式：\n修改/etc/resolv.conf中的nameserver nameserver地址换成自建的dns服务地址，默认监听53端口。\n1 nameserver 192.168.100.254 修改coredns配置文件 ConfigMap coredns 1 kubectl -n kube-system edit configmap coredns 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 apiVersion: v1 data: Corefile: | .:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa ttl 30 } prometheus :9153 proxy . 192.168.100.254 # 修改为上游dns服务地址,端口默认53 cache 30 loop reload loadbalance } kind: ConfigMap metadata: name: coredns namespace: kube-system 配置修改后，需要重启coredns服务\n查询coredns 的POD\n1 kubectl -n kube-system get pods -l k8s-app=kube-dns 删除 coredns 让 k8s 重新创建新的 coredns\n1 kubectl -n kube-system delete pod -l k8s-app=kube-dns 2. 通过hosts添加自定义DNS解析记录 coredns 自带 hosts 插件， 允许像配置 hosts 一样配置自定义 DNS 解析\n修改命名空间 kube-system 下的 configMap coredns\n1 kubectl edit configmap coredns -n kube-system 添加如下设置即可。\n1 2 3 4 5 6 hosts { 172.21.91.28 cache.redis 172.21.91.28 persistent.redis fallthrough } 修改后文件如下（根据kubernetes 安装方式不同，可能有些许差别）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 apiVersion: v1 data: Corefile: | .:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa ttl 30 } hosts { 10.10.0.10 reg.chebai.org 10.15.0.2 hub.icos.city fallthrough } prometheus :9153 forward . /etc/resolv.conf cache 30 loop reload loadbalance } kind: ConfigMap metadata: name: coredns namespace: kube-system 删除命名空间kube-system下的coredns pod，重启dns服务。\n3. 通过pod增加hostalias 以deployment修改举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: hostAliases: - ip: \u0026#34;192.168.100.106\u0026#34; hostnames: - \u0026#34;rancher.icos.city\u0026#34; containers: - env: - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace image: nginx name: nginx Reference 开发服务器 k8s 设置 自定义 dns解析\ncoredns 官网\n","description":"","id":79,"section":"posts","tags":["Kubernetes","Coredns"],"title":"Minikube--增加外部dns解析","uri":"https://hex-go.github.io/posts/kubernetes/2020-08-07-minikube--%E5%A2%9E%E5%8A%A0%E5%A4%96%E9%83%A8dns%E8%A7%A3%E6%9E%90/"},{"content":"重要 最重要的事:\nQv2ray开代理\n本人使用Qv2ray 设置系统代理 勾选SOCKS设置，并填写端口1088，UDP本地IP127.0.0.1。 设置docker代理配置 1 2 sudo mkdir -p /etc/systemd/system/docker.service.d/ sudo vim /etc/systemd/system/docker.service.d/http-proxy.conf 将以下内容填入文件http-proxy.conf\n1 2 3 4 5 [Service] Environment=\u0026#34;HTTP_PROXY=http://127.0.0.1:30388\u0026#34; Environment=\u0026#34;HTTPS_PROXY=http://127.0.0.1:30388\u0026#34; Environment=\u0026#34;ALL_PROXY=socks5://127.0.0.1:1088\u0026#34; Environment=\u0026#34;NO_PROXY=localhost,127.0.0.1,reg.chebai.org,icosdop.service.rd,hub.icos.city,registry.npm.taobao.org\u0026#34; 重启docker服务 1 2 root@:~# systemctl daemon-reload root@:~# systemctl restart docker 查看配置 1 2 systemctl show --property=Environment docker Environment=HTTP_PROXY=http://127.0.0.1:30388 HTTPS_PROXY=http://127.0.0.1:30388 ALL_PROXY=socks5://127.0.0.1:1088 NO_PROXY=localhost,127.0.0.1,reg.chebai.org,hub.icos.city,icosdop.service.rd docker pull 谷歌仓库镜像 1 2 3 4 5 6 7 8 9 10 root@:~# docker pull gcr.io/google_containers/pause-amd64:3.0 3.0: Pulling from google_containers/pause-amd64 a3ed95caeb02: Pull complete f11233434377: Pull complete Digest: sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 Status: Downloaded newer image for gcr.io/google_containers/pause-amd64:3.0 root@:~# docker images REPOSITORY TAG IMAGE ID CREATED SIZE stephenlu/pause-amd64 3.0 78ba6fae6829 3 weeks ago 747 kB gcr.io/google_containers/pause-amd64 3.0 99e59f495ffa 20 months ago 747 kB minikube启动k8s集群 1 minikube start 使用国内proxy启动 1 2 3 minikube start --registry-mirror=https://registry.docker-cn.com # 或 minikube start --vm-driver=none --registry-mirror=https://registry.docker-cn.com --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers 使用docker体验容器搬运镜像 官方体验虚拟机\n进入虚拟机，拉取gcr等墙外镜像。再推送至docker.io中\nReference docker使用代理pull gcr仓库镜像\ndocker官方文档设置HTTP/HTTPS Proxy\n遗留问题 docker 配置 no_proxy 无法使用 通配模式。\n","description":"","id":80,"section":"posts","tags":["个人工具","Docker","V2ray"],"title":"翻墙--docker拉取镜像","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-08-05-%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91-3_docker%E9%95%9C%E5%83%8F/"},{"content":"引言 如何在windows环境搭建环境，解决日常访问github的需求需要做到以下几步：\n获取代理工具（本文clash）与机场配置 配置浏览器，使浏览器可通过代理访问github等网站 通过代理工具，实现windows常见工具、软件翻墙 1. 代理工具配置 2. 浏览器配置 3. 常见工具 设置docker代理配置 1 2 sudo mkdir -p /etc/systemd/system/docker.service.d/ sudo vim /etc/systemd/system/docker.service.d/http-proxy.conf 将以下内容填入文件http-proxy.conf\n1 2 3 [Service] Environment=\u0026#34;ALL_PROXY=socks5://127.0.0.1:1088\u0026#34; NO_PROXY=localhost,127.0.0.1,reg.chebai.org,hub.icos.city,icosdop.service.rd,icos.city 重启docker服务 1 2 root@:~# systemctl daemon-reload root@:~# systemctl restart docker 查看配置 1 2 systemctl show --property=Environment docker Environment=ALL_PROXY=socks5://127.0.0.1:1080 NO_PROXY=localhost,127.0.0.1,reg.chebai.org,hub.icos.city,icosdop.service.rd,icos.city docker pull 谷歌仓库镜像 1 2 3 4 5 6 7 8 9 10 root@:~# docker pull gcr.io/google_containers/pause-amd64:3.0 3.0: Pulling from google_containers/pause-amd64 a3ed95caeb02: Pull complete f11233434377: Pull complete Digest: sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 Status: Downloaded newer image for gcr.io/google_containers/pause-amd64:3.0 root@:~# docker images REPOSITORY TAG IMAGE ID CREATED SIZE stephenlu/pause-amd64 3.0 78ba6fae6829 3 weeks ago 747 kB gcr.io/google_containers/pause-amd64 3.0 99e59f495ffa 20 months ago 747 kB minikube启动k8s集群 1 minikube start 使用国内proxy启动 1 2 3 minikube start --registry-mirror=https://registry.docker-cn.com # 或 minikube start --vm-driver=none --registry-mirror=https://registry.docker-cn.com --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers Reference docker使用代理pull gcr仓库镜像\ndocker官方文档设置HTTP/HTTPS Proxy\n遗留问题 docker 配置 no_proxy 无法使用 通配模式。\n","description":"","id":81,"section":"posts","tags":["个人工具","V2ray","Chrome","SwitchOmega","Clash"],"title":"科学上网","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-08-05-%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91-1_%E6%B5%8F%E8%A7%88%E5%99%A8/"},{"content":"重要 最近研究grafana与keycloak集成，能正常解决认证问题，但用户只会在grafana通过keycloak用户登录时，才会在grafana的数据库中创建用户。\n需要研究如何通过API触发此操作，为后续在grafana中给此用户授权做准备。grafana本身无此API，相近的功能Openldap与grafana用户同步也是在企业版。\n由此需要研究grafana源码，首选API实现，无法成功则研究API背后的逻辑，直接操作数据库实现。\n环境说明 grafana: v7.1.0\nkeycloak: 10.0.2\n安装 使用 Reference ","description":"","id":82,"section":"posts","tags":["Go"],"title":"Go-源码解读--grafana-v7.1.0","uri":"https://hex-go.github.io/posts/golang/2020-07-24-go-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB--grafana-v7.1.0/"},{"content":"重要 最近由于工作需求，需要统一调用各个系统的相同逻辑。并不想每集成一个服务就修改调用的代码，而是想实现插件机制。\n利用go包的init特性，将示例插件注册，并在主程序中调用。\n环境说明 代码结构如下：\n1 2 3 4 5 6 7 8 9 10 11 └── src └── test ├── main.go └── adaptor ├── init.go └── standard └── imports.go └── cls1 └── base.go └── cls2 └── base.go 项目代码\n使用 类工厂 具体文件: ./example-adaptor/adaptor/init.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package adaptor // 定义接口 type Adaptors interface { CreateUser(user string) (status bool, err error) DeleteUser(user string) (status bool, err error) Policies() (status bool, err error) } var ( // 插件字典 FactoryByName = make(map[string]func() Adaptors) ) // 注册插件 func Register(name string, factory func() Adaptors) { FactoryByName[name] = factory } 插件类 cls1 cls2 具体文件： adaptor/cls1/base.go 和 adaptor/cls2/base.go\n以cls1举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package cls1 import ( \u0026#34;example/adaptor\u0026#34; \u0026#34;fmt\u0026#34; ) // 定义 Cls1 type Cls1 struct { Name string } // 实现Class接口， 分别为 CreateUser DeleteUser Policies func (g *Cls1) CreateUser(user string) (status bool, err error) { fmt.Println(\u0026#34;Cls1 - create user: \u0026#34;, user) return true, nil } func (g *Cls1) DeleteUser(user string) (status bool, err error) { fmt.Println(\u0026#34;Cls1 - Delete user: \u0026#34;, user) return true, nil } func (g *Cls1) Policies() (status bool, err error) { fmt.Println(\u0026#34;Cls1 - get policies\u0026#34;) return true, nil } // 导入时注册插件的方法 func init() { // 导入包时 注册 cls1 adaptor.Register(\u0026#34;Cls1\u0026#34;, func() adaptor.Adaptors { return new(Cls1) }) } 导入包,实现插件自动注册到 Struct FactoryByName 具体文件： ./example-adaptor/adaptor/standard/imports.go\n1 2 3 4 5 6 7 package standard import ( // 统一导入， 触发init() 实现自动注册 _ \u0026#34;example/adaptor/cls1\u0026#34; // 匿名引用cls1包, 自动注册 _ \u0026#34;example/adaptor/cls2\u0026#34; // 匿名引用cls2包, 自动注册 ) 然后在项目入口文件处，导入adaptor/standard包即可\n1 2 3 4 5 6 7 8 9 10 11 package main import ( _ \u0026#34;example/adaptor/standard\u0026#34; // 统一导入，实现插件注册 \u0026#34;example/api\u0026#34; ) func main() { engine := api.Routers() _ = engine.Run(\u0026#34;:8887\u0026#34;) } 写新的插件 创建插件类\n创建包cls-new，并在包内做到这几件事： 创建 struct Cls-new 实现在adaptor中interface的方法 在init方法中注册 在adaptor/standard包处进行导入 文件路径: adaptor/standard/imports.go\n1 2 3 4 5 6 7 8 package standard import ( // 统一导入， 触发init() 实现自动注册 _ \u0026#34;example/adaptor/cls1\u0026#34; _ \u0026#34;example/adaptor/cls2\u0026#34; _ \u0026#34;example/adaptor/cls-new\u0026#34; ) Reference Useful Go语言工厂模式自动注册\n借鉴caddy插件机制博客\nGo-Plugin机制说明、简单示例\n","description":"","id":83,"section":"posts","tags":["Go"],"title":"Go-Module实现go语言的插件机制","uri":"https://hex-go.github.io/posts/golang/2020-07-23-go-module%E5%AE%9E%E7%8E%B0go%E8%AF%AD%E8%A8%80%E7%9A%84%E6%8F%92%E4%BB%B6%E6%9C%BA%E5%88%B6/"},{"content":"重要 生成自签发证书 生成CA根证书以及根证书私钥. output: ca.crt和 ca.key, pem格式. input ''\n1 2 3 4 5 # Generate a CA private key openssl genrsa -out ca.key 4096 # Create a self signed Certificate, valid for 10yrs with the \u0026#39;signing\u0026#39; option set openssl req -x509 -new -nodes -key ca.key -subj \u0026#34;/CN=company.COM\u0026#34; -days 3650 -reqexts v3_req -extensions v3_ca -out ca.crt 生成*.example.domain通配符证书私钥 output: example.domain.key, pem格式. input: ''\n1 openssl genrsa -out example.domain.key 4096 根据*.example.domain通配符证书私钥，生成证书请求文件(csr)example.domain.csr output: example.domain.csr, pem格式. input: example.domain.key.\n1 openssl req -new -sha256 -key example.domain.key -out example.domain.csr -subj \u0026#34;/CN=svc.example.domain\u0026#34; 根据证书请求文件通过根证书、根证书私钥签发证书。 output: example.domain.crt, pem格式. input: example.domain.csr和ca.crt和ca.key 以及配置文件example.domain.ini.\n其中，配置文件example.domain.ini的内容如下：\n1 2 3 4 5 [ ext ] subjectAltName = @dns [ dns ] DNS.1 = *.example.domain 执行下面命令：\n1 openssl x509 -req -in example.domain.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 3560 -out example.domain.crt -extfile example.domain.ini -extensions ext 生成k8s中的secret. output: k8s-secret example-certs, pem格式. input: example.domain.crt 和 example.domain.key pem格式.\n1 kubectl create secret tls example-certs --cert=example.domain.crt --key=example.domain.key Reference 概念说明\n生成证书\n","description":"","id":84,"section":"posts","tags":["Devops","证书","PKI"],"title":"PKI-自签发证书说明","uri":"https://hex-go.github.io/posts/devops/2020-07-08-pki-%E8%87%AA%E7%AD%BE%E5%8F%91%E8%AF%81%E4%B9%A6%E8%AF%B4%E6%98%8E/"},{"content":" 当下流行两种方式来为云原生应用提供后台服务： Operators和Open Services Broker API。本文比较两种技术，并针对性研究如何整合两者协同工作。\n运行在Kubernetes集群上的工作负载，需要访问许多相同的服务集。因此，Kubernetes社区构建了对OSBAPI规范，并创建了ServiceCatalog项目\n来提供Kubernetes集群内的服务市场。云计算服务API规范变成了OSBAPI(Open Service Broker API)。Operator是这一领域出现的新技术。\nOperators介绍 最近一段时间，Operator的人气飙升。原因很简单。Operators允许使用Kubernetes的开发人员直接使用Kubernetes集群中的托管服务。\n随后，Operator模式经常被用作构建符合OSBAPI的service broker的替代方案。\nOperator：\n是一组自定义资源定义(crd)，具有对其进行操作的自定义控制器。 重要 环境说明 安装 使用 Reference Operator和OSBAPI的最佳结合\n","description":"","id":85,"section":"posts","tags":["Kubernetes"],"title":"ServiceCatalog和Operator结合","uri":"https://hex-go.github.io/posts/kubernetes/2020-06-29-servicecatalog%E5%92%8Coperator%E7%BB%93%E5%90%88/"},{"content":"问题 容器中的进程默认以 root 用户权限运行，如果k8s集群中的容器进程也以root用户运行，会存在容器提权获取节点主机权限的风险。一旦容器有权限访问所在节点资源，则带来巨大的安全隐患。安全漏洞 CVE-2019-11245 解决办法 为容器中的进程指定一个具有合适权限的用户，而不要使用默认的 root 用户。 应用Linux的user namespace技术，配置 docker 开启 user namespace 隔离用户。 由于docker user-namespace种种限制而让其它的个别功能出现问题，推荐第一种解决方案，本文也重点介绍\n配置合适的用户 因此，首先需要在镜像中添加一个合适权限的用户；之后需要在k8s-pod中通过security-context中指定通过此用户运行容器。\n注意两点：\n用户必须指定UID, 因为k8s通过uid非0来确定是否为非root启动，当runAsNonRoot设置为true时，必须指定数字类型UID。 用户ID建议\u0026gt;=10000,以避免避与节点普通用户的常用范围冲突。\n低于10000的UID在多个系统上都存在安全风险，因为如果有人设法在Docker容器外提升权限，Docker容器UID可能会与权限更高的系统用户的UID重叠，从而获取更高的权限。为了避免这种安全隐患，建议以高于10000的UID运行进程。 在Dockerfile 中指定用户身份 可参考dockerfile的最佳实践\n1 2 3 4 5 RUN addgroup -S paas \u0026amp;\u0026amp; \\ adduser paas -u 10000 -S paas -G paas \u0026amp;\u0026amp; \\ su paas -s /bin/sh -c \u0026#34;mkdir -p /home/paas/config\u0026#34; \u0026amp;\u0026amp; \\ su paas -s /bin/sh -c \u0026#34;mkdir -p /home/paas/data\u0026#34; USER 10000 在 Pod Security Policies 中指定用户身份 1 2 3 4 5 6 7 # deployment 举例 spec: template: spec: containers: securityContext: runAsUser: 10001 Pod Security Policies中的配置优先级更高，可以覆盖Dockerfile中的参数。\n带来的问题以及解决方案 1. 权限不足，导致服务无法监听在80端口 在大多数操作系统中，监听\u0026lt;1024的低端口需要特殊权限。这些端口通常用于一些系统服务或者敏感服务，比如 HTTP（80端口）、HTTPS（443端口）、SSH（22端口）、FTP（21端口）等。\n改变容器监听端口（\u0026gt;1024），将服务的监听端口通过Service资源设置。例如容器监听端口设置为8080，服务端口设置为80。\n2. 构建镜像时，提示权限不足 将USER 10000命令放到包安装等特权命令之后， 此命令执行后的构建操作，才会以uid=10000的用户执行。\n3. 开源中间件镜像如何处理 SecurityContext中指定的uid必须实际存在于容器中。 而很多开源中间件镜像已经被配置为以 root 身份运行。因此必须重新构建镜像，并在镜像中创建非root用户。常见方案有两种：\n以开源中间件镜像为基础镜像，再在之后运行创建用户的构建命令。 选择Bitnami等公司已重新打包·构建过的镜像（推荐）。 相关概念 Linux中的UID/GID uid: 范围为0~65535（Ubuntu中为65533），0~999留给系统用户，普通用户为1000~65533.\n进程如果不声明uid，启动时以登录用户uid启动进程；进程可以声明任一存在或不存在的uid启动进程。\n创建用户时若不指定uid, 默认就是直接从已存在的uid中找到最大的那个加1。\n综上，\n每个uid不一定有对应的用户名 每个用户一定有自己的uid 每个进程必定有uid 进程uid不指定，则与启动命令的用户uid一致 创建用户uid不指定，则每多一个用户，uid会max+1递增。 容器中的UID/GID 容器中的进程默认以 root 用户权限运行，Docker默认不启用user namespace, 所有的容器共用一个内核，所以内核控制的 uid 和 gid 则仍然只有一套。\n如果容器内使用root用户，则容器内的进程与宿主机的root具有相同权限。会有很大的安全隐患，一旦容器有权限访问宿主机资源，则将具备宿主机root相同权限。\n具体容器中的原理可参考官方文档\nReference Ubuntu下的用户权限\nDocker官网-Linux内核功能 理解 docker 容器中的 uid 和 gid\n隔离 docker 容器中的用户\n为pod设置权限和AccessControl\n","description":"容器中的进程默认以 root 用户权限运行，Docker默认不启用user namespace, 所有的容器共用一个内核，所以内核控制的 uid 和 gid 则仍然只有一套。如果容器内使用root用户，则容器内的进程与宿主机的root具有相同权限。会有很大的安全隐患，一旦容器有权限访问宿主机资源，则将具备宿主机root相同权限。","id":86,"section":"posts","tags":["Kubernetes"],"title":"2020-06-28-K8S容器进程以root运行带来的安全隐患及解决","uri":"https://hex-go.github.io/posts/kubernetes/2020-06-28-docker-kubernetes%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%BB%A5%E9%9D%9Eroot%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8/"},{"content":"重要 最重要的事: 本文包括\n初始包安装； 安装翻墙软件； 安装docker； 安装Goland开发环境gvm+golang-1.13； 安装前端环境npm-nodejs-yarn； docker运行微信； 安装finalshell； 安装Goland并激活； 安装其他，postman、typora、git-client、docker-compose等； 初始包安装 必备工具\n1 sudo apt install openssh-server curl unrar net-tools 为Gland准备\n1 sudo apt-get install libcanberra-gtk-module openjdk-11-jre-headless 为前端和Golang编译安装\n1 sudo apt-get install curl git mercurial make binutils bison gcc build-essential 为搜狗输入法准备\n1 sudo apt-get install fcitx-bin fcitx-table 显卡驱动（draft） 卸载已存在驱动旧组件\n1 2 3 4 sudo apt-get purge nvidia* sudo apt-get autoremove # 删除/etc/apt/sources.list.d下的相关记录 sudo dpkg -P cuda-repo-ubuntu1404 下载驱动\n1 2 cd ~ wget http://us.download.nvidia.com/XFree86/Linux-x86_64/384.69/NVIDIA-Linux-x86_64-384.69.run 安装依赖\n1 2 3 4 5 6 7 8 # 用来编译驱动 sudo apt install build-essential # 用来支持32位系统(可选) sudo apt install gcc-multilib # 用来提供dkms支持 sudo apt install dkms # 带图形显示的系统必须装，但一般都装过了(因为你已经能看到桌面，说明已经装好了)。server版的机器不用装(可选) sudo apt install xorg xorg-dev 安装驱动\n1 sudo apt-get nvidia-375 nvidia-modprobe 安装配置翻墙软件 下载Qv2ray软件包 下载v2ray核心软件包 集成并配置订阅地址 chrome配置 安装配置Docker 卸载机器上docker组件 1 sudo apt-get remove docker docker-engine docker.io containerd runc 安装Docker 1 2 curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh 解决Docker命令和socket文件权限问题 1 2 3 4 5 6 # 将操作的用户加入docker组中 sudo usermod -aG docker ${USER} # 注销重新登录，或者执行下面命令来使改变生效 newgrp docker # 执行下面命令测试 docker run hello-world 配置国内镜像加速\n创建或修改 /etc/docker/daemon.json：\n1 2 3 4 5 6 7 8 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://1nj0zren.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;http://f1361db2.m.daocloud.io\u0026#34;, \u0026#34;https://registry.docker-cn.com\u0026#34; ] } 重启docker服务\n1 2 sudo systemctl daemon-reload sudo systemctl restart docker 执行docker info命令，查看配置是否已生效。\nGVM+Go1.13 安装GVM 如果下载超时的话，就尝试下搭个梯子。系统proxy不想配的话，就chrome配置好SwitchOMG，通过浏览器下载脚本。\n1 bash \u0026lt; \u0026lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) 安装go1.4 Go 1.5+从工具链中删除了C编译器，并用Go编写的代码替换了它们。 实现了自举。为了编译Go 1.5+，请确保先安装Go 1.4\n1 2 gvm install go1.4 -B gvm use go1.4 安装go1.13 1 2 export GOROOT_BOOTSTRAP=$GOROOT gvm intall go1.13 others 1 2 3 4 5 6 # 查看本地版本 gvm list # 查看所有版本 gvm listall # 卸载gvm和所有go gvm implode 前端环境 安装nvm 1 2 3 4 5 6 7 8 9 10 # 下载脚本并执行 curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.34.0/install.sh | bash # 使修改在当前回话生效 source ~/.profile # 检查nvm安装 nvm --version # list所有可用的nodejs版本(安装lts版本) nvm ls-remote # list所有已安装的nodejs nvm list 安装nodejs 1 2 3 4 5 6 7 nvm install 10.15 # select 安装的nodejs nvm use 10.15 # 检查 node -v npm -v 安装yarn，npm 1 2 3 4 5 6 7 8 9 npm i -g npm --registry https://registry.npm.taobao.org npm i -g yarn --registry https://registry.npm.taobao.org # 设置yarn yarn config set registry https://registry.npm.taobao.org -g yarn config set sass_binary_site http://cdn.npm.taobao.org/dist/node-sass -g # 设置npm export NVM_NODEJS_ORG_MIRROR=http://npm.taobao.org/mirrors/node npm config set registry https://registry.npm.taobao.org 运行微信 运行时有报错MIT-SHM，增加参数\u0026ndash;ipc=host解决问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 docker container run -d wechat \\ --device /dev/snd \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -v ${XDG_RUNTIME_DIR}/pulse/native:${XDG_RUNTIME_DIR}/pulse/native \\ -v $HOME:$HOME \\ -v $HOME/WeChatFiles:/WeChatFiles \\ -e DISPLAY=unix${DISPLAY} \\ -e XMODIFIERS=@im=fcitx \\ -e QT_IM_MODULE=fcitx \\ -e GTK_IM_MODULE=fcitx \\ -e AUDIO_GID=`getent group audio | cut -d: -f3` \\ -e VIDEO_GID=`getent group video | cut -d: -f3` \\ -e GID=`id -g` \\ -e UID=`id -u` \\ -e DPI=120 \\ --ipc=host \\ hoking007/wechat:latest 终端管理工具 \u0026ndash; FinalShell 一键安装\n安装路径/usr/lib/FinalShell/\n配置文件路径/home/$USER/.finalshell/\n1 2 3 4 rm -f finalshell_install_linux.sh wget www.hostbuf.com/downloads/finalshell_install_linux.sh chmod +x finalshell_install_linux.sh ./finalshell_install_linux.sh 安装配置Goland（draft） 下载安装包\n其他 安装最新git-client 1 2 3 4 5 6 7 8 9 sudo apt-add-repository ppa:git-core/ppa sudo apt-get update sudo apt-get install git # if `add-apt-repository` not found ## ubuntu 14.04 sudo apt-get install software-properties-common ## ubuntu 13.10 or earlier sudo apt-get install python-software-properties 安装最新docker-compose 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 1. remove the old version: ## If installed via apt-get sudo apt-get remove docker-compose ## If installed via curl sudo rm /usr/local/bin/docker-compose ## If installed via pip pip uninstall docker-compose # 2. install latest docker-compose VERSION=$(curl --silent https://api.github.com/repos/docker/compose/releases/latest | jq .name -r) DESTINATION=/usr/local/bin/docker-compose sudo curl -L https://github.com/docker/compose/releases/download/${VERSION}/docker-compose-$(uname -s)-$(uname -m) -o $DESTINATION sudo chmod 755 $DESTINATION 安装typora 1 sudo apt-get install typora 安装postman 通过软件中心安装。\n安装wps 通过软件中心安装。\nReference 显卡驱动\n安装NVIDIA驱动和CUDA在Linux上\n安装最新版NVIDIA驱动在Ubuntu上\nGVM+GO\nGVM-github\n安装golang的依赖-linux\nGVM安装go1.4报错\u0026quot;go: command not found\u0026quot;\nQv2ray\nQv2ray-git博客\n翻墙相关的git项目 new-pac\nDocker\n官方文档-在Ubuntu上安装Docker-Engine\n官方文档-在Ubuntu非root用户相关配置\nDocker hub 设置代理服务器\n前端\n使用nvm安装nodejs\napt安装nodejs并配置\n微信\n知乎-wine安装微信和QQ\n微信docker镜像-github\n微信docker镜像-github-高分屏显示问题\n微信docker镜像-github-MIT-SHM error solutions\n使用docker运行GUI工具\n使用docker运行GUI应用-stack-overflow\nGUI不工作\u0026ndash;报错MIT-SHM\n终端管理工具\nFinalShell官网-Linux安装\nFinalShell博客\u0026ndash;使用说明\nFinalShell博客\u0026ndash;建立隧道\ngotty+ssh/tmux实现web-xshell,并协同\n","description":"","id":87,"section":"posts","tags":["个人工具","Ubuntu","Docker","Go","GVM","Goland","Nodejs","Postman","Typora","Finalshell"],"title":"ubuntu18.04初始开发环境搭建","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-05-10-ubuntu18.04_%E5%88%9D%E5%A7%8B%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"content":"重要 最重要的事:\nGoTTY\u0026ndash;将终端共享为web应用 GoTTY是一个简单的命令行工具，可以将CLI工具转换为web应用程序\n使用场景：\n共享ssh gotty ssh 127.0.0.1 共享ssh，并共享session gotty -w tmux new -s test 共享docker，提供一个隔离的环境 gotty -w docker run -it --rm busybox Tmux\u0026ndash;终端多路复用器 通过tmux可以在一个终端上轻松地切换多个程序，分离它们(它们在后台运行)并重新连接到另一个终端.\n新建 session\n命令tmux new -s 如 tmux new -s \u0026lt;session-name\u0026gt;\n离开 session\n命令 tmux detach ； 快捷键 ctrl + b 然后 按 d\n查看 session 列表\n命令tmux ls ；快捷键操作 ctrl + b 然后 按s 列出所有的 session\n进入 session\n离开 session 之后，有时候我们还需要对某个 session 进行操作，这时候可以通过如下的操作：\ntmux attach -t \u0026lt;session-name\u0026gt;\n关闭 session\n如果需要关闭 session, 可以通过执行如下的命令即可：\ntmux kill-session -t \u0026lt;session-name\u0026gt;\n切换 session\n执行命令,可以从当前的 session 快速切换到另一个 session：\ntmux switch -t\n重命名 session\n命令tmux rename-session -t 快捷键 ctrl +d 然后 按$ 来重命名当前的session 。\n切换窗口\n在同一个会话的多个窗口之间可以通过如下快捷键进行切换:\n快捷键ctrl+b 然后 按p (previous的首字母) 切换到上一个window。\n快捷键ctrl+b 然后 按n (next的首字母) 切换到下一个window。\n快捷键ctrl+b 然后 按0 切换到0号window，依次类推，可换成任意窗口序号\n快捷键ctrl+b 然后 按w (windows的首字母) 列出当前session所有window，通过上、下键切换窗口\n快捷键ctrl+b 然后 按l (字母L的小写)相邻的window切换\n快捷键ctrl+b 然后 按\u0026amp;\n分屏\n快捷键ctrl+b 然后 按%， 垂直分屏\n快捷键ctrl+b 然后 按\u0026quot;， 水平分屏\n切换pane\n快捷键ctrl+b 然后 按o， 依次切换当前窗口下的各个pane。\n快捷键ctrl+b 然后 按Up|Down|Left|Right 根据按箭方向，选择切换到某个pane。\n快捷键ctrl+b 然后 按Space (空格键)， 对当前窗口下的所有pane重新排列布局，每按一次，换一种样式。\n快捷键ctrl+b 然后 按z ，最大化当前pane。再按一次后恢复。\n快捷键ctrl+b 然后 按x，关闭pane：\n帮助：\n快捷键ctrl+b 然后 按？\nReference ubuntu配置\nubuntu18.10给应用程序添加快捷键\nLinux 让终端走代理的几种方法\n[ubuntu18.04 ]\n安装工具，\u0026lsquo;Open in Terminal\u0026rsquo;\n常用工具使用\n破坏性测试工具：chaos-mesh\nKafaka客户端工具：kaf\nk8s切换集群、命名空间工具：kubectx 博客\nk8s自动合并kubeconfig工具： mergeKubeConfig\n完美替换terraform，支持Go和Python：pulumi\n终端共享为WEB应用：gotty\n终端共享为WEB应用：webtty\n终端多路复用器：tmux\nDevOPS工具：\n独立编译镜像(without connect to docker-daemon)工具: kaniko\n文件传输工具: croc\nLinux权限详解\n","description":"","id":88,"section":"posts","tags":["个人工具","GoTTY","Tmux","Ubuntu"],"title":"ubuntu系统配置+常用工具使用","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-04-23-ubuntu_18.04-%E4%BD%BF%E7%94%A8%E9%85%8D%E7%BD%AE%E6%8A%80%E5%B7%A7/"},{"content":"重要 记录常用的一些函数\n1. 字符串转int64 1 2 3 4 5 6 7 // Use the max value for signed 64 integer. http://golang.org/pkg/builtin/#int64 var s string = \u0026#34;9223372036854775807\u0026#34; i, err := strconv.ParseInt(s, 10, 64) if err != nil { panic(err) } fmt.Printf(\u0026#34;Hello, %v with type %s!\\n\u0026#34;, i, reflect.TypeOf(i)) 输出：\nHello, 9223372036854775807 with type int64!\n2. 最小化gormigrate 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 package main import ( \u0026#34;log\u0026#34; \u0026#34;gopkg.in/gormigrate.v1\u0026#34; \u0026#34;github.com/jinzhu/gorm\u0026#34; _ \u0026#34;github.com/jinzhu/gorm/dialects/sqlite\u0026#34; ) type Person struct { gorm.Model Name string } type Pet struct { gorm.Model Name string PersonID int } func main() { db, err := gorm.Open(\u0026#34;sqlite3\u0026#34;, \u0026#34;mydb.sqlite3\u0026#34;) if err != nil { log.Fatal(err) } if err = db.DB().Ping(); err != nil { log.Fatal(err) } db.LogMode(true) m := gormigrate.New(db, gormigrate.DefaultOptions, []*gormigrate.Migration{ { ID: \u0026#34;201608301400\u0026#34;, Migrate: func(tx *gorm.DB) error { return tx.AutoMigrate(\u0026amp;Person{}).Error }, Rollback: func(tx *gorm.DB) error { return tx.DropTable(\u0026#34;people\u0026#34;).Error }, }, { ID: \u0026#34;201608301430\u0026#34;, Migrate: func(tx *gorm.DB) error { return tx.AutoMigrate(\u0026amp;Pet{}).Error }, Rollback: func(tx *gorm.DB) error { return tx.DropTable(\u0026#34;pets\u0026#34;).Error }, }, }) err = m.Migrate() if err == nil { log.Printf(\u0026#34;Migration did run successfully\u0026#34;) } else { log.Printf(\u0026#34;Could not migrate: %v\u0026#34;, err) } } 3. 判断元素在Slice中 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package main import ( \u0026#34;fmt\u0026#34; ) func main() { items := []string{\u0026#34;A\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;3\u0026#34;} // Missing Example _, found := Find(items, \u0026#34;golangcode.com\u0026#34;) if !found { fmt.Println(\u0026#34;Value not found in slice\u0026#34;) } // Found example k, found := Find(items, \u0026#34;B\u0026#34;) if !found { fmt.Println(\u0026#34;Value not found in slice\u0026#34;) } fmt.Printf(\u0026#34;B found at key: %d\\n\u0026#34;, k) } // Find takes a slice and looks for an element in it. If found it will // return it\u0026#39;s key, otherwise it will return -1 and a bool of false. func Find(slice []string, val string) (int, bool) { for i, item := range slice { if item == val { return i, true } } return -1, false } Reference ","description":"","id":89,"section":"posts","tags":["Go"],"title":"Go-常用函数备忘","uri":"https://hex-go.github.io/posts/golang/2020-05-29-go-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%A4%87%E5%BF%98/"},{"content":"重要 1. 概念说明 构建Context说明\n执行docker build命令时，当前工作目录称为构建上下文。默认情况下，dockerfile也在当前目录，但可以使用文件标志（-f）指定不同的位置。 无论dockerfile实际在哪里，执行构建命令的当前目录中的文件和目录的所有递归内容都将作为Context发送到Docker Daemon程序。\n操作 镜像大小 安全 构建性能 可读性 尽可能使用官方Docker镜像;使用明确的镜像标签 否 是 否 是 RUN、COPY、ADD命令会创建layer，其他指令不会增加layer 是 否 否 否 始终在同一运行语句中结合运行 apt-get update 和 apt-get install 否 否 是 否 使用.dockerignore排除构建不需要的文件。 否 是 是 否 将长或复杂的RUN语句拆分到多行上，用反斜杠分隔。 否 否 否 是 以非root用户运行；uid\u0026gt;10000；使用静态 UID 和 GID 否 是 否 否 使用静态 UID 和 GID 否 是 否 否 只在CMD中存储参数 否 否 否 是 使用COPY代替ADD 否 是 否 否 采取多阶段构建, 以减少最终运行镜像大小，环境clean。 是 是 否 是 2. 最佳实践 尽可能使用官方Docker镜像 Alpine并不一定是最佳选择 使用明确的镜像标签，而非latest 始终在同一运行语句中结合运行 apt-get update 和 apt-get install 限制镜像layers数量 以非root用户运行 请勿使用低于10000的UID 使用静态 UID 和 GID 只在CMD中存储参数 使用COPY代替ADD 尽可能使用官方Docker镜像 相比自己构建镜像安装sdk来说，使用适合的官方镜像是首选。因为官方镜像经过了数百万用户的优化和测试。找不到合适的官方镜像或者官方基础镜像包含漏洞时，再考虑自己从头创建镜像。\n例如，相较于手动安装SDK，如下\n1 2 3 4 5 6 7 8 9 FROM ubuntu RUN wget -qO- https://packages.microsoft.com/keys/microsoft.asc \\ | gpg --dearmor \u0026gt; microsoft.asc.gpg \\ \u0026amp;\u0026amp; sudo mv microsoft.asc.gpg /etc/apt/trusted.gpg.d/ \\ \u0026amp;\u0026amp; wget -q https://packages.microsoft.com/config/ubuntu/18.04/prod.list \\ \u0026amp;\u0026amp; sudo mv prod.list /etc/apt/sources.list.d/microsoft-prod.list \\ \u0026amp;\u0026amp; sudo chown root:root /etc/apt/trusted.gpg.d/microsoft.asc.gpg \\ \u0026amp;\u0026amp; sudo chown root:root /etc/apt/sources.list.d/microsoft-prod.list RUN sudo apt-get install dotnet-sdk-3.1 更推荐使用官方镜像\n1 FROM mcr.microsoft.com/dotnet/core/sdk:3.1-buster Alpine并不一定是最佳选择 Alpine镜像由于受到严格控制，具备镜像小，安全性高的特点，在绝大多少情况下被推荐使用（Docker官方推荐）。\n但无脑使用Alpine也并不可取，也要意识到以下两个问题：\n像python使用Alpine会带来构建慢、镜像体积过大且有时会引入运行时错误，不推荐使用详情可参考：禁止使用Alpine作为Python的基础镜像构建 Alpine镜像的第二点\u0026ndash;安全性。大多数漏扫工具都找不到Alpine镜像的任何漏洞。但这并不意味着Alpine百分百安全。 使用明确的镜像标签，而非latest 基于lastest镜像构建的缺点如下：\nDocker 镜像编译不一致。latest 标签，那么每次构建都会拉取一个最新构建的Docker镜像。引入这种非确定性的行为会影响编译的可重复性。 node Docker 映像基于成熟的操作系统，其中包含运行 Node.js 网络应用时可能需要也可能不需要的各种库和工具。这有两个缺点。首先，更大的映像意味着更大的下载量，除了增加存储需求外，还意味着需要更多时间下载和重新构建映像。其次，这意味着您有可能将所有这些库和工具中可能存在的安全漏洞引入到映像中。 使用 major.minor，而不是 major.minor.patch，以确保您始终使用特定的图像版本：\n保持你的构建正常工作（最新版本意味着你的构建在未来可能会任意损坏，而 major.minor 版本则意味着这种情况不会发生）\n在您构建的新镜像中包含最新的安全更新。\n始终在同一RUN语句中运行apt-get update和apt-get install 在 RUN 中单独使用 apt-get update 会导致缓存问题和后续的 apt-get install指令失败。\n这与 Docker 使用的缓存机制有关。在构建镜像时，Docker 会将初始指令和修改后的指令对比，指令未修改的会使用之前构建的缓存。例如：\n将apt-get update单独放到一个RUN语句中：\n1 2 3 FROM ubuntu:22.04 RUN apt-get update RUN apt-get install -y curl 之后修改dockerfile，增加nginx\n1 2 3 FROM ubuntu:22.04 RUN apt-get update RUN apt-get install -y curl nginx 因为RUN apt-get update未发生变化，apt-get update 就不会被执行，而是使用之前构建的缓存。由于没有运行apt-get update，构建可能无法获得最新版本的 curl 和 nginx 软件包。\n下面是推荐的Dockerfile写法：\n1 2 3 4 5 6 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ curl \\ git \\ build-essential \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # Debian和Ubuntu的官方镜像会自动执apt-get clean，因此无需明确调用。 限制镜像layers数量 Dockerfile中的每一条RUN指令最终都会在最终镜像中创建一个额外的layer。限制layer的数量，以保持镜像的轻量级。\n以非root用户运行 以非 root 用户身份运行容器可大大降低从容器到主机提权的风险。详情参考Docker文档。\n对于基于 Debian 的映像，可以通过下面命令从容器中移除 root 用户：\n1 2 3 4 5 RUN groupadd -g 10001 paas \u0026amp;\u0026amp; \\ useradd -u 10000 -g paas paas \\ \u0026amp;\u0026amp; chown -R paas:paas /app USER 10001 从容器中移除root后，会存在权限问题，比如安装软件没有权限，可以将USER 10001命令放到这些命令之后；再比如，如果没有 root 权限，应用程序无法在 80 端口上运行，因此必须更改端口\u0026gt;1024。\nUID\u0026gt;=10000 低于 10000 的 UID 在多个系统上都存在安全风险，因为如果有人设法在 Docker 容器外提升权限，他们的 Docker 容器 UID 可能会与权限更高的系统用户的 UID 重叠，从获取更高的权限。为了避免这种安全隐患，建议以高于 10000 的 UID 运行进程。\n使用静态UID和GID 运行容器时，需要为容器所拥有的文件设置文件权限。如果镜像没有设置静态UID/GID，就必须从运行的容器中提取该信息，然后才能在主机上分配正确的文件权限。最好为所有镜像设置一个固定的静态UID/GID。建议使用 10000:10001，这样可以减少不必要的运维复杂度。\n只在CMD中存储参数 如果 CMD 包含命令名称，在运行容器时就必须猜出命令名称，以便传递参数等。\n将ENTRYPOINT作为命令名称：\n1 ENTRYPOINT [\u0026#34;/sbin/tini\u0026#34;, \u0026#34;--\u0026#34;, \u0026#34;myapp\u0026#34;] 而CMD只是命令的参数：\n1 CMD [\u0026#34;--foo\u0026#34;, \u0026#34;5\u0026#34;, \u0026#34;--bar=10\u0026#34;] 运行容器时参数传递的方式更人性化，而无需猜测其名称，例如\n1 docker run IMAGE --some-argument 使用COPY代替ADD 使用 ADD 的唯一例外是 tar 自动提取功能\nADD local-file.tar.xz /usr/share/files\n禁止ADD指定URL，这样可能会导致MITM攻击或恶意数据源。此外，ADD会隐式解压本地压缩包，这可能会导致路径遍历和 Zip Slip漏洞。\n应避免这样做：\n1 ADD https://example-url.com/file.tar.xz /usr/share/files 使用多阶段构建 在使用 Dockerfile 构建应用程序时，会创建许多仅在构建时需要的工件。这些工件可以是编译所需的开发工具和库等软件包，也可以是运行单元测试所需的依赖项、临时文件、密钥等。\n在基础镜像中保留这些人工制品（可能用于生产）会导致 Docker 镜像大小增大，这不仅会严重影响下载时间，还会因为安装了更多软件包而增加攻击面。您使用的 Docker 镜像也是如此\u0026ndash;您可能需要特定的 Docker 镜像来构建，但不需要它来运行应用程序的代码。\nGolang 就是一个很好的例子。要构建 Golang 应用程序，你需要 Go 编译器。编译器生成的可执行文件可以在任何操作系统上运行，无需依赖，包括从头镜像。\n这也是 Docker 具有多阶段构建功能的一个很好的原因。该功能允许你在构建过程中使用多个临时镜像，只保留最新的镜像和你复制到其中的信息。这样，你就有了两个镜像：\n第一个镜像\u0026ndash;非常大的镜像，捆绑了许多依赖项，用于构建应用程序和运行测试。\n第二个镜像\u0026ndash;在大小和库数量方面都非常小的镜像，只有在生产中运行应用程序所需的工件副本。\n3. 常见配置备忘 3.1 安装包 3.1.1 apt包安装 使用RUN apt-get update \u0026amp;\u0026amp; apt-get install -y 确保dockerfile安装最新的软件包版本。(如果将命令分成两行RUN, 会导致缺少缓存，apt-get install失败)。 apt-get clean命令清理/var/cache/apt/archives目录下的内容，且在官方Ubuntu/Debian镜像会在安装后自动清理，所以不需要显示使用。 1 2 3 4 5 6 7 8 ## 国内加速-设置阿里源 RUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list RUN apt-get update \u0026amp;\u0026amp; apt-get install -y --no-install-recommends \\ package-bar \\ package-baz \\ package-foo \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* 3.1.2 apk安装 1 2 3 4 5 ## 国内加速 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN apk upgrade --update \\ \u0026amp;\u0026amp; apk add -U tzdata \\ \u0026amp;\u0026amp; rm -rf /var/cache/apk/* 3.2 设置时区 时区原理以及具体说明，参考理解容器时区问题的根源及常见解决方法\n3.2.1 alpine发行版 1 2 3 4 FROM alpine:3.19.1 ENV TZ=Asia/Shanghai RUN apk add --no-cache tzdata 3.2.2 Ubuntu发行版 ubuntu\\debian\\centos默认安装tzdata，因此只需设置环境变量，如果缺少tzdata包，请参考理解容器时区问题的根源及常见解决方法设置\n1 2 FROM ubuntu:22.04 ENV TZ=Asia/Shanghai 3.3 创建用户 3.3.1 alpine 1 2 3 4 5 6 7 8 9 10 11 12 FROM reg.svc.com/paas/alpine:3.11.5 LABEL MAINTAINER = \u0026#34;Hex\u0026#34; RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN apk add --no-cache ca-certificates # Create user paas RUN addgroup -S paas \\ \u0026amp;\u0026amp; adduser paas -u 10001 -S paas -G paas \\ \u0026amp;\u0026amp; su paas -s /bin/sh -c \u0026#34;mkdir -p /home/paas/config\u0026#34; \\ \u0026amp;\u0026amp; su paas -s /bin/sh -c \u0026#34;mkdir -p /home/paas/data\u0026#34; USER 10001 3.4 多阶段构建 3.4.1 Alpine-golang 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # Build image (Golang) FROM golang:1.13-alpine3.11 AS build-stage ENV GO111MODULE on ENV GOPROXY https://goproxy.io ENV CGO_ENABLED 0 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN apk add --no-cache gcc git make WORKDIR /src COPY . . RUN go mod download RUN go build -a -ldflags \u0026#39;-extldflags \u0026#34;-static\u0026#34;\u0026#39; -o paas-api # Final Docker image FROM reg.svc.com/paas/alpine:3.11.5 AS final-stage LABEL MAINTAINER = \u0026#34;Hex\u0026#34; RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN apk add --no-cache ca-certificates # Create user paas RUN addgroup -S paas \u0026amp;\u0026amp; adduser paas -u 10001 -S paas -G paas \u0026amp;\u0026amp; su paas -s /bin/sh -c \u0026#34;mkdir -p /home/paas/config\u0026#34; \u0026amp;\u0026amp; su paas -s /bin/sh -c \u0026#34;mkdir -p /home/paas/data\u0026#34; # must be numeric to work with Pod Security Policies: # https://kubernetes.io/docs/concepts/policy/pod-security-policy/#users-and-groups USER 10001 WORKDIR /home/paas/ COPY --from=build-stage /src/paas-api . COPY --chown=paas:paas config /home/paas/config COPY --chown=paas:paas data /home/paas//data COPY helm /usr/local/bin/helm COPY kubectl /usr/local/bin/kubectl ENTRYPOINT [\u0026#34;/home/paas/paas-api\u0026#34;, \u0026#34;server\u0026#34;,\u0026#34;--config=./config/config.yaml\u0026#34;,\u0026#34;--port=8081\u0026#34;,\u0026#34;--cors=false\u0026#34;] 3.4.2 Ubuntu-golang 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # Build image (Golang) FROM golang:1.17.8-alpine3.15 AS build-stage ENV GO111MODULE on ENV GOPROXY https://goproxy.cn ENV CGO_ENABLED 0 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN apk add --no-cache gcc git make WORKDIR /src COPY . . RUN go mod download RUN go build -a -ldflags \u0026#39;-extldflags \u0026#34;-static\u0026#34;\u0026#39; -o devops-api # Final Docker image FROM reg.svc.com/paas/ubuntu:20.04 AS final-stage LABEL MAINTAINER = \u0026#34;Hex\u0026#34; RUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list RUN set -x; \\ apt-get update \u0026amp;\u0026amp; apt-get install -y --no-install-recommends \\ tzdata \\ jq \\ telnet \\ dnsutils \\ iputils-ping \\ net-tools \\ netcat \\ ca-certificates \\ curl \\ vim-tiny \\ git \\ openssl \\ ldap-utils \\ tree \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* RUN mkdir -p /home/paas WORKDIR /home/paas/ COPY --from=build-stage /src/paas-api . ENV ROOT /tmp ENV HDFS_ALGO_PATH /algos/ ENV HADOOP_CONF_DIR /etc/hadoop/conf ENV TZ=Asia/Shanghai COPY ./pkg/api/middleware/builder/ /tmp/builder COPY config /home/paas/config COPY data /home/paas/data COPY ./bin/ /usr/local/bin/ #EXPOSE 8081 ENTRYPOINT [\u0026#34;/usr/local/bin/entrypoint\u0026#34;] Reference Docker官方文档-Dockerfile最佳实践\n10 Docker Image Security Best Practices\n10 best practices to build a Java container with Docker\n10 best practices to containerize Node.js web applications with Docker\n","description":"","id":90,"section":"posts","tags":["Devops","Docker","Dockerfile"],"title":"Docker-Dockerfile的最佳实践","uri":"https://hex-go.github.io/posts/devops/2020-05-29-docker-dockerfile%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"},{"content":"重要 在为 Docker 镜像选择基础镜像时，通常会推荐使用 Alpine Linux。使用 Alpine 会让镜像体积更小，并加快构建速度。如果编程语言是Go，这个是合理的。\n但如果编程语言是Python，Alpine Linux会带来以下问题：\n构建速度变的特别慢。 让docker镜像变大。 偶尔会引入一些不起眼的运行时错误。 Alpine的优点 大多数情况下Alpine具备构建时间短，镜像小的优点，被广泛推荐使用。\n下面测试Alpine作为基础镜像的优点。假设需要安装 gcc 作为镜像构建的一部分，对比Alpine Linux与Ubuntu 18.04在构建时间和镜像大小方面的区别。\n首先，拉取两个镜像，并检查它们的大小：\n1 2 3 4 5 6 7 8 9 10 $ docker pull --quiet ubuntu:18.04 docker.io/library/ubuntu:18.04 $ docker pull --quiet alpine docker.io/library/alpine:latest $ docker image ls ubuntu:18.04 REPOSITORY TAG IMAGE ID SIZE ubuntu 18.04 ccc6e87d482b 64.2MB $ docker image ls alpine REPOSITORY TAG IMAGE ID SIZE alpine latest e7d92cdc71fe 5.59MB 可以看出来，Alpine Linux基础镜像小得多。\n接下来，在Ubuntu系统中安装gcc：\n1 2 3 4 FROM ubuntu:18.04 RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install --no-install-recommends -y gcc \u0026amp;\u0026amp; \\ apt-get clean \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* 构建命令（使用time计时）\n1 2 3 4 5 6 7 8 9 $ time docker build -t ubuntu-gcc -f Dockerfile.ubuntu --quiet . sha256:b6a3ee33acb83148cd273b0098f4c7eed01a82f47eeb8f5bec775c26d4fe4aae real 0m29.251s user 0m0.032s sys 0m0.026s $ docker image ls ubuntu-gcc REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu-gcc latest b6a3ee33acb8 9 seconds ago 150MB 然后，在Alpine系统中安装gcc：\n1 2 FROM alpine RUN apk add --update gcc 构建命令（使用time计时）\n1 2 3 4 5 6 7 8 9 $ time docker build -t alpine-gcc -f Dockerfile.alpine --quiet . sha256:efd626923c1478ccde67db28911ef90799710e5b8125cf4ebb2b2ca200ae1ac3 real 0m15.461s user 0m0.026s sys 0m0.024s $ docker image ls alpine-gcc REPOSITORY TAG IMAGE ID CREATED SIZE alpine-gcc latest efd626923c14 7 seconds ago 105MB 构建时间 镜像大小 Alpine 15s 105MB Ubuntu 30s 150MB 总结，Alpine镜像的生成速度更快，体积更小。\nAlpine不适合Python 以使用pandas和matplotlib的Python应用程序举例。\n基于Debian的Python官方镜像（python:3.8-slim），并使用以下 Dockerfile：\n1 2 FROM python:3.8-slim RUN pip install --no-cache-dir matplotlib pandas 构建命令与输出为\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $ docker build -f Dockerfile.slim -t python-matpan. Sending build context to Docker daemon 3.072kB Step 1/2 : FROM python:3.8-slim ---\u0026gt; 036ea1506a85 Step 2/2 : RUN pip install --no-cache-dir matplotlib pandas ---\u0026gt; Running in 13739b2a0917 Collecting matplotlib Downloading matplotlib-3.1.2-cp38-cp38-manylinux1_x86_64.whl (13.1 MB) Collecting pandas Downloading pandas-0.25.3-cp38-cp38-manylinux1_x86_64.whl (10.4 MB) ... Successfully built b98b5dc06690 Successfully tagged python-matpan:latest real 0m30.297s user 0m0.043s sys 0m0.020s 基于Alpine镜像，使用以下Dockerfile:\n1 2 FROM python:3.8-alpine RUN pip install --no-cache-dir matplotlib pandas 构建命令与输出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ docker build -t python-matpan-alpine -f Dockerfile.alpine . Sending build context to Docker daemon 3.072kB Step 1/2 : FROM python:3.8-alpine ---\u0026gt; a0ee0c90a0db Step 2/2 : RUN pip install --no-cache-dir matplotlib pandas ---\u0026gt; Running in 6740adad3729 Collecting matplotlib Downloading matplotlib-3.1.2.tar.gz (40.9 MB) ERROR: Command errored out with exit status 1: command: /usr/local/bin/python -c \u0026#39;import sys, setuptools, tokenize; sys.argv[0] = \u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;/ tmp/pip-install-a3olrixa/matplotlib/setup.py\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;; __file__=\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;/tmp/pip-install-a3olrixa/matplotlib/setup.py\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;;f=getattr(tokenize, \u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;open\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;, open)(__file__);code=f.read().replace(\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;\\r\\n\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;, \u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;\\n\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;);f.close();exec(compile(code, __file__, \u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;exec\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;))\u0026#39; egg_info --egg-base /tmp/pip-install-a3olrixa/matplotlib/pip-egg-info ... ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output. The command \u0026#39;/bin/sh -c pip install matplotlib pandas\u0026#39; returned a non-zero code: 1 因为 标准PyPI wheels 无法在 Alpine 上运行\n对比上面两次构建的日志输出，会发现不同：\n基于 Debian 的构建，下载的是matplotlib-3.1.2-cp38-cp38-manylinux1_x86_64.whl。这是一个预编译的二进制文件。相比之下，Alpine 下载的是源代码包matplotlib-3.1.2.tar.gz，因为标准的 Linux wheel文件无法在Alpine Linux上运行。\n大多数 Linux 发行版都使用GNU 版本（glibc）的标准C库，几乎所有C程序（包括 Python）都依赖glibc。但Alpine Linux使用的是musl，而python预编译的*.whl文件是针对glibc编译的，因此 Alpine 禁用了对 Linux wheel的支持。\n然而，大多数Python软件包都在PyPI上包含了*whl预编译文件，来大大加快了安装时间。但使用Alpine Linux，就需要编译每个 Python 软件包中的所有 C 代码。\n这也意味着,需要自己找出每一个系统库的依赖关系。在这种情况下，根据依赖关系跟新Dockerfile如下：\n1 2 3 FROM python:3.8-alpine RUN apk --update add gcc build-base freetype-dev libpng-dev openblas-dev RUN pip install --no-cache-dir matplotlib pandas Alpine Linux 可导致难以预料的运行时错误 虽然从理论上讲，Alpine 使用的musl C库与其他 Linux 发行版使用的glibc基本兼容，但在实践中，两者之间的差异可能会导致问题。而且，一旦出现问题，这些问题会非常奇怪，出乎意料。\n举几个例子：\nmusl 不支持 DNS over TCP，这意味着某些DNS配置（如 Kubernetes 中的配置）可能会导致DNS查询失败。 Alpine 的线程默认堆栈大小较小，这可能导致Python程序崩溃。 由于 musl 分配内存的方式与 glibc 截然不同，导致Python程序速度慢了很多。 还有时间格式化和解析方面的问题。 这些问题的大部分或全部都已得到修复，但无疑还有更多问题有待发现。这种兼容性带来的不确定性太可怕。\nAlpine与Ubuntu作为基础镜像的对比如下\n基础镜像 构建时间 镜像大小 是否存在其他问题 python:3.8-slim 30s 363MB 否 python:3.8-alpine 1557s 851MB 是 Alpine的构建速度要慢得多，镜像体积也更大，而且必须做大量的研究。\n是否能解决 关于构建速度 Alpine Edge（最终将成为下一个稳定版本）拥有 matplotlib 和 pandas，可以加快构建速度。安装系统包的速度也相当快。不过，截至 2020 年 1 月，当前的稳定版本并不包含这些流行软件包。\n不过，即使这些包可用，系统包也几乎总是落后于 PyPI 上的包，而且 Alpine 也不太可能把 PyPI 上的所有包都打包。实际上，所知的大多数 Python 团队都不使用系统包，而是依赖 PyPI 或 Conda Forge。\n关于镜像大小 可以通过删除最初安装的软件包，或添加不缓存软件包下载的选项，或使用多阶段构建的方法减小镜像大小，但镜像大小也在470MB。与基于python:3.8-slim的镜像大小差不多。但 Alpine Linux 的目的是更小的镜像和更快的构建速度。也许可以通过足够的努力获得更小的镜像，但仍然要忍受 1500 秒的构建时间，而使用 python:3.8-slim 镜像只需 30 秒。\n运行时错误 未知的不确定性，遇到一个解决一个\n总结 由于Alpine发行版默认c库(musl)与python预编译文件(*.whl)所依赖的c库(glibc)不同，如果python使用Alpine基础镜像，就无法使用PyPI库中已编译的wheel文件，只能下载源码包重新编译。 从而导致构建时间长，镜像体积大，兼容性带来不确定的运行时错误。因此不建议使用Alpine作为Python的基础镜像构建。\nReference Using Alpine can make Python Docker builds 50× slower\n","description":"Alpine 会使 Python Docker 构建速度降低50倍,还可能会触发不可预料的运行时错误。禁止使用Alpine作为Python的基础镜像构建","id":91,"section":"posts","tags":["Devops","Docker","Dockerfile"],"title":"禁止使用Alpine作为Python的基础镜像构建","uri":"https://hex-go.github.io/posts/devops/2020-05-29-docker-%E7%A6%81%E6%AD%A2%E4%BD%BF%E7%94%A8alpine%E4%BD%9C%E4%B8%BApython%E7%9A%84%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA/"},{"content":"引言 Kubernetes 设计初衷是为模块化的云原生应用程序的部署、扩展和管理提供便捷性和灵活性。在 Kubernetes 的背后，有许多关键组件和接口，这些组件协同工作，以确保集群的正常运行。\n本文将重点介绍三个重要的 Kubernetes 接口：CRI、CNI 和 CSI，它们在容器运行时、网络和存储方面发挥着关键作用。\n1. 容器运行时接口（CRI） CRI（Container Runtime Interface）是k8s用于与容器运行时通信的主要协议。容器运行时负责管理和执行容器的生命周期，包括创建、启动、停止和销毁容器。\nCRI 通过定义一组 gRPC 服务和数据结构，使kubelet能够与各种容器运行时（如 Docker、Containerd 等）交互，无需重新编译集群组件。\nContainer Runtime 实现了CRI gRPC Server，包括RuntimeService和ImageService。该 gRPC Server 需要监听本地的Unix socket，而 kubelet 则作为gRPC Client运行。\n2. 容器网络接口（CNI） CNI（Container Network Interface）是k8s中负责处理容器网络配置的接口。在 Kubernetes 集群中，各个容器需要能够相互通信，而 CNI 就负责为容器配置网络。\nCNI 插件通过在容器创建、启动或停止时设置网络环境，使得容器能够正确地连接到集群网络。这种设计允许用户根据需要选择不同的网络解决方案，从而满足不同的网络需求。\n2.1 CNI设计考量 CNI 插件分配了命名空间隔离、流量和 IP 过滤等功能，而 Kubernetes Kube-Net 插件默认情况下不提供这些功能。假设开发人员想要实现这些高级网络功能。\n在这种情况下，他们必须使用带有容器网络接口（CNI）的 CNI 插件，以便更轻松地创建和管理网络。\n容器运行时必须在调用任何插件之前为容器创建一个新的网络命名空间。 然后，容器运行时必须确定这个容器应属于哪个网络，并为每个网络确定哪些插件必须被执行。 2.2 CNI网络模型 CNI 网络插件实现网络结构的网络模型分为两类：封装网络模型（例如 Virtual Extensible Lan，缩写是 VXLAN）或非封装网络模型（例如 Border Gateway Protocol，缩写是 BGP）。\n封装网络(encapsulated network) 封装信息由 Kubernetes worker 之间的 UDP 端口分发，交换如何访问 MAC 地址的网络控制平面信息。此类网络模型中常用的封装是 VXLAN、Internet 协议安全性 (IPSec) 和 IP-in-IP。\n封装网络在现有的 Kubernetes 集群节点三层（L3）网络拓扑之上创建了一个逻辑二层（L2）网络。通过这一模型，你能够为容器提供隔离的 L2 网络，无需进行路由分发。\n封装网络会带来少量的处理开销，并因覆盖封装（生成IP header）而增加 IP 包的大小。封装信息通过K8s-worker之间的 UDP 端口传输，交换着关于访问 MAC 地址的网络控制平面信息。\n在这类网络模型中，常见的封装方式包括 VXLAN、IPSec（Internet 协议安全性）和 IP-in-IP。\n简单来说，这种网络模型在 k8s-worker 之间生成了一种扩展网桥，连接了各个pod。\n如果偏向使用扩展 L2 网桥，则可以选择此网络模型。此网络模型对 Kubernetes worker 的 L3 网络延迟很敏感。如果数据中心位于不同的地理位置，请确保它们之间的延迟较低，以避免最终的网络分割。\n使用这种网络模型的 CNI 网络插件包括 Flannel、Canal、Weave 和 Cilium。默认情况下，Calico 不会使用此模型，但你可以对其进行配置。\n非封装网络(Unencapsulated Network) 此网络模型创建了一个 L3 网络，用于在容器之间进行数据包路由。这种模型并不创建隔离的 L2 网络，因此不会引起额外的开销。然而，这些优点的代价是，k8s-worker节点必须管理所有必要路由分发。\n该网络模型避免了使用 IP header 进行封装，而是通过k8s-worker之间的网络协议来传播路由信息，比如使用 BGP 协议，以实现 Pod 之间的连接。\n简单来说，这种网络模型在k8s-worker之间形成了一个扩展网络路由器，提供了连接 Pod 所需的信息。\n如果更偏好采用 L3 网络，则可以选择此网络模型。该模型在操作系统层面上为k8s-worker节点动态更新路由信息，对延迟不太敏感。\n使用这一网络模型的 CNI 网络插件包括 Calico 和 Cilium。Cilium 也能够通过这一模型进行配置，尽管这并非其默认模式。\n3. 容器存储接口（CSI） CSI（Container Storage Interface）是 Kubernetes 中处理容器存储的接口。CSI 使存储供应商能够开发插件，将各种存储系统集成到 Kubernetes 中。\n这些插件允许管理员在不影响应用程序的情况下管理存储，例如动态卷配置、快照和克隆操作。通过 CSI，Kubernetes 的存储管理变得更加灵活，能够适应不同的存储需求。\n总结：\nKubernetes 的成功在很大程度上得益于其丰富的接口体系，使得不同的组件能够协同工作，提供全面的容器编排解决方案。CRI、CNI 和 CSI 是 Kubernetes 中三个关键的接口，它们分别处理容器运行时、网络和存储方面的任务。\n理解这些接口如何工作以及它们的作用，有助于更好地管理和优化 Kubernetes 集群，从而更好地支持应用程序的部署和运行。\n参考文献 Understanding Kubernetes Interfaces: CRI, CNI, \u0026amp; CSI\nK8S-handbook\u0026ndash;容器存储接口\n","description":"","id":92,"section":"posts","tags":["Kubernetes","CNI","CSI","CRI"],"title":"K8S基石-理解k8s接口CRI、CNI、CSI","uri":"https://hex-go.github.io/posts/kubernetes/2020-05-29-k8s%E5%9F%BA%E7%9F%B3-%E7%90%86%E8%A7%A3k8s%E6%8E%A5%E5%8F%A3cricnicsi/"},{"content":"重要 环境说明 安装 使用 0. 校验kubeconfig可用性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import ( \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; clientcmdapi \u0026#34;k8s.io/client-go/tools/clientcmd/api\u0026#34; ) ## 解析kubeConfig文件， 校验 func (k *K8S) ParseConf(kubeConfig []byte) (Conf clientcmdapi.Config, err error) { var ( restConf clientcmd.ClientConfig ) if restConf, err = clientcmd.NewClientConfigFromBytes(kubeConfig); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not load kube Config : %s\u0026#34;, err.Error())) return } Conf, _ = restConf.RawConfig() return } 1. 初始化客户端clientSet 1.1 集群内初始化ClientSet 官方Example\n1.2 集群外初始化ClientSet 官方Example\n1.3 从字节流创建ClientSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package k8s import ( \u0026#34;k8s.io/client-go/rest\u0026#34; \u0026#34;k8s.io/client-go/kubernetes\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; clientcmdapi \u0026#34;k8s.io/client-go/tools/clientcmd/api\u0026#34; ) type K8S struct { clientSet *kubernetes.Clientset } // Connect - 初始化k8s客户端 func (k *K8S) Connect(kubeConfig []byte) (err error) { var ( restConf *rest.Config ) if restConf, err = clientcmd.RESTConfigFromKubeConfig(kubeConfig); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not load kube Config : %s\u0026#34;, err.Error())) return } // 生成client-set配置 if k.clientSet, err = kubernetes.NewForConfig(restConf); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not connect k8s : %s\u0026#34;, err.Error())) return } log.Info(\u0026#34;Successfully connected to k8s\u0026#34;) return } 1.4 创建Dynamic ClientSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package fleet import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;k8s.io/client-go/dynamic\u0026#34; \u0026#34;k8s.io/client-go/rest\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; ) type Crd struct { Client dynamic.Interface } // Connect 初始化Fleet客户端 func (i *Crd) Connect(kubeConfig []byte) (err error) { var ( restConf *rest.Config ) if restConf, err = clientcmd.RESTConfigFromKubeConfig(kubeConfig); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not load kube Config : %s\u0026#34;, err.Error())) return } if i.Client, err = dynamic.NewForConfig(restConf); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not connect FleetCrd-k8s : %s\u0026#34;, err.Error())) return } log.Info(\u0026#34;Successfully connected to FleetCrd\u0026#34;) return } 3. 根据Deployment|StatefulSet获取Pods 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import ( \u0026#34;k8s.io/api/apps/v1\u0026#34; coreV1 \u0026#34;k8s.io/api/core/v1\u0026#34; metaV1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/labels\u0026#34; ) func (k *K8S) PodGetByStatefulSet(namespace string, statefulSet v1.StatefulSet) ([]*coreV1.Pod, error) { var podList []*coreV1.Pod labelsMap := statefulSet.ObjectMeta.GetLabels() log.DebugF(\u0026#34;[Middleware-K8s] StatefulSet:Labels: %#v\u0026#34;, labelsMap) labelSets := labels.SelectorFromSet(labelsMap) options := metaV1.ListOptions{ LabelSelector: labelSets.String(), } podsClient := k.clientSet.CoreV1().Pods(namespace) pods, err := podsClient.List(context.TODO(), options) if err != nil { return nil, err } for _, pod := range pods.Items { log.DebugF(\u0026#34;[Middleware-K8s] Pod:Labels: %#v, pod_name=%s\u0026#34;, pod.ObjectMeta.GetLabels(), pod.ObjectMeta.Name) podList = append(podList, \u0026amp;pod) } return podList, err } 4. 根据Job获取Pods 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import ( batchV1 \u0026#34;k8s.io/api/batch/v1\u0026#34; coreV1 \u0026#34;k8s.io/api/core/v1\u0026#34; metaV1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/labels\u0026#34; ) func (k *K8S) PodGetByJob(namespace string, job batchV1.Job) ([]*coreV1.Pod, error) { var podList []*coreV1.Pod labelsMap := map[string]string{ \u0026#34;job-name\u0026#34;: job.ObjectMeta.Name, \u0026#34;controller-uid\u0026#34;: string(job.ObjectMeta.UID), } log.DebugF(\u0026#34;[Middleware-K8s] Jobs:Labels: %#v\u0026#34;, labelsMap) labelSets := labels.SelectorFromSet(labelsMap) options := metaV1.ListOptions{ LabelSelector: labelSets.String(), } podsClient := k.clientSet.CoreV1().Pods(namespace) pods, err := podsClient.List(context.TODO(), options) if err != nil { return nil, err } for _, pod := range pods.Items { log.DebugF(\u0026#34;[Middleware-K8s] Pod:Labels: %#v, pod_name=%s\u0026#34;, pod.ObjectMeta.GetLabels(), pod.ObjectMeta.Name) podList = append(podList, \u0026amp;pod) } return podList, err } 5. Dynamic-client-go操作CRD资源 以rancher fleet项目的CRD clusters.fleet.cattle.io举例\n完整的包引用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package fleet import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; fleet \u0026#34;github.com/rancher/fleet/pkg/apis/fleet.cattle.io/v1alpha1\u0026#34; \u0026#34;icosdeploy/pkg/api/log\u0026#34; metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1/unstructured\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime/schema\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime/serializer/yaml\u0026#34; \u0026#34;k8s.io/client-go/dynamic\u0026#34; \u0026#34;k8s.io/client-go/rest\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; ) 5.1 初始化ClientSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package fleet import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;k8s.io/client-go/dynamic\u0026#34; \u0026#34;k8s.io/client-go/rest\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; ) type Crd struct { Client dynamic.Interface } // Connect 初始化Fleet客户端 func (i *Crd) Connect(kubeConfig []byte) (err error) { var ( restConf *rest.Config ) if restConf, err = clientcmd.RESTConfigFromKubeConfig(kubeConfig); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not load kube Config : %s\u0026#34;, err.Error())) return } if i.Client, err = dynamic.NewForConfig(restConf); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not connect FleetCrd-k8s : %s\u0026#34;, err.Error())) return } log.Info(\u0026#34;Successfully connected to FleetCrd\u0026#34;) return } 5.2 Cluster CRD的查询、删除操作 资源定义\n1 2 3 4 5 var clusterCRD = schema.GroupVersionResource{ Group: \u0026#34;fleet.cattle.io\u0026#34;, Version: \u0026#34;v1alpha1\u0026#34;, Resource: \u0026#34;clusters\u0026#34;, } 上面的值在CRD``中获取\n1 2 3 4 5 6 7 8 9 10 11 12 13 spec: # group name to use for REST API: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt; # 对应 Group 字段的值 group: fleet.cattle.io # list of versions supported by this CustomResourceDefinition versions: # 对应 Version 字段的可选值 - name: v1alpha1 # ... names: # plural name to be used in the URL: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;/\u0026lt;plural\u0026gt; # 对应 Resource 字段的值 plural: clusters 5.2.1 List查询资源 如果资源对象不是Namespace隔离的，则不指定Namespace: i.Client.Resource(xxxCRD).List(context.TODO(), metav1.ListOptions{})\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func (i *Crd) ListClusters(namespace string) (clusters *fleet.ClusterList, err error) { list, err := i.Client.Resource(clusterCRD).Namespace(namespace).List(context.TODO(), metav1.ListOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err := json.Unmarshal(data, \u0026amp;clusters); err != nil { return nil, err } return clusters, nil } 5.2.2 Get查询资源详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func (i *Crd) GetCluster(namespace string, name string) (cluster *fleet.Cluster, err error) { list, err := i.Client.Resource(clusterCRD). Namespace(namespace).Get(context.TODO(), name, metav1.GetOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err := json.Unmarshal(data, \u0026amp;cluster); err != nil { return nil, err } return cluster, nil } 5.2.3 删除资源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (i *Crd) DelCluster(namespace string, name string) (err error) { deletePolicy := metav1.DeletePropagationForeground cluster, err := i.GetCluster(namespace, name) if err != nil { log.Error(err.Error()) return err } if cluster == nil { err = errors.New(fmt.Sprintf(\u0026#34;Cluster -- %s not exists\u0026#34;, name)) log.Error(err.Error()) return } err = i.Client.Resource(clusterCRD). Namespace(namespace).Delete(context.TODO(), name, metav1.DeleteOptions{PropagationPolicy: \u0026amp;deletePolicy}) if err != nil { return } return } 5.3 Token CRD的创建操作 资源定义\n1 2 3 4 5 var tokenCRD = schema.GroupVersionResource{ Group: \u0026#34;fleet.cattle.io\u0026#34;, Version: \u0026#34;v1alpha1\u0026#34;, Resource: \u0026#34;clusterregistrationtokens\u0026#34;, } 5.3.1 List查询资源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func (i *Crd) ListToken(namespace string) (tokenList *fleet.ClusterRegistrationTokenList, err error) { list, err := i.Client.Resource(tokenCRD).Namespace(namespace).List(context.TODO(), metav1.ListOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err = json.Unmarshal(data, \u0026amp;tokenList); err != nil { return nil, err } return tokenList, nil } 5.3.2 Get查询资源详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func (i *Crd) GetToken(namespace string, name string) (token *fleet.ClusterRegistrationToken, err error) { list, err := i.Client.Resource(tokenCRD).Namespace(namespace).Get(context.TODO(), name, metav1.GetOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err = json.Unmarshal(data, \u0026amp;token); err != nil { return nil, err } return token, nil } 5.3.3 创建资源 注意: yaml包一定要用 \u0026quot;k8s.io/apimachinery/pkg/runtime/serializer/yaml\u0026quot;， 否则想资源部分数据解析会报错\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 var CreateData = ` kind: ClusterRegistrationToken apiVersion: \u0026#34;fleet.cattle.io/v1alpha1\u0026#34; metadata: name: new-token namespace: fleet-local spec: ttl: 240h ` func (i *Crd) CreateToken(namespace string) (token *fleet.ClusterRegistrationToken, err error) { decoder := yaml.NewDecodingSerializer(unstructured.UnstructuredJSONScheme) obj := \u0026amp;unstructured.Unstructured{} gvk := schema.GroupVersionKind{ Group: \u0026#34;fleet.cattle.io\u0026#34;, Version: \u0026#34;v1alpha1\u0026#34;, Kind: \u0026#34;ClusterRegistrationToken\u0026#34;, } if _, _, err := decoder.Decode([]byte(CreateData), \u0026amp;gvk, obj); err != nil { return nil, err } one, err := i.Client.Resource(tokenCRD).Namespace(namespace).Create(context.TODO(), obj, metav1.CreateOptions{}) if err != nil { return nil, err } data, err := one.MarshalJSON() if err != nil { return nil, err } if err = json.Unmarshal(data, \u0026amp;token); err != nil { return nil, err } return token, nil } 5.4 GitRepo CRD的操作 资源定义\n1 2 3 4 5 var gitRepoCRD = schema.GroupVersionResource{ Group: \u0026#34;fleet.cattle.io\u0026#34;, Version: \u0026#34;v1alpha1\u0026#34;, Resource: \u0026#34;gitrepos\u0026#34;, } 5.4.1 List查询资源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func (i *Crd) ListGitRepo(namespace string) (repoList *fleet.GitRepoList, err error) { list, err := i.Client.Resource(gitRepoCRD).Namespace(namespace).List(context.TODO(), metav1.ListOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err := json.Unmarshal(data, \u0026amp;repoList); err != nil { return nil, err } return repoList, nil } 6. 查看容器日志 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // PodLogs - pod logs func (k *K8S) PodLogs(namespace string, name string) (string, error) { podLogOpts := coreV1.PodLogOptions{} jobsClient := k.clientSet.CoreV1().Pods(namespace) result := jobsClient.GetLogs(name, \u0026amp;podLogOpts) podLogs, err := result.Stream(context.TODO()) if err != nil { log.ErrorF(\u0026#34;error in opening stream: %v\u0026#34;, err) return \u0026#34;\u0026#34;, err } defer podLogs.Close() buf := new(bytes.Buffer) _, err = io.Copy(buf, podLogs) if err != nil { log.ErrorF(\u0026#34;error in copy information from podLogs to buf: %v\u0026#34;, err) return \u0026#34;\u0026#34;, err } logs := buf.String() return logs, err } Reference 第一参考 client-go简介\nclient-go官方实例\u0026ndash;集群内client配置\nclient-go针对crd资源，代码生成器\nUnit test kubernetes client in Go\nDynamic-client-go操作CRD资源\n基于Dynamic-client, 开发第三方资源Informer和Controller\n","description":"","id":93,"section":"posts","tags":["Kubernetes","Client-go","Go"],"title":"k8S-使用client-go操作集群","uri":"https://hex-go.github.io/posts/kubernetes/2020-05-28-k8s-%E4%BD%BF%E7%94%A8client-go%E6%93%8D%E4%BD%9C%E9%9B%86%E7%BE%A4/"},{"content":"重要 开发过程中，需要解析helm-manifest获取到的各种资源的yaml。每个都写映射\n环境说明 helm 3 kubernetes-v1.15.6 安装 无\n使用 注意:\nk8s版本不同。，资源所在的api接口会有变化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 package k8s import ( \u0026#34;fmt\u0026#34; \u0026#34;heroku/pkg/api/log\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime\u0026#34; \u0026#34;k8s.io/client-go/kubernetes/scheme\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;strings\u0026#34; ) func ParseK8sYaml(fileR []byte) []runtime.Object { acceptedK8sTypes := regexp.MustCompile(`(Role|ClusterRole|RoleBinding|ClusterRoleBinding|ServiceAccount|Deployment|StatefulSet|Service|Ingress|HorizontalPodAutoscaler)`) fileAsString := string(fileR[:]) sepYamlfiles := strings.Split(fileAsString, \u0026#34;---\u0026#34;) retVal := make([]runtime.Object, 0, len(sepYamlfiles)) for _, f := range sepYamlfiles { if f == \u0026#34;\\n\u0026#34; || f == \u0026#34;\u0026#34; { // ignore empty cases continue } checkList := strings.Split(f, \u0026#34;#\u0026#34;) if len(checkList) \u0026gt; 10 { // ignore annotation resource log.Warn(fmt.Sprintf(\u0026#34;ignore annotation resource: %s\u0026#34;, f[:10])) continue } decode := scheme.Codecs.UniversalDeserializer().Decode obj, groupVersionKind, err := decode([]byte(f), nil, nil) if err != nil { log.Warn(fmt.Sprintf(\u0026#34;Error while decoding YAML object. Err was: %s\u0026#34;, err)) continue } log.Debug(fmt.Sprintf(\u0026#34;Helm-Manitest:--:%s\u0026#34;, groupVersionKind)) if !acceptedK8sTypes.MatchString(groupVersionKind.Kind) { log.Info(fmt.Sprintf(\u0026#34;The custom-roles configMap contained K8s object types which are not supported! Skipping object with type: %s\u0026#34;, groupVersionKind.Kind)) } else { retVal = append(retVal, obj) } } return retVal } func stringToFile(outDir string, aut model.Aut) (configFile string, err error) { filename := filepath.Join(outDir, \u0026#34;config\u0026#34;) var data = []byte(aut.K8sConf) err = ioutil.WriteFile(filename, data, 0666) if err != nil { return \u0026#34;\u0026#34;, errors.New(fmt.Sprintf(\u0026#34;k8s-config load to tmp Error : %s\u0026#34;, err.Error())) } return filename, nil } func Show(helmRelease string, aut model.Aut) (instances []runtime.Object, err error) { tmp, err := ioutil.TempDir(\u0026#34;\u0026#34;, \u0026#34;curator-\u0026#34;) if err != nil { return nil, errors.Wrapf(err, \u0026#34;Error while preparing temp Dir\u0026#34;) } defer os.RemoveAll(tmp) // clean up configPath, err := stringToFile(tmp, aut) if err != nil { return nil, err } log.Info(\u0026#34;Started Helm-show:\u0026#34;) args := []string{ \u0026#34;--kubeconfig\u0026#34;, configPath, \u0026#34;get\u0026#34;, \u0026#34;manifest\u0026#34;, helmRelease, \u0026#34;-n\u0026#34;, aut.Namespace, } stdout, err := utils.ExecCMD(\u0026#34;helm\u0026#34;, args) if err != nil { return nil, err } instances = k8s.ParseK8sYaml(stdout) return instances, err } Reference Support for parsing K8s yaml spec into client-go data structures\n","description":"","id":94,"section":"posts","tags":["Kubernetes","Go"],"title":"解析k8s-yaml成client-go中的data-structs","uri":"https://hex-go.github.io/posts/kubernetes/2020-05-25-%E8%A7%A3%E6%9E%90k8s-yaml%E6%88%90client-go%E4%B8%AD%E7%9A%84data-structs/"},{"content":"重要 最重要的事:\n1.安装软件 1.1 通过软件中心安装 Show Applications \u0026raquo; Search Ubuntu software center.\n1.2 安装.deb文件 所有安装deb文件的方式\n1.2.1 双击安装 双击.deb安装包，进入软件中心安装软件。\n1.2.2 dpkg命令安装 1 2 3 4 5 6 7 dpkg -i XXX.deb ## 如果您得到任何依赖项错误，请运行下面的命令。它将修复所有的错误 apt install -f ## 删除应用 dpkg -r packagename.deb ## 重新配置/修复deb安装 dpkg-reconfigure packagename 1.2.3 apt命令安装 1 2 3 ## 还有一种方法可以在Ubuntu系统上安装deb文件，apt-get工具。 sudo apt install ./name.deb 1.3 snap安装 ​ Canonical为在任何Linux发行版上安装应用程序提供了跨平台的解决方案。这是一个通用的包管理系统，它提供了在任何Linux系统上运行软件所需的所有依赖项和库。\n​ Ubuntu18.04之后都默认支持Snaps包。如果是Ubuntu 16.04和更老的版本环境，则在终端中运行以下命令来安装Snap包管理环境。\n1 sudo apt install snapd 执行以下命令，通过snap安装软件\n1 sudo snap install \u0026lt;package\u0026gt; 1.4 安装AppImage包 ​ Deb软件包和RPM文件格式分别用于在Debian或Ubuntu和基于Fedora / SUSE的Linux发行版上安装软件。 对于应用程序开发人员来说，存在一个问题，他们必须为各种Linux发行版维护多个软件包。 为了克服这个问题，AppImage出现了，它为所有Linux发行版提供了通用的软件包管理系统。\n​ AppImage文件格式类似于Windows系统中使用的.exe文件。但随着。AppImage格式，没有提取或安装，你删除AppImage，软件就会从Ubuntu中删除，双击AppImage就会运行该应用程序。\n运行软件包，只用通过下面三步：\n下载.appimage格式的软件包。 给次文件可执行权限。点击软件\u0026raquo;属性\u0026raquo;权限标签\u0026raquo;使其可执行，检查允许作为程序执行文件。 双击运行。 1.5 通过apt命令安装 ​ Ubuntu Linux上安装软件的另一种简单方法。就像从Ubuntu软件中心安装软件一样，命令行也类似于它。唯一不同的是Ubuntu软件中心是基于图形用户界面，apt命令是基于命令行界面。许多软件都提供了apt命令来安装软件 。\n​ 例如，Chromium浏览器有两种方式，Ubuntu软件中心和apt命令，可以在Ubuntu上安装它。如果你想安装它，那么去Ubuntu软件中心，通过关键字Chromium进行搜索，或者在终端中输入这个简单的apt命令。\n1 2 3 4 5 ## 创建应用 sudo apt install -y chromium-browser ## 删除应用 sudo apt chromium-browser 1.6 通过PPA安装应用 ​ PPA个人软件包存档是另一种简单的方式来安装软件在Ubuntu Linux。许多开发人员希望直接向最终用户提供他们的软件的最新版本。在这种情况下，PPA可以作为Ubuntu官方软件仓库使用，需要一个月的时间在Ubuntu软件中心包含任何尖端软件。所以很多Ubuntu用户可能不会等待那么长时间，而是可以使用PPA立即安装最新版本。\n举例：\n1 2 3 sudo add-apt-repository ppa:embrosyn/cinnamon sudo apt update sudo apt install cinnamon 注意，这里总共遵循了三个命令。第一个用于将PPA知识库添加到系统s源列表中，第二个用于更新软件列表的缓存，最后一个用于使用PPA apt命令安装特定的软件。\n2. 常用软件 免费的密码管理软件： Bitwarden\nRedis可视化工具： Redis Desktop Manager\nOpenLDAP可视化工具：\nReference ubuntu安装软件说明\n","description":"","id":95,"section":"posts","tags":["个人工具","Ubuntu","Appimage","Snap"],"title":"Ubuntu常见安装软件方式(ded、appimage、snap)说明.md","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-04-23-ubuntu_%E5%B8%B8%E8%A7%81%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%96%B9%E5%BC%8Fdedappimagesnap%E8%AF%B4%E6%98%8E/"},{"content":"重要 minikube 主要是镜像都在k8s.gcr.io上，需要设置proxy。\n环境说明 Ubuntu18.04 driver = docker 安装 1. 初始配置 验证机器支持虚拟化。执行下面命令，如果输出非空则说明支持。\n1 grep -E --color \u0026#39;vmx|svm\u0026#39; /proc/cpuinfo 2. 安装minikube 安装配置kubectl 1 2 3 4 5 6 7 # 下载最新版本 curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl # 配置 chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl # 检查安装 kubectl version --client 安装minikube\n1 2 3 4 5 6 7 8 # 下载最新版本 curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 # 配置 chmod +x minikube sudo install minikube /usr/local/bin/ # 检查安装 minikube start --driver=docker minikube status 使用 启动 由于在Ubuntu下，参数--image-mirror-country=cn存在bug，所以通过image-repository指定阿里的源进行安装。\n参数说明：\n参数 参数说明 值 \u0026ndash;driver 常用值说明：\nvirtualbx\u0026ndash;使用virtualbox\nvmware\u0026ndash;使用vmware\nnone: 在主机上而不是在虚拟机中运行Kubernetes组件。您需要运行Linux并安装Docker。\ndocker: Docker驱动程序允许您将Kubernetes安装到现有的Docker安装中。在Linux上，这并不需要启用虚拟化。\npodman: 在PodMan中运行k8s组件。需要安装podman. 使用\u0026quot;docker\u0026quot;，注意一些访问权限的问题。和局限性 \u0026ndash;registry-mirror 手动启动dockerd时，通过\u0026ndash;registry-mirror选项，或编辑/etc/docker/daemon.json并添加Registry-mirrors键和值，以使更改持久化。 \u0026ldquo;https://registry.docker-cn.com\u0026quot;国内registry-mirror \u0026ndash;image-repository 对gcr.io的访问权限有限时，指定拉取镜像的地址。例如registry.cn-hangzhou.aliyuncs.com/google_containers registry.cn-hangzhou.aliyuncs.com/google_containers \u0026ndash;kubernetes-version 指定k8s版本，如 \u0026lsquo;\u0026ndash;kubernetes-version=v1.19.6\u0026rsquo; \u0026ndash;vm-driver 废弃，使用--driver 代替 1 minikube start --driver=docker --kubernetes-version=\u0026#39;v1.19.6\u0026#39; --registry-mirror=https://registry.docker-cn.com --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers 停止 1 minikube stop 删除（清除本地数据） 1 minikube delete 常见问题 minikube start时报错缺包\nk8s-1.18.2以上版本需要依赖包 报错信息：\nExiting due to GUEST_MISSING_CONNTRACK: Sorry, Kubernetes 1.19.6 requires conntrack to be installed in root's path\n解决方案：\n1 sudo apt-get install -y conntrack Reference 备注 install minikube\nInstalling Kubernetes with Minikube\nminikube启动带参数--image-mirror-country=cn失败\nMinikube 安装踩坑记\n也可以考虑ubuntu出的microk8s\n","description":"","id":96,"section":"posts","tags":["Kubernetes"],"title":"Minikube本地启动","uri":"https://hex-go.github.io/posts/kubernetes/2020-04-20-minikube%E6%9C%AC%E5%9C%B0%E5%90%AF%E5%8A%A8/"},{"content":"重要 Kubernetes资料汇总\n环境说明 Reference 备注 Kubernetes-handbook(宋净超-jimmy Song)\nInstalling Kubernetes with Minikube\nminikube启动带参数--image-mirror-country=cn失败\nMinikube 安装踩坑记\n也可以考虑ubuntu出的microk8s\n","description":"","id":97,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes资料汇总","uri":"https://hex-go.github.io/posts/kubernetes/2020-03-20-kubernetes%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/"},{"content":"重要 本文概述了使用Flask和Flask-restplus创建REST API所需的步骤。这些工具组合成一个框架，Swagger被整合在Flask-restplus中。\nAPI参数校验 格式化输出（Json） 生成交互式API文档 将python异常转化为Readable http响应。 API文档可导出Swagger格式，也可以导出为Postman-collection 1.简介 Flask: 轻量级的Python Web框架。\nFlask-RestPlus 使开发REST api变得快速和简单。它提供了足够的语法糖，使您的代码易于阅读和维护。它集成Swagger UI为API生成交互式文档。\n2.环境准备 git Virtualenv 建议python3，python2也可以正常工作 3. 运行Demo应用 下载示例代码 1 2 3 cd ~/work_space/ git clone https://github.com/hex-go/restplus-api-demo.git cd restplus-api-demo 构建运行的venv环境 1 2 3 virtualenv -p `which python3` venv source venv/bin/activate (venv) $ pip install -r requirements.txt 初始化应用，并启动 1 2 (venv) $ python setup.py develop (venv) $ python rest_api_demo/app.py 访问地址http://localhost:8888/api/，可以查看API文档如下:\n4. 使用 4.1 HelloWorld举例 1 2 3 4 5 6 7 8 9 10 11 12 13 from flask import Flask from flask_restplus import Resource, Api app = Flask(__name__) # Create a Flask WSGI application api = Api(app) # Create a Flask-RESTPlus API @api.route(\u0026#39;/hello\u0026#39;) # Create a URL route to this resource class HelloWorld(Resource): # Create a RESTful resource def get(self): # Create GET endpoint return {\u0026#39;hello\u0026#39;: \u0026#39;world\u0026#39;} if __name__ == \u0026#39;__main__\u0026#39;: app.run(debug=True) # Start a development server 4.2应用目录结构规划 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ├── api # │ ├── blog # Blog-related API directory │ │ ├── business.py # │ │ ├── endpoints # API namespaces and REST methods │ │ │ ├── categories.py # │ │ │ └── posts.py # │ │ ├── parsers.py # Argument parsers │ │ └── serializers.py # Output serializers │ └── restplus.py # API bootstrap file ├── app.py # Application bootstrap file ├── database # │ └── models.py # Definition of SQLAlchemy models ├── db.sqlite # └── settings.py # Global app settings Rest API 定义放在文件rest_api_demo/api/restplus.py\nFlask app 的配置和实例化放在文件rest_api_demo/app.py\n重点注意的是app.py文件的initialize_app函数：\n1 2 3 4 5 6 7 8 9 10 def initialize_app(flask_app): configure_app(flask_app) blueprint = Blueprint(\u0026#39;api\u0026#39;, __name__, url_prefix=\u0026#39;/api\u0026#39;) api.init_app(blueprint) api.add_namespace(blog_posts_namespace) api.add_namespace(blog_categories_namespace) flask_app.register_blueprint(blueprint) db.init_app(flask_app) Blueprint 注册/apiURL前缀的路由；这样就可以通过前缀区分不同部分或不同版本的api。 add_namespace api本身也分为多个namespace， 每个ns都有自己的URL-prefix，在/api/blog/endpoints目录下配置。 4.3 定义 API api=namespace+resource+method\nrest_api_demo/api/blog/endpoints/categories.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ns = api.namespace(\u0026#39;blog/categories\u0026#39;, description=\u0026#39;Operations related to blog categories\u0026#39;) # # @ns.route(\u0026#39;/\u0026#39;) # class CategoryCollection(Resource): # # def get(self): # 1. Retrieve a list of categories \u0026#34;\u0026#34;\u0026#34;Returns list of blog categories.\u0026#34;\u0026#34;\u0026#34; # curl -X GET \u0026#39;http://localhost:8888/api/blog/categories/\u0026#39; return get_all_categories() # # @api.response(201, \u0026#39;Category successfully created.\u0026#39;) # def post(self): # 2. Create a new category \u0026#34;\u0026#34;\u0026#34;Creates a new blog category.\u0026#34;\u0026#34;\u0026#34; # POST \u0026#39;http://localhost:8888/api/blog/categories/\u0026#39; create_category(request.json) # return None, 201 # # # @ns.route(\u0026#39;/\u0026lt;int:id\u0026gt;\u0026#39;) # @api.response(404, \u0026#39;Category not found.\u0026#39;) # class CategoryItem(Resource): # # def get(self, id): # 3. Retrieve category with ID 1 \u0026#34;\u0026#34;\u0026#34;Returns details of a category.\u0026#34;\u0026#34;\u0026#34; # GET \u0026#39;http://localhost:8888/api/blog/categories/1\u0026#39; return get_category(id) # # @api.response(204, \u0026#39;Category successfully updated.\u0026#39;) # def put(self, id): # 4. Update the category with ID 1 \u0026#34;\u0026#34;\u0026#34;Updates a blog category.\u0026#34;\u0026#34;\u0026#34; # PUT \u0026#39;http://localhost:8888/api/blog/categories/1\u0026#39; update_category(id, request.json) # return None, 204 # # @api.response(204, \u0026#39;Category successfully deleted.\u0026#39;) # def delete(self, id): # 5. Delete the category with ID 1 \u0026#34;\u0026#34;\u0026#34;Deletes blog category.\u0026#34;\u0026#34;\u0026#34; # DELETE \u0026#39;http://localhost:8888/api/blog/categories/1\u0026#39; delete_category(id) # return None, 204 # api.namespace() 创建某个URL-prefix的namespace， 其中description的内容会在api文档中。 @ns.route() 将URLs与函数绑定，可以指定路径参数。比如@ns.route('/\u0026lt;int:id\u0026gt;')。string:(default),path:,int:,float:,uuid: 每个Resource 都是一个类，类包含的方法与http-method对应。包括：get, post, put, delete, patch, options, head. @api.response 声明每个方法的返回状态码+信息 上面代码生成的api文档页面如下图：\nSwagger UI文档还包括一个可以设置参数的表单。如果需要一个请求体，它的格式可以指定。 点击Try it out！按钮，将会给后端服务发请求，并显示response信息。\n4.4 参数+method校验 上面提到了在path中用\u0026lt;\u0026gt;传参，下面介绍:\nrequest请求中传参(?xx=xxx) headers中传参(\u0026ndash;heads HOST=xxx) form表单中(in request body)\n所以需要用到RequestParser对象，可以通过函数add_argument()来声明参数以及参数的类型。 4.4.1 通用配置 rest_api_demo/api/blog/parsers.py\n1 2 3 4 5 6 from flask_restplus import reqparse pagination_arguments = reqparse.RequestParser() pagination_arguments.add_argument(\u0026#39;page\u0026#39;, type=int, required=False) pagination_arguments.add_argument(\u0026#39;per_page\u0026#39;, type=int, required=False, choices=[5, 10, 20, 30, 40, 50], default=10) 然后通过装饰器@api.expect，将这个parser与方法绑定。\nrest_api_demo/api/blog/endpoints/posts.py\n1 2 3 4 5 6 @ns.route(\u0026#39;/\u0026#39;) class PostsCollection(Resource): @api.expect(pagination_arguments, validate=True) def get(self): ... 配置了参数校验后，Swagger-UI会显示一个form表单来校验参数。\n参数校验可以通过@api.expect的参数validate来启用或关闭。(分别在每个方法上做设置) 全局启用/关闭 app.config['RESTPLUS_VALIDATE'] = True。(在开发时，debug使用) 4.4.2 add_argument参数说明 type allowed value： int,str,bool.\nlocation 声明参数在哪儿, allowed value： headers, form, json\u0026hellip;\n1 2 3 parser.add_argument(\u0026#39;args1\u0026#39;, location=\u0026#39;headers\u0026#39;) parser.add_argument(\u0026#39;args2\u0026#39;, location=\u0026#39;form\u0026#39;) parser.add_argument(\u0026#39;args2\u0026#39;, location=\u0026#39;json\u0026#39;) action 多值参数 1 parser.add_argument(\u0026#39;args1\u0026#39;, type=int, action=\u0026#39;append\u0026#39;, required=True) choise 可选值 1 pagination_arguments.add_argument(\u0026#39;pages\u0026#39;, choices=[5, 10, 20, 30, 40, 50]) 4.5 json对象的值校验和说明 4.5.1 通用配置 通过api.model()列出所有期望的字段来定义对象的格式。每个字段都有一个关联的类型(e.g. String, Integer, DateTime)\nrest_api_demo/api/blog/serializers.py\n1 2 3 4 5 6 7 8 9 10 from flask_restplus import fields from rest_api_demo.api.restplus import api blog_post = api.model(\u0026#39;Blog post\u0026#39;, { \u0026#39;id\u0026#39;: fields.Integer(description=\u0026#39;The unique identifier of a blog post\u0026#39;), \u0026#39;title\u0026#39;: fields.String(required=True, description=\u0026#39;Article title\u0026#39;), \u0026#39;body\u0026#39;: fields.String(required=True, description=\u0026#39;Article content\u0026#39;), \u0026#39;status\u0026#39;: fields.String(required=True, enum=[\u0026#39;DRAFT\u0026#39;, \u0026#39;PUBLISHED\u0026#39;, \u0026#39;DELETED\u0026#39;]), \u0026#39;pub_date\u0026#39;: fields.DateTime, }) 将定义的校验model绑定给指定的Resource, 通过@api.expect(blog_post)\n1 2 3 4 5 6 7 @ns.route(\u0026#39;/\u0026#39;) class BlogPostCollection(Resource): @api.response(201, \u0026#39;Blog post successfully created.\u0026#39;) @api.expect(blog_post) def post(self): ... 4.5.2 fields参数说明 公共参数选项： required: True/False是否必填项; default: 该字段的默认值; description: 该字段说明(会在SwaggerUI中显示); example: 字段值示例(会在SwaggerUI中显示); 更具体的校验参数选项 字符串类型(包括String)： min_length 和 max_length: 字符串最大或最小长度。\npattern: 正则表达式。\n举例(字符串长度5\u0026lt;=len\u0026lt;=200, 必填, 正则: 小写字母+数字+符号\u0026rsquo;-\u0026rsquo;)：\n1 \u0026#39;slug\u0026#39;: fields.String(required=True, pattern=\u0026#39;^[a-z0-9-]+$\u0026#39;, min_length=5, max_length=200) 数字类型(包括Integer,Float,Fixed,Arbitrary)： min 和 max: 该字段最大值或最小值, 包括边界值, 即 min\u0026lt;value\u0026lt;max; exclusiveMin and exclusiveMax: 该字段最大值或最小值, 但不包过边界值, 即 exclusiveMin\u0026lt;value\u0026lt;exclusiveMax; multiple: 该字段必须是多值; 嵌套类型配置 API-model的一个字段可以使用另一个API-model作为它的期望值。然后提供一个JSON对象作为该字段的有效值。 1 \u0026#39;details\u0026#39;: fields.Nested(blog_post_details) API-model的一个字段是一个值列表，甚至是一个嵌套对象列表。 1 2 \u0026#39;item_ids\u0026#39;: fields.List(fields.Integer), \u0026#39;items\u0026#39;: fields.List(fields.Nested(blog_post)) Model继承 相似的API-model可以使用继承来扩展带有其他字段的API-model的定义。在下面的示例中，父类：通用分页API模型pagination，子类：更具体的博客文章分页page_of_blog_posts。使用api.inherit()方法继承父类。\n1 2 3 4 5 6 7 8 9 10 pagination = api.model(\u0026#39;A page of results\u0026#39;, { \u0026#39;page\u0026#39;: fields.Integer(description=\u0026#39;Number of this page of results\u0026#39;), \u0026#39;pages\u0026#39;: fields.Integer(description=\u0026#39;Total number of pages of results\u0026#39;), \u0026#39;per_page\u0026#39;: fields.Integer(description=\u0026#39;Number of items per page of results\u0026#39;), \u0026#39;total\u0026#39;: fields.Integer(description=\u0026#39;Total number of results\u0026#39;), }) page_of_blog_posts = api.inherit(\u0026#39;Page of blog posts\u0026#39;, pagination, { \u0026#39;items\u0026#39;: fields.List(fields.Nested(blog_post)) }) 4.6 处理输出json对象 可以根据上文提的 API-model定义，通过方法@api.marshal_with(model)将生成一个与model定义相同的json对象返回。值对应可以是两种方式：\n被装饰函数返回一个object，object具有跟model中字段名相同的属性; 被装饰函数返回一个dict，dict具有跟model中字段名相同的key; 例如，方法返回与API-model具有相同字段的SQLAlchemy ORM对象。\nrest_api_demo/api/blog/endpoints/categories.py\n1 2 3 4 5 6 7 8 9 10 @ns.route(\u0026#39;/\u0026lt;int:id\u0026gt;\u0026#39;) @api.response(404, \u0026#39;Category not found.\u0026#39;) class CategoryItem(Resource): @api.marshal_with(category_with_posts) def get(self, id): \u0026#34;\u0026#34;\u0026#34; Returns a category with a list of posts. \u0026#34;\u0026#34;\u0026#34; return Category.query.filter(Category.id == id).one() 如果返回值是list, 使用装饰器@api.marshal_list_with(model).\nattribute: 显式声明值来自于函数返回对象的哪个字段;\n1 \u0026#39;firstName\u0026#39;: fields.String(attribute=\u0026#39;first_name\u0026#39;), 通过attribute参数，可以提取嵌套在对象结构深处的值:\n1 \u0026#39;firstName\u0026#39;: fields.String(attribute=\u0026#39;user.first_name\u0026#39;), 更复杂的情形, 使用lambda函数提取值:\n1 \u0026#39;fullName\u0026#39;: fields.String(attribute=lambda x: \u0026#39;{} {}\u0026#39;.format(x.first_name, x.last_name)), 4.7 处理Errors 通过函数api.abort()抛出异常\n1 api.abort(code=400, message=\u0026#34;Sorry, Dave. I\u0026#39;m afraid I can\u0026#39;t do that.\u0026#34;) 如果没有显式地自己处理错误，Flask将捕获异常并将其转换为一个HTTP 500错误页面。\n通过装饰器@api.errorhandler重写默认的错误处理函数\nrest_api_demo/api/restplus.py\n1 2 3 4 @api.errorhandler(NoResultFound) def database_not_found_error_handler(e): log.warning(traceback.format_exc()) return {\u0026#39;message\u0026#39;: \u0026#39;A database result was required but none was found.\u0026#39;}, 404 Flask debug模式下，上面default_error_handler不会生效。异常只会触发Werkzeug interactive debugger页面。\n4.8 重置数据库 如果删除数据库db.sqlite文件或只是想将数据库重置为空状态，可以在Python控制台中输入以下命令。\n1 2 3 4 5 6 \u0026gt;\u0026gt;\u0026gt; from rest_api_demo.app import initialize_app, app \u0026gt;\u0026gt;\u0026gt; from rest_api_demo.database import reset_database \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; initialize_app(app) \u0026gt;\u0026gt;\u0026gt; with app.app_context(): ... reset_database() Reference Rest API Design Rulebook\nflask-restplus stable文档\napi export to Postman\napi export to PostMan\n","description":"","id":98,"section":"posts","tags":["Python","RestAPI","Flask","Swagger","Web Develop"],"title":"Python-RestAPI使用Flask、Flask-RestPlus","uri":"https://hex-go.github.io/posts/python/20200110-python-restapi%E4%BD%BF%E7%94%A8flaskswaggeruiflask-restplus/"},{"content":"重要 定义共享库 目录结构 1 2 3 4 5 6 7 8 9 10 11 12 (root) +- src # Groovy source files | +- org | +- foo | +- Bar.groovy # for org.foo.Bar class +- vars | +- foo.groovy # for global \u0026#39;foo\u0026#39; variable | +- foo.txt # help for \u0026#39;foo\u0026#39; variable +- resources # resource files (external libraries only) | +- org | +- foo | +- bar.json # static helper data for org.foo.Bar src目录: Java 源目录结构。当执行流水线时，该目录被添加到类路径下。\nvars目录: 定义Pipeline中使用的全局变量。 *.groovy文件名=variable-name, *.txt该变量说明文档，内容可以是 Markdown 等，但扩展名必须为txt)。\nresources目录: 目录允许从外部库中使用libraryResource加载有关的非 Groovy 文件\njenkins配置 全局共享库 全局可用 需要 Overall/RunScripts 权限配置这些库，权限过大，不安全。\nManage Jenkins » Configure System » Global Pipeline Libraries\nJenkinsFile引用共享库 勾选 Load implicitly, 可直接引用共享库中变量方法； 不勾选，则需要使用@Library显式引用。 1 2 3 4 5 @Library(\u0026#39;my-shared-library\u0026#39;) _ /* Using a version specifier, such as branch, tag, etc */ @Library(\u0026#39;my-shared-library@1.0\u0026#39;) _ /* Accessing multiple libraries with one statement */ @Library([\u0026#39;my-shared-library\u0026#39;, \u0026#39;otherlib@abc1234\u0026#39;]) _ 编写Pipeline-lib steps 共享库：\n1 2 3 4 5 6 7 8 // src/org/foo/Zot.groovy package org.foo; def checkOutFrom(repo) { git url: \u0026#34;git@github.com:jenkinsci/${repo}\u0026#34; } return this jenkinsFile中引用:\n1 2 def z = new org.foo.Zot() z.checkOutFrom(repo) vars 1 2 3 4 5 6 7 8 vars/log.groovy def info(message) { echo \u0026#34;INFO: ${message}\u0026#34; } def warning(message) { echo \u0026#34;WARNING: ${message}\u0026#34; } 1 2 3 4 5 Jenkinsfile @Library(\u0026#39;utils\u0026#39;) _ log.info \u0026#39;Starting\u0026#39; log.warning \u0026#39;Nothing to do!\u0026#39; Reference jenkins 共享库官方文档\n","description":"","id":99,"section":"posts","tags":["Devops","Jenkins","JenkinsFile","Pipeline"],"title":"jenkins-pipeline-lib使用","uri":"https://hex-go.github.io/posts/devops/2020-01-09-jenkins-pipeline-lib%E4%BD%BF%E7%94%A8/"},{"content":"重点 DN 是一条LDAP记录项的名字，并作为唯一标识。可以理解成uuid，具体格式像： \u0026ldquo;cn=admin,dc=service,dc=corp\u0026rdquo; 1.概念 LDAP：Lightweight Directory Access Protocol，轻量目录访问协议。 LDAP服务是一个为只读（查询、浏览、搜索）访问而优化的非关系型数据库，呈树状结构组织数据。 LDAP主要用做用户信息查询（如邮箱、电话等）或对各种服务访问做后台认证以及用户数据权限管控。 名词解释：\nDC: domain component一般为公司名，例如：dc=163,dc=com\nOU: organization unit为组织单元，最多可以有四级，每级最长32个字符，可以为中文\nCN: common name为用户名或者服务器名，最长可以到80个字符，可以为中文\nDN: distinguished name为一条LDAP记录项的名字，有唯一性，例如：dc:\u0026ldquo;cn=admin,ou=developer,dc=163,dc=com\u0026rdquo;\n图形示例:\n2.安装 2.1docker 安装 openldap官方镜像-Github ldap-account-manager Docker-hub 1 2 3 4 5 6 7 8 9 10 11 12 # 拉取镜像 docker pull osixia/openldap # 启动容器 docker run \\ -p 389:389 \\ --name openldap \\ --restart=always \\ --env LDAP_ORGANISATION=\u0026#34;sotemalltest\u0026#34; \\ --env LDAP_DOMAIN=\u0026#34;sotemalltest.com\u0026#34; \\ --env LDAP_ADMIN_PASSWORD=\u0026#34;redhat\u0026#34; \\ --detach osixia/openldap 说明：\n389端口：默认ldap服务是使用389端口 LDAP_ORGANISATION 表示ldap的机构组织 LDAP_DOMAIN 配置LDAP域 LDAP_ADMIN_PASSWORD 配置LDAP管理员(admin)的密码 默认用登陆用户名admin 如果是Windows用户，建议使用ldapadmin， 这样就省去安装管理ldap的服务，如果使用Ubuntu，建议还是装一个管理服务，毕竟Ubuntu下的管理ldap工具都太原始了，还不如命令来的好用。\n1 2 3 4 5 6 7 8 9 10 11 12 # 拉取ldap account manager镜像 docker pull ldapaccountmanager/lam # 启动容器 docker run -d \\ --restart=always \\ --name ldap-account-manager \\ -p 80:80 \\ --link openldap:ldap-host \\ --env PHPLDAPADMIN_LDAP_HOSTS=ldap-host \\ --env PHPLDAPADMIN_HTTPS=false \\ --detach ldapaccountmanager/lam 说明：\n--link这里连接到OpenLDAP容器并起了一个别名ldap-host PHPLDAPADMIN_LDAP_HOSTS这里直接通过别名指向OpenLDAP容器，这样不需要写死IP地址 PHPLDAPADMIN_HTTPS不使用443协议 --restart=always加入此参数是防止系统重启了容器未启动。(docker服务开机启动) 2.2Kubernetes 安装 获取chart:\ngithub地址: https://github.com/helm/charts.git\n文件路径: charts-stable-openldap\n1 helm install --name=openldap openldap 具体详细配置，参考该chart readme文件。\n3.使用 3.1Docker 版使用 访问ldap-account-manager,打开网页访问： http://IP\n点击上图3号位置，配置lam。如下图所示，点击Edit server profiles\n提示输入Lam密码，默认密码lam，可自行修改。登录后如下图做相应修改:\n修改一下默认的管理员帐号：\n接下来是修改默认创建的两个组，这两个会在首次登陆系统时提示创建\n保存后，登陆系统\n提示创建默认的组:\nlam详细使用 参考博客ldap account manager 使用\nReference 运维吧-ldap1-openldap部署及管理维护\n运维吧-ldap2-SVN集成openldap\n运维吧-ldap3-GitLab集成OpenLDAP认证\n运维吧-ldap4-Jenkins集成OpenLDAP认证\nldap-jenkins\nldap-grafana\nlam 使用说明\n","description":"","id":100,"section":"posts","tags":["Devops","LDAP","Deployment"],"title":"LDAP部署手册","uri":"https://hex-go.github.io/posts/devops/2020-01-08-ldap%E9%83%A8%E7%BD%B2%E6%89%8B%E5%86%8C/"},{"content":"运行环境\npython环境: python3.7\n安装包\n1 pip install ldap3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 #!/usr/bin/python # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; @Time : 2019/11/14 5:37 PM @Author : Hex @File : ldapBaseApi.py @Software: PyCharm # ApiDocument: https://ldap3.readthedocs.io/ # https://ldap3.readthedocs.io/tutorial_operations.html# \u0026#34;\u0026#34;\u0026#34; # import sys # reload(sys) # sys.setdefaultencoding(\u0026#39;utf8\u0026#39;) from ldap3 import Server, Connection, SUBTREE, ALL_ATTRIBUTES from ldap3.core.exceptions import LDAPBindError from ldap3 import MODIFY_REPLACE from ldap3.utils.dn import safe_rdn from rest_framework.exceptions import APIException class LDAP(object): def __init__(self, host, port, user, password, base_dn): dn = \u0026#34;cn=%s,%s\u0026#34; % (user, base_dn) self.server = Server(host=host, port=port) self.base_dn = base_dn self.__conn = Connection(self.server, dn, password, auto_bind=True) def add_ou(self, ou, oid): \u0026#34;\u0026#34;\u0026#34; 参考: https://ldap3.readthedocs.io/tutorial_operations.html#create-an-entry 添加oy :param ou: \u0026#39;ou=测试部,dc=domain,dc=com\u0026#39; 或者 \u0026#39;ou=测试子部门,ou=测试部,dc=domain,dc=com\u0026#39; :param oid: 部门id保存至st中 :return: \u0026#34;\u0026#34;\u0026#34; return self.__conn.add(ou, \u0026#39;organizationalUnit\u0026#39;, {\u0026#34;st\u0026#34;: oid}) def add_user(self, userid, username, mobile, mail, title, ou_dn, gidnumber=501, alias=None): \u0026#34;\u0026#34;\u0026#34; 参考: https://ldap3.readthedocs.io/tutorial_operations.html#create-an-entry :param userid: \u0026#34;linan\u0026#34; :param username: \u0026#34;姓名\u0026#34; cn=姓名 :param mobile: :param mail: \u0026#34;xxx@domain.com\u0026#34; :param title: :param ou_dn: \u0026#34;ou=运维中心,dc=domain,dc=com\u0026#34; :param gidnumber: 501 默认用户组 :return: \u0026#34;\u0026#34;\u0026#34; l = self.__conn objectclass = [\u0026#39;top\u0026#39;, \u0026#39;person\u0026#39;, \u0026#39;inetOrgPerson\u0026#39;, \u0026#39;posixAccount\u0026#39;] add_dn = \u0026#34;cn=%s,%s\u0026#34; % (username, ou_dn) # 也可以随机生成,我先随便写一个值，这个需要自己定义规则 password = \u0026#39;%s@qwe\u0026#39; % userid uidNumber = \u0026#39;%s\u0026#39; % userid.strip(\u0026#34;xxx\u0026#34;) # 添加用户 s = l.add(add_dn, objectclass, {\u0026#39;mobile\u0026#39;: mobile, \u0026#39;sn\u0026#39;: userid, \u0026#39;mail\u0026#39;: mail, \u0026#39;userPassword\u0026#39;: password, \u0026#39;title\u0026#39;: title, \u0026#39;uid\u0026#39;: username, \u0026#39;gidNumber\u0026#39;: gidnumber, \u0026#39;uidNumber\u0026#39;: uidNumber, \u0026#39;homeDirectory\u0026#39;: \u0026#39;/home/users/%s\u0026#39; % userid, \u0026#39;loginShell\u0026#39;: \u0026#39;/bin/bash\u0026#39; }) return s def get_oudn_by_st(self, st, base_dn=None): \u0026#34;\u0026#34;\u0026#34; 根据 st值 获取组织dn 参考: https://ldap3.readthedocs.io/tutorial_searches.html :param base_dn: :param st: 部门id :return: entry \u0026#34;\u0026#34;\u0026#34; if not base_dn: base_dn = self.base_dn # 查询ou 中 返回的信息 attribute 包含 st status = self.__conn.search(base_dn, \u0026#39;(objectclass=organizationalUnit)\u0026#39;, attributes=[\u0026#34;st\u0026#34;]) if status: flag = False for i in self.__conn.entries: if st: if st in i.entry_attributes_as_dict[\u0026#34;st\u0026#34;]: return i else: return False else: return False def get_object_classes_info(self, objec_classes): \u0026#34;\u0026#34;\u0026#34; 获取 Ldap中 object_classes的必要参数以及其他信息 参考: https://ldap3.readthedocs.io/tutorial_searches.html :param objec_classes: objec_classes :return: \u0026#34;\u0026#34;\u0026#34; print(self.server.schema.object_classes[objec_classes]) def get_userdn_by_mail(self, mail, base_dn=None): \u0026#34;\u0026#34;\u0026#34; 通过邮箱地址，获取用户dn。部分没有邮箱地址的用户被忽略，不能使用ldap认证 参考: https://ldap3.readthedocs.io/tutorial_searches.html :param mail: :param base_dn: :return: \u0026#34;\u0026#34;\u0026#34; if not base_dn: base_dn = self.base_dn status = self.__conn.search(base_dn, search_filter=\u0026#39;(mail={})\u0026#39;.format(mail), search_scope=SUBTREE, attributes=ALL_ATTRIBUTES, ) if status: flag = False for i in self.__conn.entries: # print(i.entry_dn) return i else: return False else: return False def get_userdn_by_args(self, base_dn=None, **kwargs): \u0026#34;\u0026#34;\u0026#34; 参考: https://ldap3.readthedocs.io/tutorial_searches.html 获取用户dn, 通过 args 可以支持多个参数: get_userdn_by_args(mail=\u0026#34;xxx@domain.com\u0026#34;, uid=\u0026#34;姓名\u0026#34;) 会根据 kwargs 生成 search的内容，进行查询: 多个条件是 \u0026amp; and查询 返回第一个查询到的结果, 建议使用唯一标识符进行查询 这个函数基本可以获取所有类型的数据 :param base_dn: :param kwargs: :return: \u0026#34;\u0026#34;\u0026#34; search = \u0026#34;\u0026#34; for k, v in kwargs.items(): search += \u0026#34;(%s=%s)\u0026#34; % (k, v) if not base_dn: base_dn = self.base_dn if search: search_filter = \u0026#39;(\u0026amp;{})\u0026#39;.format(search) else: search_filter = \u0026#39;\u0026#39; status = self.__conn.search(base_dn, search_filter=search_filter, search_scope=SUBTREE, attributes=ALL_ATTRIBUTES ) if status: return self.__conn.entries else: return False def authenticate_userdn_by_mail(self, mail, password): \u0026#34;\u0026#34;\u0026#34; 验证用户名密码 通过邮箱进行验证密码 :param mail: :param password: :return: \u0026#34;\u0026#34;\u0026#34; entry = self.get_userdn_by_mail(mail=mail) if entry: bind_dn = entry.entry_dn try: Connection(self.server, bind_dn, password, auto_bind=True) return True except LDAPBindError: return False else: print(\u0026#34;user: %s not exist! \u0026#34; % mail) return False def update_user_info(self, user_dn, action=MODIFY_REPLACE, **kwargs): \u0026#34;\u0026#34;\u0026#34; :param dn: 用户dn 可以通过get_userdn_by_args，get_userdn_by_mail 获取 :param action: MODIFY_REPLACE 对字段原值进行替换 MODIFY_ADD 在指定字段上增加值 MODIFY_DELETE 对指定字段的值进行删除 :param kwargs: 要进行变更的信息内容 uid userPassword mail sn gidNumber uidNumber mobile title :return: \u0026#34;\u0026#34;\u0026#34; allow_key = \u0026#34;uid userPassword mail sn gidNumber uidNumber mobile title\u0026#34;.split(\u0026#34; \u0026#34;) update_args = {} for k, v in kwargs.items(): if k not in allow_key: msg = \u0026#34;字段: %s, 不允许进行修改, 不生效\u0026#34; % k print(msg) return False update_args.update({k: [(action, [v])]}) print(update_args) status = self.__conn.modify(user_dn, update_args) return status def update_user_cn(self, user_dn, new_cn): \u0026#34;\u0026#34;\u0026#34; 修改cn dn: cn=用户,ou=运维部,ou=研发中心,dc=domain,dc=com rdn就是 cn=用户 Example: from ldap3.utils.dn import safe_rdn safe_rdn(\u0026#39;cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org\u0026#39;) [cn=b.smith] :param dn: :param new_cn: :return: \u0026#34;\u0026#34;\u0026#34; s = self.__conn.modify_dn(user_dn, \u0026#39;cn=%s\u0026#39; % new_cn) return s def update_ou(self, dn, new_ou_dn): \u0026#34;\u0026#34;\u0026#34; 更换所在的OU :param dn: 要进行变动的DN :param new_ou_dn: 新的OU DN :return: \u0026#34;\u0026#34;\u0026#34; rdn = safe_rdn(dn) print(rdn) s = self.__conn.modify_dn(dn, rdn[0], new_superior=new_ou_dn) return s def delete_dn(self, dn): \u0026#34;\u0026#34;\u0026#34; 要进行删除的DN :param dn: :return: \u0026#34;\u0026#34;\u0026#34; # 如果不是以cn开头的需要清理(删除) sub-link if not dn.startswith(\u0026#34;cn\u0026#34;): # 获取dn 下所有 sub Person DN 进行删除 allUserEntry = self.get_userdn_by_args(base_dn=dn, objectClass=\u0026#34;Person\u0026#34;) if allUserEntry: for userentry in allUserEntry: self.__conn.delete(userentry.entry_dn) print(\u0026#34;deleting ou %s and delete sub Person DN: %s\u0026#34; % (dn, userentry.entry_dn)) # 获取dn 下所有 sub OU进行删除 allOuEntry = self.get_userdn_by_args(base_dn=dn, objectClass=\u0026#34;organizationalUnit\u0026#34;) if allOuEntry: for ouEntry in reversed(allOuEntry): s = self.__conn.delete(ouEntry.entry_dn) print(\u0026#34;deleting ou %s and delete sub organizationalUnit DN: %s\u0026#34; % (dn, ouEntry.entry_dn)) else: s = self.__conn.delete(dn) # print(self.__conn.result) return s if __name__ == \u0026#39;__main__\u0026#39;: ldap_config = { \u0026#39;host\u0026#39;: \u0026#34;10.12.0.23\u0026#34;, \u0026#39;port\u0026#39;: 32616, \u0026#39;base_dn\u0026#39;: \u0026#39;dc=service,dc=corp\u0026#39;, \u0026#39;user\u0026#39;: \u0026#39;admin\u0026#39;, \u0026#39;password\u0026#39;: \u0026#39;xxxxxx\u0026#39;, } ldapObj = LDAP(**ldap_config) # 同步企业微信 组织架构 to Ldap # 同步企业微信 User To ldap # ------------------------------- # 删除DN, 对DN下的 sub 进行递归删除 # s = ldapObj.get_oudn_by_st(\u0026#34;1\u0026#34;) # status = ldapObj.delete_dn(s.entry_dn) # print(status) # ------------------------------- # 验证用户密码 # s = ldapObj.authenticate_userdn_by_mail(\u0026#34;linan@domain.com\u0026#34;, \u0026#34;xxx9999@qwe\u0026#34;) # - ----------------------------- # 添加用户 # s = ldapObj.add_user(\u0026#34;xxx9999\u0026#34;, \u0026#34;李南\u0026#34;, \u0026#34;190283812\u0026#34;, \u0026#34;linan@domain.com\u0026#34;, \u0026#34;运维\u0026#34;, # ou_dn=\u0026#34;ou=运维中心,dc=domain,dc=com\u0026#34;) # -------------------------------- # 查询 ou st 组id # s = obj.get_oudn_by_st(st=\u0026#34;1\u0026#34;) # -------------------------------- # 添加OU # obj.add_ou(\u0026#34;ou=总部,dc=domain,dc=com\u0026#34;, 1) # obj.add_ou(\u0026#34;ou=研发中心,ou=总部,dc=domain,dc=com\u0026#34;, 2) # -------------------------------- # 查询用户是否存在 - 通过 mail 获取用户 dn_entry # ldapObj.get_userdn_by_mail(mail=\u0026#34;linan@domain.com\u0026#34;) # -------------------------------- # 根据 参数 查询用户DN data = [dn_entry, ...] ，多个参数为 \u0026amp; # data = ldapObj.get_userdn_by_args(cn=\u0026#34;李南\u0026#34;,mail=\u0026#34;xxxx\u0026#34;) # -------------------------------- # 对指定dn 进行参数修改 多个参数可以一起修改 # s = ldapObj.update_user_info(data[0].entry_dn, userPassword=\u0026#34;123456\u0026#34;) # -------------------------------- # 对指定DN 变更 OU-DN # s = ldapObj.update_user_ou(data[0].entry_dn, s.entry_dn) # -------------------------------- # 对指定DN 修改CN名称 # ldapObj.update_cn(data[0].entry_dn,new_cn=\u0026#34;李南男\u0026#34;) # -------------------------------- # 获取objectClass 详细信息 # ldapObj.get_object_classes_info(\u0026#34;organizationalUnit\u0026#34;) # ldapObj.get_object_classes_info(\u0026#34;posixAccount\u0026#34;) # ldapObj.get_object_classes_info(\u0026#34;inetOrgPerson\u0026#34;) # ldapObj.get_object_classes_info(\u0026#34;person\u0026#34;) # 没有邮箱地址的用户: s = ldapObj.get_userdn_by_args(ou=\u0026#34;Product\u0026#34;) data = ldapObj.get_userdn_by_args(base_dn=s[0].entry_dn, objectclass=\u0026#34;inetOrgPerson\u0026#34;) for i in data: print(i.entry_dn) print(s) ","description":"","id":101,"section":"posts","tags":["Python","LDAP"],"title":"LDAP-Python 操作库","uri":"https://hex-go.github.io/posts/python/20200108-ldap-python%E6%93%8D%E4%BD%9C%E5%BA%93/"},{"content":"重点 如果使用multi-pipeline， 则在---之后不能跟注释。而且multi-pipeline之间的无法共通数据，每个新的pipeline就是一个完全新的环境。 能在DockerFile中处理的，就不要放在drone中处理。 同一Pipeline不同step可以相互引用生成的文件，不同Pipeline完全独立。都是重新的目录，新的clone文件。 Drone Pipeline的构建命令都是在一个容器中去执行的，比如要使用Helm来部署应用，就需要容器有helm，并能够目标Kubernetes集群联通。一种方式：可以自己做一个镜像，把 helm 命令和连接集群的配置文件都内置到里面去，但这样不是很灵活，不具有通用性。另一种方法： Drone 的插件机制，使用插件配置。 示例 go项目 项目 go代码： 下面是用go-web框架gin创建一个简单的 web 服务，在 GitHub 上创建一个名为 drone-demo 的代码仓库，Clone 到本地，添加名为 main.go 的文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/sirupsen/logrus\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/health\u0026#34;, func(c *gin.Context) { c.JSON(http.StatusOK, gin.H { \u0026#34;health\u0026#34;: true, }) }) if err := r.Run(\u0026#34;:8080\u0026#34;); err != nil { logrus.WithError(err).Fatal(\u0026#34;Couldn\u0026#39;t listen\u0026#34;) } } 服务监听在 8080 端口，提供了一个简单的/health路由，返回一个简单的 JSON 消息表示应用状态状态，本地我们使用的是 go1.11.4 版本，所以可以通过 Go Modules 来管理应用的依赖，在项目目录下面执行 mod init：\n1 go mod init dronek8s 项目DockerFile： 生产环境，建议在DockerFile中多阶段构建来将项目的构建和打包工作放在同一个 Dockerfile， 此处为了研究Drone的Pipeline使用，将两步分开。\n在项目根目录下面创建 Dockerfile 文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 FROM alpine WORKDIR /home # 修改alpine源为阿里云 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g\u0026#39; /etc/apk/repositories \u0026amp;\u0026amp; \\ apk update \u0026amp;\u0026amp; \\ apk upgrade \u0026amp;\u0026amp; \\ apk add ca-certificates \u0026amp;\u0026amp; update-ca-certificates \u0026amp;\u0026amp; \\ apk add --update tzdata \u0026amp;\u0026amp; \\ rm -rf /var/cache/apk/* COPY demo-app /home/ ENV TZ=Asia/Shanghai EXPOSE 8080 ENTRYPOINT ./demo-app 构建结果文件demo-app拷贝到镜像中去执行来构建镜像，手动构建生成该文件命令是在根目录下面执行 go build 命令：\n1 2 3 4 5 # build CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o demo-app # docker image docker build -t hex/drone-demo . 项目 .drone.yml 项目根目录下创建一个名为.drone.yml文件，文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 kind: pipeline name: default steps: - name: linter image: golang:latest environment: GOPROXY: https://mirrors.aliyun.com/goproxy/ commands: - go get -u github.com/golangci/golangci-lint/cmd/golangci-lint - golangci-lint run - name: build image: golang:latest environment: GOPROXY: https://mirrors.aliyun.com/goproxy/ commands: - CGO_ENABLED=0 go build -o demo-app - name: docker image: plugins/docker settings: repo: hex/drone-demo use_cache: true username: from_secret: docker_username password: from_secret: docker_password tags: - latest when: event: push branch: master - name: deploy image: quay.io/ipedrazas/drone-helm environment: STABLE_REPO_URL: https://mirror.azure.cn/kubernetes/charts/ SERVICE_ACCOUNT: tiller API_SERVER: from_secret: api_server KUBERNETES_TOKEN: from_secret: kubernetes_token KUBERNETES_CERTIFICATE: from_secret: kubernetes_ca settings: client-only: true wait: true recreate_pods: true chart: ./helm release: drk8d values_files: [\u0026#34;./helm/my-values.yaml\u0026#34;] namespace: kube-ops 说明:\nlinter: 在golang:latest镜像中执行任务commands中的命令 build: 在golang:latest镜像中执行任务commands中的命令 docker: 使用官方插件plugins/docker，该镜像可以指定Dockerfile 的路径，镜像的tag，以及镜像仓库的用户名和密码。\n此处用户名密码通过secret的方式传入。该secret可以通过drone-cli创建，也可以Drone网页配置。 deploy: 使用官方插件drone-helm\nDrone 的插件页面找到和 Helm 相关的插件：http://plugins.drone.io/ipedrazas/drone-helm/，这个插件的基本用法如下: 1 2 3 4 5 6 7 8 9 pipeline: helm_deploy: image: quay.io/ipedrazas/drone-helm skip_tls_verify: true chart: ./charts/my-chart release: ${DRONE_BRANCH} values: secret.password=${SECRET_PASSWORD},image.tag=${TAG} prefix: STAGING namespace: development 上面Pipeline相当于：\n1 helm upgrade --install ${DRONE_BRANCH} ./charts/my-chart --namespace development --set secret.password=${SECRET_PASSWORD},image.tag=${TAG} helm连接Kubernetes集群可以通过API_SERVER、KUBERNETES_TOKEN、KUBERNETES_CERTIFICATE 三个环境变量来指定。\nAPI_SERVER就是集群的APIServer服务地址；KUBERNETES_TOKEN获取通过创建一个 ServiceAccount，去绑定一个的集群角色权限(比如cluster-admin)，然后获取ServiceAccount 对应的TOKEN。比如我们 Helm 的服务端 Tiller 服务对应的 ServiceAccount，我们可以这样来获取：\n1 2 3 4 $ kubectl -n kube-system get secrets | grep tiller tiller-token-z4f6k kubernetes.io/service-account-token 3 115d $ kubectl get secret tiller-token-z4f6k -o jsonpath={.data.token} -n kube-system | base64 --decode eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.xxxxx.jO7vEZCzLbtBg 证书信息同样可以通过上面的 secret 来获取：\n1 kubectl get secret tiller-token-z4f6k -o jsonpath={.data.ca\\\\.crt} -n kube-system 注意： 证书信息不需要用 base64 解码。\nnode项目 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 workspace: base: /data/apps/opt path: web-im pipeline: restore-cache: image: drillster/drone-volume-cache restore: true mount: - node_modules - tag volumes: - /data/apps/opt/web-im:/cache build: image: node:7.8 privileged: true commands: - npm run build - mkdir -p publish/demo/javascript - cp -r demo/images publish/demo - cp -r demo/stylesheet publish/demo - cp -r demo/javascript/dist publish/demo/javascript/ - cp -r demo/javascript/src publish/demo/javascript/ - mkdir publish/sdk - cp -r sdk/dist publish/sdk - cp -r sdk/src publish/sdk - cp sdk/*.* publish/sdk - cp -r webrtc publish - cp favicon.ico publish/ - cp index.html publish/ - cp CHANGELOG.md publish/ - cp package.json publish/ - cp webpack.config.js publish/ - cp README.md publish/ - cp .babelrc publish/ - cp -rf publish image/docker/webim/webim - echo \u0026#39;build success\u0026#39; when: branch: [ dev, online ] dockerize-latest: image: plugins/docker environment: - DOCKER_LAUNCH_DEBUG=true debug: true repo: docker-registry-cn.easemob.com/kubernetes/im/webim tags: latest registry: docker-registry-cn.easemob.com secrets: [ docker_username, docker_password ] dockerfile: image/docker/webim/Dockerfile context: image/docker/webim/ when: branch: dev deploy-latest: image: docker-registry-cn.easemob.com/kubernetes/im/webim-deploy:latest pull: true environment: - DOCKER_LAUNCH_DEBUG=true - TAG=latest secrets: [ ssh_key, jumpserver_host, jumpserver_port, sandbox_host ] debug: true when: branch: dev dockerize-online: image: plugins/docker environment: - DOCKER_LAUNCH_DEBUG=true debug: true repo: docker-registry-cn.easemob.com/kubernetes/im/webim tags: ${DRONE_COMMIT:0:7} registry: docker-registry-cn.easemob.com secrets: [ docker_username, docker_password ] dockerfile: image/docker/webim/Dockerfile context: image/docker/webim/ when: branch: online deploy-online: image: docker-registry-cn.easemob.com/kubernetes/im/webim-online:latest pull: true environment: - DOCKER_LAUNCH_DEBUG=true - TAG=${DRONE_COMMIT:0:7} secrets: [ ssh_key, jumpserver_host, jumpserver_port, online_host ] debug: true when: branch: online rollback-online: image: docker-registry-cn.easemob.com/kubernetes/im/webim-rollback:latest pull: true environment: - DOCKER_LAUNCH_DEBUG=true secrets: [ ssh_key, jumpserver_host, jumpserver_port, online_host ] debug: true when: branch: rollback rebuild-cache: image: drillster/drone-volume-cache rebuild: true mount: - node_modules - tag volumes: - /data/apps/opt/web-im:/cache notify: image: drillster/drone-email port: 25 secrets: [ plugin_host, plugin_from, plugin_username, plugin_password ] when: status: [ failure, success ] Reference ","description":"","id":102,"section":"posts","tags":["Devops","Drone","Pipeline","Dockerfile"],"title":"Drone-Pipeline使用举例","uri":"https://hex-go.github.io/posts/devops/2020-01-07-drone-pipeline%E4%BD%BF%E7%94%A8%E4%B8%BE%E4%BE%8B/"},{"content":"重点 能在DockerFile中做的，比如多阶段构建，就在Dockerfile中做。不能在Jenkinsfile中做太多特例化的事情，否则不好管理迁移。 如果有时间，可以做一个简单的ui来配置生成Jenkinsfile，这样就可以省去开发人员学习JenkinsFile的成本。也可以增加限制，把控标准。 JenkinsFile 文档目录 拉代码 代码构建 构建+推送镜像 推送初始化脚本 推送chart 1 拉取代码 1 2 3 stage(\u0026#39;Check out\u0026#39;) { checkout scm } 1.1 镜像版本控制 \u0026ndash; {ver} master \u0026ndash;\u0026gt; latest\nrelease \u0026ndash;\u0026gt; stable\nTAG \u0026ndash;\u0026gt; 保持不变\n1 2 3 4 5 6 name_list = \u0026#34;$JOB_NAME\u0026#34;.split(\u0026#39;/\u0026#39;) def ver = name_list[1] def ver_map = [\u0026#34;master\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;release\u0026#34;: \u0026#34;stable\u0026#34;] if(ver_map.containsKey(ver)){ ver = ver_map.get(ver) } 1.2 镜像版本控制 \u0026ndash; {ver} 举例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 jenkins配置的job名为 \u0026#39;paas-devops-ui\u0026#39; 选择 master 分支构建 $JOB_NAME : paas-devops-ui/master name_list : [\u0026#39;paas-devops-ui\u0026#39;, \u0026#39;master\u0026#39;] ver : \u0026#39;master\u0026#39; job : \u0026#39;paas-devops-ui\u0026#39; job_list : [\u0026#39;paas\u0026#39;, \u0026#39;devops\u0026#39;, \u0026#39;ui\u0026#39;] project : paas job_size : 2 img_list : [\u0026#39;devops\u0026#39;, \u0026#39;ui\u0026#39;] img : devops-ui ver : \u0026#39;latest\u0026#39; (重赋值) tag : \u0026#34;reg.service.com/paas/devops-ui:latest\u0026#34; script_dir : paas/devops-ui/latest slug_dir : /tmp/paas/devops-ui/latest slug_file : /tmp/paas/devops-ui/latest/slug.tgz 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 name_list = \u0026#34;$JOB_NAME\u0026#34;.split(\u0026#39;/\u0026#39;) def ver = name_list[1] def job = name_list[0] job_list = \u0026#34;$job\u0026#34;.split(\u0026#39;-\u0026#39;) def project = job_list[0] job_size = job_list.size()-1 img_list = [] for(x in (1..job_size)){ img_list.add(job_list[x]) } def img = img_list.join(\u0026#39;-\u0026#39;) def ver_map = [\u0026#34;master\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;release\u0026#34;: \u0026#34;stable\u0026#34;] if(ver_map.containsKey(ver)){ ver = ver_map.get(ver) } def tag = \u0026#34;reg.service.com/\u0026#39;${ project }\u0026#39;/\u0026#39;${ img }\u0026#39;:\u0026#39;${ ver }\u0026#39;\u0026#34; // def tag = \u0026#34;reg.service.com\u0026#34;+\u0026#34;/\u0026#34;+project+\u0026#39;/\u0026#39;+img+\u0026#39;:\u0026#39;+ver def script_dir= project+\u0026#39;/\u0026#39;+img+\u0026#39;/\u0026#39;+ver def slug_dir = \u0026#34;/tmp/\u0026#39;${script_dir}\u0026#39;\u0026#34; def slug_file = \u0026#34;\u0026#39;${slug_dir}\u0026#39;/slug.tgz\u0026#34; 2. 代码构建 2.1 mvn项目构建 1 2 3 4 5 6 7 def mvnHome = tool \u0026#39;maven_3_5_4\u0026#39; stage(\u0026#39;Build\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn clean package -DskipTests=true\u0026#34; } } 2.2 Node项目构建 1 2 3 4 5 6 7 8 9 10 11 12 13 def nodeHome = tool \u0026#39;NodeJS_8.12\u0026#39; stage(\u0026#39;Build\u0026#39;) { withEnv([\u0026#34;PATH+NODE=${ nodeHome }/bin\u0026#34;]) { dir(\u0026#39;devops_ui\u0026#39;){ sh \u0026#39;npm install\u0026#39; sh \u0026#34;${ng_cmd}\u0026#34; } dir(\u0026#39;devops_ui/devops\u0026#39;){ sh \u0026#39;npm install\u0026#39; } } } 3. Build+Push 镜像 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def script_dir= project+\u0026#39;/\u0026#39;+img+\u0026#39;/\u0026#39;+ver def slug_dir = \u0026#34;/tmp/\u0026#39;${script_dir}\u0026#39;\u0026#34; def slug_file = \u0026#34;\u0026#39;${slug_dir}\u0026#39;/slug.tgz\u0026#34; stage(\u0026#39;Docker build\u0026#39;) { // 创建存放代码slug包的目录 sh(\u0026#34;mkdir -p \u0026#39;${ slug_dir }\u0026#39;\u0026#34;) // 在DevopsUI目录，将当前文件夹除去.git src 的所有内容打成 slug.tgz包 // 目录结构为： /tmp/{project}/{img}/{ver}/slug.tgz dir(\u0026#39;devops_ui\u0026#39;){ sh(\u0026#34;tar -z --exclude=\u0026#39;.git\u0026#39; --exclude=\u0026#39;src\u0026#39; -cf \u0026#39;${slug_file}\u0026#39; .\u0026#34;) } // 将/tmp/{project}/{img}/{ver}/slug.tgz 拷贝到 Dockerfile 同级 sh(\u0026#34;cp ${slug_file} .\u0026#34;) // docker构建 sh(\u0026#34;docker build -t ${tag} .\u0026#34;) // 推送镜像 sh(\u0026#34;docker push ${tag}\u0026#34;) } 4. 推送初始化脚本 项目根目录下如果没有/deploy/install.sh, 那么说明该项目不需要初始化脚本，跳过。\n1 2 3 4 5 6 7 8 9 stage(\u0026#39;Send script\u0026#39;) { def exists = fileExists \u0026#39;./deploy/install.sh\u0026#39; if (exists) { sh(\u0026#34;tar -zcvf deploy.tgz deploy/\u0026#34;) sh(\u0026#34;curl -v -u username:password -X POST \u0026#39;http://nexus.service.com/service/rest/v1/components?repository=paasinstall\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: multipart/form-data\u0026#39; -F \u0026#39;raw.directory=${script_dir}\u0026#39; -F \u0026#39;raw.asset1=@deploy.tgz;type=application/x-compressed-tar\u0026#39; -F \u0026#39;raw.asset1.filename=deploy.tgz\u0026#39;\u0026#34;) } else { println \u0026#34;File doesn\u0026#39;t exist\u0026#34; } } 5. 推送chart 1 2 3 4 5 6 7 stage(\u0026#39;Send Helm\u0026#39;) { def gitUrl = \u0026#39;https://git.service.com/plugins/git/paas/charts.git\u0026#39; def gitCredentialsId = \u0026#39;4116a55e-8551-46b7-b864-xxxxxxxxxxxx\u0026#39; git credentialsId: \u0026#34;${ gitCredentialsId }\u0026#34;, url: \u0026#34;${ gitUrl }\u0026#34; helm package \u0026#39;\u0026#39; curl -X POST \u0026#34;http://dop.service.com/service/rest/v1/components?repository=market\u0026#34; -H \u0026#34;accept: application/json\u0026#34; -H \u0026#34;Content-Type: multipart/form-data\u0026#34; -F \u0026#34;helm.asset=@monitor-1.2.1.tgz;type=application/x-compressed-tar\u0026#34; } 6. 清理环境 1 2 3 4 5 6 7 8 9 stage(\u0026#39;Cleanup\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn -Dmaven.test.failure.ignore clean\u0026#34; } sh(\u0026#34;docker rmi ${tag}\u0026#34;) sh(\u0026#34;rm -f ${slug_file}\u0026#34;) sh \u0026#34;rm -rf *\u0026#34; sh \u0026#34;rm -rf .git\u0026#34; } 项目个性化需求 前端命令 如果job名末尾为-onlyapi ng命令为 ng build -c=onlyApi\n否则 ng命令为 ng build --prod\n1 2 3 4 5 6 7 8 9 10 11 12 13 def nodeHome = tool \u0026#39;NodeJS_8.12\u0026#39; def label = \u0026#34;$project\u0026#34;.split(\u0026#39;-\u0026#39;)[-1] def ng_cmd = \u0026#34;ng build --prod\u0026#34; def ng_map = [\u0026#34;onlyapi\u0026#34;: \u0026#34;ng build -c=onlyApi\u0026#34;] if(ng_map.containsKey(label)){ ng_cmd = ng_map.get(label) } withEnv([\u0026#34;PATH+NODE=${ nodeHome }/bin\u0026#34;]) { sh \u0026#39;npm install\u0026#39; sh \u0026#34;${ng_cmd}\u0026#34; } 在某个目录下执行命令 1 2 3 4 //例 在 **.git/devops_ui 目录下 执行编译命令 dir(\u0026#39;devops_ui/devops\u0026#39;){ sh \u0026#39;npm install\u0026#39; } 完整示例 node 项目 jenkinsFile:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 node { currentBuild.result = \u0026#34;SUCCESS\u0026#34; def ng_cmd = \u0026#34;ng build --prod\u0026#34; def nodeHome = tool \u0026#39;NodeJS_8.12\u0026#39; def ng_map = [\u0026#34;onlyapi\u0026#34;: \u0026#34;ng build -c=onlyApi\u0026#34;] if(ng_map.containsKey(label)){ ng_cmd = ng_map.get(label) } name_list = \u0026#34;$JOB_NAME\u0026#34;.split(\u0026#39;/\u0026#39;) //eg : \u0026#39;devops-api/master\u0026#39; --\u0026gt; [\u0026#39;devops-api\u0026#39;, \u0026#39;master\u0026#39;] def ver = name_list[1] //eg : \u0026#39;master\u0026#39; def job = name_list[0] //eg : \u0026#39;devops-api\u0026#39; job_list = \u0026#34;$job\u0026#34;.split(\u0026#39;-\u0026#39;) //eg : \u0026#39;devops-api\u0026#39; --\u0026gt; [\u0026#39;devops\u0026#39;, \u0026#39;api\u0026#39;] def project = job_list[0] //eg : \u0026#39;devops\u0026#39; job_size = job_list.size()-1 img_list = [] for(x in (1..job_size)){ img_list.add(job_list[x]) } def img = img_list.join(\u0026#39;-\u0026#39;) def ver_map = [\u0026#34;master\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;release\u0026#34;: \u0026#34;stable\u0026#34;] if(ver_map.containsKey(ver)){ ver = ver_map.get(ver) } def tag = \u0026#34;reg.service.com/\u0026#39;${ project }\u0026#39;/\u0026#39;${ img }\u0026#39;:\u0026#39;${ ver }\u0026#39;\u0026#34; // def tag = \u0026#34;reg.service.com\u0026#34;+\u0026#34;/\u0026#34;+project+\u0026#39;/\u0026#39;+img+\u0026#39;:\u0026#39;+ver def script_dir= project+\u0026#39;/\u0026#39;+img+\u0026#39;/\u0026#39;+ver def slug_dir = \u0026#34;/tmp/\u0026#39;${script_dir}\u0026#39;\u0026#34; def slug_file = \u0026#34;\u0026#39;${slug_dir}\u0026#39;/slug.tgz\u0026#34; try { stage(\u0026#39;Check out\u0026#39;) { checkout scm } stage(\u0026#39;Cleanup-before\u0026#39;) { withEnv([\u0026#34;PATH+NODE=${ nodeHome }/bin\u0026#34;]) { // sh \u0026#39;npm prune\u0026#39; sh \u0026#34;rm -rf devops_ui/node_modules\u0026#34; sh \u0026#34;rm -rf devops_ui/package-lock.json\u0026#34; sh \u0026#34;rm -rf devops_ui/devops/node_modules\u0026#34; sh \u0026#34;rm -rf devops_ui/devops/package-lock.json\u0026#34; } } stage(\u0026#39;Build\u0026#39;) { withEnv([\u0026#34;PATH+NODE=${ nodeHome }/bin\u0026#34;]) { dir(\u0026#39;devops_ui\u0026#39;){ sh \u0026#39;npm install\u0026#39; sh \u0026#34;${ng_cmd}\u0026#34; } dir(\u0026#39;devops_ui/devops\u0026#39;){ sh \u0026#39;npm install\u0026#39; } } } stage(\u0026#39;Docker build\u0026#39;) { sh(\u0026#34;mkdir -p \u0026#39;${ slug_dir }\u0026#39;\u0026#34;) dir(\u0026#39;devops_ui\u0026#39;){ sh(\u0026#34;tar -z --exclude=\u0026#39;.git\u0026#39; --exclude=\u0026#39;src\u0026#39; -cf \u0026#39;${slug_file}\u0026#39; .\u0026#34;) } sh(\u0026#34;cp ${slug_file} .\u0026#34;) sh(\u0026#34;docker build -t ${tag} .\u0026#34;) sh(\u0026#34;docker push ${tag}\u0026#34;) } stage(\u0026#39;Send script\u0026#39;) { def exists = fileExists \u0026#39;./deploy/install.sh\u0026#39; if (exists) { sh(\u0026#34;tar -zcvf deploy.tgz deploy/\u0026#34;) sh(\u0026#34;curl -v -u username:password -X POST \u0026#39;http://nexus.service.com/service/rest/v1/components?repository=paasinstall\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: multipart/form-data\u0026#39; -F \u0026#39;raw.directory=${script_dir}\u0026#39; -F \u0026#39;raw.asset1=@deploy.tgz;type=application/x-compressed-tar\u0026#39; -F \u0026#39;raw.asset1.filename=deploy.tgz\u0026#39;\u0026#34;) } else { println \u0026#34;File doesn\u0026#39;t exist\u0026#34; } } stage(\u0026#39;Send Helm\u0026#39;) { def gitUrl = \u0026#39;https://git.service.com/plugins/git/paas/devops-api.git\u0026#39; def gitCredentialsId = \u0026#39;4116a55e-8551-46b7-b864-xxxxxxxxxxxx\u0026#39; git credentialsId: \u0026#34;${ gitCredentialsId }\u0026#34;, url: \u0026#34;${ gitUrl }\u0026#34; curl -X POST \u0026#34;http://dop.service.com/service/rest/v1/components?repository=market\u0026#34; -H \u0026#34;accept: application/json\u0026#34; -H \u0026#34;Content-Type: multipart/form-data\u0026#34; -F \u0026#34;helm.asset=@monitor-1.2.1.tgz;type=application/x-compressed-tar\u0026#34; } stage(\u0026#39;Cleanup\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn -Dmaven.test.failure.ignore clean\u0026#34; sh(\u0026#34;docker rmi ${tag}\u0026#34;) sh(\u0026#34;rm -f ${slug_file}\u0026#34;) sh \u0026#34;rm -rf *\u0026#34; sh \u0026#34;rm -rf .git\u0026#34; } } } catch (err) { currentBuild.result = \u0026#34;FAILURE\u0026#34; throw err } } DockerFile:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 FROM reg.service.com/paas/node:8.12 # Create app directory RUN mkdir -p /usr/src/app # Bundle app source ADD ./devops_ui/slug.tgz /usr/src/app WORKDIR /usr/src/app/devops_ui ENV NODE_ENV dev CMD [\u0026#34;/usr/src/app/devops_ui/start.sh\u0026#34;] EXPOSE 8080 # Build image # docker build -t devops-api:v1 . #image save #docker save d38ea8888a73 -o ~/work/thirdCode/paas/devops-api.tar #docker images|grep none|awk \u0026#39;{print \u0026#34;docker rmi -f \u0026#34; $3}\u0026#39;|sh # docker rm -f $(docker ps -q -a) #tar zcvf devops.tgz devops # Run docker # docker run -e SYSTEMCONFIG=\u0026#39;{\u0026#34;port\u0026#34;:\u0026#34;8080\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;http://49.4.93.173:32090\u0026#34;}\u0026#39; -p 8080:8080 devops_ui:v1 #数据格式 http://localhost:8080/api/products/seed #{ # \u0026#34;port\u0026#34;:\u0026#34;8080\u0026#34;, # \u0026#34;url\u0026#34;:\u0026#34;http://49.4.93.173:32090\u0026#34; #} maven 项目 jenkinsFile:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 node { currentBuild.result = \u0026#34;SUCCESS\u0026#34; def mvnHome = tool \u0026#39;maven_3_5_4\u0026#39; name_list = \u0026#34;$JOB_NAME\u0026#34;.split(\u0026#39;/\u0026#39;) //eg : \u0026#39;devops-api/master\u0026#39; --\u0026gt; [\u0026#39;devops-api\u0026#39;, \u0026#39;master\u0026#39;] def ver = name_list[1] //eg : \u0026#39;master\u0026#39; def job = name_list[0] //eg : \u0026#39;devops-api\u0026#39; job_list = \u0026#34;$job\u0026#34;.split(\u0026#39;-\u0026#39;) //eg : \u0026#39;devops-api\u0026#39; --\u0026gt; [\u0026#39;devops\u0026#39;, \u0026#39;api\u0026#39;] def project = job_list[0] //eg : \u0026#39;devops\u0026#39; job_size = job_list.size()-1 img_list = [] for(x in (1..job_size)){ img_list.add(job_list[x]) } def img = img_list.join(\u0026#39;-\u0026#39;) def ver_map = [\u0026#34;master\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;release\u0026#34;: \u0026#34;stable\u0026#34;] if(ver_map.containsKey(ver)){ ver = ver_map.get(ver) } def tag = \u0026#34;reg.service.com/\u0026#39;${ project }\u0026#39;/\u0026#39;${ img }\u0026#39;:\u0026#39;${ ver }\u0026#39;\u0026#34; // def tag = \u0026#34;reg.service.com\u0026#34;+\u0026#34;/\u0026#34;+project+\u0026#39;/\u0026#39;+img+\u0026#39;:\u0026#39;+ver def script_dir= project+\u0026#39;/\u0026#39;+img+\u0026#39;/\u0026#39;+ver def slug_dir = \u0026#34;/tmp/\u0026#39;${script_dir}\u0026#39;\u0026#34; def slug_file = \u0026#34;\u0026#39;${slug_dir}\u0026#39;/slug.tgz\u0026#34; try { stage(\u0026#39;Check out\u0026#39;) { checkout scm } stage(\u0026#39;Build\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn clean package -DskipTests=true\u0026#34; //执行mvn命令 } } stage(\u0026#39;Docker build\u0026#39;) { sh(\u0026#34;mkdir -p \u0026#39;${ slug_dir }\u0026#39;\u0026#34;) sh(\u0026#34;tar -z --exclude=\u0026#39;.git\u0026#39; --exclude=\u0026#39;src\u0026#39; -cf \u0026#39;${slug_file}\u0026#39; .\u0026#34;) sh(\u0026#34;cp ${slug_file} .\u0026#34;) sh(\u0026#34;docker build -t ${tag} .\u0026#34;) sh(\u0026#34;docker push ${tag}\u0026#34;) } stage(\u0026#39;Send script\u0026#39;) { def exists = fileExists \u0026#39;./deploy/install.sh\u0026#39; if (exists) { sh(\u0026#34;tar -zcvf deploy.tgz deploy/\u0026#34;) sh(\u0026#34;curl -v -u admin:admin123 -X POST \u0026#39;http://nexus.service.com/service/rest/v1/components?repository=paasinstall\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: multipart/form-data\u0026#39; -F \u0026#39;raw.directory=${script_dir}\u0026#39; -F \u0026#39;raw.asset1=@deploy.tgz;type=application/x-compressed-tar\u0026#39; -F \u0026#39;raw.asset1.filename=deploy.tgz\u0026#39;\u0026#34;) } else { println \u0026#34;File doesn\u0026#39;t exist\u0026#34; } } stage(\u0026#39;Send Helm\u0026#39;) { def gitUrl = \u0026#39;https://git.service.com/plugins/git/paas/charts.git\u0026#39; def gitCredentialsId = \u0026#39;4116a55e-8551-46b7-b864-xxxxxxxxxxxx\u0026#39; git credentialsId: \u0026#34;${ gitCredentialsId }\u0026#34;, url: \u0026#34;${ gitUrl }\u0026#34; curl -X POST \u0026#34;http://dop.service.com/service/rest/v1/components?repository=market\u0026#34; -H \u0026#34;accept: application/json\u0026#34; -H \u0026#34;Content-Type: multipart/form-data\u0026#34; -F \u0026#34;helm.asset=@monitor-1.2.1.tgz;type=application/x-compressed-tar\u0026#34; } stage(\u0026#39;Cleanup\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn -Dmaven.test.failure.ignore clean\u0026#34; } sh(\u0026#34;docker rmi ${tag}\u0026#34;) sh(\u0026#34;rm -f ${slug_file}\u0026#34;) sh \u0026#34;rm -rf *\u0026#34; sh \u0026#34;rm -rf .git\u0026#34; } } catch (err) { currentBuild.result = \u0026#34;FAILURE\u0026#34; throw err } } DockerFile:\n1 2 3 4 5 6 7 8 FROM reg.service.com/paas/jrunner:1.0.0 ENV LANG C.UTF-8 RUN set -x; \\ { \\ echo [program:customer-profile]; \\ echo command=/runner/init start web; \\ autorestart=true; \\ } \u0026gt; /etc/supervisor/conf.d/customer-profile.conf ","description":"","id":103,"section":"posts","tags":["Devops","Jenkins","Pipeline"],"title":"Jenkins-Pipeline使用举例","uri":"https://hex-go.github.io/posts/devops/2020-01-07-jenkins-pipeline%E4%BD%BF%E7%94%A8%E4%B8%BE%E4%BE%8B/"},{"content":"重要 Gogs 支持 本地认证+LDAP认证 模式。 Gogs 要求LDAP中的DN必须具备mail属性。 配置 使用安装时配置的管理帐号登陆gogs系统，点击头像进入管理面板—\u0026gt;认证管理源—\u0026gt;添加新的源,根据自己的ldap配置填入即可。\n这里就是一个绑定帐号，配置过gitlab的也差不多，也是需要一个帐号来获取ldap 帐号树的信息.\n说明:\n非必填项都未做配置\n认证名称: 必填项, 随意填写。 安全协议: 不加密。 主机地址: 此处部署k8s中，用的主机名。如果虚拟机部署可以填IP。 主机端口: ldap服务端口。 绑定DN: 绑定的dn，此处绑定的admi账号。 绑定密码: 上面dn的密码。 用户搜索基准: 从ou=Product往下查找匹配用户 用户过滤规则: dn的属性objectClass=posixAccount \u0026amp; uid=用户登录输入的用户名 邮箱属性: 由于Gogs要求邮箱属性必填，所以ldap创建的用户条目，必须具备mail属性。此处填写mail属性的键名 该授权认证将作为默认登录源: 勾选该配置。Gogs支持本地认证+ldap认证。比jenkins强太多了。 Reference Gogs 集成 LDAP\n","description":"","id":104,"section":"posts","tags":["Devops","LDAP","Gogs"],"title":"Gogs集成LDAP","uri":"https://hex-go.github.io/posts/devops/2020-01-06-gogs%E9%9B%86%E6%88%90ldap/"},{"content":"重要 ldap创建两个groupjenkins-admin和jenkins-manager。并分别将用户admin， operator各自分配到两个组下。（ldapadmin工具操作用户分配组: 在用户条目上右键View\\Edit Group Membership，选择要加入的组。 配置之前备份一下config.xml配置文件，方便出错恢复。文件地址/var/lib/jenkins_home/config.xml。 Jenkins一旦集成LDAP认证就无法使用本地认证。因此在保存ldap配置之前多测试下ldap连接，否则配置错误就无法登录jenkins，参考后面，解决错误配置ldap，导致无法登录问题。 Jenkins 的root DN和User search base需要重点注意。 配置jenkins-ldap 0. LDAP准备 添加jenkins相关的测试账户和组\n在group这个ou里面创建2个组，名为jenkins-admin,jenkins-manager。 在ou=people下面创建4个账户，名为admin,test01,test02,test03,配置好邮箱和密码。 在三个组上面添加对应的用户， jenkins-admin组添加admin， jenkins-manager组添加operator用户\n最终组织图如下： 1. jenkins插件安装 使用LDAP认证需要安装LDAP插件，安装插件有两种方法：\n方法一：后台插件管理里直接安装\n优点：简单方便，不需要考虑插件依赖问题 缺点：因为网络等各种问题安装不成功\n安装方法：登录Jenkins \u0026ndash;\u0026gt; 系统管理 \u0026ndash;\u0026gt; 插件管理 \u0026ndash;\u0026gt; 可选插件 \u0026ndash;\u0026gt; 搜索LDAP \u0026ndash;\u0026gt; 选中 \u0026ndash;\u0026gt; 直接安装 \u0026ndash;\u0026gt; 安装完成重启 如果安装失败，网上也有说在插件管理 \u0026ndash;\u0026gt; 高级 \u0026ndash;\u0026gt; 升级站点里替换URL为https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json，但替换了之后依然没有成功，最后还是使用方法二安装成功\n方法二：官网下载安装文件后台上传\n优点：一定可以安装成功的 缺点：麻烦，要去官网找插件并解决依赖\n插件下载地址：https://updates.jenkins-ci.org/download/plugins/ 安装方法：官网下载插件 \u0026ndash;\u0026gt; 登录Jenkins \u0026ndash;\u0026gt; 系统管理 \u0026ndash;\u0026gt; 插件管理 \u0026ndash;\u0026gt; 高级 \u0026ndash;\u0026gt; 上传插件 \u0026ndash;\u0026gt; 选择文件 \u0026ndash;\u0026gt; 上传 \u0026ndash;\u0026gt; 安装完成后重启\n上传插件安装可能会失败，大部分都是提示你当前插件依赖某些插件，只需要下载全部依赖插件，按照顺序上传安装即可，LDAP插件安装完成后，所有依赖的插件如下：\n2. 配置LDAP认证 登录Jenkins \u0026ndash;\u0026gt; 系统管理 \u0026ndash;\u0026gt; 全局安全配置\n访问控制选择“LDAP”，Server输入LDAP服务器地址，有其他配置可以点击“Advanced Server Configuration\u0026hellip;”\n说明：\nroot DN：这里的root DN只是指搜索的根，并非LDAP服务器的root dn。由于LDAP数据库的数据组织结构类似一颗大树，而搜索是递归执行的，理论上，我们如果从子节点（而不是根节点）开始搜索，因为缩小了搜索范围那么就可以获得更高的性能。这里的root DN指的就是这个子节点的DN，当然也可以不填，表示从LDAP的根节点开始搜索 User search base：这个配置也是为了缩小LDAP搜索的范围，例如Jenkins系统只允许ou为Admin下的用户才能登陆，那么你这里可以填写ou=Admin，这是一个相对的值，相对于上边的root DN，例如你上边的root DN填写的是dc=domain,dc=com，那么user search base这里填写了ou=Admin，那么登陆用户去LDAP搜索时就只会搜索ou=Admin,dc=domain,dc=com下的用户 User search filter：这个配置定义登陆的“用户名”对应LDAP中的哪个字段，如果你想用LDAP中的uid作为用户名来登录，那么这里可以配置为uid={0}（{0}会自动的替换为用户提交的用户名），如果你想用LDAP中的mail作为用户名来登录，那么这里就需要改为mail={0}。在测试的时候如果提示你user xxx does not exist，而你确定密码输入正确时，就要考虑下输入的用户名是不是这里定义的这个值了 Group search base：参考上边User search base解释 Group search filter：这个配置允许你将过滤器限制为所需的objectClass来提高搜索性能，也就是说可以只搜索用户属性中包含某个objectClass的用户，这就要求你对你的LDAP足够了解，一般我们也不配置 Group membership：没配置，没有详细研究 Manager DN：这个配置在你的LDAP服务器不允许匿名访问的情况下用来做认证，通常DN为cn=admin,dc=domain,dc=com这样 Manager Password：上边配置dn的密码 Display Name LDAP attribute：配置用户的显示名称，一般为显示名称就配置为uid，如果你想显示其他字段属性也可以这里配置，例如mail Email Address LDAP attribute：配置用户Email对应的字段属性，一般没有修改过的话都是mail，除非你用其他的字段属性来标识用户邮箱，这里可以配置 Enable Cache: 当你的LDAP数据量很大或者LDAP服务器性能较差时，可以开启缓存，配置缓存条数和过期时间，那么在过期时间内新请求优先查找本地缓存认证，认证通过则不会去LDAP服务器请求，以减轻LDAP服务器的压力。 配置完成后，不要立刻保存，点击``Test LDAP Settings`验证配置的准确性。\n这里输入的用户名就是你上边配置的User search filter里定义的LDAP中的属性, 本文配置的是uid 密码就是LDAP的密码\n3. 配置ldap分组认证 操作步骤: 选择 jenkins -\u0026gt; 系统管理-\u0026gt; 全局安全设置 -\u0026gt; 访问控制 -\u0026gt; ldap -\u0026gt; 授权策略，选择安全矩阵授权策略。\n备注 解决错误配置ldap，导致无法登录问题 为方便用户管理，想通过ldap集中式认证，接入harbor， Gogs， Gitlab， Jenkins，省去每个系统分别创建账号，并管理的问题。但Jenkins集成LDAP配置不当导致Jenkins无法登陆。下面是解决办法：\n首先在配置LDAP之前，可以先备份配置文件/var/lib/jenkins_home/config.xml， ldap的配置只会影响这个文件，可以在无法登录时，重新还原该文件，并重启jenkins服务. 如果没有备份该文件，也可以手动修改已变化的部分。在config.xml配置文件中找到这段关于ldap认证的信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;securityRealm class=\u0026#34;hudson.security.LDAPSecurityRealm\u0026#34; plugin=\u0026#34;ldap@1.20\u0026#34;\u0026gt; \u0026lt;disableMailAddrexxxesolver\u0026gt;false\u0026lt;/disableMailAddrexxxesolver\u0026gt; \u0026lt;configurations\u0026gt; \u0026lt;jenkins.security.plugins.ldap.LDAPConfiguration\u0026gt; \u0026lt;server\u0026gt;ldap://XXXXXX.com:389\u0026lt;/server\u0026gt; \u0026lt;rootDN\u0026gt;dc=XXXXXX,dc=com\u0026lt;/rootDN\u0026gt; \u0026lt;inhibitInferRootDN\u0026gt;false\u0026lt;/inhibitInferRootDN\u0026gt; \u0026lt;userSearchBase\u0026gt;\u0026lt;/userSearchBase\u0026gt; \u0026lt;userSearch\u0026gt;uid={0}\u0026lt;/userSearch\u0026gt; \u0026lt;groupMembershipStrategy class=\u0026#34;jenkins.security.plugins.ldap.FromGroupSearchLDAPGroupMembershipStrategy\u0026#34;\u0026gt; \u0026lt;filter\u0026gt;cn=jenkins\u0026lt;/filter\u0026gt; \u0026lt;/groupMembershipStrategy\u0026gt; \u0026lt;managerDN\u0026gt;uid=jarry,ou=People,dc=XXXXXX,dc=com\u0026lt;/managerDN\u0026gt; \u0026lt;managerPasswordSecret\u0026gt;{AQAAABAAAAAQWfZrb7qoIjeM=}\u0026lt;/managerPasswordSecret\u0026gt; \u0026lt;displayNameAttributeName\u0026gt;uid\u0026lt;/displayNameAttributeName\u0026gt; \u0026lt;mailAddressAttributeName\u0026gt;mail\u0026lt;/mailAddressAttributeName\u0026gt; \u0026lt;ignoreIfUnavailable\u0026gt;false\u0026lt;/ignoreIfUnavailable\u0026gt; \u0026lt;extraEnvVars class=\u0026#34;linked-hash-map\u0026#34;\u0026gt; \u0026lt;entry\u0026gt; \u0026lt;string\u0026gt;\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;\u0026lt;/string\u0026gt; \u0026lt;/entry\u0026gt; \u0026lt;/extraEnvVars\u0026gt; \u0026lt;/jenkins.security.plugins.ldap.LDAPConfiguration\u0026gt; \u0026lt;/configurations\u0026gt; \u0026lt;userIdStrategy class=\u0026#34;jenkins.model.IdStrategy$CaseInsensitive\u0026#34;/\u0026gt; \u0026lt;groupIdStrategy class=\u0026#34;jenkins.model.IdStrategy$CaseInsensitive\u0026#34;/\u0026gt; \u0026lt;disableRolePrefixing\u0026gt;true\u0026lt;/disableRolePrefixing\u0026gt; \u0026lt;/securityRealm\u0026gt; 上面的配置不当无法通过ldap认证，jenkins也无法正常登陆。可以把上面一段替换成以下内容：\n1 2 3 4 \u0026lt;securityRealm class=\u0026#34;hudson.security.HudsonPrivateSecurityRealm\u0026#34;\u0026gt; \u0026lt;disableSignup\u0026gt;false\u0026lt;/disableSignup\u0026gt; \u0026lt;enableCaptcha\u0026gt;false\u0026lt;/enableCaptcha\u0026gt; \u0026lt;/securityRealm\u0026gt; Reference Jenkins ldap配置不当导致无法登录\n运维吧-ldap4-Jenkins集成OpenLDAP认证\nldap-jenkins\n","description":"","id":105,"section":"posts","tags":["Devops","Jenkins","LDAP"],"title":"jenkins集成LDAP","uri":"https://hex-go.github.io/posts/devops/2020-01-06-jenkins%E9%9B%86%E6%88%90ldap/"},{"content":"申请Github OAuth Application Github OAuth Application是为了授权Drone Server读取Github信息。\n参考连接\n部署drone+mysql+nginx 部署的组件\nDrone-server (中央Drone服务器) Drone-agent (接受来自中央Drone服务器的指令以执行构建Pipeline) Mysql (Drone默认的数据存储是sqlite3, 本次部署改用mysql) Nginx (使用Nginx来做对外服务代理) Reference:\nDrone安装官方文档 Drone集成GitHub官方文档 DockerHub Mysql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 version: \u0026#34;3.7\u0026#34; services: nginx: image: nginx:alpine container_name: drone_nginx ports: - \u0026#34;80:80\u0026#34; restart: always networks: - dronenet mysql: image: mysql:5.7 restart: always container_name: drone_mysql environment: - MYSQL_ROOT_PASSWORD=root_password - MYSQL_DATABASE=drone - MYSQL_USER=drone - MYSQL_PASSWORD=drone_password networks: - dronenet volumes: - /path/to/conf/my.cnf:/etc/mysql/my.cnf:rw - /path/to/data:/var/lib/mysql/:rw - /path/to/logs:/var/log/mysql/:rw drone-server: image: drone/drone:1.0.0-rc.5 #不要用latest,latest并非稳定版本 container_name: drone-server networks: - dronenet volumes: - ${DRONE_DATA}:/var/lib/drone/:rw - /var/run/docker.sock:/var/run/docker.sock:rw restart: always environment: - DRONE_DEBUG=true - DRONE_DATABASE_DATASOURCE=drone:drone_password@tcp(drone_mysql:3306)/drone?parseTime=true #mysql配置，要与上边mysql容器中的配置一致 - DRONE_DATABASE_DRIVER=mysql - DRONE_GITHUB_SERVER=https://github.com - DRONE_GITHUB_CLIENT_ID=${Your-Github-Client-Id} #Github Client ID - DRONE_GITHUB_CLIENT_SECRET=${Your-Github-Client-Secret} #Github Client Secret - DRONE_RUNNER_CAPACITY=2 - DRONE_RPC_SECRET=YOU_KEY_ALQU2M0KdptXUdTPKcEw #RPC秘钥 - DRONE_SERVER_PROTO=http\t#这个配置决定了你激活时仓库中的webhook地址的proto - DRONE_SERVER_HOST=dronetest.qloud.com - DRONE_USER_CREATE=username:hex,admin:true #管理员账号，一般是你github用户名 drone-agent: image: drone/agent:1.0.0-rc.5 container_name: dronetest_agent restart: always networks: - dronenet depends_on: - drone-server #依赖drone_server，并在其后启动 volumes: - /var/run/docker.sock:/var/run/docker.sock:rw environment: - DRONE_RPC_SERVER=http://drone-server:8000\t#drone用的http请求包，url一定要写上协议才能支持 - DRONE_RPC_SECRET=YOU_KEY_ALQU2M0KdptXUdTPKcEw #RPC秘钥，与drone_server中的一致 - DRONE_DEBUG=true networks: dronenet: 执行以下命令，创建容器、网络\n1 docker-compose up -d 修改Nginx配置\n1 docker exec -it nginx ash 容器内执行以下命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 vim /etc/nginx/conf.d/drone.conf server { listen 80; server_name drone.qloud.com; location / { proxy_pass http://drone-server:8000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } nginx -s reload 使用 创建仓库，并保证仓库中存在.drone.yml文件; 访问drone服务， 并刷新。找到刷新出的新项目,点击active; 查看webhook中是否多出drone的webhook记录； 手动出发，看是否出发Drone构建过程。 注意：\n1. 如果文件名要自定义，需要再drone active的设置里修改成自定义的名字， 负责会发生正常事件触发drone时失败，返回状态码与信息均为N/A\n2. Drone 的编写总体符合yaml格式, 但要注意，第一个构建步骤之前是不能加注释的, 否则会报错\n举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 pipeline: restore-cache: image: drillster/drone-volume-cache restore: true mount: - ./node_modules volumes: # Mount the cache volume, needs \u0026#34;Trusted\u0026#34; | https://docs.drone.io/administration/user/admins/ # DRONE_USER_CREATE=username:{alicfeng},admin:true # source path {/tmp/cache/composer need to mkdir on server} - /tmp/cache/node_modules:/cache build-tests: image: node:latest commands: - node -v \u0026amp;\u0026amp; npm -v - npm install -g cnpm --registry=https://registry.npm.taobao.org - cnpm install - npm run build rebuild-cache: image: drillster/drone-volume-cache rebuild: true mount: - ./node_modules volumes: - /tmp/cache/node_modules:/cache sit-deploy: image: appleboy/drone-ssh host: $host username: $username password: $password port: $port command_timeout: 300s script: # sit env deploy shell script list - cd /www/code.samego.com/ - git pull - git pull - cnpm install -ddd - npm run build -ddd prod-deploy: image: appleboy/drone-ssh host: $host username: $username password: $password port: $port command_timeout: 300s script: # prod env deploy shell script list # todo awaiting extend to deploy | main scp - node -v \u0026amp;\u0026amp; npm -v - cd /www/code.samego.com/ - git pull - cnpm install -ddd - npm run build -ddd when: event: - push branch: - prod mail-notify: image: drillster/drone-email from: $from host: smtp.163.com username: $username password: $password port: 465 subject: CICD fail notify recipients: - a@test.com when: status: [ failure ] Reference Drone CI for GitHub\nDrONE CD for k8s\n","description":"","id":106,"section":"posts","tags":["Devops","Drone","CI/CD","Deployment","Docker"],"title":"GitHub-drone-dockercompose","uri":"https://hex-go.github.io/posts/devops/2020-01-06-github-drone-dockercompose/"},{"content":"写在前面 最重要的事: 可以提供java\\node\\python\\docker-image\\chart的仓储服务，但对镜像仓库的支持不足，不如harbor，helm-chart也值相当于原始文件存储的级别。\n1.简介 2.环境准备 3.部署 1 2 docker volume create --name nexus-data docker run -d -p 8081:8081 --name nexus -v nexus-data:/nexus-data sonatype/nexus3:3.20.1 4.使用 Reference nexus hub.docker 说明\n","description":"","id":107,"section":"posts","tags":["Persistence","Devops","Nexus"],"title":"提供健全的私仓服务-Nexus","uri":"https://hex-go.github.io/posts/persistence/2020-01-03-%E6%8F%90%E4%BE%9B%E5%81%A5%E5%85%A8%E7%9A%84%E7%A7%81%E4%BB%93%E6%9C%8D%E5%8A%A1-nexus/"},{"content":"写在前面 最重要的事: 备份一定要包含恢复脚本，一个不可恢复的备份就是脏数据！！！\n简介 Restic是一个用Go语言编写，安全且高效的备份客户端。它可以将本地文件备份到许多不同的后端存储库，例如本地目录，SFTP服务器或对象存储服务。公司由于Git-Server跑在本地办公网络,需要提供一个异地定期备份的方案,备份数据要求加密存储。选定CronTab+Restic+MinIO备份至华为云虚拟机上。\n获取Restic并在对象存储服务上初始化存储库。 准备要备份的文件，并将文件备份到存储库。 配置CronTab，自动执行备份以获取每小时快照，并在必要时自动精简旧快照。 环境准备 Restic可执行文件\nMinIO信息获取\n访问秘钥: AWS_ACCESS_KEY_ID 秘钥: AWS_SECRET_ACCESS_KEY 服务器URL: RESTIC_REPOSITORY Bucket名称: RESTIC_REPOSITORY RESTIC_PASSWORD定义Restic将用于加密备份的密码。此加密发生在本地，因此可以备份到不受信环境的异地服务器，并将其复制到安全备份的地方。可以通过KeyPass软件，或者通过openSSL命令:\n1 openssl rand -base64 24 环境准备过程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 1. Get Restic bin-file cd ~ curl -LO https://github.com/restic/restic/releases/download/v0.9.6/restic_0.9.6_linux_amd64.bz2 # Extract Here bzip2 -dk restic* # Set file cp restic* /usr/local/bin/restic chmod +x /usr/local/bin/restic # test restic version # 2. set Environments to access MinIO-bucket export AWS_ACCESS_KEY_ID=\u0026#34;minio-access-key\u0026#34; export AWS_SECRET_ACCESS_KEY=\u0026#34;minio-secret-key\u0026#34; export RESTIC_REPOSITORY=\u0026#34;s3:\u0026lt;server-url|eg=http://127.0.0.1:9000\u0026gt;/\u0026lt;bucket-name|eg=restic-git\u0026gt;/\u0026#34; export RESTIC_PASSWORD=\u0026#34;\u0026lt;a-strong-password|eg=j8CGOSdz8ibUYK137wtYdVsRoGUp\u0026gt;\u0026#34; 1. 初始化存储库 1 restic init 2. 准备备份文件 备份服务为内部开发服务, docker-run 跑在虚拟机上.所以做如下准备:\n服务的镜像文件 服务的数据文件 服务恢复脚本 3. crontab设置定时备份 最近24小时备份,7天备份,12月备份\n1 2 /usr/local/bin/restic backup -q ./restic-jenkins /usr/local/bin/restic forget -q --prune --keep-hourly 24 --keep-daily 30 --keep-monthly 12 restic 操作备查 1 2 3 4 5 6 7 8 # backup restic backup --tag data /opt/bkp_dir # show snapshots restic snapshots # restore restic restore \u0026lt;snapshot-id\u0026gt; --target /opt/restore-data Reference Restic备份对象存储服务器\n示例参考\n","description":"","id":108,"section":"posts","tags":["Persistence","Restic"],"title":"服务数据备份方案-Restic","uri":"https://hex-go.github.io/posts/persistence/2020-01-02-%E6%9C%8D%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E6%96%B9%E6%A1%88-restic/"},{"content":"摘要 对象存储服务可以用来存储各类文件，公司前端项目中的图片存储采用的是OSS，也采取过Minio+Restic给虚拟机服务提供定期异地加密备份方案。小记对minio服务的理解。\nMinIo简介 MinIO是一款基于Go语言的高性能对象存储服务，基于Apache License v2.0开源协议。在Github上已有19K+Star。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。\nMinIo可以单机或分布式模式运行。单机Minio服务存在单点故障，通常仅用于测试环境。分布式Minio将多块硬盘（甚至在不同的机器上）组成一个对象存储服务。由于硬盘分布在不同的节点上，分布式Minio避免了单点故障。如果是一个N节点的分布式Minio,只要有N/2节点在线，数据就是安全的。不过你需要至少有N/2+1个节点 Quorum 来创建新的对象。\n分布式模式与单机模式搭建的流程基本一样，Minio服务基于命令行传入的参数自动切换成单机模式还是分布式模式。启动一个分布式Minio实例，你只需要把硬盘位置做为参数传给minio server命令即可，然后，需要在所有其它节点运行同样的命令。\nMinio服务器将监控数据通过无须认证的端点暴露出来\n健康检查侦测：存活侦测（/minio/health/live），就绪侦测（/minio/health/ready）\nPrometheus侦测：/minio/prometheus/metrics\n安装及部署 1. Docker运行MinIo单点模式 MinIO 需要持久化配置(容器内: /root/.minio)和应用数据(容器内: /data)。传递的参数/data是数据存储目录，如果不存在会在容器启动时在容器的文件系统中创建。\n1 2 3 4 5 docker pull minio/minio docker run -p 9000:9000 --name minio \\ -v /mnt/data:/data \\ -v /mnt/config:/root/.minio \\ minio/minio server /data 2. Docker-compose运行MinIo分布式模式 分布式MinIO可以通过Docker Compose或者Swarm mode进行部署,本文docker-compose部署.\nDocker-Compose部署 Docker-swarm 节点规划 单个主机，多容器部署 多主机，多容器部署 优缺点 可以让快速的在机器上快速使用分布式MinIO，非常适合开发\\测试环境 提供了更健壮,生产级别的部署.但生产环境更建议部署到k8s中 Docker Compose允许定义和运行单主机，多容器Docker应用程序。使用Compose，可以使用Compose文件来配置MinIO服务。 然后，使用单个命令，您可以通过你的配置创建并启动所有分布式MinIO实例。 分布式MinIO实例将部署在同一主机上的多个容器中。 适合创建基于分布式MinIO的开发，测试环境。\n在Docker Compose上部署分布式MinIO,请下载docker-compose.yaml到你的当前工作目录。执行下面命令：\n1 2 3 4 5 6 7 8 # 1. Get docker-compose.yaml wget https://raw.githubusercontent.com/minio/minio/master/docs/orchestration/docker-compose/docker-compose.yaml # 2. pull image docker-compose pull # 3. container create \u0026amp; up docker-compose up Docker compose file中的MinIO服务使用的端口是9001到9004。\n3. Kubernetes-Helm MinIO生产环境更建议部署再kubernetes,不建议使用Swarm.而且\nMinIO Helm Chart部署MinIO。 Kubernetes MinIO参考示例 ，通过.yaml文件部署MinIO。 3.1前提条件 部署环境检查\n默认standaline模式下，需要开启Beta API的Kubernetes 1.4+。 distributed 模式，需要开启Beta API的Kubernetes 1.5+。 底层支持PV provisioner。 helm安装病配置完成。 3.2使用Helm Chart 部署 1 helm install --name=minio --namespace paas stable/minio 3.3分布式节点规划： 分布式Minio单租户存在最少4个盘最多32个盘的限制。只要遵守分布式Minio的限制，可以组合不同的节点和每个节点几块盘。比如，可以使用2个节点，每个节点4块盘，也可以使用4个节点，每个节点两块盘，诸如此类。 多个节点的存储容量和就是分布式Minio的存储容量。 mode：Minio服务器运行模式(standalone或distributed) replicas：节点数(仅适用于distributed模式).4 \u0026lt;= x \u0026lt;= 32,默认为4 3.4冒烟测试 1 2 3 4 5 6 7 8 9 # curl curl http://\u0026lt;service-name:9000\u0026gt;/minio/health/live curl http://\u0026lt;service-name:9000\u0026gt;/minio/health/ready # mc client mc config host add \u0026lt;ALIAS\u0026gt; \u0026lt;ENDPOINT\u0026gt; \u0026lt;ACCESS-KEY\u0026gt; \u0026lt;SECRET-KEY\u0026gt; mc ls \u0026lt;ALIAS\u0026gt; mc mb \u0026lt;ALIAS\u0026gt;/testbucket mc ls \u0026lt;ALIAS\u0026gt; 使用 (未完待续)\nReference Docker Compose 部署 MinIO\nKubernetes 部署 MinIO\nChart 获取\n","description":"","id":109,"section":"posts","tags":["Persistence","MinIO"],"title":"对象存储服务-Minio","uri":"https://hex-go.github.io/posts/persistence/2020-01-02-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1-minio/"},{"content":"重要 提前说明 开发人员提交代码到 Gitlab 代码仓库 通过 Gitlab 配置的 Jenkins Webhook 触发 Pipeline 自动构建 Jenkins 触发构建构建任务，根据 Pipeline 脚本定义分步骤构建 先进行代码静态分析，单元测试 然后进行 Maven 构建（Java 项目） 根据构建结果构建 Docker 镜像 推送 Docker 镜像到 Harbor 仓库 触发更新服务阶段，使用 Helm 安装/更新 Release 查看服务是否更新成功。 部署Jenkins chart地址: https://github.com/helm/charts/tree/master/stable/jenkins\n1 helm install --name jenkins stable/jenkins 1.后端服务容器化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 FROM maven:3.6-alpine as BUILD COPY src /usr/app/src COPY pom.xml /usr/app RUN mvn -f /usr/app/pom.xml clean package -Dmaven.test.skip=true FROM openjdk:8-jdk-alpine ENV LANG en_US.UTF-8 ENV LANGUAGE en_US:en ENV LC_ALL en_US.UTF-8 ENV TZ=Asia/Shanghai RUN mkdir /app WORKDIR /app COPY --from=BUILD /usr/app/target/polls-0.0.1-SNAPSHOT.jar /app/polls.jar EXPOSE 8080 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-Djava.security.egd=file:/dev/./urandom\u0026#34;, \u0026#34;-jar\u0026#34;,\u0026#34;/app/polls.jar\u0026#34;] 页面打包到一个jar文件build-container-/usr/app/target/polls-0.0.1-SNAPSHOT.jar 将上面jar文件添加到 jdk-container-/app/polls.jar目录 2. 前段服务容器化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 FROM node:alpine as BUILD WORKDIR /usr/src/app RUN mkdir -p /usr/src/app ADD . /usr/src/app RUN npm install \u0026amp;\u0026amp; \\ npm run build FROM nginx:1.15.10-alpine COPY --from=BUILD /usr/src/app/build /usr/share/nginx/html ADD nginx.conf /etc/nginx/conf.d/default.conf 页面打包到一个build目录build-container-/usr/src/app/build 将上面目录添加到 nginx-container-/usr/share/nginx/html目录 3. Jenkins task配置 在 Pipeline 中去自定义Slave Pod中所需要用到的容器模板，需要什么镜像只需要在Slave Pod Template中声明即可，不需要安装了所有工具的Slave镜像。\n首先Jenkins 中 kubernetes 配置，Jenkins -\u0026gt; 系统管理 -\u0026gt; 系统设置 -\u0026gt; 云 -\u0026gt; Kubernetes区域\n新建一个名为polling-app-server类型为流水线(Pipeline)的任务：\n勾选触发远程构建的触发器，其中令牌我们可以随便写一个字符串，然后记住下面的 URL，将 JENKINS_URL 替换成 Jenkins 的地址,我们这里的地址就是：http://jenkins.qikqiak.com/job/polling-app-server/build?token=server321\n在下面的流水线区域，可以选择Pipeline script，测试流水线脚本。正常配置选择Pipeline script from SCM，就是从代码仓库中通过Jenkinsfile文件获取Pipeline script脚本定义，选择 SCM 来源为Git。配置仓库地址http://git.qikqiak.com/course/polling-app-server.git，由于是在一个 Slave Pod 中去进行构建，所以如果使用 SSH 的方式去访问 Gitlab 代码仓库的话就需要频繁的去更新 SSH-KEY，所以直接采用用户名和密码的形式来访问：\n在Credentials区域点击添加按钮添加我们访问 Gitlab 的用户名和密码：\n配置用于构建的分支，如果所有的分支需要进行构建，将Branch Specifier区域留空即可，一般情况下，只有不同的环境对应的分支才需要构建，比如 master、develop、test 等，平时开发的 feature 或者 bugfix 的分支没必要频繁构建，下图只配置 master 和 develop 两个分支用户构建：\n然后前往 Gitlab 中配置项目polling-app-server Webhook，settings -\u0026gt; Integrations，填写上面得到的 trigger 地址：\n保存后，可以直接点击Test -\u0026gt; Push Event测试是否可以正常访问 Webhook 地址，这里需要注意的是我们需要配置下 Jenkins 的安全配置，否则这里的触发器没权限访问 Jenkins，系统管理 -\u0026gt; 全局安全配置：取消防止跨站点请求伪造，勾选上匿名用户具有可读权限：\n如果测试出现了Hook executed successfully: HTTP 201则证明 Webhook 配置成功了，否则就需要检查下 Jenkins 的安全配置是否正确了。\n4. JenkinsFile Clone 代码 -\u0026gt; 代码静态分析 -\u0026gt; 单元测试 -\u0026gt; Maven 打包 -\u0026gt; Docker 镜像构建/推送 -\u0026gt; Helm 更新服务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def label = \u0026#34;slave-${UUID.randomUUID().toString()}\u0026#34; podTemplate(label: label, containers: [ containerTemplate(name: \u0026#39;maven\u0026#39;, image: \u0026#39;maven:3.6-alpine\u0026#39;, command: \u0026#39;cat\u0026#39;, ttyEnabled: true), containerTemplate(name: \u0026#39;docker\u0026#39;, image: \u0026#39;docker\u0026#39;, command: \u0026#39;cat\u0026#39;, ttyEnabled: true), containerTemplate(name: \u0026#39;kubectl\u0026#39;, image: \u0026#39;hex/kubectl\u0026#39;, command: \u0026#39;cat\u0026#39;, ttyEnabled: true), containerTemplate(name: \u0026#39;helm\u0026#39;, image: \u0026#39;hex/helm\u0026#39;, command: \u0026#39;cat\u0026#39;, ttyEnabled: true) ], volumes: [ hostPathVolume(mountPath: \u0026#39;/root/.m2\u0026#39;, hostPath: \u0026#39;/var/run/m2\u0026#39;), hostPathVolume(mountPath: \u0026#39;/home/jenkins/.kube\u0026#39;, hostPath: \u0026#39;/root/.kube\u0026#39;), hostPathVolume(mountPath: \u0026#39;/var/run/docker.sock\u0026#39;, hostPath: \u0026#39;/var/run/docker.sock\u0026#39;) ]) { node(label) { def myRepo = checkout scm def gitCommit = myRepo.GIT_COMMIT def gitBranch = myRepo.GIT_BRANCH stage(\u0026#39;单元测试\u0026#39;) { echo \u0026#34;测试阶段\u0026#34; } stage(\u0026#39;代码编译打包\u0026#39;) { container(\u0026#39;maven\u0026#39;) { echo \u0026#34;打码编译打包阶段\u0026#34; } } stage(\u0026#39;构建 Docker 镜像\u0026#39;) { container(\u0026#39;docker\u0026#39;) { echo \u0026#34;构建 Docker 镜像阶段\u0026#34; } } stage(\u0026#39;运行 Kubectl\u0026#39;) { container(\u0026#39;kubectl\u0026#39;) { echo \u0026#34;查看 K8S 集群 Pod 列表\u0026#34; sh \u0026#34;kubectl get pods\u0026#34; } } stage(\u0026#39;运行 Helm\u0026#39;) { container(\u0026#39;helm\u0026#39;) { echo \u0026#34;查看 Helm Release 列表\u0026#34; sh \u0026#34;helm list\u0026#34; } } } } /root/.m2 挂载为了maven构建添加缓存，否则每次构建重新下载依赖，太慢。 ~/.kube 挂载为了让kubectl和helm访问 Kubernetes 集群。 /var/run/docker.sock 挂载为了docker客户端与Docker Daemon通信，构建镜像。 label标签的定义 使用 、UUID生成随机字符串，让Slave Pod每次的名称不一样，不会被固定在一个Pod上面了，而且有多个构建任务的时候就不会存在等待的情况. Reference k8s-deploy jenkins 动态slaves\njenkins pipeline 部署k8s应用\njenkin Blue Ocean 使用\njenkins-pipeline to k8s\n","description":"","id":110,"section":"posts","tags":["Devops","Jenkins","JenkinsFile","Gitlab","Kubernetes","Docker"],"title":"基于Jenkins、gitlab、docker、helm和Kubernetes的CI/CD","uri":"https://hex-go.github.io/posts/devops/2019-12-31-%E5%9F%BA%E4%BA%8Ejenkinsgitlabdockerhelm%E5%92%8Ckubernetes%E7%9A%84ci-cd/"},{"content":"重要 Drone登录的账号需要在Gogs设置为管理员，他俩兄弟的账密是互通的 Gogs的仓库会自动同步到Drone上，此时，需要在Drone开启激活该项目才能正常运行，激活后能在Gogs仓库WeHooks多一个记录。 Drone默认读取的配置文件名为项目根下.drone.yml，如果仓库内文件名不是。需要再Drone-setting中做修改。 正文 CI / CD( 持续集成 / 持续部署 )方案是DevOps中不可或缺的流程之一，本文简单介绍选择 Gogs + Drone 通过docker compose部署。\n主机名 gitLab + jenkins Gogs + Drone NUM 成熟度 GitLab是一个非常成熟的git工具之一，同时Jenkins也是非常成熟的CICD组件，功能非常强大。 性能高，并且简单易用 1 语言技术栈 GitLab是使用Ruby编写的，Jenkins更是了不起，使用Java来编写的，项目整体比较膨大，同时它们对硬件、CPU等开销比较高 Drone、Gogs皆是使用Go语言来编写构建，在整体的语言性能与内存开销算是有一定的优势 2 Drone是一种基于容器技术的持续交付系统。Drone使用简单的YAML配置文件（docker-compose的超集）来定义和执行Docker容器中的Pipelines。Drone与流行的源代码管理系统无缝集成，包括GitHub，GitHub Enterprise，Gogs，Bitbucket等。\n镜像说明 drone升级使用1.0.0-rc6版本，此版本并非稳定版本，推荐使用1版本甚至是0.8.6更稳定的版本。1.0后的版本较之前而言，配置更加灵活、优化版本，同时界面也变化了。drone\n环境准备 使用的前提，必须符合以下条件\n系统安装了Docker，同时要安装了Docker编排工具docker-compose 主流的x64位系统，Linux、Mac、Window等 安装了git版本控制工具 安装 安装非常简单，拉取docker-compose.yml编排文件，基于Docker环境自动构建即可！\ndocker-compose: https://github.com/alicfeng/gogs-drone-docker.git/deployment/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 version: \u0026#34;2\u0026#34; services: gogs: container_name: gogs image: gogs/gogs:0.11.91 ports: - 3000:3000 - 10022:22 volumes: - ./data/gogs/data:/data environment: - TZ=Asia/Shanghai restart: always networks: - dronenet drone-server: image: drone/drone:1.6.1 container_name: drone-server ports: - 8000:80 volumes: - /var/run/docker.sock:/var/run/docker.sock - ./data/drone/:/var/lib/drone environment: - DRONE_OPEN=true - DRONE_SERVER_HOST=drone-server:8000 - DRONE_DEBUG=true - DRONE_GIT_ALWAYS_AUTH=false - DRONE_GOGS=true - DRONE_GOGS_SKIP_VERIFY=false - DRONE_GOGS_SERVER={http://gogs:3000} - DRONE_PROVIDER=gogs - DRONE_SERVER_PROTO=http - DRONE_RPC_SECRET=7b4eb5caee376cf81a2fcf7181e66175 - DRONE_USER_CREATE=username:alic,admin:true - DRONE_DATABASE_DATASOURCE=/var/lib/drone/drone.sqlite - DRONE_DATABASE_DRIVER=sqlite3 - TZ=Asia/Shanghai restart: always networks: - dronenet drone-agent: image: drone/agent:1.6.1 container_name: drone-agent depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_RPC_SERVER={docker-server:8000} - DRONE_RPC_SECRET=7b4eb5caee376cf81a2fcf7181e66175 - DRONE_RUNNER_CAPACITY=2 - DRONE_DEBUG=true - TZ=Asia/Shanghai restart: always nginx: image: nginx:alpine container_name: drone_nginx ports: - \u0026#34;80:80\u0026#34; restart: always networks: - dronenet networks: dronenet: 执行以下命令，创建容器、网络\n1 docker-compose up -d 修改Nginx配置\n1 docker exec -it nginx ash 容器内执行以下命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 vim /etc/nginx/conf.d/drone.conf server { listen 80; server_name drone.qloud.com; location / { proxy_pass http://drone-server:8000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } nginx -s reload 运行 docker-runner\n1 2 3 4 5 6 7 8 9 10 11 docker run -d \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -e DRONE_RPC_PROTO=http \\ -e DRONE_RPC_HOST=10.8.3.206:8000 \\ -e DRONE_RPC_SECRET=7b4eb5caee376cf81a2fcf7181e66175 \\ -e DRONE_RUNNER_CAPACITY=2 \\ -e DRONE_RUNNER_NAME=${HOSTNAME} \\ -p 3002:3000 \\ --restart always \\ --name docker-runner \\ drone/drone-runner-docker:1 使用 每当分支的代码更新的时候，Gogs会动过钩子同步通知Drone，而Drone收到通知后根据.drone.yml配置执行命令。\n通过git clone分支代码到容器里面 单元测试, 代码静态检查 编译代码，构建可执行文件 build image镜像，发布到Registry 部署至生产环境 发送邮件等通知信息，这里还有很多插件，比如微信、钉钉、电报等 价值源于技术，技术源于分享\nReference Nginx代理\n","description":"","id":111,"section":"posts","tags":["Devops","CI/CD","Drone","Gogs","Docker"],"title":"gogs-drone-dockercompose","uri":"https://hex-go.github.io/posts/devops/2019-12-30-gogs-drone-dockercompose/"},{"content":" 计算机原理 网络 dns bgp 证书 ssl 编译原理 编程思想 linux ","description":"","id":112,"section":"posts","tags":["计算机原理"],"title":"Tree","uri":"https://hex-go.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/20191230-tree/"},{"content":" kubernetes源码阅读 Docker源码 flask源码 DBaas源码 ","description":"","id":113,"section":"posts","tags":["Source Code"],"title":"k8s源码阅读","uri":"https://hex-go.github.io/posts/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/20191229-k8s%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"content":"{% note success %} 不错的备查资料 {% endnote %}\n超详细备查(利于排查概念模糊点)\nGo语言入门教程，Golang入门教程（非常详细）\n超级实用\nGo语言标准库》The Golang Standard Library by Example\nGolang设计模式\u0026ndash;k8s源码为例\nGlang设计模式\u0026ndash;概念+示例\nGo by Example\ngo社区知识图谱\ngo语言的leetcode刷题\nThe Way To Go-ZH_CN\n交互式go工具\u0026ndash;lgo\n容器的top\u0026ndash;ctop\ndocker和docker-compose的终端UI\n","description":"","id":115,"section":"posts","tags":["Go"],"title":"Golang学习资料","uri":"https://hex-go.github.io/posts/golang/2019-12-29-golang%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/"},{"content":"SecureCRT/SecureFX 8.5.4安装使用 1. 下载 官网下载地址\n直接到官网上下载即可，下载过程可能会提示要先注册，直接注册，然后再下载。\n我直接下载的是最新版secureCRT+secureFX的合体包：scrt-sfx-8.5.4-1942.ubuntu16-64.x86_64.deb\n2.安装 sudo dpkg -i scrt-sfx-8.5.4-1942.ubuntu16-64.x86_64.deb\n如果安装过程中因为缺少依赖而安装失败，只需要通过命令：apt-get install -f即可完成依赖的安装。\n3.破解 破解文件下载：https://share.weiyun.com/5Mc38uB 密码：yetp32\nsecureCRT破解\n1 2 # /usr/bin/SecureCRT 路径如果不知道,请自行find sudo perl securecrt_forgeek_crack.pl /usr/bin/SecureCRT 打开SecureCRT，会弹出配置存放路径，点OK，跳出激活界面，还有30天过期什么的。\na. 点Enter License Data，跳出一个文本框，不用输任何东西!!! 直接点下一步 b. 他肯定报错，说license无效，不用管， c. 点左下角的 Enter Licence Manually, 然后要求输入各种信息，照着上面命令执行完的output信息复制粘贴上去就行。下面是举例: Name:REIZ Company:Toyota Serial Number: 请复制卡号 03-52-039026 License Key:请复制密码 AAS4RS X1MU15 G9S6WV VTA5TV ACXK55 1JKW75 8R8Z5Z PK4FXJ Issue Date: 08-08-2088 SecureFX破解\n1 sudo perl securefx_forgeek_crack.pl /usr/bin/SecureFX 打开SecureFX，参考SecureCRT激活步骤.\nReference linux破解资源\nWindows破解资源\n","description":"","id":116,"section":"posts","tags":["Ubuntu","个人工具","SSH"],"title":"Ubuntu18.04安装SecureCRT.","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-12-26-ubuntu_18.04%E5%AE%89%E8%A3%85securecrt/"},{"content":"前言 博客 评论系统 技术选型：\nDisqus 国内无法访问。 gitment很久没有维护、更新。 选用Gitalk 评论插件。 Gitalk 说明 Gitalk 的界面和功能：\ngitalk 使用 Github 帐号登录，界面干净整洁，且支持 MarkDown语法。\n正文 1. 获取 Token Gitalk 需要一个 Github Application，点击这里申请。\n填写下面参数：\n点击创建，获取 Client ID 和 Client Secret 之后填入 博客配置 Gitalk 部分\n2. 博客配置 博客配置文件source/_data/next.yml，增加以下配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026lt;!-- Gitalk start --\u0026gt; {% if site.gitalk.enable %} \u0026lt;!-- Link Gitalk 的脚本 --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://unpkg.com/gitalk/dist/gitalk.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/gitalk@latest/dist/gitalk.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;div id=\u0026#34;gitalk-container\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; var gitalk = new Gitalk({ // gitalk的主要参数 clientID: `Github Application clientID`, clientSecret: `Github Application clientSecret`, repo: `存储评论 issue 的 Github 仓库名（一般设置为 GitHub Page 的仓库名）`, owner: \u0026#39;Github 用户名\u0026#39;, admin: [\u0026#39;Github 用户名\u0026#39;], id: \u0026#39;页面的唯一标识。gitalk会根据这个标识，自动创建issue的标签\u0026#39;, }); gitalk.render(\u0026#39;gitalk-container\u0026#39;); \u0026lt;/script\u0026gt; {% endif %} \u0026lt;!-- Gitalk end --\u0026gt; 主要参数配置如下：\n1 2 3 4 5 6 clientID: `Github Application clientID`, clientSecret: `Github Application clientSecret`, repo: `Github 仓库名`,//存储评论 issue 的 Github 仓库名（建议直接用 GitHub Page 的仓库名） owner: \u0026#39;Github 用户名\u0026#39;, admin: [\u0026#39;Github 用户名\u0026#39;], //这个仓库的管理员，可以有多个，数组表示 id: \u0026#39;window.location.pathname\u0026#39;, //页面的唯一标识。gitalk 会根据这个标识，自动创建issue的标签，使用页面的相对路径作为标识 其他参数说明见官方文档 。比如，增加 全屏遮罩 的参数。\n1 distractionFreeMode: true, 结语 遗留问题\nGitalk 需要点开每篇文章的页面，进行初始化issue创建。解决方案参考 自动初始化 Gitalk 和 Gitment 评论。\n","description":"","id":117,"section":"posts","tags":["Hexo"],"title":"为博客添加 Gitalk 评论插件","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-06-23-hexo_%E4%B8%BA%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0gitalk%E8%AF%84%E8%AE%BA%E6%8F%92%E4%BB%B6/"},{"content":"简化命令行交互, 简化应用程序部署语法 1. Kubectl 自动补全 kubectl 工具本身支持自动补全,只需要简单设置一下即可\n1 2 3 echo \u0026#34;source \u0026lt;(kubectl completion bash)\u0026#34; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 如果没有安装bash-completion, 按如下命令安装\n1 2 apt update apt install bash-completion 2. 自定义 kubectl get 输出 kubectl get 相关资源，默认输出为 kubectl 内置，一般我们也可以使用-o json/-o jsonpath=''或者-o yaml查看其完整的资源信息。但是很多时候，我们需要关心的信息并不全面，因此我们需要自定义输出的列，那么可以使用 go-template 来进行实现。\ngo-template 是 golang 的一种模板，可以参考 template 的相关说明。\n比如仅仅想要查看获取的 pods 中的各个 pod 的 uid，则可以使用以下命令：\n1 kubectl get pods --all-namespaces -o go-template=\u0026#39;{{range .items}}{{.metadata.uid}} {{end}}\u0026#39; 比如使用 jsonpath 获取数据\n1 2 export ISTIO_PILOT_PORT=$(kubectl get -n istio-system service istio-ingressgateway -o jsonpath=\u0026#39;{.spec.ports[?(@.name==\u0026#34;tcp-pilot-grpc-tls\u0026#34;)].nodePort}\u0026#39;) echo ${ISTIO_PILOT_PORT} 3. k8s强制删除提示 Terminating 的namespace a. 首先尝试强制删除参数 1 kubectl delete namespace example-ns -force --grace-period=0 b. 如果不能删除，则采取以下方法 1 kubectl edit namespace example-ns 将其中spec.finalizers的值删除，也可以设置为[]。保存退出后，namespace就会被删除。\n1 2 3 4 5 6 7 8 9 10 11 apiVersion: v1 kind: Namespace metadata: finalizers: - controller.cattle.io/namespace-auth name: mars spec: finalizers: - kubernetes status: phase: Active 思路：\n命名空间无法删除通常是因为还有资源在使用这个命名空间，执行kubectl delete namespace xxx 时候，虽然显示deleted，但是命令夯死。我们可以查看资源使用情况：\n1 kubectl api-resources --namespaced=true -o name | xargs -n 1 kubectl get --show-kind --ingore-not-found -n xxxx Reference Kubernetes 的奇技淫巧\n删除一直处于terminating状态的namespace\n","description":"","id":118,"section":"posts","tags":["Kubernetes","运维笔记"],"title":"kubectl 小技巧","uri":"https://hex-go.github.io/posts/kubernetes/2019-12-13-k8s%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"content":"下载补丁文件 补丁文件地址：\n下载补丁文件后放置到任一目录下,建议放在pycharm安装目录, egg: /home/hex/apps/pycharm-2018.3.6/\n修改pycharm文件,安装目录bin下 pycharm64.vmoptions 和 pycharm.vmoptions, 文件末尾追加一下内容 1 2 # 格式为 -javaagent:补丁的文件地址 -javaagent:/home/hex/apps/pycharm-2018.3.6/JetbrainsCrack-release-enc.jar 启动pycharm, 输入如下 Activation code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ThisCrackLicenseId-{ “licenseId”:”1”, “licenseeName”:”Hex”, “assigneeName”:”Hex”, “assigneeEmail”:”892120992@qq.com”, “licenseRestriction”:””, “checkConcurrentUse”:false, “products”:[ {“code”:”II”,”paidUpTo”:”2099-12-31”}, {“code”:”DM”,”paidUpTo”:”2099-12-31”}, {“code”:”AC”,”paidUpTo”:”2099-12-31”}, {“code”:”RS0”,”paidUpTo”:”2099-12-31”}, {“code”:”WS”,”paidUpTo”:”2099-12-31”}, {“code”:”DPN”,”paidUpTo”:”2099-12-31”}, {“code”:”RC”,”paidUpTo”:”2099-12-31”}, {“code”:”PS”,”paidUpTo”:”2099-12-31”}, {“code”:”DC”,”paidUpTo”:”2099-12-31”}, {“code”:”RM”,”paidUpTo”:”2099-12-31”}, {“code”:”CL”,”paidUpTo”:”2099-12-31”}, {“code”:”PC”,”paidUpTo”:”2099-12-31”} ], “hash”:”2911276/0”, “gracePeriodDays”:7, “autoProlongated”:false} ","description":"","id":119,"section":"posts","tags":["Python","Pycharm","个人工具"],"title":"Pycharm2018 破解","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-12-13-pycharm_%E7%A0%B4%E8%A7%A3/"},{"content":"配置pycharm 同步代码至docker容器 参考连接\n容器配置 22端口暴露： 1 docker run --name chartbackend -d -p 5556:5555 -p8022:22 reg.qloudhub.com/qloudpaas/chartbackend:latest4 安装配置ssh服务 1 2 3 4 5 6 7 # Ubuntu 16.04 apt install openssh-server sed -i\u0026#39;s/PermitRootLogin prohibit-password/PermitRootLogin yes/\u0026#39; /etc/ssh/sshd_config # sed \u0026#39;s@sessions*requireds*pam_loginuid.so@session optional pam_loginuid.so@g\u0026#39; -i /etc/pam.d/sshd # echo \u0026#34;export VISIBLE=now\u0026#34; \u0026gt;\u0026gt; /etc/profile service ssh restart 设置容器用户名密码 1 2 3 passwd # 查看用户 whoami pycharm配置 add sftp server PyCharm Tools \u0026gt; Deployment \u0026gt; Configuration\nset project interpreter use sftp\u0026rsquo;s 点击 PyCharm 的 File \u0026gt; Setting \u0026gt; Project \u0026gt; Project Interpreter 右边的设置按钮新建一个项目的远程解释器：\n","description":"","id":120,"section":"posts","tags":["Python","Pycharm","个人工具"],"title":"Pycharm配置Sftp远程开发","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-05-13-pycharm_%E9%85%8D%E7%BD%AEsftp%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91/"},{"content":"1. ubuntu 18.04 install Ansible software-properties-common package installed. This software will make it easier to manage this and other independent software repositories:\n1 2 apt update apt install software-properties-common Then add the Ansible PPA by typing the following command:\n1 apt-add-repository ppa:ansible/ansible install Ansible\n1 2 apt update apt install ansible 2. config ssh access to ansible-hosts 3. ansible 注意 ansible 主机需要安装 pip install netaddr，因为 playbook 依赖 ansible 主机需要安装 apt install sshpass ，因为使用密码连接 ansible 主机需要安装 apt install zip unzip 因为 playbook 需要解压文件 ansible 主机需要配置 ansible 的host_key_checking(/etc/ansible/ansible.cfg)为False，因为所有主机都是第一次连接，还没有主机指纹在known_hosts中，需要忽略 4. 测试Ansible-Hosts连通性方法 vi /etc/ansible/hosts追加以下内容，IP地址即为要测试的机器 1 2 [test] 10.8.2.95 ansible_ssh_user=root ansible_ssh_pass=Qloud@123 docker_registry=true 执行以下命令，用ping模块进行测试。test为上面为hosts配置的主机组名字。 1 ansible -i /etc/ansible/hosts test -m ping 5. Ansible 的一些约定 inventory 主机清单\n-i参数指定主机清单。例如ansible-playbook -i inventory.py nomad.yaml\n1.1 静态inventory，通过静态配置文件inventory.json配置。\n1.2 动态inventory，通过动态生成脚本inventory.py生成。\nroles目录必须与playbook文件同级，并且文件夹名必须为roles。playbook文件中通过roles下的各个文件夹名字引用role\n例如\n1 2 3 4 5 6 - name: install mirrors and initialization hosts: all roles: # roles/ - yum-mirrors # |-- yum-mirrors/ - initialization # |-- initializations/ - docker-registry # |-- docker-registry/ 单个role目录结构说明。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . ├── install_nginx.yml # playbook 文件和 roles 目录应该处于平级目录 └── roles # 存放所有角色的的目录 └── nginx # nginx 角色 │ ├── defaults # 设定默认变量 │ │ └── main.yml │ ├── files # 存放由 copy 或 script 模块等调用的文件 │ │ └── index.html │ ├── handlers # 触发器任务 │ │ └── main.yml │ ├── meta # 定义当前角色的特殊设定及其依赖关系 │ ├── tasks # 定义任务，它是 role 的基本元素 │ │ └── main.yml │ ├── templates # templates 模块查找所需要模板文件的目录 │ │ └── nginx.conf.j2 │ └── vars # 定义变量 │ └── main.yml └── php # php 角色 └── ... playbook文件的定义中，优先级: role \u0026gt; task; 如果task-A必须要在某role-B之前执行，需要将task-A封装为role-A，放到role-B之前。\ntask中常用的模块\n模块名称 作用 ping 检查指定节点机器是否还能连通 command 执行命令模块，可以不填，是ansible默认的模块，命令中无法使用变量，管道。 shell 启动一个子shell执行命令，执行的命令中有管道或者变量，就需要使用shell模块。 script 将本机的shell脚本在被管理主机运行 copy 将本机复制文件到远程位置 service 用于控制远程主机的服务 cron 用于管理定时任务 file 用于远程主机上的文件操作 yum 使用yum包管理器来管理软件包 user、group user、goup分别请求：useradd、userdel、usermod；groupadd、groupdel、groupmod filesystem 在块设备上创建文件系统 get_url 下载文件 synchronize 同步文件模块 Reference Install Ansible on Ubuntu 18.04\n官方文档\n中文文档\nansible Ad-Hoc命令集\n金恒博客\n","description":"记录Ansible使用，包括环境准备、注意事项与操作记录","id":121,"section":"posts","tags":["Ansible","运维笔记","Python"],"title":"简记 Ansible 使用","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-12-13-ansible_%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"},{"content":"环境准备 1. install nvm 1 2 3 4 5 6 # refrence (https://hackernoon.com/how-to-install-node-js-on-ubuntu-16-04-18-04-using-nvm-node-version-manager-668a7166b854) curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.34.0/install.sh | bash bash install_nvm.sh source ~/.profile nvm --version nvm ls-remote 2. install nodejs 1 2 3 4 nvm install 10.15 nvm use 10.15 node -v npm -v 3. install+set yarn 1 2 3 4 npm i -g npm --registry https://registry.npm.taobao.org npm i -g yarn --registry https://registry.npm.taobao.org # set yarn use taobao proxy yarn config set registry https://registry.npm.taobao.org 4. install hexo 1 2 3 4 5 6 7 # install pkg yarn install # 安装包 npm install hexo-generator-searchdb --save npm install -g hexo-cli npm install -g hexo@3.9.0 使用说明 1. 本地调试 1 2 3 4 5 6 7 # local start hexo g ## 启动服务 hexo s ## 清理 hexo clean 2. 创建博客 1 2 3 4 5 6 7 8 9 10 11 12 # 创建博客（TITLE 不能带空格，不能加特殊字符） hexo new devops --path devops/ TITLE # 创建草稿 hexo new draft hexo常用命令备忘录 # 本机预览草稿 hexo S --draft # 将草稿发布为正式文章 hexo P hexo常用命令备忘录 # 或者 将草稿 以 bash 的布局发布(不支持--path参数知道目录，文件会保存在_post目录下，只能手动移动到相应子文件夹下) hexo publish bash hexo常用命令备忘录 配置文件 ./_config.yml\n./themes/next/_config.yml\n./source/_data/next.yml\n常见配置 1. 放图片或文件下载 本网站挂载\nhexo在构建成静态页面时，会将目录./source/images/下的内容全部拷贝至./public/images/目录。而public目录为网站根目录。 所以需要以下操作：\n将文件或照片放至./source/images/目录下 在md文件中，图片通过![例子](/images/\u0026lt;相对source/images目录的路径\u0026gt;)或\u0026lt;img src=\u0026quot;/images/\u0026lt;相对source/images目录的路径\u0026gt;\u0026quot; width=\u0026quot;80%\u0026quot;\u0026gt;\n文件通过[例子-文件](/images/\u0026lt;相对source/images目录的路径\u0026gt;) hexo构建后的静态网页会将source目录下的文件夹(除_data/, _drafts, posts)放至 根目录下，所以可以通过绝对路径索引。\n第三方工具挂载 使用chrome插件微博图床工具上传图片 将url放至md文件中例如![xxx图片](https://hex-cdn.oss-cn-hangzhou.aliyuncs.com/old/yNuAgl.jpg) 遗留问题 计划迁移 hugo, 遗留以下问题 暂不处理\nlocal-search设置\nCDN加速\n国内字体\n参考 Hexo生成Post: post、page、draft\nHexo文章保存为草稿\nHexo+Github博客搭建小白教程\n","description":"记录hexo的环境准备、常用命令、常规配置。","id":122,"section":"posts","tags":["个人工具","Hexo","Blog"],"title":"hexo常用命令备忘录","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-06-22-hexo_%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%E5%BD%95/"},{"content":"云原生，目前坐标西安。刚毕业两三年用Python做安全平台开发。18年入SRE岗，接触Kubernetes、devops、云原生，打开新世界大门。19年开始将Golang作为主要语言，成为一名Gopher。\n22年初集成优秀开源项目、开发创新平台。语言学习以及平台框架都渐入佳境。喜欢瞎折腾感兴趣的开源项目。本站主要作为工作和学习生活中的备忘录。\n三个方向\ngo的运行底层原理 （为什么） go的设计模式 （怎么写） 算法 （上魔法） 领域\n存储 网络 运行时 Learn more on GitHub.\n","description":"大胆假设 小心求证 认真做事 严谨做人","id":123,"section":"page","tags":null,"title":"关于","uri":"https://hex-go.github.io/page/about/"},{"content":" 汇总的Linux面试题，仅用于个人备忘\n1、如何看当前Linux系统有几颗物理CPU和每颗CPU的核数？ 查看物理cup：\n1 cat /proc/cpuinfo|grep -c ‘physical id’ 查看每颗cup核数\n1 cat /proc/cpuinfo|grep -c ‘processor’ 2、查看系统负载有两个常用的命令，是哪两个？这三个数值表示什么含义呢？ （1）命令：w\nw命令用于显示目前登入系统的用户信息，如下。\n1 2 3 4 hex@Hex-Code:~$ w 12:42:51 up 1 day, 1:28, 1 user, load average: 0.00, 0.00, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT hex pts/1 - Mon11 25:28m 0.06s 0.06s -bash （2）命令：uptime\n其中load average即系统负载，三个数值分别表示一分钟、五分钟、十五分钟内系统的平均负载，即平均任务数。\n3、vmstat r, b, si, so, bi, bo 这几列表示什么含义呢？ 执行命令vmstat，结果如下图。\n1 2 3 4 hex@Hex-Code:~$ vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 29823280 233316 1270552 0 0 1 0 3 12 0 0 100 0 0 r：表示running，表示正在跑的任务数\nb：表示blocked，表示被阻塞的任务数\nsi：表示有多少数据从交换分区读入内存\nso：表示有多少数据从内存写入交换分区\nbi：表示有多少数据从磁盘读入内存\nbo：表示有多少数据从内存写入磁盘\n简记：\ni \u0026ndash;input，进入内存\no \u0026ndash;output，从内存出去\ns \u0026ndash;swap，交换分区\nb \u0026ndash;block，块设备，磁盘。单位都是KB。\n4、linux系统里，您知道buffer和cache如何区分吗？ buffer和cache都是内存中的一块区域，当CPU需要写数据到磁盘时，由于磁盘速度比较慢，所以CPU先把数据存进buffer，然后CPU去执行其他任务，buffer中的数据会定期写入磁盘；当CPU需要从磁盘读入数据时，由于磁盘速度比较慢，可以把即将用到的数据提前存入cache，CPU直接从Cache中拿数据要快的多。\n5、使用top查看系统资源占用情况时，哪一列表示内存占用呢？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 hex@Hex-Code:~$ top top - 12:45:32 up 1 day, 1:31, 1 user, load average: 0.00, 0.00, 0.00 Tasks: 50 total, 1 running, 49 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st MiB Mem : 31456.3 total, 29122.7 free, 864.7 used, 1468.9 buff/cache MiB Swap: 8192.0 total, 8192.0 free, 0.0 used. 30143.0 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 167124 12484 8056 S 0.0 0.0 5:08.46 systemd 2 root 20 0 2276 1292 1184 S 0.0 0.0 0:00.00 init-systemd(Ub 7 root 20 0 2320 136 132 S 0.0 0.0 0:00.02 init 36 root 19 -1 48160 16460 15340 S 0.0 0.1 0:00.25 systemd-journal 61 root 20 0 22176 6004 4476 S 0.0 0.0 0:00.21 systemd-udevd 73 root 20 0 4496 192 44 S 0.0 0.0 0:00.00 snapfuse 如上所示：\nVIRT：虚拟内存用量\nRES：物理内存用量\nSHR：共享内存用量\n%MEM：内存用量\n%CPU：cpu用量\n6、如何实时查看网卡流量为多少？如何查看历史网卡流量？ 安装sysstat包，使用sar命令查看。\n#安装sysstat包，获得sar命令\nyum install -y sysstat\n#查看网卡流量，默认10分钟更新一次\nsar -n DEV\n#一秒显示一次，一共显示10次\nsar -n DEV 1 10\n#查看指定日期的流量日志\nsar -n DEV -f /var/log/sa/sa22\n7、如何查看当前系统都有哪些进程？ 可以使用ps -aux 或者ps –elf命令。\nps –aux命令结果如下。\n1 2 3 4 5 6 7 hex@Hex-Code:~$ ps -aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.3 0.0 167280 12484 ? Ss Apr08 5:08 /sbin/init root 2 0.0 0.0 2276 1292 ? Sl Apr08 0:00 /init root 7 0.0 0.0 2320 136 ? Sl Apr08 0:00 plan9 --control-socket 6 --log-level 4 --server-fd 7 --pipe-fd 9 --log-truncate root 36 0.0 0.0 48160 16460 ? S\u0026lt;s Apr08 0:00 /lib/systemd/systemd-journald root 61 0.0 0.0 22176 6004 ? Ss Apr08 0:00 /lib/systemd/systemd-udevd ps –elf结果如下\n1 2 3 4 5 6 7 hex@Hex-Code:~$ ps -elf F S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD 4 S root 1 0 0 80 0 - 41820 - Apr08 ? 00:05:08 /sbin/init 5 S root 2 1 0 80 0 - 569 - Apr08 ? 00:00:00 /init 0 S root 7 2 0 80 0 - 580 - Apr08 ? 00:00:00 plan9 --control-socket 6 --log-level 4 --server-fd 7 --pipe-fd 9 --log-truncate 4 S root 36 1 0 79 -1 - 12040 - Apr08 ? 00:00:00 /lib/systemd/systemd-journald 4 S root 61 1 0 80 0 - 5544 - Apr08 ? 00:00:00 /lib/systemd/systemd-udevd 8、ps 查看系统进程时，有一列为STAT， 如果当前进程的stat为Ss 表示什么含义？如果为Z表示什么含义？ S表示正在休眠；s表示主进程；Z表示僵尸进程。\n示例见。\n1 2 3 4 5 6 7 hex@Hex-Code:~$ ps -aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.3 0.0 167280 12484 ? Ss Apr08 5:08 /sbin/init root 2 0.0 0.0 2276 1292 ? Sl Apr08 0:00 /init root 7 0.0 0.0 2320 136 ? Sl Apr08 0:00 plan9 --control-socket 6 --log-level 4 --server-fd 7 --pipe-fd 9 --log-truncate root 36 0.0 0.0 48160 16460 ? S\u0026lt;s Apr08 0:00 /lib/systemd/systemd-journald root 61 0.0 0.0 22176 6004 ? Ss Apr08 0:00 /lib/systemd/systemd-udevd 9、如何查看系统都开启了哪些端口？ 命令：netstat -lnp\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 hex@Hex-Code:~$ netstat -lnp (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:9999 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.42:53 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::9999 :::* LISTEN - tcp6 0 0 :::22 :::* LISTEN - udp 0 0 127.0.0.53:53 0.0.0.0:* - udp 0 0 127.0.0.42:53 0.0.0.0:* - udp 0 0 127.0.0.1:323 0.0.0.0:* - udp6 0 0 ::1:323 :::* - Active UNIX domain sockets (only servers) Proto RefCnt Flags Type State I-Node PID/Program name Path 10、如何查看网络连接状况？ 命令：netstat –an\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 hex@Hex-Code:~$ netstat -an Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:9999 0.0.0.0:* LISTEN tcp 0 0 127.0.0.42:53 0.0.0.0:* LISTEN tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp6 0 0 :::9999 :::* LISTEN tcp6 0 0 :::22 :::* LISTEN udp 0 0 127.0.0.53:53 0.0.0.0:* udp 0 0 127.0.0.42:53 0.0.0.0:* udp 0 0 127.0.0.1:323 0.0.0.0:* udp6 0 0 ::1:323 :::* Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node Path unix 2 [ ACC ] STREAM LISTENING 25616 /run/WSL/2_interop unix 2 [ ACC ] STREAM LISTENING 18464 /run/WSL/1_interop 11、想修改ip，需要编辑哪个配置文件，修改完配置文件后，如何重启网卡，使配置生效？ 使用vi或者vim编辑器编辑网卡配置文件/etc/sysconfig/network-scripts/ifcft-eth0（如果是eth1文件名为ifcft-eth1），内容如下：\nDEVICE=eth0\nHWADDR=00:0C:29:06:37:BA\nTYPE=Ethernet\nUUID=0eea1820-1fe8-4a80-a6f0-39b3d314f8da\nONBOOT=yes\nNM_CONTROLLED=yes\nBOOTPROTO=static\nIPADDR=192.168.140.130\nNETMASK=255.255.255.0\nGATEWAY=192.168.140.2\nDNS1=192.168.140.2\nDNS2=8.8.8.8\n修改网卡后，可以使用命令重启网卡：\n1 2 ifdown eth0 ifup eth0 也可以重启网络服务：\nservice network restart\n12、能否给一个网卡配置多个IP? 如果能，怎么配置？ 可以给一个网卡配置多个IP，配置步骤如下：\n（1）查看eth0的配置，命令如下。\ncat /etc/sysconfig/network-scripts/ifcfg-eth0\n例如ifcfg-eth0 文件内容如下：\nDEVICE=eth0\nHWADDR=00:0C:29:06:37:BA\nTYPE=Ethernet\nUUID=0eea1820-1fe8-4a80-a6f0-39b3d314f8da\nONBOOT=yes\nNM_CONTROLLED=yes\nBOOTPROTO=static\nIPADDR=192.168.140.130\nNETMASK=255.255.255.0\nGATEWAY=192.168.140.2\nDNS1=192.168.140.2\nDNS2=8.8.8.8\n（2）新建一个ifcfg-eth0:1文件，命令如下。\ncp /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth0:1\n1\n（3）使用vi编辑器修改其内容。\nvi /etc/sysconfig/network-scripts/ifcfg-eth0:1\n1\n多绑定一个ip192.168.140.131，内容如下。\nDEVICE=eth0:1\nHWADDR=00:0C:29:06:37:BA\nTYPE=Ethernet\nUUID=0eea1820-1fe8-4a80-a6f0-39b3d314f8da\nONBOOT=yes\nNM_CONTROLLED=yes\nBOOTPROTO=static\nIPADDR=192.168.140.131\nNETMASK=255.255.255.0\nGATEWAY=192.168.140.2\nDNS1=192.168.140.2\nDNS2=8.8.8.8\n（4）重启网络服务：\nservice network restart\n13、如何查看某个网卡是否连接着交换机？ 使用命令mii-tool，例如查询网卡eth0\nmii-tool eth0\n14、如何查看当前主机的主机名，如何修改主机名？要想重启后依旧生效，需要修改哪个配置文件呢？ （1）查看主机名：hostname\n（2）修改主机名：hostname centos-db\n永久生效需要修改配置文件network：\nvi /etc/sysconfig/network\n将HOSTNAME等号后面改成新的主机名。\nNETWORKING=yes\nHOSTNAME= centos-db\n15、设置DNS需要修改哪个配置文件？ （1）在文件 /etc/resolv.conf 中设置DNS\n（2）在文件 /etc/sysconfig/network-scripts/ifcfg-eth0 中设置DNS\n16、使用iptables 写一条规则：把来源IP为192.168.1.101访问本机80端口的包直接拒绝 iptables -I INPUT -s 192.168.1.101 -p tcp \u0026ndash;dport 80 -j REJECT\n17、要想把iptable的规则保存到一个文件中如何做？如何恢复？ 使用iptables-save重定向到文件中：\niptables-save \u0026gt; 1.ipt\n1\n使用iptables-restore反重定向回来：\niptables-restore \u0026lt; 1.ipt\n1\n18、如何备份某个用户的任务计划？ 将/var/spool/cron/目录下指定用户的任务计划拷贝到备份目录cron_bak/下即可：\ncp /var/spool/cron/rachy /tmp/bak/cron_bak/\n19、任务计划格式中，前面5个数字分表表示什么含义？\n依次表示：分、时、日、月、周\n20、如何可以把系统中不用的服务关掉？\n（1）使用可视化工具：ntsysv\n（2）使用命令：chkconfig servicename off\n21、如何让某个服务（假如服务名为 nginx）只在3,5两个运行级别开启，其他级别关闭？\n先关闭所有运行级别：chkconfig nginx off\n然后打开35运行级别：chkconfig \u0026ndash;level 35 nginx on\n22、rsync 同步命令中，下面两种方式有什么不同呢？\n(1) rsync -av /dira/ ip:/dirb/\n(2) rsync -av /dira/ ip::dirb\n其中(1)是通过ssh方式同步的，(2)后者是通过rsync服务的方式同步的。\n23、rsync 同步时，如果要同步的源中有软连接，如何把软连接的目标文件或者目录同步？\n同步源文件需要加-L选项\n24、某个账号登陆linux后，系统会在哪些日志文件中记录相关信息？ 用户身份验证过程记录在/var/log/secure中，登录成功的信息记录在/var/log/wtmp。\n25、网卡或者硬盘有问题时，我们可以通过使用哪个命令查看相关信息？ 使用命令dmesg\n1 2 3 4 5 6 7 8 9 10 hex@Hex-Code:~$ dmesg [ 0.000000] Linux version 5.15.137.3-microsoft-standard-WSL2 (root@613b06102641) (gcc (GCC) 11.2.0, GNU ld (GNU Binutils) 2.37) #1 SMP Mon Nov 6 23:32:38 UTC 2023 [ 0.000000] Command line: initrd=\\initrd.img WSL_ROOT_INIT=1 panic=-1 nr_cpus=16 bonding.max_bonds=0 dummy.numdummies=0 fb_tunnels=none console=hvc0 debug pty.legacy_count=0 [ 0.000000] KERNEL supported cpus: [ 0.000000] Intel GenuineIntel [ 0.000000] AMD AuthenticAMD [ 0.000000] Centaur CentaurHauls [ 0.000000] BIOS-provided physical RAM map: [ 0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009ffff] usable [ 0.000000] BIOS-e820: [mem 0x00000000000e0000-0x00000000000e0fff] reserved 26、分别使用xargs和exec实现这样的需求，把当前目录下所有后缀名为.txt的文件的权限修改为777\n使用xargs ：\nfind ./ -type f -name \u0026ldquo;*.txt\u0026rdquo; |xargs chmod 777\n使用exec ：\nfind ./ -type f -name \u0026ldquo;*.txt\u0026rdquo; -exec chmod 777 {} ;\n27、有一个脚本运行时间可能超过2天，如何做才能使其不间断的运行，而且还可以随时观察脚本运行时的输出信息？\n使用screen工具\n28、在Linux系统下如何按照下面要求抓包：只过滤出访问http服务的，目标ip为192.168.0.111，一共抓1000个包，并且保存到1.cap文件中？\n使用tcpdump命令：\ntcpdump -nn -s0 host 192.168.0.111 and port 80 -c 1000 -w 1.cap\n29、rsync 同步数据时，如何过滤出所有.txt的文件不同步？\n加上–exclude选项：–exclude=“*.txt”\n30、rsync同步数据时，如果目标文件比源文件还新，则忽略该文件，如何做？\n保留更新使用-u或者–update选项\n31、想在Linux命令行下访问某个网站，并且该网站域名还没有解析，如何做？\n在/etc/hosts文件中增加一条从该网站域名到其IP的解析记录即可，或者使用curl -x\n32、自定义解析域名的时候，我们可以编辑哪个文件？是否可以一个ip对应多个域名？是否一个域名对应多个ip？\n编辑 /etc/hosts 文件,可以一个ip对应多个域名，不可以一个域名对多个ip。\n33、我们可以使用哪个命令查看系统的历史负载（比如说两天前的）？\n#例如查看22号的系统负载\nsar -q -f /var/log/sa/sa22\n34、在Linux下如何指定dns服务器，来解析某个域名？\n使用dig命令，例如使用谷歌DNS解析百度\ndig @8.8.8.8 www.baidu.com\n35、使用rsync同步数据时，假如我们采用的是ssh方式，并且目标机器的sshd端口并不是默认的22端口，那我们如何做？\n方式1：\nrsync \u0026ldquo;\u0026ndash;rsh=ssh -p 10022\u0026rdquo;\n方式2：\nrsync -e \u0026ldquo;ssh -p 10022\u0026rdquo;\n36、rsync同步时，如何删除目标数据多出来的数据，即源上不存在，但目标却存在的文件或者目录？\n加上–delete选项即可。\n37、使用free查看内存使用情况时，哪个数值表示真正可用的内存量？\nfree命令后第二列的值，如下图。\n1 2 3 4 hex@Hex-Code:~$ free -h total used free shared buff/cache available Mem: 30Gi 862Mi 28Gi 3.0Mi 1.4Gi 29Gi Swap: 8.0Gi 0B 8.0Gi 38、有一天你突然发现公司网站访问速度变的很慢很慢，你该怎么办呢？\n可以从系统负载和网卡流量方面入手分析。分析系统负载，使用w命令或者uptime命令查看系统负载，如果负载很高，则使用top命令查看CPU，MEM等占用情况，要么是CPU繁忙，要么是内存不够，如果这二者都正常，再去使用sar命令分析网卡流量，分析是不是遭到了攻击。一旦分析出问题的原因，采取对应的措施解决，如决定要不要杀死一些进程，或者禁止一些访问等。\n39、rsync使用服务模式时，如果我们指定了一个密码文件，那么这个密码文件的权限应该设置成多少才可以？\n600或400\n40、给您一台最小化安装的linux机器，如何进行基础优化？\n（1）更新yum官方源\n（2）关闭不需要的服务\n（3）关闭不需要的TTY\n（4）对TCP/IP网络参数进行调整。例如：优化Linux下的内核TCP参数以提高系统性能。\n（5）设置时间同步\n（6）优化最大文件数限制\n（7）关闭SELINUX\n（8）修改SSH登录配置\n（9）清理登陆的时候显示的系统及内核版本\n（10）删除不必要的系统用户和群组\n（11）关闭重启ctl-alt-delete组合键\n（12）设置一些全局变量\n（13）设置history历史记录\n（14）centos6.4最小化安装后启动网卡\n（15）添加普通用户，设置sudo权限\n（16）禁止root远程用户登录\n（17）sed修改远程端口\n（18）防火墙iptables配置。\n（19）修改默认DNS\n（20）安装必要软件,更新yum源 [epel源]\n（21）更新内核和软件到最新版本\n（22）去除上次登录的信息\n41、请说出内核调优配置文件名字？举例几个内核需要优化的参数配置？\n文件名称：/etc/sysctl.conf\n以下表示开启TCP连接中TIME-WAIT sockets的快速收回功能，默认为 0 ，表示关闭。\nnet.ipv4.tcp_tw_recycle = 1\n以下表示开启重用。允许将TIME-WAIT sockets重新用于新的 TCP 连接，默认为 0 表示关闭。\nnet.ipv4.tcp_tw_reuse = 1\n在内核放弃建立连接之前发送SYN包的数量。 默认6（即时间为2^7-1 =127s）\nnet.ipv4.tcp_syn_retries = 6\n#允许系统打开的端口范围\nnet.ipv4.ip_local_port_range = 1024 65000\n最大打开文件数，单个进程可分配的最大文件数\nfs.nr_open = 10000000\n表示系统级别的能够打开的文件句柄的数量。是对整个系统的限制,并不是针对用户的\nfs.file-max = 11000000\n42、当你需要给命令绑定一个宏或者按键的时候，应该怎么做呢?\n可以使用bind命令，bind可以很方便地在shell中实现宏或按键的绑定。在进行按键绑定的时候，我们需要先获取到绑定按键对应的字符序列。\n例如获取F12的字符序列获取方法如下：\n先按下Ctrl+V,然后按下F12 .我们就可以得到F12的字符序列 ^[[24~。\n接着使用bind进行绑定。\nbind ‘”\\e[24~\u0026quot;:\u0026ldquo;date\u0026rdquo;'\n注意：相同的按键在不同的终端或终端模拟器下可能会产生不同的字符序列。也可以使用showkey -a命令查看按键对应的字符序列。\n43、如果一个linux新手想要知道当前系统支持的所有命令的列表，他需要怎么做？\n使用命令compgen -c，可以打印出所有支持的命令列表。\n44、如果你的助手想要打印出当前的目录栈，你会建议他怎么做?\n使用Linux 命令dirs可以将当前的目录栈打印出来。\n45、你的系统目前有许多正在运行的任务，在不重启机器的条件下，有什么方法可以把所有正在运行的进程移除呢?\n使用Linux命令disown -r可以将所有正在运行的进程移除。\n46、bash shell 中的hash 命令有什么作用?\nlinux命令hash管理着一个内置的哈希表，记录了已执行过的命令的完整路径, 用该命令可以打印出你所使用过的命令以及执行的次数。\n47、哪一个bash内置命令能够进行数学运算?\nbash shell 的内置命令let可以进行整型数的数学运算。\n48、怎样一页一页地查看一个大文件的内容呢?\n通过管道将命令”cat file_name.txt” 和 ’more’ 连接在一起可以实现这个需要.\ncat file_name.txt | more\n49、数据字典属于哪一个用户的?\n数据字典是属于’SYS’用户的，用户‘SYS’ 和 ’SYSEM’是由系统默认自动创建的。\n50、怎样查看一个linux命令的概要与用法?\n使用命令whatis 可以先出显示出这个命令的用法简要。\n例如：可以使用whatis netstat 去查看netstat命令的介绍以及使用简要。\n51、使用哪一个命令可以查看自己文件系统的磁盘空间配额呢?\n使用命令repquota能够显示出一个文件系统的配额信息\n52、如何查看 http 的并发请求数与其 TCP 连接状态？\nnetstat -n | awk \u0026lsquo;/^tcp/ {++b[$NF]} END {for(a in b) print a, b[a]}\u0026rsquo;\n53、如何修改系统打开最大句柄数？\nulimit -n 查看 linux 系统打开最大的文件描述符，这里默认 1024，不修改这里 web 服务器修改再大也没用。\n修改/etc/security/limits.conf文件，修改内容如下。\nsoft nofile 10240 hard nofile 10240\n54、用 tcpdump 嗅探 80 端口的访问看看谁最高 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F\u0026quot;.\u0026quot; \u0026lsquo;{print $1\u0026quot;.\u0026quot;$2\u0026quot;.\u0026quot;$3\u0026quot;.\u0026quot;$4}\u0026rsquo; | sort | uniq -c | sort -nr |head -5\n55、查看当前系统每个 IP 的连接数\nnetstat -n | awk \u0026lsquo;/^tcp/ {print $5}\u0026rsquo;| awk -F: \u0026lsquo;{print $1}\u0026rsquo; | sort | uniq -c | sort -rn\n56、shell 下 32 位随机密码生成\ncat /dev/urandom | head -1 | md5sum | head -c 32 \u0026raquo; /pass\n1\n57.如何查看二进制文件的内容？\n我们一般通过 hexdump 命令 来查看二进制文件的内容。\n例如hexdump -C XXX(文件名)， -C 是参数，不同的参数有不同的意义。\n简单例举几个参数：\n-C 是比较规范的 十六进制和 ASCII 码显示\n-c 是单字节字符显示\n-b 单字节八进制显示\n-o 是双字节八进制显示\n-d 是双字节十进制显示\n-x 是双字节十六进制显示\n58、ps aux 中的 VSZ 代表什么意思，RSS 代表什么意思\nVSZ:虚拟内存集,进程占用的虚拟内存空间\nRSS:物理内存集,进程战用实际物理内存空间\n59、如何检测并修复/dev/hda5？\nfsck 用来检查和维护不一致的文件系统。若系统掉电或磁盘发生问题，可利用 fsck 命令对文件系统进行检查。\n60、描述Linux 系统的开机启动顺序\n加载 BIOS–\u0026gt;读取 MBR–\u0026gt;Boot Loader–\u0026gt;加载内核–\u0026gt;用户层 init 一句 inittab 文件来设定系统运行的等级(一般 3 或者 5，3 是多用户命令行，5 是界面)–\u0026gt;init 进程执行 rc.syninit–\u0026gt;启动内核模块–\u0026gt;执行不同级别运行的脚本程序–\u0026gt;执行/etc/rc.d/rc.local(本地运行服务)–\u0026gt;执行/bin/login,就可以登录了。\n61、符号链接与硬链接的区别？\n我们可以把符号链接，也就是软连接 当做是 windows 系统里的 快捷方式。\n硬链接就好像是又复制了一份。\n例如下述命令，这是硬链接，相当于复制，不可以跨分区，但修改 3.txt,4.txt会跟着变，若删除 3.txt,4.txt不受任何影响。\nln 3.txt 4.txt\n例如下述命令， 这是软连接，相当于快捷方式。修改 4.txt,3.txt也会跟着变，若删除3.txt,4.txt就坏掉了。不可以用了。\nln -s 3.txt 4.txt\n62、如何保存当前磁盘分区的分区表？\ndd 命令是以个强大的命令，在复制的同时进行转换\ndd if=/dev/sda of=./mbr.txt bs=1 count=512\n63、说说FTP 的主动模式和被动模式\nFTP 协议有两种工作方式，PORT 方式和 PASV 方式，中文意思为主动式和被动式。\nPORT（主动）方式的连接过程是：\n客户端向服务器的 FTP 端口（默认是 21）发送连接请 求，服务器接受连接，建立一条命令链路。当需要传送数据时，客户端在命令链路上用 PORT 命令告诉服务器：“我打开了 XX 端口，你过来连接我”。于是服务器从 20 端口向客户端的 XX 端口发送连接请求，建立一条数据链路来传送数据。\nPASV（被动）方式的连接过程是：\n客户端向服务器的 FTP 端口（默认是 21）发送连接请 求，服务器接受连接，建立一条命令链路。当需要传送数据时，服务器在命令链路上用 PASV 命令告诉客户端：“我打开了 XX 端口，你过来连接我”。于是客户端向服务器的 XX 端口 发送连接请求，建立一条数据链路来传送数据。\n从上面可以看出，两种方式的命令链路连接方法是一样的，而数据链路的建立方法就完 全不同。\n64、怎么把脚本添加到系统服务里，即用 service 来调用？\n在脚本里加入如下内容，第一行脚本自带，第三行为脚本描述，无实际意义。\n#!/bin/bash\n65、如何将本地80端口的请求转发到8080端口,当前主机IP为192.168.16.1,其中本地网卡eth0\n方式一：\niptables-tnat -A PREROUTING -d 192.168.16.1 -p tcp –dport 80 -j DNAT –to192.168.16.1:8080\n方式二：\niptables-t nat -A PREROUTING -i eth0 -d 192.168.16.1 -p tcp -m tcp –dport 80 -j REDIRECT –to-ports 8080\n66、什么是NAT,常见分为那几种，DNAT与SNAT有什么不同，应用事例有那些？\nSNAT，DNAT，MASQUERADE都是NAT。\nMASQUERADE是SNAT的一个特例。\nSNAT是指在数据包从网卡发送出去的时候，把数据包中的源地址部分替换为指定的IP，这样，接收方就认为数据包的来源是被替换的那个IP的主机。\nMASQUERADE是用发送数据的网卡上的IP来替换源IP，因此，对于那些IP不固定的场合，比如拨号网络或者通过dhcp分配IP的情况下，就得用MASQUERADE。\nDNAT，就是指数据包从网卡发送出去的时候，修改数据包中的目的IP，表现为如果你想访问A，可是因为网关做了DNAT，把所有访问A的数据包的目的IP全部修改为B，那么，你实际上访问的是B，因为，路由是按照目的地址来选择的，因此，DNAT是在PREROUTING链上来进行的，而SNAT是在数据包发送出去的时候才进行，因此是在POSTROUTING链上进行的。\n67、包过滤防火墙与代理应用防火墙有什么区别，能列举几种相应的产品吗？\n包过滤防火墙是根据包头进行的过滤，并且是处于网络层的，根据包的源ip地址，目标ip地址，协议类型，端口号，进行过滤；代理应用防火墙工作在应用层，他使用代理服务器技术，将内网对外网的访问，变为防火墙对外网的访问，可以对包的内容进行分辨，从而过滤。\n代理应用防火墙：天融信GFW4000\n包过滤防火墙：华为NE 16E\n68、iptables是否支持time时间控制用户行为，如有请写出具体操作步骤。\n支持。需要增加相关支持的内核补丁，并且要重新编译内核。\n或者使用crontab配合iptables：\n首先：vi /deny.bat 输入以下命令后保存退出。\n/sbin/iptables -A OUTPUT -p tcp -s 192.168.1.0/24 \u0026ndash;dport 80 -j DROP\n打开crontab-e输入以下内容：\n00 21＊　＊　＊ /bin/sh /deny.bat\n69、说出你知道的几种linux/unix发行版本。\nRedhat、CentOS、Fedora、SuSE、Slackware、Gentoo、Debian、Ubuntu、FreeBSD、Solaris、SCO、AIX、HP等等。\n70、列出linux常见打包工具并写相应解压缩参数(至少三种)\ntar、gz、bz三个打包工具。\nTar -xvzf\ngzip -d\nbzip2 -d\n71、计划每星期天早8点服务器定时重启，如何实现？\n执行以下命令：\ncrontab -e\n输入以下内容：\n0008 * * 7 /sbin/init 6\n72、列出作为完整邮件系统的软件,至少二类。\nSendmail,postfix,qmail\n73、当用户在浏览器当中输入一个网站，说说计算机对dns解释经过那些流程？注：本机跟本地dns还没有缓存。\n（1）用户输入网址到浏览器；\n（2）浏览器发出DNS请求信息；\n（3）计算机首先查询本机HOST文件，看是否存在，存在直接返回结果，不存在，继续下一步；\n（4）计算机按照本地DNS的顺序，向合法dns服务器查询IP结果；\n（5）合法dns返回dns结果给本地dns，本地dns并缓存本结果，直到TTL过期，才再次查询此结果；\n（6）返回IP结果给浏览器；\n（7）浏览器根据IP信息，获取页面；\n74、我们都知道，dns既采用了tcp协议，又采用了udp协议，什么时候采用tcp协议？什么时候采用udp协议？为什么要这么设计？\n这个题需要理解的东西比较的多，分以下两个方面：\n（1）从数据包大小上分：UDP的最大包长度是65507个字节，响应dns查询的时候数据包长度超过512个字节，而返回的只要前512个字节，这时名字 解释器通常使用TCP从发原来的请求。\n（2）从协议本身来分：大部分的情况下使用UDP协议，大家都知道UDP协议是一种不可靠的协议，dns不像其它的使用UDP的Internet应用 (如：TFTP，BOOTP和SNMP等)，大部分集中在局域网，dns查询和响应需要经过广域网，分组丢失和往返时间的不确定性在广域网比局域网上更大，这就要求dns客户端需要好的重传和超时算法，这时候使用TCP。\n75、一个EXT3的文件分区，当使用touch test.file命令创建一个新文件时报错，报错的信息是提示磁盘已满，但是采用df -h命令查看磁盘大小时，只使用了，60%的磁盘空间，为什么会出现这个情况，说说你的理由。\n两种情况，一种是磁盘配额问题，另外一种就是EXT3文件系统的设计不适合很多小文件跟大文件的一种文件格式，出现很多小文件时，容易导致inode耗尽了。\n76、我们都知道FTP协议有两种工作模式，说说它们的大概的一个工作流程？\nFTP两种工作模式：主动模式（Active FTP）和被动模式（Passive FTP）\n在主动模式下，FTP客户端随机开启一个大于1024的端口N向服务器的21号端口发起连接，然后开放N+1号端口进行监听，并向服务器发出PORT N+1命令。\n服务器接收到命令后，会用其本地的FTP数据端口（通常是20）来连接客户端指定的端口N+1，进行数据传输。\n在被动模式下，FTP客户端随机开启一个大于1024的端口N向服务器的21号端口发起连接，同时会开启N+1号端口。然后向服务器发送PASV命令，通 知服务器自己处于被动模式。服务器收到命令后，会开放一个大于1024的端口P进行监听，然后用PORTP命令通知客户端，自己的数据端口是P。客户端收到命令后，会通过N+1号端口连接服务器的端口P，然后在两个端口之间进行数据传输。\n总的来说，主动模式的FTP是指服务器主动连接客户端的数据端口，被动模式的FTP是指服务器被动地等待客户端连接自己的数据端口。\n被动模式的FTP通常用在处于防火墙之后的FTP客户访问外界FTp服务器的情况，因为在这种情况下，防火墙通常配置为不允许外界访问防火墙之后主机，而只允许由防火墙之后的主机发起的连接请求通过。\n因此，在这种情况下不能使用主动模式的FTP传输，而被动模式的FTP可以良好的工作。\n77、编写个shell脚本将当前目录下大于10K的文件转移到/tmp目录下\n该问题主要是考察awk的用法：\nfor FileName in ls -l |awk ‘$5\u0026gt;10240 {print $9}’\ndo\nmv $FileName /tmp\ndone\nls -la /tmp\necho “Done! ”\n78、apache有几种工作模式，分别介绍下其特点，并说明什么情况下采用不同的工作模式？\napache主要有两种工作模式：prefork(apache的默认安装模式)和worker(可以在编译的时候加参数–with-mpm- worker选择工作模式)\nprefork的特点是：\n（1）这种模式可以不必在请求到来时再产生新的进程，从而减小了系统开销\n（2）可以防止意外的内存泄漏\n（3）在服务器负载下降的时候会自动减少子进程数\nworker的特点是：\n支持混合的多线程多进程的多路处理模块。如果对于一个高流量的HTTP服务器，worker MPM是一个比较好的选择，因为worker MPM占用的内存要比prefork要小。\n79、名词解释：请解释以下词的含义？\n例如解释以下名词：HDLC,VTP,OSPF,RIP,DDOS,systemV,GNU,netscreen,ssh,smartd,apache,WAIT_TIME 等等。\nHDLC:高级链路控制；\nVTP：vlan 传输协议；\nOSPF：开放最短路径优先；\nRIP：路由信息协议；\nDDOS：分布式拒绝服务攻击；\nsystem V：UNIX版本V；\nGNU：非UNIX，开放源码软件工程；\nnetscreen：国际著名防火墙厂家之一，04年后被juniper收购，变为其防火墙的一个系列；\nssh：安全外壳，防止中间人攻击的一种连接方式；\nsmartd：硬盘检测工具s.m.a.r.t的进程；\nApache：web服务器软件；\nWAIT_TIME：netstat命令显示的参数，客户端正在等待。\n80、编写shell脚本获取本机的网络地址。比如：本机的ip地址是：\n192.168.100.2/255.255.255.0，那么它的网络地址是192.168.100.1/255.255.255.0\n方法一：\n#!/bin/bash\nfile=”/etc/sysconfig/network-scripts/ifcfg-eth0″\nif [ -f $file ] ;then\nIP=grep “IPADDR” $file|awk -F”=” ‘{ print $2 }’\nMASK=grep “NETMASK” $file|awk-F”=” ‘{ print $2 }’\necho “$IP/$MASK”\nexit 1\nfi\n方法二：\n#!/bin/bash\nIP=ifconfig eth0 |grep ‘inet ‘ |sed ’s/^.*addr://g’|sed ’s/ Bcast.*$//g’\nNETMASK=ifconfig eth0 |grep ‘inet ‘|sed ’s/^.*Mask://g’\necho “$IP/$NETMASK”\nexit\n81、在命令行下发一邮件，发件人：123@abc.com,收信人：abc@xyz.com\n使用mail命令\nmail -s \u0026ldquo;hello\u0026rdquo; abc@xyz.com\n82、linux下如何改IP、主机名、DNS？\nsetup命令：\n可以修改IP 和DNS ，修改完后执行重启网络使用命令service network restart，临时修改即时生效，重启后失效。\nHostname命令：\n修改主机名\nIfconfig命令修改IP：\nIfconfig eth0 IP netmask 掩码\n永久修改主机名：\n修改：/etc/sysconfig/network 文件，修改HOSTNAME=主机名\n永久修改IP地址：\n修改 /etc/sysconfig/network-scripts/ifcfg-eth0 文件，修改完后执行重启网络命令service network restart\n83、linux下如何添加路由？\n添加到主机路由\nroute add –host 192.168.168.110 dev eth0\nroute add –host 192.168.168.119 gw 192.168.168.1\n添加到网络的路由\nroute add –net IP netmask MASK deveth0\nroute add –net IP netmask MASK gw IP\n添加默认网关\nroute add default gw IP\n删除路由\nroute del –host 192.168.168.110 dev eth0\n84、简述linux下编译内核的意义与步骤\n编译内核的意义在于让硬件设备更稳定的发挥其应有的效能；\n内核编译：\n（1）内核裁减\n（2）打补丁\n（3）添加新功能/模块\n步骤：\n（1）下载新内核源代码\n（2）配置内核编译参数：make menuconfig\n（3）选择需要添加的模块\n（4）开始编译\n（5）安装编译好到模块和内核\n（6）修改GRUB启动菜单，增加使用新内核启动到项目\n85、简述DDOS攻击的原理\n黑客劫持大量傀儡主机，对目标服务器进行合理的资源请求，导致服务器资源耗尽而不能进行正常的服务。\n86、简述Tcp三次握手的过程\n第一次握手，建立连接，客户端发送SYN包到服务器，并进入SYN_SEND状态，等待服务器确认；\n第二次握手，服务器收到SYN，同时自己也发送一个SYN包和一个ACK包来确认客户端的SYN，并进入SYN_RECV；\n第三次握手，客户端收到服务器发来的SYN+ACK后，回复服务器端一个ACK确认，发送完毕后，双方进入ESTABLISHED状态。\n三次握手成功后，开始传输数据。\n87、简述VPN，常见有哪几种？\nVPN是指在公共的网络上建立专用网络的技术，但是两个节点间并没有物理上的专用的端到端链路，而是通过广域网或者运营商提供的网络平台之上的逻辑网络，用户数据在逻辑链路中传输，它可以有效的节省一般需要达到DDN专线所能达到的同样的目的，而且VPN采用身份验证和加密技术，充分保证了安全性。常见的VPN有：ipsec vpn、PPTPvpn、L2TP vpn、SSL vpn\n88、解释下什么是GPL,GNU,自由软件？\nGPL：（通用公共许可证）：一种授权，任何人有权取得、修改、重新发布自由软件的权力。\nGNU:(革奴计划)：目标是创建一套完全自由、开放的的操作系统。\n自由软件：是一种可以不受限制地自由使用、复制、研究、修改和分发的软件。主要许可证有GPL和BSD许可证两种。\n89、如何选择Linux操作系统版本?\n一般来讲，桌面用户首选Ubuntu；服务器首选RHEL或CentOS，两者中首选CentOS。\n根据具体要求：\n（1）安全性要求较高，则选择Debian或者FreeBSD。\n（2）需要使用数据库高级服务和电子邮件网络应用的用户可以选择SUSE。\n（3）想要新技术新功能功能可以选择Feddora，Feddora是RHEL和CentOS的一个测试版和预发布版本。\n（4）根据现有状况，绝大多数互联网公司选择CentOS。现在比较常用的是6系列，现在市场占有大概一半左右。另外的原因是CentOS更侧重服务器领域，并且无版权约束。\n90、初学者在Linux系统的开机启动项如何选择？\n建议选择五个开机启动项：\n（1）crond： 该服务用于周期地执行系统及用户配置的计划任务。有要周期性执行的任务计划需要开启，此服务是生产场景必须要用的一个软件。\n（2）iptables： iptables包过滤防火墙，有外网IP时，考虑开启。\n（3）network： 启动系统时，若想激活/关闭启动时的各个网络接口，则应（必须）考虑开启。\n（4）sshd： 远程连接Linux服务器时需要用到这个服务程序，所以必须要开启，否则将无法远程连接到Linux服务器。\n（5）rsyslog： 是操作系统提供的一种机制，系统的守护程序通常会使用rsyslog将各种信息收集写入到系统日志文件中，CentOS6以前此服务的名字为syslog。\n（6）sysstat: 是一个软件包，包含监测系统性能及效率的一组工具，这些工具对于Linux系统性能数据很有帮助，比如CPU使用率、硬盘和网络吞吐数据等，这些数据的分析，有利于判断系统运行是否正常，所以它是提高系统运行效率、安全运行服务的助手。\n91、请描述Linux系统优化的12个步骤。\n（1）登录系统:不使用root登录，通过sudo授权管理，使用普通用户登录。\n（2）禁止SSH远程：更改默认的远程连接SSH服务及禁止root远程连接。\n（3）时间同步：定时自动更新服务器时间。\n（4）配置yum更新源，从国内更新下载安装rpm包。\n（5）关闭selinux及iptables（iptables工作场景如有wan ip，一般要打开，高并发除外）\n（6）调整文件描述符数量，进程及文件的打开都会消耗文件描述符。\n（7）定时自动清理/var/spool/clientmquene/目录垃圾文件，防止节点被占满（c6.4默认没有sendmail，因此可以不配。）\n（8）精简开机启动服务（crond、sshd、network、rsyslog）\n（9）Linux内核参数优化/etc/sysctl.conf，执行sysct -p生效。\n更改字符集，支持中文，但是还是建议使用英文，防止乱码问题出现。\n（10）锁定关键系统文件（chattr +i /etc/passwd /etc/shadow /etc/group /etc/gshadow /etc/inittab 处理以上内容后，把chatter改名，就更安全了。）\n（11）清空/etc/issue，去除系统及内核版本登陆前的屏幕显示。\n92、描述Linux运行级别0-6的各自含义\n0：关机模式\n1：单用户模式\u0026lt;==破解root密码\n2：无网络支持的多用户模式\n3：有网络支持的多用户模式（文本模式，工作中最常用的模式）\n4：保留，未使用\n5：有网络支持的X-windows支持多用户模式（桌面）\n6: 重新引导系统，即重启\n93、描述Linux系统从开机到登陆界面的启动过程\n（1）开机BIOS自检，加载硬盘。\n（2）读取MBR,MBR引导。\n（3）grub引导菜单(Boot Loader)。\n（4）加载内核kernel。\n（5）启动init进程，依据inittab文件设定运行级别\n（6）init进程，执行rc.sysinit文件。\n（7）启动内核模块，执行不同级别的脚本程序。\n（8）执行/etc/rc.d/rc.local\n（9）启动mingetty，进入系统登陆界面。\n94、描述Linux下软链接和硬链接的区别\n在Linux系统中，链接分为两种，一种是硬链接（Hard link），另一种称为符号链接或软链接（Symbolic Link）。\n（1）默认不带参数的情况下，ln创建的是硬链接，带-s参数的ln命令创建的是软链接。\n（2）硬链接文件与源文件的inode节点号相同，而软链接文件的inode节点号，与源文件不同，\n（3）ln命令不能对目录创建硬链接，但可以创建软链接。对目录的软链接会经常使用到。\n（4）删除软链接文件，对源文件和硬链接文件无任何影响。\n（5）删除文件的硬链接文件，对源文件及软链接文件无任何影响。\n（6）删除链接文件的源文件，对硬链接文件无影响，会导致其软链接失效（红底白字闪烁状）。\n（7）同时删除源文件及其硬链接文件，整个文件才会被真正的删除。\n（8）很多硬件设备的快照功能，使用的就是类似硬链接的原理。\n（9）软链接可以跨文件系统，硬链接不可以跨文件系统。\n95、生产场景如何对linux系统进行合理规划分区？\n分区的根本原则是简单、易用、方便批量管理。根据服务器角色定位建议如下：\n（1）单机服务器：如8G内存，300G硬盘\n分区： /boot 100-200M，swap 16G，内存大小8G*2，/ 80G，/var 20G（也可不分），/data 180G（存放web及db数据）\n优点：数据盘和系统盘分开，有利于出问题时维护。\nRAID方案：视数据及性能要求，一般可采用raid5折中。\n（2）负载均衡器（如LVS等）\n分区：/boot 100-200M，swap 内存的1-2倍，/ ，\n优点：简单方便，只做转发数据量很少。\nRAID方案：数据量小，重要性高，可采用RAID1\n（3）负载均衡下的RS server\n分区： /boot 100-200M，swap 内存的1-2倍，/\n优点：简单方便，因为有多机，对数据要求低。\nRAID方案：数据量大，重要性不高，有性能要求，数据要求低，可采用RAID0\n（4）数据库服务器mysql及oracle如16/32G内存\n分区：/boot 100-200M，swap 16G，内存的1倍，/ 100G，/data 剩余（存放db数据）\n优点：数据盘和系统盘分开，有利于出问题时维护,及保持数据完整。\nRAID方案：视数据及性能要求主库可采取raid10/raid5，从库可采用raid0提高性能（读写分离的情况下。）\n（5）存储服务器\n分区：/boot 100-200M，swap 内存的1-2倍，/ 100G，/data(存放数据)\n优点：此服务器不要分区太多。只做备份，性能要求低。容量要大。\nRAID方案：可采取sata盘，raid5\n（6）共享存储服务器（如NFS）\n分区：/boot 100-200M，swap 内存的1-2倍，/ 100G，/data(存放数据)\n优点：此服务器不要分区太多。NFS共享比存储多的要求就是性能要求。\nRAID方案：视性能及访问要求可以raid5,raid10,甚至raid0（要有高可用或双写方案）\n（7）监控服务器cacti,nagios\n分区：/boot 100-200M，swap 内存的1-2倍，/\n优点：重要性一般，数据要求也一般。\nRAID方案：单盘或双盘raid1即可。三盘就RAID5，看容量要求加盘即可。\n96、描述Linux下文件删除的原理\nLinux系统是通过link的数量来控制文件删除的，只有当一个文件不存在任何link的时候，这个文件才会被删除。一般来说每个文件两个link计数器来控制i_count和i_nlink。当一个文件被一个程序占用的时候i_count就加1。当文件的硬链接多一个的时候i_nlink也加1。删除一个文件，就是让这个文件，没有进程占用，同时i_link数量为0。\n97、请简单描述VI编辑器的使用\n（1）vi编辑器是linux系统下最最基本和最常用的标准文本编辑器。\n（2）vi编辑器有三种工作模式：普通模式、编辑模式、命令模式。\n（3）普通模式下的键盘输入任何字符都是当作命令来执行的，也可以输入命令进行光标的移动，字符、单词、行的复制、粘帖以及删除等操作。\n（4）编辑模式主要用于文本的输入。在该模式下，用户输入的任何字符都被作为文件的内容保存起来。\n（5）命令模式下，用户可以对文件进行一些如字符串查找、替换、显示行号等操作还是必须要进入命令模式的。\n（6）在普通模式下输入冒号即可进入命令模式，此时vi窗口的状态行会显示出冒号，等待用户输入命令。“i”插入模式，即可以进行编辑。用户输入完成后，按【Esc】之后编辑器又返回到普通模式下，在命令模式下，保存退出，可以使用的命令为wq和x。前面加！表示强制退出，强制保存等。\n98、请简单说出用户管理的相关命令及用途\n（1）组管理命令\ngroupadd #添加组\ngroupdel #删除用户组\ngroupmod #修改用户组\ngroups #显示当前用户所属的用户组\ngrpck #检查用户组及密码文件的完整性（etc/group以及/etc/gshadow文件）\ngrpconv #通过/etc/group和/etc/gshadow 的文件内容来同步或创建/etc/gshadow ，如果/etc/gshadow 不存在则创建；\ngrpunconv #通过/etc/group 和/etc/gshadow 文件内容来同步或创建/etc/group ，然后删除gshadow文件 。\n（2）用户管理命令\nuseradd #添加用户\nadduser #添加用户\npasswd #为用户设置密码\nusermod #修改用户命令，可以通过usermod 来修改登录名、用户的家目录等等\npwcov #同步用户从/etc/passwd 到/etc/shadow\npwck #pwck是校验用户配置文件/etc/passwd 和/etc/shadow文件内容是否合法或完整\npwunconv #执行pwunconv指令可以关闭用户投影密码，它会把密码从shadow文件内，重回存到passwd文件里。\nfinger #查看用户信息工具（危险命令，一般不用）\nid #查看用户的UID、GID及所归属的用户组\nchfn #更改用户信息工具\nsu #用户切换工具\n99、请简述基础正则表达式grep高级参数的使用\n常用参数：\n“-v”排除匹配内容，\n“-e”支持扩展的正则表达式，\n“-i”忽略大小写，\n“-o”输出匹配的内容（只是一块，不是行），\n“–color=auto” 匹配内容显示颜色，\n“-n” 在行首显示行号。\n特殊字符注意事项：\n“^”(尖括号)word ，表示搜索以word开头的内容。\nword$ 表示搜索以word结尾的内容。\n“^$ ”表示的是空行，不是空格。\n“.” 代表且只能代表任意一个字符。非正则表达式其他功能（当前目录，加载文件）\n\\ 转义字符，让有着特殊身份意义的字符，脱掉马甲，还原原型。例如.只表示原始小数点意义。\n“* ” 表示重复0个或多个前面的一个字符。不代表所有。\n“.* ” 表示匹配所有的字符。^.*表示以任意字符开头。\n[任意字符如abc] 匹配字符集内任意一个字符[a-z]。 [^abc] ^在中括号里面是非的意思，不包含之意。意思就是不包含a或b或c的行。\n{n，m} 表示重复n到m次前一个字符。｛n｝至少n次，多了不限。｛n｝N次，｛，m｝至多m次，少了不限。\n注：使用grep或sed要对｛｝转义。即\\｛\\｝.egrep就不需要转义了。\n100、请简述基础正则表达式sed高级参数的使用\n解答：\n-n取消默认输出\n-p 打印\n-d删除\n-e允许多项编辑\nsed取行，要特别注意sed -n ‘s###g’ filename 的使用，sed的的功能可以记住正则表达式的一部分，其中，\\1为第一个记住的模式即第一个小括号中的匹配内容，\\2第二记住的模式，即第二个小括号中的匹配内容，sed最多可以记住9个。\n实际字符的选取最好要唯一，正则表达式是贪婪的，总是尽可能的匹配更远的符合匹配的内容。另外注意字符串中的空格。\n101、请给出查看当前哪些用户在线的Linux命令\nw #显示目前系统登录用户\nwho #显示目前已登录用户信息\nlast #列出目前与过去登入系统的用户相关信息\nlastlog #检查某特定用户上次登录时间\nwhoami #打印与当前生效的用户ID关联的用户名\nfinger #用户信息查找程序\nid #显示指定用户或当前用户的用户与组信息\n102、请你描述下crontab的作用和语法，以及书写定时任务注意的要点。\n设置crontab后我们可以使得Linux主动执行的在固定的间隔时间，执行指定的系统指令或 shell script脚本。生产环境可以用来日志分析或生产备份等。\n语法格式：\ncrontab [ -u user ] file ===》-u的意思就是指定用户\ncrontab [ -u user ] { -l 显示文件内容| -r全部删除crontab文件 | -e 编辑crontab文件| -i删除crontab文件前确认提示}\n举例：\n*/5 10，12 * 3-8 * * /usr/sbin/ntpdate 10.0.0.155 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1\n前五段是时间间隔的设定，单位分别是分钟、小时、日、月、周（尽量避免使用日月和周同时出现，以免造成系统误判）。\n第一个时间段 分钟 范围0-59\n第二个时间段 小时 范围0-23\n第三个世间段 日 范围1-31\n第四个时间段 月 范围1-12\n第五个时间段 周 范围0-7\n“*”星号代表任何时间都接受命令\n“,”逗号，表示隔开。代表分隔的时间都适用此命令。\n“-”减号，两个时间段之间，代表在此时间段内执行定时任务。\n/n斜线和n（数字）表示每隔n段时间执行一次。\n注意要点分为：书写基本要领与书写注意事项，掌握7个基本要领：\n第一、为定时任务规则加必要的注释\n第二、定时任务命令或程序最好写到脚本里执行\n第三、定时任务执行的脚本要规范路径，如：/server/scripts\n第四、执行shell脚本任务时前加/bin/sh\n执行定时任务时，如果是执行脚本，尽量在脚本前面带上/bin/sh命名\n第五、定时任务结尾加 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1\n第六、/dev/null为特殊的字符设备文件，表示黑洞设备或空设备。\n第七、有关重定向的说明\n“\u0026gt;或1\u0026gt; ” 输出重定向：把前面输出的东西输入到后边的文件中，会删除文件原有内容。\n“\u0026raquo;或1\u0026raquo;” 追加重定向：把前面输出的东西追加到后边的文件中，不会删除文件原有内容。\n“\u0026lt;或\u0026lt;0 ” 输入重定向：输入重定向用于改变命令的输入，指定输入内容，后跟文件名。\n“\u0026laquo;或\u0026laquo;0” 输入重定向：后跟字符串，用来表示“输入结束”，也可用ctrl+d来结束输入。\n“2\u0026gt;” 错误重定向：把错误信息输入到后边的文件中，会删除文件原有内容。\n“2\u0026raquo;” 错误追加重定向：把错误信息追加到后边的文件中，不会删除文件原有内容。\n标准输入（stdin）：代码为0，使用\u0026lt;或\u0026laquo;。\n标准输出（stdout）:代码为1，使用\u0026gt;或\u0026raquo;。正常的输出。\n标准错误输出（sederr）：代码为2，使用2\u0026gt;或2\u0026raquo;。\n特殊记忆：\n“2\u0026gt;\u0026amp;1”就是把标准错误重定向到标准输出（\u0026gt;\u0026amp;）。\n/dev/null 2\u0026gt;\u0026amp;1 等价于 1\u0026gt;/dev/null 2\u0026gt;/dev/null\n103、请列出Linux中你认为重要的文件夹及包含内容\n（1）/目录下的文件夹里面分别是以下内容：\n/usr 包含所有的命令和程序库、文档和其他文件及当前linux发行版的主要应用程序\n/var 包含正在操作的文件，还有记录文件、加密文件、临时文件等\n/home 除了root用户外的所有用户的配置文件，个性化文件和主目录，即家目录\n/proc 虚拟目录，该目录实际上指向内存而不是硬盘\n/bin 系统执行文件（二进制文件）普通用户可以使用\n/sbin 系统执行文件（二进制文件）不能被普通用户使用，通常由root用户使用\n/etc 操作系统的配置文件\n/root root用户的家目录\n/dev 系统设备文件，linux所有设备都是以文件的形式被处理，该目录不包含驱动程序\n/lib 程序和核心模块共享库（仅限于/下的程序）\n/boot 系统引导、启动文件，通常grub也在这里\n/opt 可选应用程序目录\n/tmp 临时文件，系统会自动清理\n/lost+found 恢复文件（类似回收站）\n/media 所有的磁盘（有时有光盘）将以文件夹的形式挂载，光盘镜像也可以挂载\n/cd-rom 挂载光盘的地方\n（2） /usr目录下的文件比较重要，其作用下面分类列出：\n/usr/X11 X-windows桌面环境\n/usr/doc linux系统的文档资料\n/usr/share 独立于当前计算机的数据结构，如字典中的词\n/usr/bin 类似/bin但是不参与启动，大部分命令都在这里\n/usr/local 本地管理员安装的应用程序\n/usr/local/bin 用户安装的应用程序（部分）\n（3） /proc目录的内容\n/proc/cpuinfo 处理器的信息\n/proc/devices 当前运行内核的所有设备清单\n/proc/dma 当前正在使用中的DMA通道\n/proc/filesystem 当前运行内核所配置的文件系统\n/proc/interrupts 当前使用的中断和曾经有多少个中断\n/proc/ioports 正在使用的I/O端口\n104、给出正确的关机和重启服务器的命令\n（1）shutdown\n[-t] 指定在多长时间之后关闭系统 [-r] 重启系统 [-k] 并不真正关机，只是给每个登录用户发送警告信号 [-h] 关闭系统（halt）\n（2）halt\nhalt是最简单的关机命令，其实际上是调用shutdown -h命令。halt执行时，杀死应用进程，文件系统写操作完成后就会停止内核。\nhalt命令的部分参数如下：\n[-f] 没有调用shutdown而强制关机或重启 [-i] 关机或重新启动之前，关掉所有的网络接口 [-p] 关机时调用poweroff，此选项为缺省选项\n（3）reboot\nreboot工作过程与halt类似，作用是重新启动，而halt是关机。其参数与halt类似。\n（4）init\ninit是所有进程的祖先，其进程号始终为1。init用于切换系统的运行级别，切换的工作是立即完成的。init 0命令用于立即将系统运行级别切换为0，即关机；init 6命令用于将系统运行级别切换为6，即重新启动。\n105、请简述修改/etc/sudoers配置文件的注意事项\n（1）别名的名称可以包含大写字母。数字、下划线。如果是字母必须要大写，（别名为一群拥有相同属性的集合）。\n（2）一个别名下面可以有多个成员，成员间通过半角(,)逗号隔开。成员必须有效实际存在。\n别名成员受别名类型 Host_Alias、User_Alias、Runas_Alias、Cmnd_Alias制约，定义什么类型的别名，就要有相什么类型的成员匹配。\n（3）用户组前面必须加%号。命令别名下的成员必须是文件或目录的绝对路径。\n（4）指定切换用户要用（）括号括起来，如果省略，则默认root用户，如果括号里是ALL，则代表能切换到所有用户。\n（5）命令路径要使用全路径。\n（6）别名规则每行算一个规则，一行容不下时用\\续行。另外超过一行，用反斜线换行。\n（7）一般不建议先给all权限，后面排除。用什么权限，就给什么权限。（注意权限，语法）。\n如果不需要密码直接运行命令的应该加NOPASSWD参数。\n（8）禁止某类程序或命令执行，要在命令动作前面加上“！”号，并放在允许执行命令之后。\n106、请描述如何实现linux系统集权分治的权限分级精细管理？\n（1）收集以及制定用户和权限的匹配信息，原则是给于最小权限，但是又能完成所承担的工作职责。\n（2）各个用户组设置对应权限，用什么给什么，精细到每一条指令上根据分组情况。\n（3）创建规划权限分组的用户.添加相关用户组。并修改etc/sudoers配置文件。\n（4）增加sudo的权限开放，确定相关用户加入如soduers权限列表，并详细设置所开放权限内容，并选择是否需要密码的相关执行权限开放。（注意ALL权限,以及密码修改权限设置）。\n（5）不建议先给all权限，后面排除。建议使用白名单。\n（6）实战调试测试相关权限是否正确配置完成。\n（7）编写操作说明，及相关注意事项。\n（8）调试完毕，邮件周知所有相关人员系统权限设置生效，并附带操作说明及相关注意事项。\n107、请写出下面Linux SecureCRT命令行快捷键命令的功能？\nCtrl + a 光标到开头\nCtrl + c 中断当前程序\nCtrl + d 退出当前窗口或当前用户\nCtrl + e 光标到结尾\nCtrl + l 清屏 相当与clear\nCtrl + u 剪切、删除（光标以前的）内容\nCtrl + k 剪切、删除（光标以后的）内容\nCtrl + r 查找（最近用过的命令）\ntab 所有路径以及补全命令\nCtrl+shift+c 命令行复制内容\nCtrl+shift+v 命令行粘贴内容\nCtrl + q 取消屏幕锁定\nCtrl + s 执行屏幕锁定\n108、请描述服务器账户日志审计的4种解决方案。\n（1）通过环境变量syslog对全部全部日志进行审计（信息量太大，不推荐）\n（2）sudo配合syslog服务，进行sudo操作日志进行审计（信息较少，效果不错）\n（3）在bash解释器嵌入一个监视器，让所有用户使用修改过的bash程序，作为解释程序。\n（4）齐治的堡垒机（商业产品）。\n109、如果一台办公室内主机无法上网（打不开网站），请给出你的排查步骤？\n（1）首先确定物理链路是否联通正常。\n（2）查看本机IP，路由，DNS的设置情况是否达标。\n（3）telnet检查服务器的WEB有没有开启以及防火墙是否阻拦。\n（4）ping一下网关，进行最基础的检查，通了，表示能够到达服务器。\n（5）测试到网关或路由器的通常情况，先测网关，然后再测路由器一级一级的测试。\n（6）测试ping公网ip的通常情况（记住几个外部IP），\n（7）测试DNS的通畅。ping出对应IP。\n（8）通过以上检查后，还在网管的路由器上进行检查。\n110、描述Linux shell中单引号、双引号及不加引号的简单区别？\n单引号：所见即所得，即将单引号内的内容原样输出，或者描述为单引号里面看到的是什么就输出什么。\n双引号：把双引号里面的内容给输出出来，如果内容中有命令、变量等，会先把，变来那个、命令解析出结果，然后输出最终内容。\n双引号内的命令或者变量写法’命令或变量’或$(命令或变量)\n无引号：把内容输出出来，可能不会键含有空格的字符串，视为一个整体输出，如果内容中有命令、变量等，会先把变量、命令解析出来，然后输出最终内容，如果字符串中带有空格等特殊字符，则不能完整输出，需要改加双引号。一般连续的字符串，数字，路径等可以用，不过最好用双引号，替代之。\n111、请简述Linux启动过程中几个重要配置文件的执行过程\nLinux登录后，配置执行顺序为(Debian Serials Capable)：\n/etc/environment -\u0026gt; /etc/profile -\u0026gt; (~/.bash_profile | ~/.bash_login | ~/.profile) -\u0026gt; ~/.bashrc -\u0026gt; /etc/bashrc -\u0026gt; ~/.bash_logout\n关于各个文件的作用说明：\n（1）/etc/environment：此配置文件设置基本的PATH变量，及系统当前语言变量，虽然比较短，但却在系统启动中占据举足轻重的作用，比如如下是我的系统中的内容：\n（2）/etc/profile： 此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行. 并从/etc/profile.d目录的配置文件中搜集shell的设置。\n（3）/etc/bash.bashrc: 为每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取。\n（4）~/.bash_profile: 每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次!默认情况下,他设置一些环境变量,执行用户的.bashrc文件。\n（5）~/.bashrc: 该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该该文件被读取。\n（6）~/.bash_logout: 当每次退出系统(退出bash shell)时,执行该文件. 另外,/etc/profile中设定的变量(全局)的可以作用于任何用户,而~/.bashrc等中设定的变量(局部)只能继承 /etc/profile中的变量,他们是\u0026quot;父子\u0026quot;关系。\n（7）~/.bash_profile 是交互式、login 方式进入 bash 运行的~/.bashrc 是交互式 non-login 方式进入 bash 运行的通常二者设置大致相同，所以通常前者会调用后者。\n112、请描述下列路径的内容是做什么的？\n/var/log/messages 系统日志文件\n/var/log/secure 系统安全文件（显示登录信息的文件）\n/var/spool/clientmqueue 例行性任务回执邮件存放文件\n/proc/interrupts 当前系统中断报告文件\n/etc/fstab 开机自动挂载磁盘的配置文件\n/etc/profile 环境变量存放的文件\n113、请给出Linux中eth0的IP地址和广播地址的指令，需使用cut、awk、grep、sed指令。\n第一种方法：使用grep和cut取值\n第二种方法：使用grep和awk（默认分隔符为空格）取值\n第三种方法：使用grep和awk（多分隔符）\n第四种方法：使用sed和awk\n第五种方法：使用grep和awk（多分隔符与加号+）\n第六种方法：awk （分隔符及取行）\n第七种方法：grep 网卡文件\n第八种方法：head取行 awk分割\n114、请输出你知道的20 个LINUX 命令及作用\ncp 复制 -a(drp),-r拷贝目录 -p保持属性\nmv 移动文件或目录\nmkdir 创建目录 -p递归创建目录 mkdir /a/b/c\ntouch 创建文件，\ncd 切换目录（~当前用户家目录，-上一次的目录）\ncat 查看文件内容 -n显示行号\nls 查看目录下文件，-l长格式,-d查看目录**********\nrm 删除文件或目录 -r目录 -f强制删除（慎用，mv,find）\nfind 查找文件或目录 -type 类型（f,d,l,c,b），-name名字 -exec执行动作*****\nalias 查看及设置别名\nunalias 取消别名\nseq 打印序列 -s指定分割符 -w数字前面加0补齐位数\nhead 查看文件前N行，默认10行，-n指定行数\ntail 查看文件后N行，默认10行，-n指定行数,-f实时跟踪文件结尾的变化\nsed linux三剑客老二，文件增删改查，*****\npwd打印当前工作目录\nrmdir 删除空目录\necho 显示输出\nxargs (配合find,ls)等查找到的内容处理,-n分组\ntree -L层数 -d目录\nrpm -q query查询 -a all\nuname -r内核 -m32位还是64位 -a所有信息, -n主机名（hostname）\nhostname 主机名\nwhoami 查看当前用户\nuseradd 添加用户\npasswd 改密码，–stdin 非交互设置密码\nsu 切换用户角色，-切换环境变量\n115、什么是运维？什么是游戏运维？\n（1）运维是指大型组织已经建立好的网络软硬件的维护，就是要保证业务的上线与运作的正常，\n在他运转的过程中，对他进行维护，他集合了网络、系统、数据库、开发、安全、监控于一身的技术\n运维又包括很多种，有DBA运维、网站运维、虚拟化运维、监控运维、游戏运维等等\n（2）游戏运维又有分工，分为开发运维、应用运维（业务运维）和系统运维\n开发运维：是给应用运维开发运维工具和运维平台的\n应用运维：是给业务上线、维护和做故障排除的，用开发运维开发出来的工具给业务上线、维护、做故障排查\n系统运维：是给应用运维提供业务上的基础设施，比如：系统、网络、监控、硬件等等\n总结：开发运维和系统运维给应用运维提供了“工具”和“基础设施”上的支撑\n开发运维、应用运维和系统运维他们的工作是环环相扣的\n116、在工作中，运维人员经常需要跟运营人员打交道，请问运营人员是做什么工作的？\n游戏运营要做的一个事情除了协调工作以外，还需要与各平台沟通，做好开服的时间、开服数、用户导量、活动等计划\n117、现在给你三百台服务器，你怎么对他们进行管理？\n管理三百台服务器的方式：\n（1）设定跳板机，使用统一账号登录，便于安全与登录的考量。\n（2）使用salt、ansiable、puppet进行系统的统一调度与配置的统一管理。\n（3）建立简单的服务器的系统、配置、应用的cmdb信息管理。便于查阅每台服务器上的各种信息记录。\n118、简述raid0 raid1 raid5 三种工作模式的工作原理及特点\nRAID，可以把硬盘整合成一个大磁盘，还可以在大磁盘上再分区，放数据\n还有一个大功能，多块盘放在一起可以有冗余（备份）\nRAID整合方式有很多，常用的：0 1 5 10\nRAID 0，可以是一块盘和N个盘组合\n其优点读写快，是RAID中最好的\n缺点：没有冗余，一块坏了数据就全没有了\nRAID 1，只能2块盘，盘的大小可以不一样，以小的为准\n10G+10G只有10G，另一个做备份。它有100%的冗余，缺点：浪费资源，成本高\nRAID 5 ，3块盘，容量计算10*（n-1）,损失一块盘\n特点，读写性能一般，读还好一点，写不好\n冗余从好到坏：RAID1 RAID10 RAID 5 RAID0\n性能从好到坏：RAID0 RAID10 RAID5 RAID1\n成本从低到高：RAID0 RAID5 RAID1 RAID10\n单台服务器：很重要盘不多，系统盘，RAID1\n数据库服务器：主库：RAID10 从库 RAID5\\RAID0（为了维护成本，RAID10）\nWEB服务器，如果没有太多的数据的话，RAID5,RAID0（单盘）\n有多台，监控、应用服务器，RAID0 RAID5\n我们会根据数据的存储和访问的需求，去匹配对应的RAID级别\n119、LVS、Nginx、HAproxy有什么区别？工作中你怎么选择？\nLVS： 是基于四层的转发。\nHAproxy： 是基于四层和七层的转发，是专业的代理服务器。\nNginx： 是WEB服务器，缓存服务器，又是反向代理服务器，可以做七层的转发。\n区别：\nLVS由于是基于四层的转发所以只能做端口的转发而基于URL的、基于目录的这种转发LVS就做不了。\n工作选择：\nHAproxy和Nginx由于可以做七层的转发，所以URL和目录的转发都可以做在很大并发量的时候我们就要选择LVS，像中小型公司的话并发量没那么大选择HAproxy或者Nginx足已，由于HAproxy由是专业的代理服务器配置简单，所以中小型企业推荐使用HAproxy\n6、Squid、Varinsh和Nginx有什么区别，工作中你怎么选择？\nSquid、Varinsh和Nginx都是代理服务器\n什么是代理服务器：\n能当替用户去访问公网，并且能把访问到的数据缓存到服务器本地，等用户下次再访问相同的资源的时候，代理服务器直接从本地回应给用户，当本地没有的时候，我代替你去访问公网，我接收你的请求，我先在我自已的本地缓存找，如果我本地缓存有，我直接从我本地的缓存里回复你\n如果我在我本地没有找到你要访问的缓存的数据，那么代理服务器就会代替你去访问公网\n区别：\n（1）Nginx本来是反向代理/web服务器，用了插件可以做做这个副业\n但是本身不支持特性挺多，只能缓存静态文件\n（2）从这些功能上。varnish和squid是专业的cache服务，而nginx这些是第三方模块完成\n（3）varnish本身的技术上优势要高于squid，它采用了可视化页面缓存技术\n在内存的利用上，Varnish比Squid具有优势，性能要比Squid高。\n还有强大的通过Varnish管理端口，可以使用正则表达式快速、批量地清除部分缓存\n它是内存缓存，速度一流，但是内存缓存也限制了其容量，缓存页面和图片一般是挺好的\n（4）squid的优势在于完整的庞大的cache技术资料，和很多的应用生产环境\n工作中选择：\n要做cache服务的话，我们肯定是要选择专业的cache服务，优先选择squid或者varnish。\n120、Tomcat和Resin有什么区别，工作中你怎么选择？\n区别：\nTomcat用户数多，可参考文档多，Resin用户数少，可考虑文档少\n最主要区别则是Tomcat是标准的java容器，不过性能方面比resin的要差一些\n但稳定性和java程序的兼容性，应该是比resin的要好\n工作中选择：\n现在大公司都是用resin，追求性能；而中小型公司都是用Tomcat，追求稳定和程序的兼容\n121、什么是中间件？什么是jdk？\n中间件介绍：\n中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源。中间件位于客户机/ 服务器的操作系统之上，管理计算机资源和网络通讯\n是连接两个独立应用程序或独立系统的软件。相连接的系统，即使它们具有不同的接口\n但通过中间件相互之间仍能交换信息。执行中间件的一个关键途径是信息传递\n通过中间件，应用程序可以工作于多平台或OS环境。\njdk：\njdk是Java的开发工具包。它是一种用于构建在Java平台上发布的应用程序、applet和组件的开发环境\n122、讲述一下Tomcat8005、8009、8080三个端口的含义？\n8005：关闭时使用\n8009：为AJP端口，即容器使用，如Apache能通过AJP协议访问Tomcat的8009端口\n8080：一般应用使用\n123、什么叫CDN？\nCDN是内容分发网络。其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络边缘，使用户可就近取得所需的内容，提高用户访问网站的速度。\n124、什么叫网站灰度发布？\n灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。\nAB test就是一种灰度发布方式，让一部用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。\n125、简述DNS进行域名解析的过程？\n例如用户要访问http://www.baidu.com，会先找本机的host文件，再找本地设置的DNS服务器，如果也没有的话，就去网络中找根服务器，根服务器反馈结果，说只能提供一级域名服务器.cn，就去找一级域名服务器，一级域名服务器说只能提供二级域名服务器.com.cn,就去找二级域名服务器，二级域服务器只能提供三级域名服务器.http://baidu.com.cn，就去找三级域名服务器，三级域名服务器正好有这个网站http://www.baidu.com，然后发给请求的服务器，保存一份之后，再发给客户端。\n126、RabbitMQ是什么东西？\nRabbitMQ也就是消息队列中间件，消息中间件是在消息的传息过程中保存消息的容器\n消息中间件再将消息从它的源中到它的目标中标时充当中间人的作用。\n队列的主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用消息队列不会保留消息，直到可以成功地传递为止，当然，消息队列保存消息也是有期限地。\n127、讲一下Keepalived的工作原理？\n在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP通告信息,\nBACKUP不会抢占MASTER，除非它的优先级更高。多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(\u0026lt;1s)，以保证服务的连续性。于安全性考虑，VRRP包使用了加密协议进行加密。BACKUP不会发送通告信息，只会接收通告信息。\n128、讲述一下LVS三种模式的工作过程？\nLVS 有三种负载均衡的模式，分别是VS/NAT（nat 模式） VS/DR(路由模式) VS/TUN（隧道模式）\n（1）NAT模式（VS-NAT）\n原理：就是把客户端发来的数据包的IP头的目的地址，在负载均衡器上换成其中一台RS的IP地址，并发至此RS来处理,RS处理完后把数据交给负载均衡器,负载均衡器再把数据包原IP地址改为自己的IP，将目的地址改为客户端IP地址即可期间,无论是进来的流量,还是出去的流量,都必须经过负载均衡器。\n优点：集群中的物理服务器可以使用任何支持TCP/IP操作系统，只有负载均衡器需要一个合法的IP地址\n缺点：扩展性有限。当服务器节点（普通PC服务器）增长过多时,负载均衡器将成为整个系统的瓶颈\n因为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时\n大量的数据包都交汇在负载均衡器那，速度就会变慢！\n（2）、IP隧道模式（VS-TUN）\n原理：首先要知道，互联网上的大多Internet服务的请求包很短小，而应答包通常很大\n那么隧道模式就是，把客户端发来的数据包，封装一个新的IP头标记(仅目的IP)发给RS\nRS收到后,先把数据包的头解开,还原数据包,处理后,直接返回给客户端,不需要再经过\n负载均衡器。注意,由于RS需要对负载均衡器发过来的数据包进行还原,所以说必须支持\nIPTUNNEL协议，所以,在RS的内核中,必须编译支持IPTUNNEL这个选项\n优点：负载均衡器只负责将请求包分发给后端节点服务器，而RS将应答包直接发给用户\n所以，减少了负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，就能处理很巨大的请求量\n这种方式，一台负载均衡器能够为很多RS进行分发。而且跑在公网上就能进行不同地域的分发。\n缺点：隧道模式的RS节点需要合法IP，这种方式需要所有的服务器支持”IP Tunneling”\n(IP Encapsulation)协议，服务器可能只局限在部分Linux系统上\n（3）、直接路由模式（VS-DR）\n原理：负载均衡器和RS都使用同一个IP对外服务但只有DR对ARP请求进行响应\n所有RS对本身这个IP的ARP请求保持静默也就是说,网关会把对这个服务IP的请求全部定向给DR\n而DR收到数据包后根据调度算法,找出对应的RS,把目的MAC地址改为RS的MAC（因为IP一致）\n并将请求分发给这台RS这时RS收到这个数据包,处理完成之后，由于IP一致，可以直接将数据返给客户\n则等于直接从客户端收到这个数据包无异,处理后直接返回给客户端\n由于负载均衡器要对二层包头进行改换,所以负载均衡器和RS之间必须在一个广播域\n也可以简单的理解为在同一台交换机上\n优点：和TUN（隧道模式）一样，负载均衡器也只是分发请求，应答包通过单独的路由方法返回给客户端\n与VS-TUN相比，VS-DR这种实现方式不需要隧道结构，因此可以使用大多数操作系统做为物理服务器。\n缺点：（不能说缺点，只能说是不足）要求负载均衡器的网卡必须与物理网卡在一个物理段上。\n129、统计ip访问情况，要求分析nginx访问日志，找出访问页面数量在前十位的ip\ncat access.log | awk \u0026lsquo;{print $1}\u0026rsquo; | uniq -c | sort -rn | head -10\n130、使用tcpdump监听主机为192.168.1.1，tcp端口为80的数据，同时将输出结果保存输出到tcpdump.log\ntcpdump \u0026lsquo;host 192.168.1.1 and port 80\u0026rsquo; \u0026gt; tcpdump.log\n131、如何将本地80 端口的请求转发到8080 端口，当前主机IP 为192.168.2.1\niptables -A PREROUTING -d 192.168.2.1 -p tcp -m tcp -dport 80 -j DNAT-to-destination 192.168.2.1:8080\n132、简述raid0 raid1 raid5 三种工作模式的工作原理及特点\nRAID 0：\n带区卷，连续以位或字节为单位分割数据，并行读/写于多个磁盘上，因此具有很高的数据传输率，但它没有数据冗余，RAID 0 只是单纯地提高性能，并没有为数据的可靠性提供保证，而且其中的一个磁盘失效将影响到所有数据。因此，RAID 0 不能应用于数据安全性要求高的场合。\nRAID 1：\n镜像卷，它是通过磁盘数据镜像实现数据冗余，在成对的独立磁盘上产生互为备份的数据，不能提升写数据效率。当原始数据繁忙时，可直接从镜像拷贝中读取数据，因此RAID1 可以提高读取性能，RAID 1 是磁盘阵列中单位成本最高的，镜像卷可用容量为总容量的1/2，但提供了很高的数据安全性和可用性。当一个磁盘失效时，系统可以自动切换到镜像磁盘上读写，而不需要重组失效的数据。\nRAID5：\n至少由3块硬盘组成，分布式奇偶校验的独立磁盘结构，它的奇偶校验码存在于所有磁盘上。任何一个硬盘损坏，都可以根据其它硬盘上的校验位来重建损坏的数据（最多允许1块硬盘损坏）。所以raid5可以实现数据冗余，确保数据的安全性，同时raid5也可以提升数据的读写性能。\n133、你对现在运维工程师的理解和以及对其工作的认识\n运维工程师在公司当中责任重大，需要保证时刻为公司及客户提供最高、最快、最稳定、最安全的服务。运维工程师的一个小小的失误，很有可能会对公司及客户造成重大损失\n。因此，运维工程师的工作需要严谨及富有创新精神。\n134、实时抓取并显示当前系统中tcp 80端口的网络数据信息，请写出完整操作命令\ntcpdump -nn tcp port 80\n135、Linux系统中病毒怎么解决？\n（1）最简单有效的方法就是重装系统。\n（2）要查的话就是找到病毒文件然后删除。中毒之后一般机器cpu、内存使用率会比较高。可以先用top 命令找到cpu使用率最高的进程，一般病毒文件命名都比较乱，可以用 ps aux命令找到病毒文件位置，然后执行rm -f命令删除病毒文件，最后检查计划任务、开机启动项和病毒文件目录有无其他可以文件等。\n（3）由于即使删除病毒文件不排除有潜伏病毒，所以最好是把机器备份数据之后重装一下。\n136、说说TCP/IP的七层模型？\n应用层 (Application)：\n网络服务与最终用户的一个接口。协议有：HTTP FTP TFTP SMTP SNMP DNS TELNET HTTPS POP3 DHCP。\n表示层（Presentation Layer）：\n数据的表示、安全、压缩。（在五层模型里面已经合并到了应用层）\n格式有，JPEG、ASCll、DECOIC、加密格式等。\n会话层（Session Layer）：\n建立、管理、终止会话。（在五层模型里面已经合并到了应用层）\n对应主机进程，指本地主机与远程主机正在进行的会话。\n传输层 (Transport)：\n定义传输数据的协议端口号，以及流控和差错校验。\n协议有：TCP UDP，数据包一旦离开网卡即进入网络传输层\n网络层 (Network)：\n进行逻辑地址寻址，实现不同网络之间的路径选择。\n协议有：ICMP IGMP IP（IPV4 IPV6） ARP RARP\n数据链路层 (Link)：\n建立逻辑连接、进行硬件地址寻址、差错校验等功能。（由底层网络定义协议）\n将比特组合成字节进而组合成帧，用MAC地址访问介质，错误发现但不能纠正。\n物理层（Physical Layer）：\n是计算机网络OSI模型中最低的一层，物理层规定:为传输数据所需要的物理链路创建、维持、拆除，而提供具有机械的，电子的，功能的和规范的特性。简单的说，物理层确保原始的数据可在各种物理媒体上传输。局域网与广域网皆属第1、2层，物理层是OSI的第一层，它虽然处于最底层，却是整个开放系统的基础，物理层为设备之间的数据通信提供传输媒体及互连设备，为数据传输提供可靠的环境，如果您想要用尽量少的词来记住这个第一层，那就是“信号和介质”。\n137、请列出你了解的web服务器负载架构？\nNginx\nHaproxy\nKeepalived\nLVS\n参考链接 https://mp.weixin.qq.com/s/WXlQD2kK1QN0C8S2hJQtGw\n","description":"","id":124,"section":"posts","tags":["Bash","Linux","面试"],"title":"Linux面试-137面试题","uri":"https://hex-go.github.io/posts/interview/2024-04-09-linux%E9%9D%A2%E8%AF%95-137%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"content":"1.awk简介 1.1 背景 awk是一个强大的文本处理工具，非常优秀的数据过滤器。它不仅仅是一个工具，还是一门语言。命名来源于三个发明者姓氏的首字母组合（Aho、Weinberger、Kernighan）。\nawk是行处理器，awk是以文件的一行为处理单位的。基于模式匹配依次对每一行文本进行处理，然后输出。如果数据规整，基于行（记录，record），也能很好地对列（字段，field）进行处理。\n1.2 基本语法 1.3 内置函数与变量 2. awk易错点 3. 面试题 3.1 询问 3.2 实例 参考 https://mp.weixin.qq.com/s?__biz=Mzg4OTc3NDcwOA==\u0026amp;mid=2247483975\u0026amp;idx=1\u0026amp;sn=176a825f737b941bff6f1a16682389c2\u0026amp;chksm=cfe7f55cf8907c4a108638035e178ab84556541f38a70be6c87524bb6252b9bc3a4dacf3e918\u0026amp;scene=178\u0026amp;cur_album_id=2379048869520670721#rd\nhttps://mp.weixin.qq.com/s/0VtDacjXyY6-cuC-RrevWA\n","description":"","id":125,"section":"posts","tags":["Bash","面试","awk"],"title":"Linux面试-awk面试题(原理篇)","uri":"https://hex-go.github.io/posts/interview/2024-04-09-linux%E9%9D%A2%E8%AF%95-awk%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"content":"1.程序相关 Ctrl + s：挂起，感觉类似于暂停。\nCtrl + q：退出挂起，感觉类似于继续，发现按键盘其它按键也可以退出挂起，有点疑问。\nCtrl + c：中断并杀死，程序终止。\nCtrl + z：中断程序放到后台，唤醒使用“fg”命令。\n2.光标移动 Ctrl+a：移动到命令行的开头。\n在命令行中输入一长串命令时，可以按下Ctrl + A来快速将光标移动到命令的开头，以便编辑。\nCtrl+e：移动到命令行的末尾。\n在命令行中输入一长串命令后，想要在最后添加内容时，可以按下Ctrl + E将光标快速移到命令的末尾。\nCtrl+左键：向左移动一个词的距离（Alt+b）\nCtrl+右键：向右移动一个词的距离（Alt+f）\nCtrl + b：向左移动光标(==键盘左键)。\nCtrl + f：向右移动光标(==键盘右键)。\nCtrl + x + x：光标在命令行中光标最后两次出现的位置间进行切换\n3. 删除 Ctrl + u：删除光标之前的所有文本。\n在命令行输入了错误的命令或者想要重新开始时，可以通过Ctrl + U快速删除之前输入的所有内容。\nCtrl + k：删除光标之后的所有文本。\nCtrl + w：删除光标前面的单词。\nAlt + d：删除光标之后的单词（可能冲突，不建议）。\nCtrl + h：退格向左删除(==Backspace键)。\nCtrl + d：向右删除(==delete键)。\n4. 粘贴 Ctrl + v：粘贴最近剪切的文本。\nCtrl + v + 特殊字符：添加一个特殊字符，如tab等。\n5. 撤销 Ctrl + shift + - 来撤销最后的操作(即 Ctrl + _)\n6. 历史命令 Ctrl + r：查看历史命令，需要输入命令的起始字母，剩下的部分自动补全。\nCtrl + p：显示上一条命令(==向上箭头)。\nCtrl + n：显示下一条命令(==向下箭头)。\nhistory：查看历史命令，按顺序全部显示出来，有对应的编号。\n!num：执行history历史命令列表中第num条命令。\n!!：执行上一条命令。\n!?string?：执行含有string字符串的最新命令。\nls !$：执行命令ls，并以上一条命令的最后一个字符串为其参数。\n","description":"","id":126,"section":"posts","tags":["Bash","Linux"],"title":"Linux效率-终端快捷命令","uri":"https://hex-go.github.io/posts/bash/2024-04-09-linux%E6%95%88%E7%8E%87-%E7%BB%88%E7%AB%AF%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"},{"content":" 如果要反馈本站存在的问题，敬请在评论区留言，或发送邮件联系我，亦可在 GitHub 上提交 Issue。\n站点概况 本站采用了 Hugo 静态博客框架，主题为 Zzo，托管在 Github page。除此之外，评论、统计等功能使用了以下服务：\n评论系统：Gitalk 访客统计：LeanCloud + 谷歌分析 静态资源：阿里云对象存储. 建站简史 记录工作、备忘.\n","description":"","id":127,"section":"page","tags":null,"title":"本站概览","uri":"https://hex-go.github.io/page/site/"},{"content":" 希望我们，都成为拥有好奇心与想象力的人，都是不断发现更大世界的有趣人类。\n{% tabs leisure %}\n1. 书目 1.1 在读书目 深入理解计算机系统. Randal E.Bryant / David O\u0026rsquo;Hallaron. 2016 1.2 已读书目 Docker从入门到实战 黄靖钧. 2017 算法图解. [美] Aditya · Bhargava. 2017 码农翻身. 刘欣. 2018 2. 优秀的开源项目 2.1 Kubernetes source-code-reading-notes k8s源码阅读笔记\n主要专注 k8s 云原生实践，包括但不限于 docker、kubernetes、promethus、istio、knative、service mesh、serverless 等。 2.2 Python psf/requests pallets/flask 2.3 Go hashicorp/raft Golang implementation of the Raft consensus protocol\nGolang implementation of the Raft consensus protocol kubernetes/kubernetes kafka-operator automate provisioning, management, autoscaling and operations of Apache Kafka clusters deployed to K8s. *keycloak A OpenID / Keycloak Proxy service 2.4 云原生 koderover/zadig 七牛云的一款面向开发者设计的云原生持续交付(Continuous Delivery)产品，具备高可用 CI/CD 能力，提供云原生运行环境，支持开发者本地联调、微服务并行构建和部署、集成测试等 2.5 其他 HelloGitHub 分享 GitHub 上有趣、入门级的开源项目\n各种语言的开源项目、让生活变得更美好的工具、书籍、学习笔记、教程等。通过这些项目你将学习到更多编程知识、提高自己的编程技巧、发现编程的乐趣。 awesomeAwesome lists\nAwesome lists about all kinds of interesting topics 3. 站点收藏夹 自己经常访问的一些站点收藏，涵盖技术工具向、学术向等各方向站点。\n3.1 学术 Websites for Economic Study \u0026amp; Research Top Journals in Economics 3.2 技术工具 GitHub Netlify 腾讯云 LeanCloud 国际版 WolframAlpha SM 公共图床 {% endtabs %}\n","description":"","id":128,"section":"page","tags":null,"title":"分享","uri":"https://hex-go.github.io/page/share/"},{"content":" 感觉内容不错的博客\n封尘网 [python ldap jenkins k8s docker]-[详细]\n阳明的博客 [DevOps Kubernetes]-[详细+深入]\nljchen\u0026rsquo;s Notes [consul istio Kubernetes]-[详细]\n田飞雨 [Kubernetes 源码阅读]-[详细]\n煎鱼 [gin 使用 example]-[详细]\nHuangHuang的博客 [python go 云原生 安全 镜像优化]-[详细]\n通过 k8s-ClientGo 的Dynamic.interface包操作CRD资源，发现此博客。后面了解技术栈也是云原生、go、python，故收藏。以下博客打算有时间细读\nGo: 关于锁（mutex）的一些使用注意事项 一个在容器外用 tcpdump 命令对容器内的网络请求抓包的方法 网络负载均衡器的类别和功能介绍 通过编写自定义内置函数的方式扩展 OPA/Rego 运行时 使用 Alpine 作为基础镜像时可能会遇到的常见问题的解决方法 shellless 容器、binaryless 容器以及 distroless 容器 当有多个可用的 Pod Security Policy 时 k8s 的 PSP 选择策略 gobpf 使用示例：使用 perf event 保存数据 健康检查功能相关的一些备忘 tcpdump 常用操作 面向信仰编程 [编译原理 操作系统 Go语言设计与实现 数据结构]-[详细] 大牛，通过Go语言设计与实现发现大牛对底层原理讲的很好。先收藏，后持续学习，记录学习新的博客。以下内容打算花时间细读\nGo语言设计与实现 为什么这么设计系列文章 云原生驿站 [云原生技术]-[详细] b站接触到小伙子的视频，刚毕业达到这水平。深受刺激\u0026hellip;\n","description":"","id":129,"section":"page","tags":null,"title":"小伙伴们","uri":"https://hex-go.github.io/page/friend/"}]