[{"content":"重要 开发或者局域网内部服务，有时候需要模拟 https 环境。使用来自真实证书颁发机构 (CA) 的证书进行开发存在私钥泄露的风险，而且不对公网暴露的服务，也没必要申请真实证书，增加成本。因此最好的解决方案是管理在自己的CA。\n一般都是自签证书，然后在 http server 中使用自签证书。并且为了解决浏览器信任问题，需要将自签证书使用的 CA 证书添加到系统或浏览器的可信 CA 证书中。 上述过程需要操作繁琐的openssl命令实现自签证书，且需要手动信任CA。对本地开发和局域网不那么友好。本文将介绍mkcert，可简化这一过程。\nmkcert简介 mkcert是一个go语言编写的小工具，可自动在系统根存储中创建和安装本地 CA，并生成本地信任的证书。可跨平台，配置简单。\n安装 自行下载，选择合适安装包进行安装 https://github.com/FiloSottile/mkcert/releases/latest\n使用 建议以管理员运行mkcert\n生成本地CA、并导入系统根存储 1 mkcert -install mkcert 支持以下根存储：\nmacOS 系统存储 Windows 系统存储 Linux update-ca-trust （Fedora、RHEL、CentOS） update-ca-certificates （Ubuntu、Debian、OpenSUSE、SLES） trust（Arch） 火狐浏览器（仅限 macOS 和 Linux） Chrome 和 Chromium Java（需要设置JAVA_HOME） 生成证书 1 mkcert example.com \u0026#34;*.example.com\u0026#34; example.test localhost 127.0.0.1 ::1 本地开发使用 创建CA及CA私钥文件，并安装至本机 1 mkcert -install 按需生成服务证书（域名、IP、通配符） 此命令执行后，返回会显示所生成证书的存储路径\n1 mkcert example.com \u0026#34;*.example.com\u0026#34; example.test localhost 127.0.0.1 ::1 将第二步生成的证书与私钥配置给服务，tls\n此处只需要第2步生成的服务证书文件+服务证书私钥。 此时本机访问服务将不会出现问题，如需要解决其他机器此服务，证书不合法问题，再执行第四步\n解决其他主机访问证书不合法问题 1 2 3 4 5 6 7 # 1. 将第一步生成的ca文件（rootCA.pem）拷贝至当前需要配置的机器 # 注意只需要rootCA.pem文件，一定不能将私钥随意拷贝 # 2. 声明变量， export CAROOT=/xxx/rootCA.pem # 3. 执行命令，本机证书导入rootStore mkcert -install 局域网 主机（mac/linux/windows） + k8s_ingress\n根CA生成与管理 建议公司只生成一个根CA，并由公司QA进行管理，尤其是rootCA-key.pem不可泄露\n执行命令\n1 mkcert install 将生成的根CA证书提供给cert-manager 通过mkcert -CAROOT命令打印CA证书rootCA.pem的目录 根据证书及其私钥，创建ClusterIssuer(CertManager的CR) k8s集群可通过挂载cert-manager生成的证书，从而实现以下能力\nk8s对外暴露ingress tls加密 服务之间加密通信 服务之间，基于证书签名、验签机制实现服务认证。 开发、测试、演示机器配置免密访问\n将ca文件rootCA.pem拷贝至需要配置的机器，执行以下命令实现配置\n1 2 3 4 # 声明变量， export CAROOT=/xxx/rootCA.pem # 执行命令，本机证书导入rootStore mkcert -install 其他场景 a. 关于CA a.1 生成CA的存储路径 可通过mkcert -CAROOT命令打印CA证书rootCA.pem与私钥rootCA-key.pem的目录，注意私钥妥善保存\na.2 导入已有CA,而不重新生成CA 通过mkcert -CAROOT命令查找rootCA.pem文件\n复制到需要配置的机器\n将设置CAROOT指向证书文件\n执行mkcert -install\n将ca文件（rootCA.pem）拷贝至当前需要配置的机器，执行下面命令\n1 2 3 export CAROOT=/xxx/rootCA.pem mkcert -install 输出\n1 2 3 Created a new local CA 💥 The local CA is now installed in the system trust store! ⚡️ The local CA is now installed in the Firefox trust store (requires browser restart)! 🦊 a.3 只导入指定的rootStore 默认导入所有支持的根存储，也可以通过环境变量TRUST_STORES，指定只导入指定的root store。选项包括\u0026quot;system\u0026quot;、\u0026ldquo;java \u0026ldquo;和 \u0026ldquo;nss\u0026rdquo;\n1 2 export TRUST_STORES=system,java,nss mkcert -install b. 关于证书 b.1 根据CSR文件生成证书 mkcert通过创建csr的能力，但提供根据csr创建证书的能力。这样可以避免服务私钥与CA私钥共同持有的安全隐患。\n使用 OpenSSL 创建证书签名请求\n1 openssl req -out example.csr -new -newkey rsa:4096 -nodes -keyout example.pem -subj \u0026#34;/C=US/ST=College Station/L=Texas/O=Home/OU=lab/CN=*.apps.svc.com\u0026#34; 上面命令会创建以下文件:\nexample.csr - 证书签名请求csr文件. example.pem - 此csr相关的私钥文件.\n利用mkcert, 根据csr文件提供的信息，创建相应证书 1 mkcert -csr example.csr 输出为\n1 2 3 4 5 Created a new certificate valid for the following names - \u0026#34;*.apps.svc.com\u0026#34; Reminder: X.569 wildcards only go one level deep，so this won\u0026#39;t match a.b.apps.svc.com The _ certificate is at \u0026#34;./_wildcard.apps.svc.com.pem\u0026#34; It will expire on 19 January 2026 b.2 生成pk12格式证书 -pkcs12命令可以产生PKCS12格式的证书。java 程序通常不支持PEM格式的证书，但是支持PKCS12格式的证书。\n1 mkcert -pkcs12 localhost 127.0.0.1 输出示例，默认密码为\n1 2 3 4 5 6 7 8 9 10 11 Note: the local CA is not installed in the Java trust store. Run “mkcert -install\u0026#34; for certificates to be trusted automtically Created a new certificate valid for the following names - \u0026#34;Localhost\u0026#34; - \u0026#34;127.0.0.1\u0026#34; The PKCS#12 bundle is at \u0026#34;./localhost+1.p12\u0026#34; The legacy PKCS#12 encryption password is the often hardcoded default \u0026#34;changeit\u0026#34; It will expire on 15 April 2026 c. 关于证书信任 c.1 设置nodejs证书信任 Node 不使用系统根存储，因此不会自动信任mkcert证书。必须设置 NODE_EXTRA_CA_CERTS 环境变量。\n1 export NODE_EXTRA_CA_CERTS=\u0026#34;$(mkcert -CAROOT)/rootCA.pem\u0026#34; Reference 概念说明\n生成证书\n","description":"","id":0,"section":"posts","tags":["Devops","证书","PKI","Mkcert"],"title":"mkcert-本地、局域网自签证书解决https访问问题","uri":"https://hex-go.github.io/posts/devops/2024-03-14-mkcert-%E6%9C%AC%E5%9C%B0%E5%92%8C%E5%B1%80%E5%9F%9F%E7%BD%91%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E8%A7%A3%E5%86%B3https%E8%AE%BF%E9%97%AE%E9%97%AE%E9%A2%98/"},{"content":"1.简介 容器在主机内核上运行，从内核中获取时钟，但时区并非来自内核，而是来自用户空间。因此，在大多数情况下，它们默认使用UTC时间。虽然代码处理时间时可以考虑时区信息从而避免时区问题带来的错误，但容器日志和系统日志信息中的时间显示会影响问题定位与解决。而且有些应用程序将机器的时区作为默认时区，并希望用户设置时区。本文将系统的说明时区问题，以及解决时区问题的几种配置方法。不过，在解决方案之前，我们先来了解一下问题所在。\n2.时区说明 2.1 时区信息格式 在大多数 UNIX 系统中，不同的时区由时区信息格式（ Time Zone Information Format）定义。这是 20 世纪 80 年代推出的一种二进制文件格式。这些文件可以在IANA 时区数据库中找到（通常位于/usr/share/zoneinfo）。在大多数发行版中，这些文件都是作为发行版的一部分，默认安装。\n对于容器基础镜像而言，大部分基础镜像（Ubuntu/Debian/alpine）默认情况下并不包含这个软件包，因此需要手动安装：\n1 2 3 4 5 # debian/ubuntu apt-get install tzdata # alpine apk add tzdata # centos/fedora的基本镜像默认安装了 tzdata 软件包 2.2 如何指定时区 但仅有这些文件还不够，我们还需要在主机（或容器）中指定所需的时区。有两种方法：\n/etc/timezone文件：只有Ubuntu/debian生效，不具备通用性，不建议使用。\n2.2.1 /etc/localtime文件 /etc/localtime文件配置本地系统的全系统时区。它通常是一个指向/usr/share/zoneinfo的软链接，后面跟一个时区数据库名称，如 \u0026ldquo;Asia/Shanghai\u0026rdquo;（即 /usr/share/zoneinfo/Asia/Shanghai）。\n1 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 2.2.2 TZ 环境变量 优先级更高\n将TZ环境变量设置为时区标识符（如 TZ=Asia/Shanghai）来设置时区，通常只在程序所需时区与主机时区不同的情况下进行设置。它的优先级比/etc/localtime更高。\n1 export TZ=Asia/Shanghai 3.配置方法 以alpine:3.19.1镜像举例说明\n通过运行下面命令\n1 docker run --rm -i alpine:3.19.1 date 输出为\n1 Wed Mar 13 06:06:18 UTC 2024 可以看出，alpine:3.19.1镜像时区为UTC。Alpine基础镜像默认不包含/usr/share/zoneinfo或/etc/localtime，正如上面对时区实现的说明，这些都是设置容器时区所必需的。\n3.1 构建镜像时配置 可以在镜像构建时，安装tzdata软件包，并设置TZ环境变量来完成时区设置。具体Dockerfile内容如下：\n1 2 3 4 5 6 7 8 9 FROM alpine:3.19.1 ENV TZ=Asia/Shanghai # 国内源加速 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN apk upgrade --update \\ \u0026amp;\u0026amp; apk add -U tzdata 如果以后时区都不需要更改，且想精简镜像体积。可以使用下面的Dockerfile\n安装 tzdata 软件包 复制需要的时区信息（例如，/usr/share/zoneinfo/Asia/Shanghai） 卸载 tzdata 软件包 重新创建文件夹 /usr/share/zoneinfo/Asia/（因为卸载会删除该文件夹） 将之前复制的文件放回该目录 设置时区。可通过TZ环境变量；也可通过/etc/localtime 软连接。 1 2 3 4 5 6 7 8 9 10 11 12 13 FROM alpine:3.19.1 ENV TZ=Asia/Shanghai # 国内源加速 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN \\ apk add tzdata \u0026amp;\u0026amp; \\ cp /usr/share/zoneinfo/Asia/Shanghai /tmp \u0026amp;\u0026amp; \\ apk del tzdata \u0026amp;\u0026amp; \\ mkdir -p /usr/share/zoneinfo/Asia/ \u0026amp;\u0026amp; \\ mv /tmp/Shanghai /usr/share/zoneinfo/Asia/ 或\n1 2 3 4 5 6 7 8 9 10 11 12 FROM alpine:3.19.1 # 国内源加速 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apk/repositories RUN \\ apk add tzdata \u0026amp;\u0026amp; \\ cp /usr/share/zoneinfo/Asia/Shanghai /tmp \u0026amp;\u0026amp; \\ apk del tzdata \u0026amp;\u0026amp; \\ mkdir -p /usr/share/zoneinfo/Asia/ \u0026amp;\u0026amp; \\ mv /tmp/Shanghai /usr/share/zoneinfo/Asia/ \u0026amp;\u0026amp; \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 缺点：\n并非所有镜像都有包管理器，有些镜像只是FROM scratch 要为所有镜像（尤其是一些不重新构建的中间件镜像）维护一个 Dockerfile，增加复杂性 需要在构建时就确定时区 3.2 容器运行时配置 除了在构建时安装 tzdata 软件包，还可以在容器运行时，从宿主机上加载所需的时区文件，例如：\n1 docker run -v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime -i --rm alpine:3.19.1 date 使用 -v 将主机上的TZif文件直接挂载到容器的/etc/localtime，从而解决了容器时区问题。\n如果容器后续需要修改其他时区，建议挂在整个/usr/share/zoneinfo目录\n缺点：\n提高了运维人员的维护成本，容易出现人为失误 需要提前确定，主机是否安装tzdata 3.3 Pod中手动设置 使用hostPath将K8S节点上的时区文件挂载至容器中。创建tz-test.yaml文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 apiVersion: v1 kind: Pod metadata: name: tz-test spec: containers: - image: alpine:3.19.1 name: tz-test args: - date volumeMounts: - name: zoneinfo mountPath: /etc/localtime subPath: Asia/Shanghai readOnly: true volumes: - name: zoneinfo hostPath: path: /usr/share/zoneinfo restartPolicy: OnFailure 缺点：\n手动操作，维护成本高 无法保证集群中的所有节点都安装了 tzdata hostPath权限问题，且有安全隐患 如果使用helm chart，则需要定制化修改 3.4 通过k8tz管理 k8tz 可以将时区注入Pod和CronJobs ，只需极少的工作就能在 pod 和命名空间中自动标准化选定的时区。它可以作为手动工具，在本地自动转换部署yaml和 Pod；也可以作为准入控制器，使用annotations为创建的任何 Pod 完全自动执行流程。\nk8tz不使用hostPath，而是分配emptyDir，并注入initContainer，用 TZif 文件填充卷。然后，使用emptyDir将/etc/localtime和/usr/share/zoneinfo挂载到Pod中的每个容器。为了确保所需的时区有效，它会在所有容器中添加TZ环境变量。\n3.4.1 安装 1 2 helm repo add k8tz https://k8tz.github.io/k8tz/ helm install k8tz k8tz/k8tz --set timezone=Asia/Shanghai 运行下面命令测试：\n1 kubectl run -it ubuntu --image=alpine:3.19.1 --restart=OnFailure --rm=true --command date 3.4.2 配置 安装时全局设置 1 helm install k8tz k8tz/k8tz --set timezone=Asia/Shanghai 通过Pod注解设置 1 kubectl run -it ubuntu --image=alpine:3.19.1 --restart=OnFailure --rm=true --command date --annotations k8tz.io/timezone=Asia/Shanghai 通过Namespace注解设置(与Pod相同) 3.4.3 注解说明 Controller的行为可通过 Pod、Namespace对象上的注解进行控制。如果在两个对象中指定了相同的注解，则Pod 优先级更高。\nAnnotation 描述 默认值 k8tz.io/inject k8tz 是否注入时区 true k8tz.io/timezone 决定设置哪个时区, e.g: Asia/Shanghai UTC k8tz.io/strategy 决定使注入策略, i.e: hostPath/initContainer initContainer 缺点：\n如果容器下集群，通过docker运行时，运维人员容易失误，遗漏时区设置 4. 总结 由于国内时区不需要频繁修改，建议需要重新构建的镜像在基础镜像中将时区配置正确；k8s集群中部署k8tz，解决中间件时区设置问题；docker-run运行的中间件，单独维护，并将运行脚本版本化控制。\n5.参考 k8tz/k8tz: Kubernetes admission controller and a CLI tool to inject timezones into Pods and CronJobs (github.com)\n","description":"理解容器时区问题的根源及常见解决方法：镜像构建时配置、容器运行命令时配置、Pod通过hostPath挂载解决、k8tz解决","id":1,"section":"posts","tags":["Kubernetes","k8tz","Timezone"],"title":"理解容器时区问题的根源及常见解决方法","uri":"https://hex-go.github.io/posts/kubernetes/2024-03-13-%E7%90%86%E8%A7%A3%E5%AE%B9%E5%99%A8%E6%97%B6%E5%8C%BA%E9%97%AE%E9%A2%98%E7%9A%84%E6%A0%B9%E6%BA%90%E5%8F%8A%E5%B8%B8%E8%A7%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"content":"1.简介 RPC是分布式系统的基础，可以像调用本地一样发起远程调用。是解决分布式系统通信问题的一大利器。\n分布式系统包括：消息队列、分布式缓存、分布式数据库、配置中心等\nRPC对网络通信的整个过程（查找对端节点、建立网络连接、编解码数据、网络连接管理）做了完整的包装，在搭建分布式系统时，简化网络通信逻辑的开发、确保网络通信的安全可靠。\nRPC基础（基本原理与网络通信）：序列化、编解码、网络传输等。\nRPC进阶（治理功能、集群管理）：连接管理、健康检测、负载均衡、优雅启停机、异常重试、业务分组、熔断限流等。\nRPC高级：性能优化与问题定位解决。\n2.概念 RPC（Remote Procedure Call）即远程过程调用。指屏蔽网络编程细节，跨机器而非本机实现调用远程方法与调用本地（同一项目中的方法）一样的体验。\n屏蔽远程调用与本地调用的区别 隐藏底层网络通信的复杂新 RPC过程：\n3.总结 4.参考 ","description":"","id":2,"section":"posts","tags":["Go"],"title":"RPC整理-1-基础概念与使用","uri":"https://hex-go.github.io/posts/golang/2024-02-25-rpc%E6%95%B4%E7%90%86-1-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"content":"1.问题描述 开发同事编写Dockerfile时遇到问题，ENTRYPOINT [\u0026quot;java\u0026quot;, \u0026quot;$JAVA_OPTS\u0026quot;, \u0026quot;-jar\u0026quot;, \u0026quot;/app.jar\u0026quot;]无法实现变量替换。自己工作中涉及变量替换等操作时，都是将shell命令放到可执行文件中，虽然对同事的这种写法奇怪，但当时也确实没发现错误的原因，深入了解过EXEC格式后，吃透了这个问题。\n2.说明 Dockerfile中的ENTRYPOINT\\RUN\\CMD具备两种格式：EXEC格式和SHELL格式。\n2.1 exec格式： 示例：\nENTRYPOINT [\u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;/start.sh\u0026quot;]，\n实现：\n直接使用命令本身来执行，不需要通过Shell解释器。实际程序PID=1，可以接收、处理信号，实现优雅启停。\n优点：\n高效 安全 缺点：\n不能使用Shell语法，灵活性差 2.2 shell格式: 写法示例：\n1 2 3 4 5 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y --no-install-recommends \\ package-A \\ package-B \\ package-C \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* 实现：\n此格式是使用Shell解释器来执行命令，最终程序被执行时，类似于/bin/sh -c的方式运行了我们的程序，这样会导致/bin/sh以PID为1的进程运行，\n而实际程序是它fork/execs出来的子进程。\n优点：\n可以使用Shell语法，例如管道、重定向等，这增加了Dockerfile的灵活性；\n缺点：\nsh父进程带来额外开销； 存在安全隐患，如shell注入攻击； 无法实现优雅启停，docker stop的SIGTERM信号只是发送给容器中PID为1的进程，无法传递给子进程，实际进程实际程序无法接收、处理信号； 3.解决 想要在EXEC格式的ENTRYPOINT中引用环境变量，需要编写shell脚本。在脚本中，变量替换与反斜线转义都是生效的。然后ENTRYPOINT使用exec格式执行。\n即脚本/start.sh内容为\n1 java $JAVA_OPTS -jar /app.jar Dockerfile中的内容为\n1 ENTRYPOINT [\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;/start.sh\u0026#34;] 也可以通过 ENTRYPOINT [\u0026quot;/bin/sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;java $JAVA_OPTS -jar /app.jar\u0026quot;]实现变量替换，但java进程无法接收、处理信号，不推荐\n3.总结 一般来说，除非需要 shell 功能，否则应使用exec格式；如果需要ENTRYPOINT或CMD中的 shell 功能，则应考虑编写shell脚本，然后使用exec格式执行。\nshell格式：使用Shell解释器来执行命令，更灵活但也更复杂、更容易受到攻击。\nexec格式：直接使用命令本身来执行，更简单、更高效、更安全，推荐使用。\n名称 最佳使用场景 shell功能 是否能处理信号 程序ID shell格式 RUN 支持(可引用变量、反斜线转义) 否 1进程的子进程 exec格式 ENTRYPOINT\\CMD 不支持 是(可将信号传递给程序处理，实现优雅启停) 1 4.参考 exec-form 变量替换\n优雅的终止docker容器\n关于 Dockerfile ENTRYPOINT 需要知道的一切\n","description":"","id":3,"section":"posts","tags":["Devops"],"title":"Docker易错集锦-1: Dockerfile的ENTRYPOINT中的环境变量无法替换","uri":"https://hex-go.github.io/posts/devops/2023-11-02-docker%E6%98%93%E9%94%99%E9%9B%86%E9%94%A6-1_dockerfile%E7%9A%84entrypoint%E4%B8%AD%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"content":"Kubernetes的网络模型是软件定义网络（SDN），原理与硬件物理网络相同，有下面几条规则需要牢记：\n每个Pod都有自己的 IP 地址：不需要在 Pod 之间创建链接，也不需要将容器端口映射到主机端口。 不需要NAT：节点上的 Pod 无需 NAT 即可与所有节点上的所有 Pod 通信。 代理获得全访问通行证：节点上的代理（系统守护进程、Kubelet）可以与该节点上的所有 Pod 通信。 共享命名空间：Pod 中的容器共享一个网络命名空间（IP 和 MAC 地址），因此它们可以使用环回地址相互通信。 K8S网络能解决什么问题 Kubernetes网络是为了确保 Kubernetes 中的不同实体类型能够通信。Kubernetes基础设施之间有很多分隔。命名空间、容器和 Pod 的目的是保持组件之间的区别，因此高度结构化的通信计划非常重要。\n参考链接 Kubernetes 网络基础知识可视化指南\n","description":"","id":4,"section":"posts","tags":["Kubernetes"],"title":"K8s网络CNI-不同对象之间通信说明","uri":"https://hex-go.github.io/posts/kubernetes/2023-09-03-k8s%E7%BD%91%E7%BB%9Ccni-%E4%B8%8D%E5%90%8C%E5%AE%9E%E4%BD%93%E4%B9%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E8%AF%B4%E6%98%8E/"},{"content":"Canal 完美保持Flannel原生的三种模式，扩展支持Calico的BGP、IPIP模式。并且支持网络策略。\nCanal 表示使用Flannel通过VXLAN处理主机间的pod流量，使用Calico处理同一主机内的pod流量和网络策略。\nCanal项目可以理解为同时使用Calico、Flannel的最佳实践, 通过Calico CNI和Calico 网络策略与Flannel和主机本地IPAM插件相结合，以提供具有策略执行功能的 VXLAN 网络。\n同时具备了flannel与calico的能力，但相应的也存在维护两个组件的复杂度。\ncanal项目初始是为了将两者深度集成，后来发现使用canal的用户的需求只是为了让两者更好的协同，没有将两者合一的需求。因此canal项目已不维护，只停留在部署方案上。如果熟悉两个中间件，又想同时使用calico、与flannel的能力，可以考虑canal\nPolicy IPAM CNI Overlay Routing Datastore Calico Host-local Calico VXLAN Static Kubernetes 路由：static，用于路由主机之间的pod流量。静态路由通常与主机本地 IPAM 插件结合使用，后者会为每个主机静态分配一个 /24 pod IP 地址范围。\n数据持久化：Kubernetes，即通过连接api-server进行数据的修改（不需要单独的存储管理；可通过api-server的rbac进行权限管理；可通过k8s的审计功能进行审计）\n参考链接 Canal项目地址(不维护)\nCalico解决网络策略，flannel解决网络通信(canal）\n","description":"","id":5,"section":"posts","tags":["Canal","Kubernetes"],"title":"K8s网络CNI-Canal详细说明","uri":"https://hex-go.github.io/posts/kubernetes/2023-09-02-k8s%E7%BD%91%E7%BB%9Ccni-canal%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E/"},{"content":"Calico由Tigera维护，是k8s中另一个流行的开源CNI插件。适用于网络性能、灵活性和功率等因素至关重要的环境。\n与 Flannel 不同，Calico 提供先进的网络管理安全功能，同时提供主机和 pod 之间的网络连接。\n1. calico架构 组件：\n在标准的 Kubernetes 集群上，Calico 可以作为 DaemonSet 轻松部署在每个节点上。集群中的每个节点都将安装三个 Calico 组件：Felix、BIRD和用于管理多个网络任务的confd。\nFelix作为 Calico 代理处理节点路由，而BIRD和confd则管理路由配置更改。\n原理：\nCalico的设计比较新颖，Flannel的Host-Gateway模式之所以不能跨二层网络，是因为它只能修改主机的路由，Calico把改路由表的做法换成了标准的BGP路由协议。\n相当于在每个节点上模拟出一个额外的路由器，由于采用的是标准协议，Calico模拟路由器的路由表信息就可以被传播到网络的其他路由设备中，这样就实现了在三层网络上的高速跨节点网络。\n不过在现实中的网络并不总是支持BGP路由的(部分内网和公网的局部区域不支持BGP)，因此Calico也设计了一种IPIP模式，使用Overlay的方式来传输数据。IPIP的包头非常小，而且也是内置在内核中的，因此它的速度理论上比VxLAN快一点点，但安全性更差。\n或 VXLAN 可以实现覆盖网络模式，像覆盖网络一样封装跨子网发送的数据包。\nCalico BGP 协议使用未封装的 IP 网络结构，无需用封装层封装数据包，从而提高了k8s工作负载的网络性能。\n2. 流量加密 集群内的 pod 流量使用Wireguard进行加密，它可以创建和管理节点之间的隧道，提供安全的通信。\n3. Calico后端模式 Flannel的Host-Gateway模式之所以不能跨二层网络，是因为它只能修改主机的路由，Calico把改路由表的做法换成了标准的BGP路由协议。\n但带来了新的问题：部分内网和公网的局部区域不支持BGP，因此Calico的妥协机制为IPIP模式，calico也支持vxlan模式\nbackend实现方式 适用场景 优点 限制 基于哪一层 实现方式 VxLAN 普遍适用，官方推荐 性能良好，手动干预少（易部署） 与部分内核不兼容 三层网络层 使用设备flannel.0进行封包解包，不是内核原生支持，上下文切换较大，性能非常差 IPIP 测试、在比较老的不支持VXLAN的Linux内核部署 简单、兼容性好 性能差 三层网络层 使用flannel.1进行封包解包，内核原生支持 bgp 网络性能要求比较高的场景 网络性能高 对基础网络架构有要求 二层网络 无需flannel.1这样的中间设备，直接宿主机当作子网的下一跳地址，性能最强 RR 网络性能要求比较高的场景 网络性能高 对基础网络架构有要求 二层网络 无需flannel.1这样的中间设备，直接宿主机当作子网的下一跳地址，性能最强 3.0 Pod-Node通信的网络模型 Node上每有一个Pod，则会在节点上创建一个veth pair, Calico 通过一个巧妙的方法将 Pod 的所有流量引导到一个特殊的网关 169.254.1.1，从而引流到主机的 calixxx 网络设备上，最终将二三层流量全部转换成三层流量来转发。\n在主机上通过开启代理 ARP 功能来实现 ARP 应答，使得 ARP 广播被抑制在主机上，抑制了广播风暴，也不会有 ARP 表膨胀的问题。\n选取节点node1中的容器pod-a作为实验节点，进入容器pod-a查看IP地址： 172.17.8.2/32 容器IP地址为/32位的地址，表示容器是一个单点的局域网\n1 2 3 4 5 6 7 8 9 [root@pod-a-bc2sm /]$ ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 3: eth0@if771: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u0026gt; mtu 1440 qdisc noqueue state UP link/ether 66:fb:34:db:c9:b4 brd ff:ff:ff:ff:ff:ff inet 172.17.8.2/32 scope global eth0 valid_lft forever preferred_lft forever 查看容器pod-a的默认路由: 根据以下路由表信息可以知道：169.254.1.1为容器默认网关，但没有任一网卡对应此IP地址。\n当一个数据包的目的地址不是本机时，会查询路由表，从路由表查询到网关后，会通过arp获取网关的mac地址，然后在二层网络数据包中将目标mac替换为网关的mac地址。也就是说，网关IP只是为了能找到网关的mac地址，响应arp就行。\n1 2 3 [root@pod-a-bc2sm /]$ ip route default via 169.254.1.1 dev eth0 169.254.1.1 dev eth0 scope link 查看容器的arp缓存： ip neigh: 用于查看系统上的邻居表(Neighbor Table)，通常也称为ARP缓存表。这个表存储本机与其它机器或网络设备之间的关联。\n返回信息依次为: 目标设备IP地址(169.254.1.1) 与目标设备通信的网卡(dev eth0) 目标设备mac地址(lladdr ee:ee:ee:ee:ee:ee) 与目标设备通信状态(REACHABLE)\narp获取mac地址过程：内核会对外发送arp请求，询问二层网络中拥有169.254.1.1地址的mac，拥有此ip的设备会在二层网络中响应自己的mac地址。\nmac地址为calico设置的，如何响应arp：容器和主机都没有169.254.1.1IP地址，甚至连主机上的端口 calicba2f87f6bb，MAC 地址也是一个无用的 ee:ee:ee:ee:ee:ee。按道理容器和主机网络根本就无法通信,但calico采用了网卡代理arp功能。\n1 2 [root@pod-a-bc2sm /]$ ip neigh 169.254.1.1 dev eth0 lladdr ee:ee:ee:ee:ee:ee REACHABLE 代理arp 代理ARP(Proxy ARP): 是 ARP 协议的一个变种，当 ARP 请求目标跨网段时，网关设备收到此 ARP 请求，会用自己的 MAC 地址返回给请求者。\n确认宿主机开启了代理arp:\n1 2 cat /proc/sys/net/ipv4/conf/calicba2f87f6bb/proxy_arp 1 3.1 BGP Flannel host-gw方式的改进版\n边界网关协议（Border Gateway Protocol， BGP）：是互联网上一个核心的去中心化自治路由协议。BGP不使用传统的内部网关协议（IGP）的指标。\n3.1 IPIP IPIP模式(IP in IP Overlay):即在IP报文基础上，又封装了一个IP头，和VXLAN类似（但封装头更小，比vxlan理论性能稍强）\n| HostMac | HostIP | RealIP | Data |\n把 IP 层封装到IP层的一个tunnel。作用其实基本上就相当于一个基于IP层的网桥！一般来说，普通的网桥是基于mac层的，根本不需IP，\n而这个IPIP则是通过两端的路由做一个tunnel，把两个本来不通的网络通过点对点连接起来。\n以两个node上的两个容器为例，说一下报文的流动过程。\n报文从PodA(10.244.104.14)发出，根据路由发往容器中的网关169.254.1.1\n但PodA中路由信息如下(没有)：\n1 2 3 4 5 [root@pod-a-bc2sm /]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 169.254.1.1 0.0.0.0 UG 0 0 0 eth0 169.254.1.1 0.0.0.0 255.255.255.255 UH 0 0 0 eth0 查看网关通向的二层地址(mac地址)，容器中网关arp地址为ee:ee:ee:ee:ee:ee：\n1 2 3 [root@pod-a-bc2sm /]# arp -n Address HWtype HWaddress Flags Mask Iface 169.254.1.1 ether ee:ee:ee:ee:ee:ee C eth0 集群节点上执行下面命令，查看mac地址ee:ee:ee:ee:ee:ee对应的网卡\n1 2 3 4 5 6 [root@node1 /]# ifconfig | grep -E \u0026#34;flags|ether\u0026#34; cali0a4fde325ea: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1480 ether ee:ee:ee:ee:ee:ee txqueuelen 0 (Ethernet) cali43af9e40d9b: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1480 ether ee:ee:ee:ee:ee:ee txqueuelen 0 (Ethernet) ... 容器中网卡是veth的pair虚拟网卡，一端连接容器(pod-a:eth0),一端连接宿主机(node-a:cali0a4fde325ea)。因此，执行下面命令，查看容器内网卡编号：\n1 2 3 [root@pod-a-bc2sm /]# ethtool -S eth0 NIC statistics: peer_ifindex: 14 确认宿主机编号为14的网卡\n1 2 3 4 [root@node1 /]# ip link show ... 14: cali0a4fde325ea@if4: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1480 qdisc noqueue state UP mode DEFAULT link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 4 因此容器(pod-a-bc2sm)中的报文通过cali0a4fde325ea网卡到达宿主机(node1)然后根据宿主机路由，将报文发往tunl0\n3.3 Route Reflector 模式（RR）（路由反射）： Calico维护的网络在默认是（Node-to-Node Mesh）全互联模式，Calico集群中的节点之间都会相互建立连接，用于路由交换。\n但是随着集群规模的扩大，mesh模式将形成一个巨大服务网格，连接数成倍增加。这时就需要使用 Route Reflector（路由器反射）模式解决这个问题。\n4. 网络策略 Calico 的网络策略实现了拒绝/匹配规则，这些规则可通过清单应用，为 pod 分配入口策略。用户可以定义全局范围的策略，并与 Istio 服务网格集成，以控制 pod 流量、提高安全性并管理k8s的工作负载。\n5. 实验举例 6. 总结 calico具有以下的优点：\n高性能：Calico BGP 协议使用未封装的 IP 网络结构，无需用封装层封装数据包，从而提高了k8s工作负载的网络性能。 支持流量加密：集群内pod流量使用Wireguard创建vpn进行安全的通信。 便于跟踪调试：因为不存在操纵数据包的包装器，跟踪和调试比其他工具容易得多。开发人员和管理员可以轻松了解数据包行为，并使用策略管理和访问控制列表等高级网络功能。 支持网络策略： 总之，对于希望控制网络组件的用户来说，Calico 是一个极佳的选择。Calico 可以与不同的k8s平台（如 kops、Kubespray）轻松配合使用，也可按需向Calico Enterprise获取商业支持。\n参考链接 Calico网络策略确保CNI的安全（利用 Calico 强化 Kubernetes 网络策略）\nKubernetes 网络：使用 Calico 实现高性能\nMAC地址、IP地址以及ARP协议详细讲解\n","description":"","id":6,"section":"posts","tags":["Calico","Kubernetes"],"title":"K8s网络CNI-Calico详细说明","uri":"https://hex-go.github.io/posts/kubernetes/2023-09-01-k8s%E7%BD%91%E7%BB%9Ccni-calico%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E/"},{"content":"Flannel由CoreOS开发，是k8s最成熟的开源CNI插件之一。它提供了一个开箱即用的网络模型，旨在实现更好的容器和主机间的网络。\nFlannel使用K8S集群的现有etcd集群来使用API存储其状态信息，不需要单独配置数据存储。\nFlannel通过配置一个3层的IPv4 Overlay网络来运行。该网络是一个跨越集群中每个节点的大型内部网络，在此Overlay网络中，每个节点都有一个子网，用于在内部分配IP地址。\n每个节点会运行一个flanneld的进程，负责子网租赁和管理。\n在配置Pod时，每个节点上的网桥接口都会为每个新容器分配一个地址。\n同一主机中的Pod可以使用网桥进行通信， 不同主机上的Pod会使用flanneld配置的后端其流量封装在UDP数据包中，以便路由到适当的目标。 Flannel有几种不同类型的后端可用于封装和路由。默认和推荐使用VXLAN，因为VXLAN性能更良好并且需要的手动干预更少。\n1. Flannel的后端 Flannel通过在每一个节点上启动一个叫flanneld的进程，负责每一个节点上的子网划分，并将相关配置信息（如各节点的子网网段、外部IP等）保存到etcd中，而具体的网络报文转发交给后端实现。\nflanneld启动时通过配置文件指定不同的后端进行网络通信，目前比较成熟的后端有UDP、VxLAN(Virtual Extensible Lan)和host-gateway三种。\nbackend实现方式 适用场景 优点 限制 基于哪一层 实现方式 VxLAN 普遍适用，官方推荐 性能良好，手动干预少（易部署） 与部分内核不兼容 三层网络层 使用设备flannel.0进行封包解包，不是内核原生支持，上下文切换较大，性能非常差 UDP 测试、在比较老的不支持VXLAN的Linux内核部署 简单、兼容性好 性能差 三层网络层 使用flannel.1进行封包解包，内核原生支持 host-gateway 网络性能要求比较高的场景 网络性能高 对基础网络架构有要求 二层网络 无需flannel.1这样的中间设备，直接宿主机当作子网的下一跳地址，性能最强 1.1 VxLan模式详解 VXLAN Overlay(L2 in UDP): 采用内置在Linux内核里的标准协议，因此虽然它的封包结构比UDP模式复杂，但由于所有数据装、解包过程均在内核中完成，实际的传输速度要比UDP模式快许多。\n| HostMac | HostIP | UDP | vxlan | RealMac | RealIP | Data |\nflanneld服务为无状态服务，在每个节点启动一个flanneld服务，监听端口为8472(VXLAN)，其它节点会用一个随机端口连接到目标主机的8472端口，采用UDP协议进行发布。\n如下面一条抓包数据所示：\n源 192.168.1.1节点的pod[10.42.1.2] 中去ping 目的 192.168.1.2节点的pod[10.42.2.6]，抓取源主机 192.168.1.1 的enp0s3设备的udp包：\n1 2 3 192.168.1.215.38381 \u0026gt; 192.168.1.216.8472: [bad udp cksum 0x11bc -\u0026gt; 0x6334!] OTV, flags [I] (0x08), overlay 0, instance 1 f2:60:ca:96:7f:1f \u0026gt; 4a:02:36:26:f9:c1, ethertype IPv4 (0x0800), length 74: (tos 0x0, ttl 64, id 34781, offset 0, flags [DF], proto TCP (6), length 60) 10.42.0.0.10384 \u0026gt; 10.42.1.7.443: Flags [S], cksum 0x1589 (incorrect -\u0026gt; 0x6701), seq 1841703998, win 64240, options [mss 1460,sackOK,TS val 3365946307 ecr 0,nop,wscale 7], length 0 192.168.1.1.39338 \u0026gt; 192.168.1.2.8472: UDP 数据包的源 IP 地址是 192.168.1.1，源端口号是 39338，目标 IP 地址是 192.168.1.2，目标端口号是 8472 以太网帧信息：\nf2:60:ca:96:7f:1f \u0026gt; 4a:02:36:26:f9:c1：源 MAC 地址是 f2:60:ca:96:7f:1f[192.168.1.1 enp0s3]，目标 MAC 地址是 4a:02:36:26:f9:c1[192.168.1.2 enp0s3]。 ethertype IPv4 (0x0800)：以太网帧的类型为 IPv4。 length 98：数据包的总长度为 98 字节。 最后是 IPv4 报文的信息：\n10.42.1.2.10384 \u0026gt; 10.42.2.6.443：TCP数据包的源IP地址是10.42.1.2，源端口号是10384，目标IP地址是10.42.2.6，目标端口号是443 Flags [S]：TCP 数据包的标志字段，其中 [S] 表示该数据包是一个 TCP 连接的初始 SYN 数据包。 cksum 0x1589 (incorrect -\u0026gt; 0x6701)：TCP 数据包的校验和字段，当前显示的是错误的校验和。 seq 1841703998：TCP 数据包的序列号。 win 64240：TCP 数据包的窗口大小。 1.2 UDP模式 UDP Overlay(IP in UDP): 使用了Flannel自定义的一种包头协议，数据是在Linux的用户态进行封包\\解包，因此当数据进入主机后，需要经历两次内核态到用户态的转换。\n| HostMac | HostIP | UDP | RealIP | Data |\n1.3 host-gateway模式 与前两种模式（覆盖网络）不同，host-gw采取的是主机路由的方案\n这种方案的思路是，既然在无法进行路由是因为网络中的节点之间没有路由信息，但Flannel是知道这个信息的，Flannel把这个信息告诉网络上的节点\n| RealIP | Data |\nFlannel通过在各个节点上的Agent进程，将容器网络的路由信息刷到主机的路由表上，这样一来所有的主机就都有整个容器网络的路由数据了。\nHost-Gateway的方式没有引入像Overlay中的额外装包解包操作，完全是普通的网络路由机制，它的效率与虚拟机直接的通信相差无几。\n然而，由于Flannel只能够修改各个主机的路由表，一旦主机直接隔了个其他路由设备，比如三层路由器，这个包就会在路由设备上被丢掉。\n这样一来，Host-Gateway的模式就只能用于二层直接可达的网络，由于广播风暴的问题，这种网络通常是比较小规模的，但近年来也出现了一些专门的设备能够构建出大规模的二层网络（就是我们经常听到的“大二层”网络）。\n2. 封装流量加密 默认情况下，封装的流量是不加密的。Flannel 提供了两种加密方案，可以在 Kubernetes 集群的工作节点之间建立加密隧道：\nIPSec：使用 strongSwan 在 Kubernetes worker 之间建立加密的 IPSec 隧道。它是加密的实验性后端。 WireGuard：比 strongSwan 更快的替代方案。 3. 总结 Flannel 以其简单而有效的网络模型而闻名，这对于初学者来说是一个巨大的优势。以下是 Flannel 的主要亮点：\n简单有效的网络模型\nFlannel 提供了一个简单但高效的网络模型，特别适合那些希望迅速入门k8s网络的初学者。它使用了一种称为VXLAN（Virtual Extensible LAN）的技术，\n将容器放置在一个逻辑二层（L2）网络中，无需分配路由。这使得容器之间的通信变得非常容易管理，而无需复杂的配置。\n流量传输的无缝控制\nFlannel 的网络模型允许在主机之间实现无缝的流量传输。这对于集群管理员来说是一个关键的优势，因为它可以确保容器之间的通信顺畅，同时不会引入额外的延迟或瓶颈。\nFlannel 将网络控制平面信息交换成轻量级的 UDP 包，从而实现了对 MAC 地址的访问控制，确保了通信的安全性。\n集成和易用性\nFlannel 是一个广泛使用的 CNI 插件，因此它与各种 Kubernetes 部署环境和工具集成良好。对于初学者来说，这使得部署和管理k8s集群变得更加容易。\n而且，Flannel 不仅易于使用，还易于配置，这对于初学者来说是一个额外的好处。\n总之，对于想要入门k8s网络的初学者，Flannel 提供了一个出色的起点。其简单而高效的网络模型以及与k8s生态系统的广泛集成，使其成为学习和掌握容器网络基础的理想选择。\n通过Flannel，你可以在不陷入复杂性的情况下，快速搭建起稳定的k8s网络基础，为你的容器化应用提供可靠的网络通信支持。\n参考链接 Comparing CNI providers \u0026ndash; Flannel\n","description":"","id":7,"section":"posts","tags":["Flannel","Kubernetes"],"title":"K8s网络CNI Flannel详细说明","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-31-k8s%E7%BD%91%E7%BB%9Ccni-flannel%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E/"},{"content":"CNI(Container Network Interface)意为容器网络接口，它是一种标准的设计，为了让用户在容器创建或销毁时都能够更容易地配置容器网络。\n由Google和CoreOS联合定制的网络标准，是Kubernetes网络插件的基础。基于CNI标准，有如下常见的CNI网络插件产品。\n目前主流的网络插件是Flannel、Calico、cillium。这些插件既可以确保满足Kubernetes的网络要求，又能为Kubernetes集群管理员提供他们所需的某些特定的网络功能。\n本文讲通过Kubernetes集群中不同网络环境下，通过Pod之间流量分析来比较Flannel、Calico、cillium、canal处理网络流量的不同之处。\n1. Canal网络插件介绍 2020年废弃不再维护，项目维护者认为应该将精力放在为flannel和calico项目增加功能上，而非深度整合两者。\nCanal结合Flannel和Calico的网络功能。将Flannel叠加网络层和VXLAN封装与Calico的网络组件（如 Felix、主机代理和网络策略）集成在一起，\n使用Flannel处理节点间的流量，使用 Calico 处理节点内流量和网络策略(Calico网络策略，可以在网络方面提供项目/命名空间隔离)。\n总之，对于希望利用具有网络策略规则的覆盖网络模型来加强安全性的企业来说，Canal 是一个不错的选择。\n优点: Flannel叠加网络且支持网络策略、提供了统一部署Flannel和Calico的方法\n缺点: Flannel和Calico之间的集成度不高\nCanal 要求在节点上安装iptables或xtables-nft包。\n2. Calico网络插件介绍 基于BGP的纯三层网络方案，与OpenStack\\k8s\\aws\\gce都有良好集成，默认配置不启用任何网络策略\nCalico在每个计算节点上实现一个高效的vRouter(使用Linux Kernel)，负责数据转发。每个vRouter使用BGP协议在整个Calico网络中传播当前节点上运行的workload的路由信息。\n这确保了workload之间的数据流量通过IP路由互联，无需额外的NAT、隧道或Overlay网络。此外，Calico还基于iptables提供了丰富和灵活的网络策略，用于实现多租户隔离、安全组和其他可达性限制。\n优点： 支持网络策略、网络性能高、支持 SCTP\n缺点： 不支持组播\n3. Flannel网络插件介绍 Flannel通过给每个宿主机分配子网的方法为容器提供虚拟网络。基于Linux TUN/TAP，使用UDP封装IP包来创建overlay网络，并依靠etcd来管理网络分配数据。\nFlannel 是为 K8s 配置 L3 网络结构的简单方法。Flannel在每台主机上运行一个名为flanneld的二进制 Agent，flanneld负责从更大的预配置地址空间中为每台主机分配子网。\nFlannel 通过k8s API或直接使用etcd来存储网络配置、分配的子网、以及其他辅助数据（例如主机的公共 IP）。数据包使用某种后端机制来转发，默认封装为 VXLAN。\n默认情况下，封装的流量是不加密的。Flannel 提供了两种加密方案：\nIPSec：使用 strongSwan 在 Kubernetes worker 之间建立加密的 IPSec 隧道。它是加密的实验性后端。 WireGuard：比 strongSwan 更快的替代方案。 优点: 支持IPsec加密、单一二进制安装和配置\n缺点: 不支持网络策略、无法通过单个守护进程运行多台主机和多个网络，但可以为每台主机运行多个守护进程。\n4. Weave网络插件介绍 Weave Net是一个去中心化的容器网络方案，各个host上的wRouter间通过建立Full Mesh的TCP连接，并通过Gossip来同步控制信息。\n这种方式省去了集中式的K/V Store，一定程度上简化了部署复杂性，Weave将其称为data centric，而非Raft或者Paxos的algorithm centric。\n在数据平面上，Weave通过UDP封装实现L2 Overlay，封装支持两种模式，一种是在用户空间运行的sleeve mode（Flannel的udp），另一种是在内核空间运行的fastpath mode（Flannel的vxlan）。\nSleeve mode通过pcap设备在Linux bridge上截获数据包并由wRouter完成UDP封装，支持对L2 traffic进行加密，还支持Partial Connection，但是性能损失明显。 Fastpath mode通过OVS的odp封装VxLAN并完成转发，wRouter不直接参与转发，而是通过下发odp流表的方式控制转发，这种方式可以明显地提升吞吐量，但是不支持加密等高级功能。 fastpass相当于vxlan overlay, sleeve相当于udp overlay, 改进点在于：1. 支持网络策略；2.去除额外的中心化容器地址分配器，将配置存储功能集成至服务内部；\n优点: 内核级通信、网络策略和加密支持、提供有偿故障排除支持\n缺点: 由于基于内核的路由选择，只支持 Linux 系统、默认加密标准导致网络速度降低\n5. Cilium网络插件介绍 Cilium 在 Kubernetes 中启用网络和网络策略（L3、L4 和 L7）。默认情况下，Cilium 使用 eBPF 技术在节点内部路由数据包，并使用 VXLAN 将数据包发送到其他节点。也可以配置非封装的技术。\nCilium 推荐大于 5.2 的内核版本，从而充分利用 eBPF 的能力。Kubernetes worker 需要打开 TCP 端口 8472（VXLAN）和 TCP 端口 4240（健康检查）。此外，还必须为健康检查启用 ICMP 8/0。\n默认情况下，Cilium 不允许 Pod 与其他节点上的 Pod 通信。要解决此问题，请启用 Ingress Controller 以使用 “CiliumNetworkPolicy” 进行跨节点路由请求。\n选择 Cilium CNI 并为新集群启用项目网络隔离后，配置如下：\n1 2 3 4 5 6 7 8 9 10 apiVersion: cilium.io/v2 kind: CiliumNetworkPolicy metadata: name: hn-nodes namespace: default spec: endpointSelector: {} ingress: - fromEntities: - remote-node 各个网络插件的 CNI 功能 下表总结了 Rancher 中每个 CNI 网络插件支持的不同功能：\n提供商 网络模型 路由分发 网络策略 网格 外部数据存储 加密 加密协议 Ingress/Egress 策略 企业支持 Canal 封装(UDP/VXLAN/IPIP)、未封装（host-gw/BGP） 否 是 否 K8s API 是 IPsec、WireGuard 是 否 Flannel 封装(UDP/VXLAN)或未封装（host-gw） 否 否 否 K8s API 是 IPsec 否 否 Calico 封装(VXLAN/IPIP）或未封装(BGP) 是 是 是 Etcd 和 K8s API 是 IPsec 是 是 WeaveNet 封装(UDP/VXLAN) 是 是 是 否 是 WireGuard 是 是 Cilium 封装(VXLAN) 是 是 是 Etcd 和 K8s API 是 IPsec 是 否 网络模型：封装或未封装。如需更多信息，请参阅 CNI 中使用的网络模型。 路由分发：一种外部网关协议，用于在互联网上交换路由和可达性信息。BGP 可以帮助进行跨集群 pod 之间的网络。此功能对于未封装的 CNI 网络插件是必须的，并且通常由 BGP 完成。如果你想构建跨网段拆分的集群，路由分发是一个很好的功能。 网络策略：Kubernetes 提供了强制执行规则的功能，这些规则决定了哪些 service 可以使用网络策略进行相互通信。这是从 Kubernetes 1.7 起稳定的功能，可以与某些网络插件一起使用。 网格：允许在不同的 Kubernetes 集群间进行 service 之间的网络通信。 外部数据存储：具有此功能的 CNI 网络插件需要一个外部数据存储来存储数据。 加密：允许加密和安全的网络控制和数据平面。 Ingress/Egress策略：允许你管理 Kubernetes 和非 Kubernetes 通信的路由控制。 CNI 社区人气 下表总结了不同的 GitHub 指标，了解每个项目的受欢迎程度和活动。数据收集于 2023 年 8 月\n提供商 项目 Stars Forks Contributors Canal https://github.com/projectcalico/canal 704 104 21 Flannel https://github.com/flannel-io/flannel 8.2k 2.9k 223 Calico https://github.com/projectcalico/calico 4.9k 1.2k 320 Weave https://github.com/weaveworks/weave/ 6.5k 673 87 Cilium https://github.com/cilium/cilium 16.3k 2.4k 640 CNI 网络性能 理论上说，这些CNI工具的网络速度应该可以分为3个速度等级。\n最快的是Romana、Gateway模式的Flannel、BGP模式的Calico。\n次一级的是IPIP模式的Calico、Swarm的Overlay网络、VxLan模式的Flannel、Fastpath模式的Weave。\n最慢的是UDP模式的Flannel、Sleeve模式的Weave。\nBare \u0026gt; Flannel(host-gw) ~ Calico(bgp) \u0026gt; Calico(ipip) ~ Flannel(vxlan) \u0026gt; Flannel(udp)\n测试容器网络速度的具体方法\n引用 calico - 确定最佳联网方案(基本概念)\nCNI 网络插件(rancher)\nKubernetes CNI 插件选型和应用场景探讨\n","description":"","id":8,"section":"posts","tags":["CNI","Kubernetes"],"title":"K8s网络CNI-常见网络插件说明与横向对比","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-30-k8s%E7%BD%91%E7%BB%9Ccni-%E5%B8%B8%E8%A7%81%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E8%AF%B4%E6%98%8E%E4%B8%8E%E5%AF%B9%E6%AF%94/"},{"content":"网络架构是 K8S 的一个复杂组件。Kubernetes 网络模型对特定网络功能提出了要求。业界已开发出许多针对特定环境和要求的网络解决方案。\n容器网络接口（CNI）可让你在创建或销毁容器时轻松配置容器网络。本文将介绍经典网络插件的工作原理以及如何使用 CNI 插件。\n1. 什么是CNI？ CNI 是 Kubernetes 中的标准网络实现接口。Kubelet 通过 CNI 调用不同的网络插件，以实现不同的网络配置方法。常见的CNI插件有Calico、Flannel、Terway、Weave Net 和 Contiv 等。\n2. K8S中的CNI调用链 在群集中创建 Pod 时，API-Server会将 Pod 配置写入群集。API-Server的某些控制组件（如scheduler）被调度到特定节点。Kubelet 监听该 Pod 的创建后，会在当前节点执行一些创建操作。\n创建网络时，Kubelet 会读取配置目录（/etc/cni/net.d/）中的配置文件。配置文件声明了要使用的插件。Kubelet 执行 CNI 插件的二进制文件。\nCNI 插件会进入 Pod 的网络空间，配置 Pod 网络。Pod 网络配置完成后，Kubelet 将创建 Pod 并将其上线。\n上述过程中的配置文件、cni插件的可执行文件，都在cni插件安装时进行了配置和安装。\n3. CNI插件选型 3.1 后端模式 CNI 插件分为三种后端模式：Overlay(覆盖)、Routing(路由)、Underlay(底层)。\nOverlay模式: 容器的CIDR地址与主机的 IP 地址范围无关。在跨主机通信期间，主机之间会建立隧道，容器CIDR中的所有数据包都会封装为底层物理网络中主机之间交换的数据包。这种模式消除了对底层网络的依赖。\nRouting模式: 主机和容器属于不同的 CIDR 块。跨主机通信通过路由实现。不同主机之间不建立用于数据包封装的隧道。不过，路由互连部分取决于底层网络。例如，从底层网络到第 2 层必须有可到达的路由。\nUnderlay模式: 容器和主机位于同一网络层，共享同一位置。容器之间的网络互联取决于底层网络。因此，这种模式高度依赖底层能力。\n3.2 环境限制 不同的环境分别会有不同的限制以及能力。\n虚拟机环境：像OpenStack，施加了许多网络限制。1. 机器之间不能通过第2层协议直接访问，只能转发具有第3层特征（如 IP 地址）的数据包，主机只能使用指定的 IP 地址。因此只能选择Overlay模式下的插件，如 Flannel-VXLAN、Calico-IPIP、Weave等。\n物理机环境：对底层网络的限制很少。因此，可以选择Underlay模式或Routing模式的插件。在Underlay模式模式下，可以将多个网络接口控制器（NIC）直接插入物理机，或在 NIC 上虚拟硬件。在Routing模式下，路由是通过 Linux 路由协议建立的。这避免了 VXLAN 封装造成的性能下降。在这种环境下，可以选择 Calico-BGP、Flannel-HostGW 和 Sriov 等插件。\n公有云环境：是一种虚拟环境，对底层功能有许多限制。不过，每个公共云都会调整容器以提高性能，并可能提供 API 以配置额外的网卡或路由功能。公有云环境建议选择公有云供应商提供的 CNI 插件，以获得兼容性和最佳性能。\n3.3 功能要求 安全要求\n通过配置网络策略(NetworkPolicy)以支持是否允许节点间访问等策略。并非每个CNI插件都支持网络策略。如果需要 NetworkPolicy 支持，可以选择 Calico 或 Weave。\n集群内外资源互连\n部署在虚拟机（VM）或物理机上的应用程序无法一次性迁移到容器化环境。因此，有必要在虚拟机或物理机和容器之间配置 IP 地址互连，将它们互连或部署在同一层。\n这种情况下，可以选择 Underlay 模式下的插件。例如，Sriov 插件允许 Pod 和传统虚拟机或物理机在同一层运行。还可以使用 Calico-BGP 插件。虽然容器与传统虚拟机或物理机处于不同的 CIDR 块中，但可以使用 Calico-BGP 向原始路由器宣传 BGP 路由，从而实现虚拟机和容器之间的互联。\nK8S服务发现和负载均衡\n服务发现和负载平衡是k8s的一种Service资源。并非所有 CNI 插件都能提供这两项功能。对于处于 Underlay 模式的许多插件来说，Pod 的网卡是 Underlay 硬件，或者是通过硬件虚拟化并插入容器的。因此，NIC 流量无法路由到主机所在的命名空间。因此，无法应用 kube-proxy 在主机上配置的规则。\n在这种情况下，插件无法访问 Kubernetes 的服务发现功能。如果需要服务发现和负载平衡，请选择支持这两种功能的 Underlay 模式插件。\n3.4 性能要求 设计两个方面：POD创建速度，POD网络性能\nPod创建速度 在Pod创建时，CNI插件创建和配置相应的网络资源。Overlay与Routing模式可以快速创建Pod，插件可在机器上实现虚拟化，因此您只需调用内核接口即可创建Pod。\n如果选择 Underlay 模式的插件，则需要创建底层网络资源，这会减慢Pod创建过程。因此，需要快速扩展Pod、创建许多Pod时建议选择 Overlay 或 Routing 模式的插件。\nPod网络性能 Pod 的网络性能是通过 Pod 间网络转发、网络带宽和每秒脉冲 (PPS) 延迟等指标来衡量的。\nOverlay模式下的插件性能将低于Underlay和Routing模式下的插件，因为前者在节点上实现了虚拟化并对数据包进行了封装。这种封装会导致数据包头丢失和 CPU 消耗。\n因此，如果您在机器学习和大数据等场景中需要较高的网络性能，请不要选择 Overlay 模式的插件。建议选择 Underlay 或 Routing 模式的 CNI 插件。\n4. 如何开发一个CNI插件 社区提供的插件可能无法满足特定要求。例如，阿里云只能使用覆盖模式下的 VXLAN 插件。该插件性能相对较差，无法满足阿里云的某些业务需求。为此，阿里云开发了 Terway 插件。\n如果社区中的插件都不适合当前环境，可以开发一个 CNI 插件。\nCNI 插件的实现方法如下：\n二进制 CNI 插件用于配置 Pod 的网卡和IP地址。这相当于将一根网线连接到 Pod，而Pod有一个IP地址和网卡。 一个守护进程用于管理 Pod 之间的网络连接。这一步将 Pod 连接到网络，使它们能够相互通信。 4.1 为Pod配置网卡和IP 为Pod准备虚拟网卡\n创建veth虚拟网卡 一端连接到Pod的网络空间，另一端连接到主机的网络空间(Pod和主机的网络命名空间就连接起来了) 为Pod分配IP地址(为Pod分配一个集群唯中一的IP地址)\n根据节点为Pod分配CIDR区块(创建集群时,如下图创建了172.16.0.0/16段，每个节点分别分配了24位掩码的172.16.0.0/24段和172.16.1.0/24段，从而避免了节点间的IP地址冲突) 从节点的CIDR区块中为Pod分配IP地址(当前节点的IP地址分配既可以DHCP,也可以按序分配) 配置Pod的IP地址和路由\n为Pod网卡配置IP地址 为Pod网卡配置路由(入pod流量：在host上配置流向此POD-IP的路由指向此pod在主机上的veth1; 出pod的流量: 在Pod内的eth0网卡配置路由，pod访问集群外部)以便将指向此 pod 的流量路由到其 NIC。此外，在此 NIC 上配置默认路由的 CIDR 块，以便将通向 Internet 的流量路由到此 NIC。 4.1.1 为Pod准备NIC 可以将veth虚拟网卡的一端连接到Pod的网络空间，另一端连接到主机的网络空间。这样，pod 和主机的命名空间就连接起来了。\n4.1.2 为Pod分配IP地址 4.2 5. 总结 在环境中部署K8S集群时，如何选择合适的 CNI 插件。 当社区中可用的CNI插件无法满足需求时，如何开发 CNI 插件。 参考链接 KubeBuilder 简明教程\n","description":"","id":9,"section":"posts","tags":["CNI","Kubernetes"],"title":"K8s网络CNI-概念与入门","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-30-k8s%E7%BD%91%E7%BB%9Ccni-%E6%A6%82%E5%BF%B5%E4%B8%8E%E4%BB%8B%E7%BB%8D/"},{"content":" Flannel 是 Kubernetes 中常用的 CNI 插件之一，用于为容器提供网络连接。然而，在某些情况下，特定版本的\nFlannel 可能与某些内核版本不兼容，导致 \u0026ldquo;bad udp checksum\u0026rdquo; 错误，从而影响了跨节点的 Pod 通信。在本篇博客中，将详细介绍如何逐步排查和定位这个问题。\n当排查 Kubernetes 网络问题，特别是与 CNI（容器网络接口）有关的问题时，需要考虑以下方面：\n防火墙 iptables 规则 路由规则 cni中间件（本文为flannel）状态 以下是一步步排查防火墙、iptables 规则、route 路由规则并通过抓包定位 \u0026ldquo;bad udp checksum\u0026rdquo; 错误的过程\n环境说明 为简单定位问题，将节点缩减为2台，master: 192.168.1.10 worker: master: 192.168.1.11\nrke配置文件举例()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 cluster_name: general nodes: - address: 192.168.1.10 role: - controlplane - etcd - worker - address: 192.168.1.11 role: - worker ssh_key_path: /home/tgde/.ssh/id_ed25519 kubernetes_version: v1.19.8-rancher1-1 # Specify network plugin-in (canal, calico, flannel, weave, or none) network: plugin: canal private_registries: - url: reg.paas.org is_default: true dns: provider: coredns ingress: provider: none services: kubelet: extra_binds: - \u0026#34;/data:/data\u0026#34; 操作系统: Ubuntu 22.04.3 LTS os内核: 5.15.0-79-generic rke: v1.2.6 k8s安装包：v1.19.8-rancher1-1 flannel版本：v0.13.0-rancher1 network-plugin: canal 1. 确认错误现象 rke up 创建集群后，部署cert-manager后，创建ClusterIssuer时，cert-manager组件之间无法通过svc.ns访问\n节点名称 节点角色 node_IP node网卡 子网 子网网卡 node-1 master 192.168.1.1 ens160 10.42.0.0/24 flannel.1 node-2 worker 192.168.1.2 ens160 10.42.1.0/24 flannel.1 pod\npod名称 所属节点 集群内部IP dnstools node-1[192.168.1.1] 10.42.0.5 coffee-85cvd node-1[192.168.1.1] 10.42.0.6 coffee-mrj6s node-2[192.168.1.2] 10.42.1.3 测试结果为:\nk8s集群内部:\npod dnstools 可以ping通pod coffee-85cvd（同节点pod）,无法ping通pod coffee-mrj6s(跨节点pod)\n宿主机节点:\n宿主机可以 ping 通部署在当前主机上的pod ，去ping 部署在其他宿主机pod ip 不通\n期望的正常结果为:\nk8s集群内部pod可以与集群内部任意pod通信; 宿主机可以ping集群内所有pod的IP; 2. 排查防火墙 同时在 node-1[192.168.1.1] node-2[192.168.1.2]执行命令检查防火墙，确认状态已关闭\n1 systemctl status ufw.service 3. 确认节点之间没有安全组规则 机器部署在云服务器，检查安全组设置，排除安全组规则设置导致通信异常的问题。\n4. 排查iptables规则 -L: 列出当前的iptables规则\n-S: 查看当前的iptables规则的详细信息\n1 sudo iptables -L 4. 检查路由规则 1 route -n 5. 检查vxlan配置 6. 抓包 tcpdump \u0026lt;参数\u0026gt; -i \u0026lt;网卡\u0026gt; \u0026lt;过滤条件: udp|icmp\u0026gt;\nX: 输出数据包的内容，以十六进制和 ASCII 文本的形式。这允许你查看数据包的实际内容。 e: 在输出中显示以太网帧的详细信息，包括源和目标 MAC 地址以及帧类型。 n: 使用数字形式显示IP地址和端口号，而不进行 DNS 解析。（性能优化、隐私保护） i: 指定要捕获数据包的网络接口。 v/vv/vvv: 增加输出的详细程度，以便查看更多的信息。 源端网络\n1 sudo tcpdump -vvvenX -i ens160 udp 目的端网络\nflannel节点之间通过udp通信，需要将协议改为udp\n1 sudo tcpdump -vvvenX -i ens160 udp 总结 checksum-offload 指定了内核不做校验和，交给网卡去做，当使用VXLAN时，由于某些原因(参考连接1和2)，校验值计算错误导致Bad udp cksum错误，所以会丢弃。\n而canal中节点中间通信通过flannel 的vxlan实现，节点内部通讯通过calico，因此出现跨节点pod无法通信，同一节点pod通信正常的现象。\n解决 关闭 CNI VXLAN 网卡的 checksum offload 升级内核版本 什么是 checksum offload Checksum Offload 是网卡的一个功能选项。如果该选项开启，则网卡层面会计算需要发送或者接收到的消息的校验和，从而节省 CPU 的计算开销。此时，在需要发送的消息到达网卡前，系统会在报头的校验和字段填充一个随机值。但是，尽管校验和卸载能够降低 CPU 的计算开销，但受到计算能力的限制，某些环境下的一些网络卡计算速度不如主频超过 400MHz 的 CPU 快。\nReference 1. 内核缺陷触发的NodePort服务63秒延迟问题\n2. k8s vxlan 作为 cni 后端引发的 63 秒延迟\n3. 63 秒延迟的触发原因定位-张浩\n4. Disable tx and rx offloading on VXLAN interfaces #1282\n","description":"","id":10,"section":"posts","tags":["Flannel","Kubernetes"],"title":"K8s部署实录-6-Flannel版本与5.15内核不兼容导致跨节点pod无法通信问题","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-29-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-6-flannel%E7%89%88%E6%9C%AC%E4%B8%8E5.15%E5%86%85%E6%A0%B8%E4%B8%8D%E5%85%BC%E5%AE%B9%E5%AF%BC%E8%87%B4%E8%B7%A8%E8%8A%82%E7%82%B9pod%E6%97%A0%E6%B3%95%E9%80%9A%E4%BF%A1%E9%97%AE%E9%A2%98/"},{"content":"部署集群后出现异常，想重新进行部署，需要在 Kubernetes 集群中清理节点，以确保不影响重新部署。\n在本篇博客中，将详细介绍如何使用 RKE（Rancher Kubernetes Engine）进行节点清理，以及确保节点重新部署的平稳进行。\n引言 在 Kubernetes 集群中，节点清理是一个关键步骤，它需要在保证应用程序的稳定运行的前提下，清理节点以进行重新部署。\nRKE（Rancher Kubernetes Engine）是一个用于部署和管理 Kubernetes 集群的强大工具。\n在本篇博客中，将深入探讨如何使用 RKE 来清理节点，以确保重新部署过程能够顺利进行。\nrke版本：v1.2.6\nk8s离线包版本：v1.19.6\n步骤 以下是执行节点清理操作的详细步骤：\n0. 预检查 该节点不应再是任何群集的成员。 清理脚本具备 root/sudo 访问权限。 检查该节点正在运行的容器或Pod，这些容器或Pod将在以下步骤中被强制删除（如果想保持业务应用的连续性，参考下面步骤1）。 确认在正确的节点上，并准备好继续清理所有容器以及 Kubernetes 和 Rancher/RKE 特有的所有数据（如有必要，可提前备份）。 1. Drain 节点 在清理节点之前，使用 kubectl drain 命令将节点上的工作负载（Pod）驱逐到其他节点上。 确保应用程序在节点清理过程中不会受到影响。\n1 kubectl drain \u0026lt;node-name\u0026gt; --ignore-daemonsets 2. 移除节点 编辑 cluster.yml 文件，将要清理的节点从 nodes 列表中删除。然后运行以下命令，使用 RKE 将节点从集群中移除。\n1 rke remove --config cluster.yml 3. 清理节点 此脚本不适用于rke2和k3s（这两者使用部署时生成的uninstall脚本）\n该脚本将删除与 Rancher 和 Kubernetes 有关的所有容器、卷、映像、网络接口和目录。还可以选择刷新所有 iptables 规则并删除容器镜像。\n登录到要清理的节点，并执行以下清理操作：\n清理脚本: extended-cleanup-rancher2.sh\n执行下面命令\n1 sudo bash extended-cleanup-rancher2.sh 如果需要，可以同时或单独使用可选的 -f 和 -i 标志来刷新 iptables (-f) 和删除容器映像 (-i)。\n1 sudo bash extended-cleanup-rancher2.sh -f -i 4. 重启节点 重启节点以应用清理和配置更改。\n5. 重新部署节点 更新 cluster.yml 文件，将节点重新添加到 nodes 列表中。然后使用 RKE 进行重新部署。\n注意事项 始终在执行节点清理之前备份重要数据。 仔细阅读 RKE 和 Kubernetes 的文档，以确保了解每个步骤的影响和细节。 执行节点清理操作时，要确保其他节点正常运行以避免服务中断。 结论 节点清理是 Kubernetes 部署过程中的关键步骤，它需要谨慎操作以确保重新部署的成功进行。通过使用 RKE 和以上步骤，可以有效地清理节点并确保应用程序的稳定运行。\n在执行节点清理操作之前，始终要备份数据并确保了解每个步骤的细节，以保证整个过程的顺利进行。\n可以了解如何使用 RKE 进行节点清理，以及如何在保持应用程序稳定性的前提下，重新部署节点。有利于在 Kubernetes 部署过程中更加灵活地管理节点，并确保系统的连续运行。\n","description":"","id":11,"section":"posts","tags":["RKE","Kubernetes"],"title":"k8s部署实录-5-RKE节点清理指南：确保节点重新部署的顺利进行","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-5-rke%E8%8A%82%E7%82%B9%E6%B8%85%E7%90%86%E6%8C%87%E5%8D%97/"},{"content":"当你在 Linux 系统中尝试使用 sudo 命令执行操作时，可能会遇到一些令人困惑的问题。其中之一是，为什么在某些情况下，即便使用 sudo 作为超级用户权限，仍然会报告权限拒绝错误。在本篇博客中，我们将探讨这个问题，并为您解释为什么在执行类似 sudo echo 的命令时，会遇到权限问题，同时提供解决方法。\n背景 在 Linux 终端中，sudo 是一种以超级用户（root）权限执行命令的方式。然而，一些情况下可能会让人感到困惑，尤其是当在 sudo 后面使用 echo 命令并附加重定向操作时，可能会遇到权限拒绝错误。让我们深入探讨一下为什么会出现这种情况。\n原因 问题的核心在于重定向操作符（\u0026gt;\u0026gt;）的工作方式。在 Linux 中，重定向操作符会在命令执行之前打开文件，而不是在命令执行期间。这意味着，即使您使用 sudo 作为超级用户来执行 echo 命令，重定向操作符在打开文件时仍然以普通用户权限进行。因此，如果您尝试执行以下命令：\n1 sudo echo \u0026#34;192.168.1.218 reg.paas.org\u0026#34; \u0026gt;\u0026gt; /etc/hosts sudo 作用于 echo 命令本身，但由于重定向操作符的权限与当前用户一致，你可能会看到 \u0026ldquo;权限拒绝\u0026rdquo; 错误。\n解决方法 要解决这个问题，可以使用以下方法之一：\n使用特权执行重定向：为了确保重定向操作以超级用户权限进行，您可以使用以下方法：\n1 echo \u0026#34;192.168.1.218 reg.paas.org\u0026#34; | sudo tee -a /etc/hosts 这会将输出通过管道传递给 tee 命令，然后使用 sudo 权限将数据追加到 /etc/hosts 文件中。\n使用 sudo -i：您可以通过使用 sudo -i 切换到超级用户环境，然后执行多个命令，其中包括重定向。但要小心在超级用户环境中执行命令。\n总结 在 Linux 中，sudo echo 后使用重定向操作符可能会导致权限拒绝错误。这是因为重定向操作符在执行命令之前以当前用户权限打开文件。通过使用管道和 tee 命令，或者在超级用户环境中执行命令，您可以解决这个问题。在处理权限问题时，始终要谨慎，确保您了解您正在执行的操作以及其潜在的影响。\n","description":"","id":12,"section":"posts","tags":["Sudo"],"title":"k8s部署实录-4-\"sudo echo '192.168.1.218 reg.paas.org' \u003e\u003e /etc/hosts\" 报权限拒绝错误","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-4-sudo%E6%8F%90%E6%9D%83echo%E5%90%8E%E7%9A%84%E9%87%8D%E5%AE%9A%E5%90%91%E6%93%8D%E4%BD%9C%E7%AC%A6%E4%BC%9A%E6%8A%A5%E6%9D%83%E9%99%90%E6%8B%92%E7%BB%9D%E9%94%99%E8%AF%AF/"},{"content":"重要 前因：\n由于客户现场不给root权限，docker-ce为客户自行安装，版本为24.0.5, 与准备的安装包不兼容（rke版本为v1.2.6, k8s版本为v1.19,兼容的docker版本为v1.13.x - v20.10.x）\n报错信息如下： 1 2 3 4 5 INFo[0000] [dialer] Setup tunnel for host [192.168.1.215] INFo[0000] [dialer] Setup tunnel for host [192.168.1.228] WARN[0000] [state] can\u0026#39;t fetch legacy cluster state from Kubernetes: Unsupported Docker version found [24.0.5] on host [192.168.1.227], supported versions are [1.13.x 17.03.x 17.06.x 17.09.x 18.06.x 18.09.x 19.03.x 20.10.x] INFO[0000] [certificates] Generating CA kubernetes certificates INFO[0000] [certificates] Generating Kubernetes API server aggregation layer requestheader client CA certificates 现状：\nrke up默认校验docker版本，docker-ce v24.0.5版本与rke-v1.2.6不兼容，导致安装失败\n原因分析：\n由于本身为开发环境部署，只为调研。打算将rke的docker版本校验忽略，继续安装\n处理方案：\nconfig.yml文件中的ignore_docker_version: true配置无效，rke的参数--ignore-docker-version有效\n1 rke up --ignore-docker-version Reference Docker version not supported even with ignore_docker_version: true\n","description":"","id":13,"section":"posts","tags":["Kubernetes"],"title":"k8s部署实录-3-rke部署集群忽略docker版本校验","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-3-rke%E9%83%A8%E7%BD%B2%E9%9B%86%E7%BE%A4%E5%BF%BD%E7%95%A5docker%E7%89%88%E6%9C%AC%E6%A0%A1%E9%AA%8C/"},{"content":"重要 前因：\n免密是由客户进行操作，出于安全的考虑，生成ssh-key-gen时选用的加密算法为ed25519, 而非默认的rsa, 从而生成的私钥文件目录为~/.ssh/id_ed25519\n现状：\n执行rke up命令，报错 ~/.ssh/id_rsa 文件不存在，集群安装失败。\n1 2 3 4 5 6 7 8 9 10 11 INFO[0000] Building Kubernetes cluster INFO[0000] [dialer] Setup tunnel for host [10.0.0.1] WARN[0000] Failed to set up SSH tunneling for host [10.0.0.1]: Can’t establish dialer connection: Error while reading SSH key file: open /root/.ssh/id_rsa: no such file or directory INFO[0000] [dialer] Setup tunnel for host [10.0.0.2] WARN[0000] Failed to set up SSH tunneling for host [10.0.0.2]: Can’t establish dialer connection: Error while reading SSH key file: open /root/.ssh/id_rsa: no such file or directory INFO[0000] [dialer] Setup tunnel for host [10.0.0.3] WARN[0000] Failed to set up SSH tunneling for host [10.0.0.3]: Can’t establish dialer connection: Error while reading SSH key file: open /root/.ssh/id_rsa: no such file or directory WARN[0000] Removing host [10.0.0.1] from node lists WARN[0000] Removing host [10.0.0.2] from node lists WARN[0000] Removing host [10.0.0.3] from node lists FATA[0000] Cluster must have at least one etcd plane host: failed to connect to the following etcd host(s) [10.0.0.1] 原因分析：\n配置ssh免密时，使用的key为ed25519加密算法生成的，而rke工具从操作机寻找文件~/.ssh/id_rsa，从而检查ssh免密，需要查找rke官方配置，从而指定ssh key的路径，替换默认值\n处理方案：\n修改配置文件cluster.yaml\n1 ssh_key_path: ~/.ssh/id_ed25519 如果在群集级别和节点级别都定义了ssh_key_path，则节点级别的密钥优先。\n集群级别设置：\n1 2 3 cluster_name: mycluster ssh_key_path: ~/.ssh/id_ed25519 nodes: 节点级别设置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cluster_name: mycluster nodes: - address: 1.1.1.1 user: ubuntu role: - controlplane - etcd - worker ssh_key_path: ~/.ssh/id_ed25519 - address: 1.1.1.2 user: ubuntu role: - controlplane - etcd - worker ssh_key_path: ~/.ssh/id_ed25519 Reference RKE配置参数-ssh_key_path\nRKE配制文件-full-example\n","description":"","id":14,"section":"posts","tags":["Kubernetes"],"title":"k8s部署实录-2-rke指定ssh_key_path配置从而替换默认路径","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-2-rke%E6%8C%87%E5%AE%9Assh_key_path%E9%85%8D%E7%BD%AE%E4%BB%8E%E8%80%8C%E6%9B%BF%E6%8D%A2%E9%BB%98%E8%AE%A4%E8%B7%AF%E5%BE%84/"},{"content":"重要 前因：\n客户现场只提供JumpServer的web-client方式连接，root密码甚至是普通用户的密码也不提供。导致只能通过web-client进行环境部署操作。\n现状：\n使用JumpServer的WebClient方式进行vim编辑文件时，发现Vim的编辑模式无法Esc退出\n原因分析：\nEsc会触发浏览器的Esc热键，导致Vim无法推出编辑模式\n处理方案\n将 jj 替代 Esc, 通过jj退出编辑模式\n在~/.vimrc下添加映射 \u0026ldquo;inoremap jj \u0026rdquo;\n1 2 3 # $vimrc_path文件存在时，向文件中追加\u0026#34;inoremap jj \u0026lt;Esc\u0026gt;\u0026#34;,否则新建文件并增加以上内容 vimrc_path=\u0026#34;$HOME/.vimrc\u0026#34; content_to_append=\u0026#34;inoremap jj \u0026lt;Esc\u0026gt;\u0026#34;; if [ -f \u0026#34;$vimrc_path\u0026#34; ]; then echo \u0026#34;$content_to_append\u0026#34; \u0026gt;\u0026gt; \u0026#34;$vimrc_path\u0026#34;; else echo \u0026#34;$content_to_append\u0026#34; \u0026gt; \u0026#34;$vimrc_path\u0026#34;; fi Reference 在 Vim 编辑器中，.vimrc 文件是用于配置 Vim 的设置和行为的配置文件。\n其中，inoremap 是 Vim 配置文件中的一个命令，用于定义插入模式（Insert Mode）下键盘映射。\n键盘映射允许您将按键序列映射为其他按键、命令或字符串，以改变编辑器的行为。\n具体来说，inoremap 是 \u0026ldquo;Insert Normal Mode Mapping\u0026rdquo; 的缩写，它会在插入模式下将一个按键序列映射为另一个按键序列。\n常见的用例是将短按键序列映射为更长或更方便的按键序列，以提高编辑效率。\ninoremap jj \u0026lt;Esc\u0026gt; 将按下两个连续的 j 键映射为按下\u0026lt;Esc\u0026gt;键，而 键用于从插入模式返回到普通模式。\n解释一下具体含义：\ninoremap: 表示在插入模式下进行键盘映射。\njj: 指定按键序列，即按两次 j 键。\n\u0026lt;Esc\u0026gt;: 是特殊字符表示 键，它在 Vim 中表示退出插入模式，返回到普通模式。\n这样，每当在插入模式中按下两次 j 键，Vim 将会识别为按下了一个 键，从而退出插入模式。\n","description":"","id":15,"section":"posts","tags":["Kubernetes"],"title":"k8s部署实录-1-web控制台Esc快捷键与vim的热键冲突无法推出编辑模式","uri":"https://hex-go.github.io/posts/kubernetes/2023-08-28-k8s%E9%83%A8%E7%BD%B2%E5%AE%9E%E5%BD%95-1-web%E6%8E%A7%E5%88%B6%E5%8F%B0esc%E5%BF%AB%E6%8D%B7%E9%94%AE%E4%B8%8Evim%E7%9A%84%E7%83%AD%E9%94%AE%E5%86%B2%E7%AA%81%E6%97%A0%E6%B3%95%E6%8E%A8%E5%87%BA%E7%BC%96%E8%BE%91%E6%A8%A1%E5%BC%8F/"},{"content":"1.简介 Linux查漏补缺，还剩：\n4-安装包管理[rpm/dpkg] 5-proc程序查看说明 6-磁盘格式化 7-mount说明 8-LVM 9-账号管理与ACL 2.说明 3.总结 4.参考 Base\nhttps://www.cnblogs.com/chengmo/archive/2010/10/25/1857775.html\nKernel - all /dev\nhttps://www.kernel.org/doc/html/v4.20/admin-guide/devices.html\n关于 /dev/tcp/${HOST}/${PORT}\nhttps://www.jianshu.com/p/f10736931b93\nhttps://ithelp.ithome.com.tw/articles/10221819\n4-安装包管理[rpm/dpkg]\n第二十二章、软件安装 RPM, SRPM 与 YUM\n5-proc程序查看说明\n16.3 程序管理\n6-磁盘格式化与逻辑卷管理\n7.3 磁盘的分区、格式化、检验与挂载\n8-LVM\n14.3 逻辑卷轴管理员 （Logical Volume Manager）\n7-mount说明\n所谓的“挂载”就是利用一个目录当成进入点，将磁盘分区的数据放置在该目录下； 也就是说，进入该目录就可以读取该分区的意思。这个动作我们称为“挂载”，那个进入点的目录我们称为“挂载点”。\n目录树与文件系统的关系：通过挂载，实现目录树的架构与磁盘内的数据(文件系统)结合。\n7.1.7 挂载点的意义 （mount point）\n7.3.5 文件系统挂载与卸载： mount, umount\n8-账号管理与ACL\n第十三章、Linux 帐号管理与 ACL 权限设置\n","description":"","id":16,"section":"posts","tags":["Bash","Linux","特殊/dev"],"title":"Linux查漏补缺-3-特殊设备文件[loop,null,zero,full,random,tcp..]","uri":"https://hex-go.github.io/posts/bash/2022-10-27-linux%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA-3-%E7%89%B9%E6%AE%8A%E8%AE%BE%E5%A4%87%E6%96%87%E4%BB%B6loopnullzerofullrandomtcp../"},{"content":"1.简介 ​\t在kubernetes中部署mariadb服务,挂载local-storage时，binlog目录赋予777权限，仍权限不足导致服务无法启动，后执行chmod 1777 binlog/ 解决问题。没有系统研究过linux的权限，以为rwx是就是所有权限，缺少对特殊权限s和t权限的理解。\n2.说明 s权限：强制位权限。可执行的文件搭配这个权限，便能得到特权，任意存取该文件的所有者能使用的全部系统资源。\n请注意具备SUID/SGID权限的文件，黑客经常利用这种权限，以SUID/SGID配上root帐号拥有者，无声无息地在系统中开扇后门，供日后进出使用。\n例如：\nSUID举例 /usr/bin/passwd SGID举例 /usr/bin/locate t权限：粘滞位权限。一般只用在目录上，在具备此权限的目录下，任何用户可写入文档，又不让用户删除这个目录下他人的文档。\n例如：\n/tmp和/var/tmp目录 2.1 SUID Set UID：简称为SUID，s的权限是在用户。\n把此进程的有效用户ID设置为此文件拥有者的用户ID，程序在执行过程中拥有文件拥有者的权限。仅可用在可执行二进制文件。\n场景举例：\n账号与密码的存放文件其实是/etc/passwd与 /etc/shadow)。而/etc/shadow文件的权限如下\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp$ stat /etc/shadow File: /etc/shadow Size: 1427 Blocks: 8 IO Block: 4096 regular file Device: 10302h/66306d Inode: 21758432 Links: 1 Access: (0640/-rw-r-----) Uid: ( 0/ root) Gid: ( 42/ shadow) Access: 2022-10-26 10:30:01.647835420 +0800 Modify: 2022-09-21 15:42:07.468201547 +0800 Change: 2022-09-21 15:42:07.472201579 +0800 Birth: 2022-09-21 15:42:07.468201547 +0800 shadow文件所有者是root，权限为0640。在这个权限中，仅有root可以存储，其他人是连看都不行的。\n现有普通用户hex也有更新自身密码的需求，即使用/usr/bin/passwd命令，存取/etc/shadow密码文件。\n这是因为/usr/bin/passwd的文件权限如下\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp$ stat /usr/bin/passwd File: /usr/bin/passwd Size: 59976 Blocks: 120 IO Block: 4096 regular file Device: 10302h/66306d Inode: 49283913 Links: 1 Access: (4755/-rwsr-xr-x) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2022-09-19 15:45:14.219152977 +0800 Modify: 2022-03-14 16:59:13.000000000 +0800 Change: 2022-09-19 02:49:39.597789775 +0800 Birth: 2022-09-19 02:49:39.597789775 +0800 passwd文件所有者是root，权限为4755。\nother位有x权限说明普通用户具备此文件的可执行权限； user位有s权限说明当其他用户执行passwd时会获得文件passwd的拥有者root的权限。 有s权限的帮助，当普通用户hex执行/usr/bin/passwd时，会“暂时”得到passwd文件拥有者root的权限。\n2.2 SGID Set GID: 简称为SGID，s的权限是在group。\n把此进程的有效用户组ID设置为此文件的组ID，程序在执行过程中拥有文件所属组的权限。\n可以用在两个方面：\n文件：如果SGID设置在二进制文件上，则不论用户是谁，在执行该程序的时候，它的有效用户组(effective group)将会变成该程序的用户组所有者(group id)。\n举例来说，/usr/bin/locate 可以读取 /var/lib/mlocate/mlocate.db 这个文件的内容 ， mlocate.db 的权限如下：\n1 2 3 root@hex-PC:/tmp# ll /usr/bin/plocate /var/lib/plocate/plocate.db -rwxr-sr-x 1 root plocate 313904 Feb 17 2022 /usr/bin/plocate* -rw-r----- 1 root plocate 70159347 Oct 26 19:14 /var/lib/plocate/plocate.db 与 SUID 类似，如果使用普通用户去执行 locate ，那 普通用户 将会取得 slocate 组的支持， 因此就能够去读取 mlocate.db 文件\n目录：如果SGID设置在A目录上，则用户在A目录下新建的文件的群组都会与A目录的群组名称相同。\n用户若对于此目录具有 r 与 x 的权限时，该用户能够进入此目录； 用户在此目录下的有效群组（effective group）将会变成该目录的群组； 用途：若用户在此目录下具有 w 的权限（可以新建文件），则用户所创建的新文件，该新文件的群组与此目录的群组相同。 2.3 SBIT Sticky Bit: 简称为SBit，只针对目录有效，对文件没有效果。\nSBIT 对于目录的作用是：用户在该目录下建立文件或目录时，只有自己与root才有权力删除。\n用户需要对SBIT标记的目录具备以下权限：\nx权限：用户具备此权限才能进入目录； r权限：用户具备此权限才能查看文件属性和内容(ls 与 cat)； w权限：用户具备此权限才能创建、修改、删除文件和子目录； 举例来说，/tmp本身的权限是“drwxrwxrwt”，在这样的权限内容下，任何人都可以在/tmp内新增、修改文件，但仅有该文件/目录的建立者与root能够删除自己的目录或文件。\n以root登入系统，并且进入 /tmp中。\ntouch test，并且更改test权限成为777.\n以一般用户登入，并进入 /tmp.\n尝试删除test文件。\n2.4 设置特殊权限 通常使用 chmod xyz filename 方式来设置filename的权限时，是假设没有SUID、SGID及SBIT。而在三位前增加一位用来表示这些特殊权限：\n4为SUID\n2为SGID\n1为SBIT\n3=SGID+SBIT; 5=SUID+SBIT; 6=SUID+SGID; 7=SUID+SGID+SBIT;\n例如：test文件权限为默认权限-rw-rw-r--\n1 2 3 4 5 hex@hex-PC:/tmp/perm-test$ ls -alh total 4K drwxrwxr-x 2 hex hex 4.0K Oct 26 18:53 . drwxrwxrwt 40 root root 4.0K Oct 26 17:29 .. -rw-rw-r-- 1 hex hex 0 Oct 26 18:53 test 为此文件test设置SUID权限，即设置s在用户权限中。因此，在原先的664之前还要加上4。命令如下：\n1 chmod 4664 test 查看修改后文件权限为\n1 2 3 4 5 hex@hex-PC:/tmp/perm-test$ ls -alh total 4K drwxrwxr-x 2 hex hex 4.0K Oct 26 18:53 . drwxrwxrwt 40 root root 4.0K Oct 26 17:29 .. -rwSrw-r-- 1 hex hex 0 Oct 26 18:53 test 2.5 延伸 2.5.1 SUID是否可用于bash脚本？否 不能用在批处理文件(shell脚本)上。这是因为shell脚本只是将很多二进制执行文件调进来执行而已。所以SUID的权限部分，还是要看shell脚本调用进来的程序设置，而不是shell脚本本身。\n2.5.2 大写S与大写T说明 chmod命令不进行必要的完整性检查，即使不设置x权限就设置s权限，chmod也不会报错。当ls -l时看到rwS，大写S说明s权限未生效。\nS_ISUID的表示方式。所属用户的S_IXUSR(x位)为S_ISUID所共用： 当S_IXUSR和S_ISUID共存时，用小写s表示； 当只设置了S_ISUID时，用大写S表示（权限未生效）； S_ISGID的表示方式。所属用户的S_IXGRP(x位)为S_ISGID所共用： 当S_IXGRP和S_ISGID共存时，用小写s表示； 当只设置了S_ISGID时，用大写S表示（权限未生效）： S_ISVTX的表示方式。所属用户的S_IXOTH(x位)为S_ISVTX所共用： 当S_IXOTH和S_ISVTX共存时，用小写t表示； 当只设置了S_ISVTX时，用大写T表示（权限未生效）： 综上：大写字母意味着该位[u|g|o]没有x权限，小写字母意味着该位[u|g|o]有x权限。因为特殊权限都必须具备x权限，所以：\n大写意味着权限一定未生效； 小写意味着权限不一定生效；(比如，SUID设置在目录；SBIT设置在文件等，仍小写但无效) 2.5.3 区别 S_UID S_GID T 文件对象 二进制、可执行文件 二进制、可执行文件；目录 目录 权限号(rwx set 755) 4755 2755 1755 生效条件 文件属主必须先设置x权限 文件属组必须先设置x权限 - 目录具备w权限，可新建文件\n- 目录具备rx权限，才能进入目录 设置命令 chmod u+s \u0026lt;bin-exec文件\u0026gt; chmod g+s \u0026lt;bin-exec文件\u0026gt; chmod o+t \u0026lt;目录\u0026gt; 移除命令 chmod u-s \u0026lt;bin-exec文件\u0026gt; chmod g-s \u0026lt;bin-exec文件\u0026gt; chmod o-t \u0026lt;目录\u0026gt; 权限显示 (4755/-rwsr-xr-x) (2755/-rwxr-sr-x) (1755/-rwxr-xr-t) 生命周期 仅在该程序的执行过程中有效 同 S_UID 文件读写 3.总结 文件具有SUID的特殊权限时，代表用户执行此二进制程序时，在执行过程中用户会暂时具有程序拥有者的权限。 目录具有SGID的特殊权限时，代表用户在这个目录下新建的文件的群组都会与该目录的群组名称相同。 目录具有SBIT的特殊权限时，代表用户在该目录下创建的文件只有自己与root能够删除。 设置权限时，了解cat、ls、执行文件等操作所需的基本权限也很重要。可参考 注2：鸟哥-常见指令需要的基本权限\n4.参考 [注1]： 鸟哥-特殊权限SUID说明\n[注2]： 鸟哥-常见指令需要的基本权限\n","description":"","id":17,"section":"posts","tags":["Bash","Linux","特殊权限"],"title":"Linux查漏补缺-2-特殊权限[s·t]","uri":"https://hex-go.github.io/posts/bash/2022-10-26-linux%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA-2-%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90st/"},{"content":"1.简介 操作机某软件异常，进行重装时。对软链接理解存在偏差导致误删除目录问题详细参考 2.3.5 删除目录的软链。\n因为未移除感觉软链接，导致安装失败；\n尝试删除软链接/root/bin -\u0026gt; /bin。\n执行命令rm /root/bin/时，报错Is a directory。\n想当然的执行rm -rf /root/bin/ 导致将其link的目录/bin删除。\n目录软链接的删除，应为rm /root/bin，而非rm -rf /root/bin/。\n本文详细记录由链接引伸出来的一系列概念。\n2.说明 2.0 基础知识 inode的相关说明：注1\n跨文件系统（磁盘分区），inode不唯一； 每个文件都会占用一个 inode ，文件内容由 inode 来指向blok获取； inode与文件名为一对多关系； 系统内部读取文件步骤：注1\n系统找到文件名对应的inode 通过 inode 号码，获取inode信息 根据 inode 信息，找到文件数据所在的 block，读出数据。 链接: UNIX文件系统提供的一种，将不同文件链接至同一个文件的机制；实际上是一种文件共享的方式，是 POSIX 中的概念，主流文件系统都支持链接文件。\n查看文件信息的命令\nls命令\n示例：\n1 2 3 4 hex@hex-PC:/tmp/ln-test$ ls -li total 4 60822147 -rw-rw-r-- 1 hex hex 12 Oct 25 17:36 test 60822175 lrwxrwxrwx 1 hex hex 4 Oct 25 17:36 test-sl -\u0026gt; test 参数：\n-i 查看inode 输出：\n第一列：inode号 第二列：文件权限 第三列：链接数目，指一共多少个文件名指向这个inode 第四列：文件拥有者 第五列：文件所属group 第六列：文件大小 第七列：文件内容上一次变动的时间 第八列：文件名 stat命令\n示例：\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp/ln-test$ stat test-sl File: test-sl -\u0026gt; test Size: 4 Blocks: 0 IO Block: 4096 symbolic link Device: 10302h/66306d Inode: 60822175 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-25 17:36:18.216885854 +0800 Modify: 2022-10-25 17:36:16.184873570 +0800 Change: 2022-10-25 17:36:16.184873570 +0800 Birth: 2022-10-25 17:36:16.184873570 +0800 参数： 无\n输出：\nFile：显示文件名\nSize：显示文件大小\nBlocks：文件使用的数据块总数\nIO Block：IO块大小\nsymbolic link：文件类型（软链接）\nInode：inode 号\nLinks：链接数，即有多少文件名指向这个 inode\nUid：文件拥有者的 Uid\nGid：文件所属group的 Gid\nAccess：文件的读、写、执行权限\n文件的时间戳，共有三个：\nChange：简写为ctime，文件状态(链接数、大小、权限、Blocks数)改变时间。 Modify：简写为mtime，文件内容的修改时间，文件内容被修改时更新。 Access：简写为atime，文件内容的访问时间。文件内容被访问时更新。 Birth: 文件创建时间。 2.1 软链接、硬链接区别 功能项 软链接 硬链接 使用对象 文件、目录 文件 inode是否相同 不同 相同 是否跨文件系统(磁盘分区) 是 否 原文件删除 软链接不可用 不受影响 与原文件的关联项 执行命令时，原文件名参数 原文件inode 原文件是否必须存在 否 是 执行命令 ln -s \u0026lt;src\u0026gt; \u0026lt;file-sl\u0026gt; ln \u0026lt;src\u0026gt; \u0026lt;file-hl\u0026gt; 2.2 软链接 软链接只是一个符号链接，其实就是新建立一个文件，这个文件就是专门用来指向别的文件。大小很小，权限是777，而真正的信息是由指向的原文件决定；\n删除软链接文件，不影响原文件； 删除原文件，则相应的软链接不可用（cat那个软链接文件，则提示“没有该文件或目录“）； 2.3 硬链接 硬链接实际上是为文件建一个别名，指向同一个inode。\n创建硬链接时，不会建立inode，只是在原文件的inode link count域再增加1； 删除硬链接时，在原文件的inode link count域再减1； 系统调用会检查inode link count的数值，如果\u0026gt;=1，那么inode不会被回收，文件的内容不会被删除。\n2.4 引申问题 2.4.1 软链接跳转靠的是文件名而非inode 验证思路：设置软链接时，原文件参数传递为相对路径；再将软链接移动到其他目录下；如果报错Not Found则说明成立\n软链接查找使用的文件名，为ln执行命令时传入的原文件，如果是相对路径，则根据软链接路径进行查找。\n准备测试环境\n1 2 3 4 5 # 创建测试目录 mkdir /tmp/ln-test/ cd /tmp/ln-test/ # 生成测试 原文件 echo \u0026#34;source file\u0026#34; \u0026gt; test 设置软链接\n1 ln -s test test-sl 查看文件状态\n执行命令ls -li(i参数为查看文件inode)\n1 2 3 4 hex@hex-PC:/tmp/ln-test$ ls -li total 4 60822147 -rw-rw-r-- 1 hex hex 12 Oct 25 17:36 test 60822175 lrwxrwxrwx 1 hex hex 4 Oct 25 17:36 test-sl -\u0026gt; test 执行命令stat \u0026lt;filename\u0026gt;\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp/ln-test$ stat test-sl File: test-sl -\u0026gt; test Size: 4 Blocks: 0 IO Block: 4096 symbolic link Device: 10302h/66306d Inode: 60822175 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-25 17:36:18.216885854 +0800 Modify: 2022-10-25 17:36:16.184873570 +0800 Change: 2022-10-25 17:36:16.184873570 +0800 Birth: 2022-10-25 17:36:16.184873570 +0800 移动软链接至其他目录\n1 mv test-sl ../ 通过软链接cat文件内容\nstat 查看软链接属性，File: test-sl -\u0026gt; test 显示软链接指向当前目录test文件，但test文件不存在。\n1 2 3 4 5 6 7 8 9 10 11 12 hex@hex-PC:/tmp/ln-test$ cd ../ hex@hex-PC:/tmp$ stat test-sl File: test-sl -\u0026gt; test Size: 4 Blocks: 0 IO Block: 4096 symbolic link Device: 10302h/66306d Inode: 60822175 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-25 17:40:57.608602008 +0800 Modify: 2022-10-25 17:36:16.184873570 +0800 Change: 2022-10-25 17:40:34.131967367 +0800 Birth: 2022-10-25 17:36:16.184873570 +0800 hex@hex-PC:/tmp$ cat test-sl cat: test-sl: No such file or directory 软链接所在新目录创建新的test文件，再查看\n1 2 3 4 5 6 hex@hex-PC:/tmp$ echo \u0026#34;Other test file\u0026#34; \u0026gt; test hex@hex-PC:/tmp$ ls -li test* 60822202 -rw-rw-r-- 1 hex hex 16 Oct 25 17:47 test 60822175 lrwxrwxrwx 1 hex hex 4 Oct 25 17:36 test-sl -\u0026gt; test hex@hex-PC:/tmp$ cat test-sl Other test file 软链接移动前后，inode为60822175，未改变；但前后的原文件test的inode已发生改变60822147 -\u0026gt; 60822202。说明软链接是通过File: test-sl -\u0026gt; test记录所跳转的原文件，而非inode。\n2.4.2 硬链接无法跨分区，而软链接可以的原因 硬盘格式化的时候，操作系统自动将硬盘分为两个区域：\n数据区：存放文件内容\ninode 区：存放 inode 包含的信息，也叫作 inode table\n硬链接通过与原文件共用同一inode访问blok读取文件内容。跨分区无法共享inode，所以硬链接无法跨分区。\n软链接记录的是原文件的文件名， 而非inode。可以跨分区。\n延伸个问题：Linux是如何跨分区寻找inode的\n2.4.3 硬链接不支持目录的原因 系统限制对目录进行硬链接只是一个硬性规定，并不是逻辑上不允许、技术上不可行。\n其实使用 ln -d 命令也允许 root 用户尝试建立目录硬链接，且.与..都是目录的硬链接。\n由于 Linux 操作系统中的目录是以 / 为节点的树状结构，对目录的硬链接有可能破坏这种结构，甚至形成循环如： /usr/bin -\u0026gt; /usr/ ，在使用遍历目录的命令时（如： ls -R ）系统就会陷入无限循环中。\n如果使用 hard link 链接到目录时， 链接的数据需要连同被链接目录下面的所有数据都创建链接。因此造成环境相当大的复杂度。\n举例来说，如果要将 /etc 使用实体链接创建一个 /etc_hd 的目录时，那么在 /etc_hd 下面的所有文件名同时都与 /etc 下面的文件名要创建 hard link 的，而不是仅链接到 /etc_hd 与 /etc 而已。 并且，未来如果需要在 /etc_hd 下面创建新文件时，连带的， /etc 下面的数据又得要创建一次 hard link。\n2.3.4 .与..是目录的硬链接，特殊在哪里 创建目录时，默认会生成两个目录项： . 和 .. 。\n. 相当于当前目录的硬链接； .. 相当于父目录的硬链接。 目录硬链接总数：\n空目录的硬链接总数，等于2（.和\u0026lt;file-name\u0026gt;）； 目录的硬链接总数，等于 2 + 它的子目录总数（子目录的 ..）； 2.3.5 目录软链接删除，注意区分 软链接/ 与 软链接 目录的软链接=文件，而非目录文件；例如\n目录文件：/tmp/ln-test/test-dir 等同于 /tmp/ln-test/test-dir/\n目录的软链接：/tmp/ln-test/test-dir-sl \u0026lt;不等于\u0026gt; /tmp/ln-test/test-dir-sl/\n​\trm 前者 == 删除软链接； rm后者 == 删除原目录。\n验证：\n准备环境\n1 2 3 4 # 创建目录 mkdir -p /tmp/ln-test/test-dir cd /tmp/ln-test/test-dir 设置软链接\n1 ln -s test-dir/ test-dir-sl 查看文件状态\n1 2 3 4 hex@hex-PC:/tmp/ln-test$ ls -li total 4 60822338 drwxrwxr-x 2 hex hex 4096 Oct 26 10:22 test-dir 60822339 lrwxrwxrwx 1 hex hex 9 Oct 26 10:23 test-dir-sl -\u0026gt; test-dir/ 软链接 stat\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp/ln-test$ stat test-dir-sl File: test-dir-sl -\u0026gt; test-dir/ Size: 9 Blocks: 0 IO Block: 4096 symbolic link Device: 10302h/66306d Inode: 60822339 Links: 1 Access: (0777/lrwxrwxrwx) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-26 10:23:12.046192861 +0800 Modify: 2022-10-26 10:23:06.810155908 +0800 Change: 2022-10-26 10:23:06.810155908 +0800 Birth: 2022-10-26 10:23:06.810155908 +0800 软链接/ 的stat\n1 2 3 4 5 6 7 8 9 hex@hex-PC:/tmp/ln-test$ stat test-dir-sl/ File: test-dir-sl/ Size: 4096 Blocks: 8 IO Block: 4096 directory Device: 10302h/66306d Inode: 60822338 Links: 2 Access: (0775/drwxrwxr-x) Uid: ( 1000/ hex) Gid: ( 1000/ hex) Access: 2022-10-26 10:23:12.046192861 +0800 Modify: 2022-10-26 10:22:18.821817214 +0800 Change: 2022-10-26 10:22:18.821817214 +0800 Birth: 2022-10-26 10:22:18.821817214 +0800 可尝试执行stat test-dir和stat test-dir/，会发现与stat test-dir-sl/的inode一致。\n测试删除\n通过上一步stat查看软链接/和软链接已足够说明问题，通过删除再二次验证\n删除软链接/\n1 2 hex@hex-PC:/tmp/ln-test$ rm test-dir-sl/ rm: cannot remove \u0026#39;test-dir-sl/\u0026#39;: Is a directory 删除软链接\n1 2 3 4 hex@hex-PC:/tmp/ln-test$ rm test-dir-sl hex@hex-PC:/tmp/ln-test$ ls -li total 4 60822338 drwxrwxr-x 2 hex hex 4096 Oct 26 10:22 test-dir 2.3.6 应用场景 软链接：\n灵活切换不同版本的目标程序\n在开发的过程中，对于同一个工具软件，可能要安装多个不同的版本，例如：Python2 和 Python3。\n当在终端窗口中输入：python 时，启动的是 python2.7 版本。\n如果有一天需要使用 python3.5 版本，只需要把软链接 python 指向 python3.5 即可。\n动态库版本管理\n场景描述： 想象这样一个情景，一个程序需要使用 foo_1.1 文件中的共享资源，由于 foo 经常改变版本号。每次升级后都得将使用 foo_1.1 的所有程序更新到 foo_1.2 文件，那么每次更新 foo 版本后，都要重复上边的工作。\n解决方案：创建一个 foo 的软链接指向 foo_1.2。这时，当一个程序访问 foo 时，实际上是访问 foo_1.2。当升级到 foo_1.3 时，只需要更新软链接指向。这不仅解决了版本升级问题，而且还允许在系统中保存两个不同的版本，如果 foo_1.3 有错误，再更新回原来的 foo_1.2 链接就可以。\n快捷方式，将目录层次较深的文件链接到一个更易访问的目录中。\n硬链接：\n不同角度对文件进行分类 文件多人共享 文件备份 3.总结 目录的软链接比较特殊，尤其删除时注意区分带与不带的/的区别。\u0026lt;软链接\u0026gt;/是原目录本身，后\u0026lt;软链接\u0026gt;是软链接文件； 硬链接无法跨分区是实现机制决定的，无法创建目录的硬链接是硬性规定（.与..都是目录的硬链接）； 硬链接共用同一inode，增加硬链接相当于文件inode的新的别名； 软链接通过创建时的原文件参数查找原文件，而非原文件inode（原文件参数==绝对路径，软链接可到处移动。否则不可以）； 4.参考 [注1]： linux-inode说明\n[注2]： \u0026ldquo;醉卧沙场：计算机专业性文章及回答总索引-存储和文件系统\u0026rdquo;\n[注3]：Linux是如何跨分区寻找inode\n[注4]： \u0026ldquo;鸟哥私房菜-链接ln说明\u0026rdquo;\n","description":"","id":18,"section":"posts","tags":["Bash","Linux"],"title":"Linux查漏补缺-1-链接","uri":"https://hex-go.github.io/posts/bash/2022-10-25-linux%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA-1-%E9%93%BE%E6%8E%A5/"},{"content":"1. 简介 本博客站使用hugo引擎，使用zzo主题并略作调整搭建起来。本文记录hugo的概念说明以及使用备忘。\n2. 说明 2.1 目录结构 1 2 3 4 5 6 7 8 9 10 11 12 13 hex-go.github.io ├── archetypes/ # 博客模板目录 │ └── default.md ├── config/ # 配置文件 ├── content/ # 博客主要内容，也是网站资源的顶层 ├── public/ # 默认存放hugo构建后的编译文件(gitignore) ├── resources/ # 缓存一些文件以加快生成速度(gitignore) ├── static/ # 静态文件 ├── themes/ # 主题（git add submodule） ├── .gitignore # 不进行版本控制的文件和目录 ├── .gitmodules # 记录主题submodule信息 ├── Makefile # make 命令 └── README.md # 本文档 2.2 内容管理 hugo的顶层为./content/\u0026lt;DIRECTORIES\u0026gt;，是用于确定布局等的内容类型。 要了解有关部分的更多信息，包括如何嵌套它们，请参阅部分。\nPage bundles: Hugo 通过Page bundles来表示页面相关的图像和其他资源。 _index.md 在 Hugo 中具有特殊作用。它允许你在列表模板中添加前置内容和内容。这些模板包括章节模板、分类模板、分类术语模板和主页模板。\n1 2 3 4 5 6 7 8 9 10 11 12 . └── content └── about | └── index.md // \u0026lt;- https://example.org/about/ ├── posts | ├── firstpost.md // \u0026lt;- https://example.org/posts/firstpost/ | ├── happy | | └── ness.md // \u0026lt;- https://example.org/posts/happy/ness/ | └── secondpost.md // \u0026lt;- https://example.org/posts/secondpost/ └── quote ├── first.md // \u0026lt;- https://example.org/quote/first/ └── second.md // \u0026lt;- https://example.org/quote/second/ 2.1 配置 配置文件\n1 2 3 4 5 ./config/ └── _default ├── config.toml ├── menus.toml └── params.toml 2.1.1 内容宽度 如果想增大博客屏幕尺寸，只需更改params.toml文件中的viewportSizeref-1值即可。一共5个选项，对应尺寸为：\n选项 对应宽度 naroow 800px normal 960px（默认） wide 1280px wider 1440px widest 1600px 2.1.2 目录设置(Toc) config.toml中关于博客目录Toc的设置 \u0026ndash; 设置博客目录以Hx起始，以及截止Hx：\n1 2 3 4 [markup.tableOfContents] endLevel = 4 ordered = false startLevel = 2 必须设置此配置参数，否则 toc 将无法运行。以上面配置为例，startLevel和endLevel意味着最多使用 h2 标签，最少使用 h4 标签作为文章标题。而 h1、h5、h6 标签不会包含在 TOC 元素中。\n博客目录可以在params.toml（全局生效）中设置，也可以在单一博客的Front-Matters(当前博客)中设置。\nparams.toml配置举例:\n1 2 3 4 5 6 7 # 博客目录 enableToc = true # 目录是否启用 hideToc = false # 目录是否隐藏 enableTocSwitch = true # 是否启用 目录隐藏\\显示 按钮 tocFolding = false # 目录是否动态显示 tocPosition = \u0026#34;outer\u0026#34; # 文档目录结构位置: 内联(inner)、外嵌(outer)。 tocLevels = [\u0026#34;h2\u0026#34;, \u0026#34;h3\u0026#34;, \u0026#34;h4\u0026#34;] # 目录所包含的标题，还受config.toml中的markup.tableOfContents配置影响 参数 说明 enableToc 在所有文章中是否显示目录，true: 显示；false: 不显示 toc 在所有文章中完全取消提示。这是 enableToc 的别名 enableTocSwitch 开启目录隐藏\\显示按钮，true: 开启；false: 隐藏 hideToc 隐藏toc(搭配enableTocSwitch=true时,默认隐藏目录)。true: 隐藏; false: 不隐藏 enableTocContent 在主文章中显示提示，不在侧边栏中显示。 tocPosition oneof [inner outer]。 inner: toc将位于边框内;；outer: Toc将位于边框之外。 tocFolding 是否动态显示目录, 默认折叠,查看至相应内容时展开当前目录 tocLevels 标题是否在目录中显示，优先级没有config.toml中的高 minimum h2, maximum h4 in your article 2.1.3 侧边栏设置 参数 说明 enableBio Bio(biography),生平 enableBioImage enableSidebar 侧边栏显示 enableSidebarTags enableSidebarSeries 侧边栏 - 系列显示 enableSidebarCategories 侧边栏 - 分类显示 enableHomeSidebarTitles 启用主页侧边栏字幕 enableListSidebarTitles itemsPerCategory enableSidebarPostsByOrder sidebarPosition 2.2 博客结构 2.2.1 调整sidebar顺序 如何修改\nzzo主题关于sidebar的标签、分类、系列的排序，未设置配置项，需要找到关于sidebar的内容部分进行调整。\nsidebar关于这些的内容在在themes/zzo/layouts/partials/sidebar目录下，分别为sidebar-home.html与sidebar-list.html\n如何生效\n由于使用git 子模块引用的主题文件，需要执行以下操作，引用最新提交的zzo主题文件\n首先,进入包含子模块的父仓库的根目录。\n使用以下命令来更新子模块内容：\n添加 --init 选项, 可在更新子模块的同时，初始化子模块\n1 git submodule update --remote --init 在父仓库中提交子模块变更\n1 2 git add path/to/submodule # 将子模块的路径添加到父仓库的暂存区 git commit -m \u0026#34;Update submodule to latest commit\u0026#34; 2.3 博客编写 2.3.1 Archetype(模板) Hugo提供Archetypes(原型)能力，定义通用的模板, 一是为了保证博客内容和数据的一致性; 二是为了快速生成,提高效率。\n如何创建\narchetype需要以类型为名称,并将模板文件保存至archetypes/目录下,以golang模板举例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 --- title: \u0026#39;{{ replace (replaceRE `\\d{4}-\\d{2}-\\d{2}-` \u0026#34;\u0026#34; .Name) \u0026#34;_\u0026#34; \u0026#34;: \u0026#34; |title}}\u0026#39; categories: - Golang tags: - Go subtitle: \u0026#34;\u0026#34; description: date: {{ .Date }} toc: true --- ## 1.简介 ## 2.说明 ## 3.总结 ## 4.参考 方法\nreplaceRE: 根据正则替换,将符合正则表达式的内容替换为指定字符, 上面模板将.Name中的日期前缀置为空;\nreplace: 将字符串中的某些字符替换为特定字符, 此处将去除日期前缀的.Name中的_字符替换为: 变量Page variables\n.Name: 当前页面名称\n.Date: 返回给定页面的日期\n如何使用\n根据指定类型,创建博客\nkind: 博客类型, 需要与archetypes目录下的模板名称保持一致, 此处以golang举例;\ntarget_file_path: 博客生成位置, 此处以content/posts/golang/2020-05-25-Go-Modules版本控制和依赖管理.md举例;\n1 hugo new --kind \u0026lt;kind|golang\u0026gt; \u0026lt;target_file_path|content/posts/golang/2020-05-25-Go-Modules版本控制和依赖管理.md\u0026gt; 2.3.2 Front-Matters Hugo将每个博客的开头区块定义为Front Matter(扉页)，定义一些当前博客相关的内容、设置。\n2.3.3 引用 在 Hugo 中，通过ref 和 relref创建链接引用或获取其他页面的元数据。根据hugo文档与源码注释，ref 用于获取相对于 Hugo 根目录的页面路径，\nrelref 用于获取相对于当前页面的页面路径。但经过翻阅源码、测试，两者没有区别，建议选用ref即可\nHeading IDs hugo会自动给文档标题增加Head_ID, 可以通过此引用具体的小节。但部分字符会被转义，因此点击目标标题的索引查看，便于确认转义后的Head_ID\n举例说明：\n文章路径中的.md后缀可带、可不带；\n示例目录结构\n1 2 3 4 5 6 7 8 9 10 11 12 . └── content ├── page | ├── about.md // \u0026lt;- https://example.org/posts/about/ | ├── friend.md // \u0026lt;- https://example.org/posts/friend/ | └── share.md // \u0026lt;- https://example.org/posts/share/ └── posts ├── kubernetes | └── 2019-12-13-k8s小技巧.md // \u0026lt;- https://example.org/posts/kubernetes/2019-12-13-k8s小技巧/ └── 个人工具 ├── 2019-06-22-hexo--常用命令备忘录.md // \u0026lt;- https://example.org/posts/个人工具/2019-06-22-hexo--常用命令备忘录/ └── 2022-09-30-博客迁移-1_调研hugo框架zzo主题.md // \u0026lt;- https://example.org/posts/个人工具/2022-09-30-博客迁移-1_调研hugo框架zzo主题/ base 页面为 content/posts/个人工具/2022-09-30-博客迁移-1_调研hugo框架zzo主题.md\n1 2 [friend](https://hex-go.github.io/page/friend/) [about](https://hex-go.github.io/page/about/) 相对引用文章\n相对引用示例-引用文章 相对引用文章，标题\n相对引用示例-异文章引用标题 当前文章，引用标题\n相对引用示例-当前文章引用标题 绝对引用标题\n绝对引用-标题示例 2.3.3 相关内容 此配置影响博客结尾的相关文章，由于相关文章设置最大显示5条(zzo主题中已写死)\n自定义相关内容算法中不同因素的权重，结合threshold=80，相关文章最大5条\n相同系列的文章，也必定为相关文章（合理） 文章\u0026gt;3个相同关键字，则为相关文章（合理） 文章\u0026gt;3个相同tag，则为相同文章(合理) 日期不纳入相关性计算（合理） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 [related] # 相关内容设置 includeNewer = false # 包括更新日期比当前文章新的相关文章 threshold = 80 # 定义两篇文章之间标签匹配的阈值。标签匹配度高于阈值的文章将被视为相关文章。 toLower = false # 将标签、关键字转换成小写进行匹配，即 false：区分大小写 [[related.indices]] # 相关性 - 系列 name = \u0026#39;series\u0026#39; # 名称，series(系列) weight = 90 # 权重，在相关性计算中的权重，范围为正整数，值越大相关性越强，0：不进行相关性计算 type = \u0026#39;basic\u0026#39; # 相关性类型， basic基本类型 applyFilter = false # 是否应用过滤器，false：不应用 cardinalityThreshold = 0 # 关键字的基础阈值，0：没有基础阈值 pattern = \u0026#39;\u0026#39; # 正则表达式模式，可用正则进行过滤 toLower = false # 转小写 [[related.indices]] # 相关性 - 关键字 name = \u0026#39;keywords\u0026#39; # 名称，keywords(关键字) weight = 30 # 权重，30：标签在相关性计算中 权重较低 type = \u0026#39;basic\u0026#39; applyFilter = false cardinalityThreshold = 0 pattern = \u0026#39;\u0026#39; toLower = false [[related.indices]] # 相关性 - 标签 name = \u0026#39;tags\u0026#39; # 名称，tag(标签) weight = 30 # 权重，30：标签在相关性计算中 权重较低 type = \u0026#39;basic\u0026#39; applyFilter = false cardinalityThreshold = 0 pattern = \u0026#39;\u0026#39; toLower = false [[related.indices]] # 相关性 - 日期 name = \u0026#39;date\u0026#39; # 名称，date(日期) weight = 0 # 权重，0：日期不进行相关性计算 type = \u0026#39;basic\u0026#39; applyFilter = false cardinalityThreshold = 0 pattern = \u0026#39;\u0026#39; toLower = false 2.3.4 代码块 代码块增加文件路径作为标题\n1 echo hello! 将行号替换为指定字符, 比如 \u0026gt;或$, 以\u0026gt;举例：\n1 echo hello! 多语言代码块\njava javascript 1 System.out.println(\u0026#39;Hello World!\u0026#39;); 1 console.log(\u0026#39;Hello World!\u0026#39;); 3.总结 4.参考 Viewport Size – Z Themes Documentation (zzo-docs.vercel.app) ","description":"","id":19,"section":"posts","tags":["个人工具","Hugo"],"title":"博客迁移-1：调研hugo框架zzo主题","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-09-30-%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB-1_%E8%B0%83%E7%A0%94hugo%E6%A1%86%E6%9E%B6zzo%E4%B8%BB%E9%A2%98/"},{"content":"前言 PipeWire开发工作最早可以追溯到2015年，最初被认为是 “视频领域的 PulseAudio\u0026quot;，但后来也扩展到了音频领域。2021年4月发布的 Fedora34 成为了第一个默认采用了这项技术的发行版，其他桌面 Linux 发行版之后也很快跟进。相比之下，Ubuntu 进度远远落后于其竞争对手。 PipeWire 的优点： - 首先 PipeWire 的实现方式更新，开发也更加积极，bug 相对也就更少； - 其次 PipeWire 有更好的硬件兼容性(PulseAudio 不支持很多新的蓝牙耳机)，还减少了 CPU 的使用，代码基础更现代化； - 与PulseAudio相比，对现代蓝牙音频设备（例如，Apple Air Pods）的支持更好； WirePlumber, 一个流行的PipeWire会话和策略管理器。 Ubuntu 22.04 LTS 的默认镜像会同时安装 PipeWire 和 PulseAudio。 PipeWire 只用于视频，PulseAudio 处理音频。需要手动将 PipeWire 设为默认的音频服务器。 Ubuntu 22.10（代号 \u0026quot;Kinetic Kudu\u0026quot;）开发版本的日常构建中，Pipewire已经取代了 PulseAudio，成为了 Ubuntu 的默认音频服务器，不再需要任何设置。 配置PipeWire为默认音频服务器 Ubuntu 22.04部分安装并启用了PipeWire。启用剩余的部分，并使用PipeWire进行音频和蓝牙，而不是PulseAudio。\n安装 检查环境\nPipewire预先安装，并自动作为后台服务运行。在终端运行下面的命令来进行确认\n1 systemctl --user status pipewire pipewire-session-manager 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ● pipewire.service - PipeWire Multimedia Service Loaded: loaded (/usr/lib/systemd/user/pipewire.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-09-29 14:21:51 CST; 8min ago TriggeredBy: ● pipewire.socket Main PID: 2657 (pipewire) Tasks: 2 (limit: 75541) Memory: 6.6M CPU: 142ms CGroup: /user.slice/user-1000.slice/user@1000.service/session.slice/pipewire.service └─2657 /usr/bin/pipewire Sep 29 14:21:51 hex-Pad systemd[2650]: Started PipeWire Multimedia Service. Sep 29 14:21:51 hex-Pad pipewire[2657]: Cannot connect to server socket err = 没有那个文件或目录 Sep 29 14:21:51 hex-Pad pipewire[2657]: Cannot connect to server request channel Sep 29 14:21:51 hex-Pad pipewire[2657]: jack server is not running or cannot be started Sep 29 14:21:51 hex-Pad pipewire[2657]: JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock Sep 29 14:21:51 hex-Pad pipewire[2657]: JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock Sep 29 14:21:51 hex-Pad pipewire[2657]: jack-device 0x5595b2c0bd58: can\u0026#39;t open client: 拒绝连接 ● pipewire-media-session.service - PipeWire Media Session Manager Loaded: loaded (/usr/lib/systemd/user/pipewire-media-session.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-09-29 14:21:51 CST; 8min ago Main PID: 2658 (pipewire-media-) Tasks: 2 (limit: 75541) Memory: 4.9M CPU: 108ms CGroup: /user.slice/user-1000.slice/user@1000.service/session.slice/pipewire-media-session.service └─2658 /usr/bin/pipewire-media-session Sep 29 14:21:51 hex-Pad systemd[2650]: Started PipeWire Media Session Manager. 安装客户端包\n默认情况下，音频输出并。运行命令安装客户端库：\n1 sudo apt install pipewire-audio-client-libraries libspa-0.2-bluetooth libspa-0.2-jack 安装WirePlumber作为会话管理器：\n1 sudo apt install pipewire-media-session- wireplumber 注意\u0026rsquo;pipe - wire-media-session\u0026rsquo;后面的\u0026rsquo;-\u0026rsquo;。这是为了在同一个命令中删除它，因为将使用\u0026rsquo;wireplumber\u0026rsquo;代替。\n1 systemctl --user --now enable wireplumber.service 安装蓝牙编码器 AAC/LDAC/AptX:\n1 2 3 4 sudo apt install \\ libfdk-aac2 \\ libldacbt-{abr,enc}2 \\ libopenaptx0 配置 Wireplumber使事情变得非常容易！如果只想用PipeWire替换Pulseaudio，则启用媒体会话服务和重新启动，仅此而已！\nALSA客户端配置PipeWire输出\n将PipeWire示例中的配置文件复制到ALSA配置目录中：\n1 sudo cp /usr/share/doc/pipewire/examples/alsa.conf.d/99-pipewire-default.conf /etc/alsa/conf.d/ JACK客户端配置PipeWire输出:\n1 sudo cp /usr/share/doc/pipewire/examples/ld.so.conf.d/pipewire-jack-*.conf /etc/ld.so.conf.d/ sudo ldconfig\nBluetooth客户端\n只需删除此包装，蓝牙将由PipeWire处理：\n1 sudo apt remove pulseaudio-module-bluetooth 检查 通过客户端工具pactl检查： 1 LANG=C pactl info | grep \u0026#39;^Server Name\u0026#39; 返回值\n1 Server Name: PulseAudio (on PipeWire 0.3.32) 通过systemctl检查pipewire服务状态 1 systemctl --user status pipewire pipewire-session-manager 配置返回值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 ● pipewire.service - PipeWire Multimedia Service Loaded: loaded (/usr/lib/systemd/user/pipewire.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-09-29 14:21:51 CST; 13min ago TriggeredBy: ● pipewire.socket Main PID: 2657 (pipewire) Tasks: 2 (limit: 75541) Memory: 7.7M CPU: 245ms CGroup: /user.slice/user-1000.slice/user@1000.service/session.slice/pipewire.service └─2657 /usr/bin/pipewire Sep 29 14:21:51 hex-Pad systemd[2650]: Started PipeWire Multimedia Service. Sep 29 14:21:51 hex-Pad pipewire[2657]: Cannot connect to server socket err = 没有那个文件或目录 Sep 29 14:21:51 hex-Pad pipewire[2657]: Cannot connect to server request channel Sep 29 14:21:51 hex-Pad pipewire[2657]: jack server is not running or cannot be started Sep 29 14:21:51 hex-Pad pipewire[2657]: JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock Sep 29 14:21:51 hex-Pad pipewire[2657]: JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock Sep 29 14:21:51 hex-Pad pipewire[2657]: jack-device 0x5595b2c0bd58: can\u0026#39;t open client: 拒绝连接 ● wireplumber.service - Multimedia Service Session Manager Loaded: loaded (/usr/lib/systemd/user/wireplumber.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-09-29 14:33:58 CST; 1min 26s ago Main PID: 10292 (wireplumber) Tasks: 4 (limit: 75541) Memory: 7.2M CPU: 170ms CGroup: /user.slice/user-1000.slice/user@1000.service/session.slice/wireplumber.service └─10292 /usr/bin/wireplumber Sep 29 14:33:58 hex-Pad systemd[2650]: Started Multimedia Service Session Manager. Sep 29 14:33:58 hex-Pad wireplumber[10292]: Failed to set scheduler settings: Operation not permitted Sep 29 14:33:59 hex-Pad wireplumber[10292]: \u0026lt;WpSiAudioAdapter:0x55ae534170e0\u0026gt; Object activation aborted: proxy destroyed Sep 29 14:33:59 hex-Pad wireplumber[10292]: \u0026lt;WpSiAudioAdapter:0x55ae534170e0\u0026gt; failed to activate item: Object activation aborted: proxy destroyed 检查已安装deb包\n1 2 3 4 5 apt list --installed | grep libldac apt list --installed | grep pipewire apt show pipewire-pulse 其他问题 1. systemctl \u0026ndash;user status 执行失败 ubuntu22.04 登录会出现问题，导致出现报错\n1 process org.freedesktop.systemd1 exited with status 1 原因是：缺少环境变量XDG_RUNTIME_DIR， 怀疑之前将18.04$HOME目录下内容覆盖了22.04下的内容，导致~/.profile或~/.bashrc的内容出现问题。目前通过下面命令进行屏蔽\n1 echo \u0026#34;export XDG_RUNTIME_DIR=/run/user/$(id -u)\u0026#34; \u0026gt;\u0026gt; /$HOME/.profile 2. wireplumber在pipewire-media-session未卸载之前，为masked状态无法enable mask 是个比disable更彻底的状态。\n使用disable会删除服务相关的unit-file；\n使用mask则会将其link至/dev/null，其对比disable的优势是防止任何形式的激活，包括手动\nsystemctl list-unit-files命令来显示unit-files的状态，(static, enabled, disabled, masked, indirect)\nsystemctl list-units命令来显示服务的状态\n3. 恢复pulseaudio为音频处理 要撤消更改，首先删除客户端库：\n1 sudo apt remove pipewire-audio-client-libraries libspa-0.2-bluetooth libspa-0.2-jack 删除WirePlumber并安装以前的pipewire-media-session\n1 sudo apt install pipewire-media-session wireplumber- 最后，重新启用PipeWire-Media-Session服务：\n1 2 rm -f ~/.config/systemd/user/pipewire-session-manager.service systemctl --user --now enable pipewire-media-session 如果声音仍无法正常工作，尝试通过命令禁用PipeWire-Pulse服务：\n1 2 3 4 # 当前用户 systemctl --user --now disable pipewire-pulse.service pipewire-pulse.socket # 全局 sudo systemctl --global --now disable pipewire-pulse.service pipewire-pulse.socket 重新启用re-enable pulseaudio服务：\n1 2 3 4 # 当前用户 systemctl --user --now reenable pulseaudio.service pulseaudio.socket # 全局 sudo systemctl --global --now reenable pulseaudio.service pulseaudio.socket 重启\n1 2 3 systemctl --user restart pulseaudio reboot Reference 上下文：\nPipeWire is the default audio server in Ubuntu 22.10.\nPipeWire\nwireplumber\n配置：\nEnable PipeWire on Ubuntu 22.04\nHow to Use PipeWire to replace PulseAudio in Ubuntu 22.04\n其他\nWhy are some systemd services in the \u0026ldquo;masked\u0026rdquo; state?\nUnmask a Masked Service in Systemd\n","description":"","id":20,"section":"posts","tags":["个人工具"],"title":"Ubuntu22.04: 声卡驱动相关","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-09-28-ubuntu22.04_%E5%A3%B0%E5%8D%A1%E9%A9%B1%E5%8A%A8%E7%9B%B8%E5%85%B3/"},{"content":"重要 记录Ubuntu工作机中，一些自定义系统配置所在目录。方便备份和恢复开发环境。\ninstall Ubuntu-22.04 登录选择 ubuntu xorg apt update apt upgrade dpkg -i # 运行APPImage的依赖sudo dpkg -i $HOME/apps/packages/libfuse2_2.9.9-5ubuntu3_amd64.deb bash get-docker.sh install sougou install chrome; restart computer 拷贝个人配置cp -r -p \u0026lt;硬盘/home/hex/\u0026gt; /home/hex/ 重启检查 1.简介 1.1 文件夹书签(Nautilus Add Bookmarks) 配置文件所在目录 cat /home/hex/.config/gtk-3.0/bookmarks，内容如下：\n1 2 3 4 file:///home/hex/WeChatFiles/hexiang3941/FileStorage/File file:///home/hex/Desktop/github file:///home/hex/workspace file:///home/hex/Documents/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/%E5%85%AC%E5%8F%B8-4-%E8%BD%A6%E7%99%BE%E6%96%87%E6%A1%A3 注意：\n需要填绝对路径 先后顺序为目录显示顺序 文件保存退出，配置即生效 1.2 用户目录(xdg-user-dirs) 详细信息,请参考man xdg-user-dirs-update\n配置文件所在目录$HOME/.config/user-dirs.dirs，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # This file is written by xdg-user-dirs-update # If you want to change or add directories, just edit the line you\u0026#39;re # interested in. All local changes will be retained on the next run. # Format is XDG_xxx_DIR=\u0026#34;$HOME/yyy\u0026#34;, where yyy is a shell-escaped # homedir-relative path, or XDG_xxx_DIR=\u0026#34;/yyy\u0026#34;, where /yyy is an # absolute path. No other format is supported. # XDG_DESKTOP_DIR=\u0026#34;$HOME/Desktop\u0026#34; XDG_DOWNLOAD_DIR=\u0026#34;$HOME/Downloads\u0026#34; XDG_TEMPLATES_DIR=\u0026#34;$HOME/Templates\u0026#34; XDG_PUBLICSHARE_DIR=\u0026#34;$HOME/Public\u0026#34; XDG_DOCUMENTS_DIR=\u0026#34;$HOME/Documents\u0026#34; XDG_PICTURES_DIR=\u0026#34;$HOME/Pictures\u0026#34; XDG_Apps_DIR=\u0026#34;$HOME/apps\u0026#34; XDG_WORKSPACE_DIR=\u0026#34;$HOME/workspace\u0026#34; XDG_MUSIC_DIR=\u0026#34;$HOME/Music\u0026#34; XDG_VIDEOS_DIR=\u0026#34;$HOME/Videos\u0026#34; 以上内容，为命令xdg-user-dirs-update生成。通常在用户会话开始时自动执行，来根据语言环境更新用户dirs。此逻辑由下面配置文件/etc/xdg/user-dirs.conf控制\n1 2 3 4 5 6 7 8 9 10 11 # This controls the behaviour of xdg-user-dirs-update which is run on user login # You can also have per-user config in ~/.config/user-dirs.conf, or specify # the XDG_CONFIG_HOME and/or XDG_CONFIG_DIRS to override this # enabled=True # This sets the filename encoding to use. You can specify an explicit # encoding, or \u0026#34;locale\u0026#34; which means the encoding of the users locale # will be used filename_encoding=UTF-8 有些目录像Music\\Vedio不会经常使用，不想让系统自动创建，可以讲上面配置文件设置为enabled=False。但这样会导致部分问题\n比如Nautilus文件工具通过$HOME/Template目录中文件，显示新建文件时的选项。删除此目录会导致鼠标右键无新建文件选项。\n(但其他文件管理系统Thunar[xfce默认]、Nemo[cinnamon默认]没有这个问题)\n隐藏不需要目录方法：\n一种：删除目录，并执行命令xdg-user-dirs-update 另一种：改变位置 最后一种：手动修改文件，并讲设置为false，禁止自动更新 简单操作举例：\n1 2 3 4 5 6 # 1. 创建默认目录 xdg-user-dirs-update # 2. 创建自定义目录 xdg-user-dirs-update --set DOWNLOAD ~/Internet # 3. 查询 xdg-user-dir TEMPLATES 1.3 本地Desktop存储目录 配置文件目录$HOME/.local/share/applications/， 配置文件jetbrains-goland.desktop示例如下：\n1 2 3 4 5 6 7 8 9 10 [Desktop Entry] Version=1.0 Type=Application Name=GoLand Icon=/home/hex/apps/GoLand-2021.1.3/bin/goland.svg Exec=\u0026#34;/home/hex/apps/GoLand-2021.1.3/bin/goland.sh\u0026#34; %f Comment=Cross-platform IDE built specially for Go developers Categories=Development;IDE; Terminal=false StartupWMClass=jetbrains-goland 1.4 快捷键存储目录(keyboard) 1.5 运行appImage失败 原因：Ubuntu 22.04 不再默认安装 libfuse2，导致运行appImage时报错如下\n1 2 3 4 5 AppImages require FUSE to run. You might still be able to extract the contents of this AppImage if you run it with the --appimage-extract option. See https://github.com/AppImage/AppImageKit/wiki/FUSE for more information 需要安装libfuse2\n1.5 截图工具flameshot无法使用(Gnome4.1+) 在登录时，选择ubuntu xorg则解决问题\n1 sudo apt install libfuse2 或者离线安装\n1 sudo dpkg -i $HOME/apps/packages/libfuse2_2.9.9-5ubuntu3_amd64.deb 1.6 压缩包安装Typora 解压安装包\n1 2 3 mkdir /tmp/typora tar -zxvf /home/hex/apps/packages/办公软件/Typora-linux-x64.tar.gz -C /tmp/typora mv /tmp/typora/bin/Typora-linux-x64 $HOME/apps/Typora 创建软连接\n是为了在命令行执行 typora \u0026lt;/md/file/path\u0026gt;, 打开命令行工具\n1 ln -s /home/hex/apps/Typora/Typora /usr/local/bin/typora 创建Desktop\n将以下内容拷贝至文件/home/hex/.local/share/applications/self-typora.desktop\n1 2 3 4 5 6 [Desktop Entry] Name=typora Exec=/home/hex/apps/Typora/Typora Icon=/home/hex/apps/Typora/resources/app/asserts/icon/icon_512x512.png Type=Application StartupNotify=true 文件保存即生效\n1.7 卸载软件 1 2 3 sudo apt-get remove --purge libreoffice* sudo apt clean sudo apt-get autoremove 1.8 个性化设置 点击最小化\n1 gsettings set org.gnome.shell.extensions.dash-to-dock click-action \u0026#39;minimize\u0026#39; 执行后即时生效\n显示电池电量百分比\nSettings - Power - Show Battery Percentage 点击开启\n改变图标大小\nSettings - Appearance - Dock Icon size 设置值 48 Settings - Appearance - Dock Icon size 设置值 48 显示设置\nUbuntu一般会自动识别HI-DPI屏幕并适当扩展。如果没有，需要手动进行调整。\nSettings -\u0026gt; Displays -\u0026gt; enable Fractional scaling -\u0026gt; 选择合适地比例\ndocker-run 地微信显示出现问题，调整DPI环境变量。此值计算方式为分别率/英寸，例如200\n安装字体、编解码器\n微软字体、主流媒体格式\n1 sudo apt install ubuntu-restricted-extras 1.9 声音 检查pulseaudio状态\n1 pulseaudio --check 它通常不打印输出，只需退出代码即可。0表示运行。\n停止\n1 2 3 pulseaudio -k # or killall pulseaudio 后台期待\n1 pulseaudio -D Reference ","description":"","id":21,"section":"posts","tags":["个人工具"],"title":"Ubuntu: 个性化配置及保存路径","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-09-19-ubuntu_%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BF%9D%E5%AD%98%E8%B7%AF%E5%BE%84/"},{"content":"重要 最重要的事:\n1.简介 Reference vimium进阶篇：高级技巧,高手必知\n知乎-vimium常见问题及处理方式\n","description":"","id":22,"section":"posts","tags":["个人工具"],"title":"浏览器插件: vimium使用和配置","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-08-23-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%8F%92%E4%BB%B6-vimium_%E4%BD%BF%E7%94%A8%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"content":"重要 环境说明 安装 使用 Reference k6-像单元测试一样做压力测试\nOpen source load testing tool review 2020\n","description":"","id":23,"section":"posts","tags":["Devops"],"title":"k6压测工具-像单元测试一样做压力测试","uri":"https://hex-go.github.io/posts/devops/2022-08-04-k6%E5%8E%8B%E6%B5%8B%E5%B7%A5%E5%85%B7-%E5%83%8F%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%B8%80%E6%A0%B7%E5%81%9A%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/"},{"content":"重要 环境说明 问题 1. Implicit memory aliasing in for loop 报错意思是：在循环中重复使用变量的地址 参考链接\n因为for语句中变量是被重用的，即变量内存地址不变，但值发生变化。当取消引用指针时，值可能发生改变，所以静态检查报错\n1.1 错误写法 1 2 3 4 for i, v := range versions { res := createWorkerFor(\u0026amp;v) ... } 1.2 正确写法 for循环中使用元素的实际地址i,而非迭代变量取值（推荐） 1 2 3 for i := range versions { res := createWorkerFor(\u0026amp;versions[i]) } 在每次循环时重新初始化迭代变量 1 2 3 4 for _, v := range versions { v := v res := createWorkerFor(\u0026amp;v) // this is now the address of the inner v } 使用闭包 1 2 3 4 5 for _, v := range versions { go func(arg ObjectDescription) { x := \u0026amp;arg // safe }(v) } 2. commentFormatting: put a space between // and comment text 注释后面需要加空格\n2.1 错误写法 1 //UpdatePatch update patch - edit qlet`s information, and generate a new version patch 2.2 正确写法 1 // UpdatePatch update patch - edit qlet`s information, and generate a new version patch 2.3 IDE配置 goland中，可以点击File - Settings - Editor - Code Style - Go -Other下，勾选Add a leading space to comments。可以实现注释代码时自动在//后加空格。\n3. Consider preallocating (prealloc) lint 考虑 预先分配问题 参考链接\n使用make预先分配合理的内存空间，能减少复制和扩展。\n3.1 错误写法 1 2 3 4 var to []string for i := range s.To { to = append(to, s.To[i].String()) } 3.2 正确写法 1 2 3 4 to := make([]string, 0, len(s.To)) for i := range s.To { to = append(to, s.To[i].String()) } 或者干脆使用append，直接对切片对象赋值\n1 2 3 4 to := make([]string, len(s.To)) for i, t := range s.To { to[i] = t.String() } 4. should replace errors.New(fmt.Sprintf(…)) with fmt.Errorf(…) go 1.13之后，推荐使用fmt.Errof(\u0026quot;%w\u0026quot;,err)来生成error\n4.1 错误写法 1 errors.New(fmt.Sprintf(\u0026#34;error is %s\u0026#34;, err.Error())) 4.2 正确写法 1 fmt.Errorf(\u0026#34;error is %w\u0026#34;, err) 5. error strings should not be capitalized or end with punctuation or a newline error 信息不应该: 以大写字母开头 或 以标点符号\\换行结尾。\n6. don’t use MixedCaps in package name 包的名称不能大小写混写，应全小写\n6.1 错误写法 1 package fileUtils 6.2 正确写法 1 package fileutils 7. exported type T should have comment or be unexported 暴露出去的结构体或方法，应该加注释或不对外暴露。\n8. comment on exported type U should be of the form \u0026ldquo;U ..\u0026rdquo; 暴露出去的类型U的注释，应该为这种格式// U xxx。即以变量名开头\n9. 使用errors.Is方法替代 使用errors.Is方法替换错误信息校验\n###　9.1 错误写法\n1 2 3 4 5 6 7 8 9 if fieldErr, ok := err.(validator.ValidationErrors); ok { var tagErrorMsg []string for key, value := range fieldErr.Translate(validate.Trans) { tagErrorMsg = append(tagErrorMsg, fmt.Sprintf(\u0026#34;%s: %s\u0026#34;, key, value)) } respErr := errors.New(strings.Join(tagErrorMsg, \u0026#34;,\u0026#34;)) return respErr } 9.2 正确写法 1 2 3 4 5 6 7 8 9 10 var fieldErr validator.ValidationErrors if errors.Is(err, fieldErr) { var tagErrorMsg []string for key, value := range fieldErr.Translate(validate.Trans) { tagErrorMsg = append(tagErrorMsg, fmt.Sprintf(\u0026#34;%s: %s\u0026#34;, key, value)) } respErr := errors.New(strings.Join(tagErrorMsg, \u0026#34;,\u0026#34;)) return respErr } Reference golint错误检查以及 min-confidence 不同等级的错误提示 ","description":"","id":24,"section":"posts","tags":["Go"],"title":"golangci-lint常见报错说明及修复建议","uri":"https://hex-go.github.io/posts/golang/2022-08-04-golangci-lint%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99%E8%AF%B4%E6%98%8E%E5%8F%8A%E4%BF%AE%E5%A4%8D%E5%BB%BA%E8%AE%AE/"},{"content":"重要 环境说明 安装 使用 Reference ","description":"","id":25,"section":"posts","tags":["Kubernetes"],"title":"sealer作为PaaS整体打包方案调研","uri":"https://hex-go.github.io/posts/kubernetes/2022-08-04-sealer%E4%BD%9C%E4%B8%BApaas%E6%95%B4%E4%BD%93%E6%89%93%E5%8C%85%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94/"},{"content":"重要 最重要的事:\n1.简介 1.2 本地模式 WindTerm有两种模式:\n远程模式\nWindTerm的远程模式是默认的模式。 在远程模式下,每个键按下发送到服务器就像其他终端。\n本地模式\n本地模式主要用于浏览文本。 在本地模式下,每个键按下将解析本地,而不是发送到服务器。\n支持大多数本地模式 导航 ， 滚动 ， 搜索 ， 复制和粘贴 ， 选择 和 折叠 Vim的捷径。\n当WindTerm在本地模式下,它就像一个只读的文本编辑器,这是非常方便的文本浏览。 特别是,快速滚动,不断输出时,切换到本地模式可以输出的立即停止滚动,方便阅读。\n快捷方式 行动 Alt + Enter 远程和本地模式切换（Toggle the remote and local mode） i 切换回远程模式（Switch back to remote mode from local mode） p 粘贴、切换回远程模式（Paste and switch back to remote mode from local mode） Ctrl + v 粘贴、切换回远程模式（Paste and switch back to remote mode from local mode） 本地模式Vim导航键说明\nShortcut Action h 左移（Move left） j 下移（Move down） k 上移（Move up） l 右移（Move right） 0 行首（Move to the begining of the line） $ 行尾（Move to the end of the line） ^ 行首非空字符（Move to the first non-blank character of the line） w 下一个单词（Move to next word） W 下一个空白分隔词（Move to next blank delimited word） b 词首（Move to the beginning of the word） B 空白分隔词首（Move to the beginning of the blank delimted word） e 词尾（Move to the end of the word） E 空白分隔词尾（Move to the end of the blank delimited word） 1G 首行（Move to the first line of the session） nG N行（Move to nth line of the session） G 尾行（Move to the last line of the session） gg 开头（move to the beginning of the session） ge 行尾单词，词首（Move to the end of the previous word） gE Move to the end of the previous Blank delimited word - 非空句首（Move to the previous non-blank sentence） + 非空句尾（Move to the next non-blank sentence） ( 句首（Move to the previous sentence） ) 句尾（Move to the next sentence） { 段首（Move to the previous paragraph） } 段尾（Move to the next paragraph） 本地模式Vim文本复制说明\n在本地模式下，可以使用y{motion}复制，其中{motion}是上面导航快捷键或搜索快捷键。例如，yw 复制下一个单词的开头。其他有用的副本命令包括：\n快捷键 动作 yy 复制当前行，包括换行符、新行起始字符（如hex@hex-ThinkPad:~$）；复制选中内容 y$ 复制当前行，不包括换行符、新行起始字符 yw 复制到下一个单词开头 ytx 当前光标位置向后复制至字符x,不包括x yfx 当前光标位置向后复制至字符x, 包括x p 粘贴、并返回Remote模式 P 粘贴、并保留Local模式(Vim文本) “xy{motion} 复制内容、并注册给变量x “xp 黏贴变量x中的内容、并返回Remote模式 “xP 黏贴变量x中的内容、并保留Local模式(Vim文本) “+y{motion} 复制内容、至系统粘贴板 “+p 从系统粘贴板粘贴、并返回Remote模式 “+P 从系统粘贴板粘贴、并保留Local模式(Vim文本) 1.2 快捷键记录 快捷键 动作 Ctrl+Shift+W 关闭页签（Close tab） Ctrl+Shift+T 回复页签（Restore tab） Ctrl+Shift+Left 转至前提示行（Goto the previous prompt line） Ctrl+Shift+Right 转至后提示行（Goto the next prompt line） Ctrl+Alt+L 锁屏 Alt+1 选择1页签 Alt+O 打开页签 Alt+S 搜索页签 批量发送（Sender Pane）快捷键 快捷键 动作 Alt+Enter 发送（Send） Alt+Q 停止（Stop） Alt+= 增加新的发送记录（Add Sender） Alt+- 删除发送（Remove Sender） Alt+X 清空（Clear Sender） 文件传输（Sftp）快捷键 快捷键 动作 Alt+Enter 发送（Send） Alt+Q 停止（Stop） Alt+= 增加新的发送记录（Add Sender） Alt+- 删除发送（Remove Sender） Alt+X 清空（Clear Sender） 快捷键 动作 F2 文件重命名（Rename） F3 文件下载 （Download） F4 文件上传 （Upload） F5 目录刷新 （Refresh） F6 移动至 （Move to） Del 删除 （Remove） Return 打开 （Open） Backspace 返回上一层（Cdup） Alt+D 选中地址栏（Select the address bar） Alt+Left 向前回滚 （Go backward） Alt+Right 向后回滚 （Go forward） Alt+Return 属性 （Show property） Ctrl+A 全选 （Select all items） Ctrl+Shift+N 新建文件夹（Create a folder） Ctrl+N 新建文件 （Create a file） Ctrl+L 新建软链 （Create a link） Ctrl+C 复制名称 （Copy names） Ctrl+Shift+C 复制路径 （Copy paths） Ctrl+P 复制名称至终端（Copy names to terminal） Ctrl+Shift+P 复制名称至终端（Copy paths to terminal） Reference ","description":"","id":26,"section":"posts","tags":["个人工具"],"title":"终端工具WindTerm使用","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-07-29-%E7%BB%88%E7%AB%AF%E5%B7%A5%E5%85%B7windterm%E4%BD%BF%E7%94%A8/"},{"content":"重要 最重要的事:\n1.简介 1.1 从LastPass迁移至Bitwarden import-from-lastpass\nlastPass导出 - Web端 左下角 Advanced Options - Export\nlastPass导出 - 浏览器插件 navigate to Account Options → Advanced → Export → LastPass CSV File\nBitwarden导入 Tools - Import Data - 选择文件格式(lastPass CSV) - 导入\n1.2 设置浏览器自动填充 auto-fill-browser\n快捷键 Windows: Ctrl + Shift + L\nMacOS: Cmd + Shift + L\nLinux: Ctrl + Shift + L\n页面加载时 浏览器插件图标，点击左键。Setting - Options - Enable Auto-fill on Page Load\n1.3 Web端设置中文显示 账号设置 - 偏好设置 - 语言\nACCOUNT SETTINGS - Preferences - Language\n1.4 Web端创建多层级文件夹 举例：\n创建 个人， 再创建个人/生活\n1.5 URI说明 URI匹配说明\n如果子域名相同(*.icos.city)，尽量不选择默认规则，否则无法区分。\n规则间关系是且，而非或， 所以可以通过正则实现多个域名用一个用户名密码访问。\n正则 只保证有唯一秘钥被匹配，下面正则并不严谨，但够用。这样自动填充就能、也只能填充唯一一个正确秘钥，节省时间。\nURI规则： ^(http|https)://((gitlab|zentao|jenkins).icos.city|(nextcloud|icoswiki).chebai.org)\n可匹配项：\n- https://zentao.icos.city\n- https://gitlab.icos.city\n- https://jenkins.icos.city\n- http://icoswiki.chebai.org\n- http://nextcloud.chebai.org\n1.6 Web修改未同步至浏览器插件 手动同步\n左键点击插件图标，点击右下角Setting - 点击上方 Sync按钮 手动同步\nReference Web端访问地址\n官方说明文档\nBitwarden 帮助中心中文版\n","description":"","id":27,"section":"posts","tags":["个人工具"],"title":"密码管理工具Bitwarden使用","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-07-28-%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7bitwarden%E4%BD%BF%E7%94%A8/"},{"content":"重要 最重要的事:\n1. 命令行快捷键 参见 man readline 来查看 Bash 中所有默认的键盘绑定, 可以使用 set -o vi 使用 vi 风格的键盘绑定。\n命令行编辑：光标移动\n##　1.1 行首、行尾\nCtrl + a: 转到行的开头。 == Home键 == alt + shift + b\nCtrl + e: 转到行的结尾。 == End键 == alt + shift + f\n##　1.2 前移、后移 1字符\nCtrl + b: 左移动1个字符。 == 方向左键\u0026lt;-\nCtrl + f: 右移动1个字符。 == 方向右键-\u0026gt;\n##　1.3 前移、后移 1单词\nCtrl + 方向左键\u0026lt;-: 左移动1个单词。== alt + b(back)\nCtrl + 方向左键-\u0026gt;: 右移动1个单词。== alt + f(forward)\n命令行编辑：快捷删除\n1.4 删除至行首、删除至行尾 Ctrl + u删除至行首，Ctrl + k删除至行尾。\n1.5 删除前一项 Ctrl + w删除删除光标处左边一个单词，或至单词首的内容。\n1.6 删除后一项 Alt + d: 删除光标处右边一个单词，或至单词末的内容\n1.7 删除前一字符 Ctrl + h: 删除删除光标处左边一个字符。\n1.8 删除后一字符 Ctrl + d: 删除光标处右边一个字符。\n1.9 插入上次删除的内容 Ctrl + y: 将上一次删除的内容插入到光标处。(光标不移动，等同于撤销操作)。\n命令行编辑：撤销\n1.10 撤销修改 Ctrl+shift+-：撤销，即恢复上一次操作，可撤销多次。\n注意，这个快捷根据自己系统设定不一样，有的Ctrl+shift+-是撤销，Ctrl+-是命令行字体变小，而有的系统设置刚好相反。\n命令行编辑：屏幕调整\n1.11 字体变小 Ctrl+-：命令行字体变小，注意看上面撤销修改Ctrl+shift+-的说明。\n1.12 字体变大 Ctrl+shift++：命令行字体变大。有的系统设置是Ctrl++，ctrl和+的组合是命令行字体变大。\n1.13 清屏 Ctrl+l: 清屏，但是当前命令行内容保留\n1.14 锁定 Ctrl+s: 锁定命令行\n1.14 解锁 Ctrl+Q: 解锁命令行\n命令行编辑：快捷输入\n1.15 使用上个命令最后一项 参数: !$ 或者 快捷键: alt+.\n1 ls /home/hex/ 1 cd !$ 等同于 cd /home/hex/\n1.16 使用上一个命令 参数: !!\n权限不足时 sudo !!\n1 2 3 vi /etc/hosts sudo !! 1.17 使用上次删除的内容 Ctrl + y: 将上一次删除的内容插入到光标处。(光标不移动，等同于撤销操作)。\n2. vim快捷键 3. bash常用命令 3.1 文件擦除数据 1 \u0026gt; /root/test.md 或者\n1 echo \u0026#39;\u0026#39; \u0026gt; /root/test.md 3.2 读取日志文件 3.2.1 实时读取日志文件 1 tail -F linuxidc_log 3.2.2 less读取文件 1 less -N linuxidc.txt //按下v键来编辑文件\n//退出编辑器后，可以继续用less浏览\n可以在更少的范围内搜索字词，按页移动，高亮与行号等。\n###　3.2.3 读取压缩日志而不解压缩\n使用zless，zcat，zgrep等z命令查看压缩包的内容，甚至不必显式提取压缩文件\n1 zcat linuxidc_log.zip | more 3.3 文件查找 3.3.1 查找包含特定文本的文件 1 grep -Pri 要搜索的字符串 路径 3.3.2 精通find命令 如何使用find命令在Linux中查找文件\n3.4 输出查看-表格 1 mount |column -t 3.5 SSH客户端配置优化 ~/.ssh/config 包含了\n避免在特定网络环境中连接被断掉的情况的设置 TCPKeepAlive=yes ServerAliveInterval=15 ServerAliveCountMax=6 使用压缩（这对于通过低带宽连接使用 scp 很有用） Compression=yes 使用一个本地控制文件来开启到同一台服务器的多通道 ControlMaster auto ControlPath /tmp/%r@%h:%p ControlPersist yes 1 2 3 4 5 6 7 TCPKeepAlive=yes ServerAliveInterval=15 ServerAliveCountMax=6 Compression=yes ControlMaster auto ControlPath /tmp/%r@%h:%p ControlPersist yes 文件传输 python2\ncaddy\n操作不被history记录 关闭history 1 history -c 操作命令前，加一个空格 清除指定history记录 1 history -d \u0026lt;num\u0026gt; 进程相关 查看运行时间 通过 -o 参数，指定只显示具体的某个字段，会得到更清晰的结果。\n通过 -o etime 获取该进程的运行时间(etime格式 = %d-%h:%m:%s etimes格式 = %s)\n1 ps -p 10167 -o etimes,etime -o rss 可以只获取该进程的内存信息\n资源使用率排序 内存使用率 排序 1 ps aux | sort -rnk 4 CPU使用率 排序 1 ps aux | sort -nk 3 网络相关 查看本机公网IP 1 2 3 curl ip.sb # 或 curl ifconfig.me Reference Linux常用命令行小技巧: 全面+有深度, 有点乱\n80%的人都不会的，15个Linux实用技巧: 清晰，量少\n30个高效的Linux命令技巧: Bash语法\n","description":"","id":28,"section":"posts","tags":["个人工具"],"title":"Linux常用快捷键","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-07-08-linux%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"content":"重要 最重要的事:\n1.简介 dd指令是一个简单的复制指令，它不管源和目标的编码、格式、数据结构，简单粗暴的把二进制数据从A复制到B。\n所以恢复的目标硬盘甚至不需要提前分区，因为dd会把分区信息也写入。\n不管源数据是文件、分区、磁盘还是光盘，都可以进行数据备份。\n优点：\n操作简单 缺点：\n速度慢 硬盘大小必须比源大 2. 操作 2.1 整盘复制 目标磁盘需要比源磁盘大。\nif=表示源磁盘，of=表示目标磁盘\n1 dd if=/dev/sda of=/dev/sdb 2.2 磁盘备份成文件再恢复 2.2.1 磁盘-\u0026gt;文件 bs参数: 一次拷贝的字节数。如：bs=4096。合理使用bs参数可优化dd执行速度，bs的合理范围要参考本机的性能进行具体设置。\n单备份 1 dd if=/dev/sda of=/home/sda.img bs=4096 备份并压缩 1 dd if=/dev/sda | gzip \u0026gt; /home/sda.img 2.2.2 文件-\u0026gt;磁盘 单备份 1 dd if=sdadisk.img of=/dev/sdb 从压缩文件恢复 1 gzip -dc /home/sda.img | dd of=/dev/sda 2.3 分区备份 把分区直接备份到另一个分区，就需要生成一个新的分区，这个分区的大小不能比源分区小，只能和源分区大小一致或比它大。\n查看磁盘sdb的分区表，查看所有分区uuid，此时各分区uuid各不相同。\n1 2 df -h blkid 备份\n1 dd if=/dev/sda1 of=/dev/sdb1 恢复\n1 dd if=/dev/sdb1 of=/dev/sda1 修复还原到大小不一样的分区时的设置：\n1 2 3 sudo dd if=/dev/sda1 of=/dev/sdb1 sudo e2fsck -f /dev/sdb1 sudo resize2fs /dev/sdb1 2.4 查看进度 watch 1 watch -n 5 killall -USR1 dd 2.5 销毁磁盘数据 原磁盘包含有敏感数据，因为所有删除甚至格式化的内容都有可能使用技术手段进行还原。使用dd命令即可完全抹盘。\n使用0填充整个硬盘：\n1 dd if=/dev/zero of=/dev/sda1 或者，使用随机数填充整个硬盘，效果更佳：\n1 dd if=/dev/urandom of=/dev/sda1 2.6 磁盘测速 1 2 dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file dd if=/root/1Gb.file bs=64k | dd of=/dev/null 2.7 磁盘修复 1 dd if=/dev/sda of=/dev/sda 或dd if=/dev/hda of=/dev/hda 2.8 制作系统盘 1 dd if=ubuntu-server-amd64.iso if=/dev/sdb 2.0 写指定大小文件 如大文件测试上传或下载的速度。下面命令生成一个文件名为 file.img 大小为 1G 的文件。\n1 dd if=/dev/zero of=file.img bs=1M count=1024 参考链接 Ubuntu 备份与恢复系统\nlinux使用dd命令备份系统\n","description":"","id":29,"section":"posts","tags":["个人工具","Disk"],"title":"Ubuntu系统dd命令备份和恢复系统","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-07-08-ubuntu_dd%E5%91%BD%E4%BB%A4%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D%E7%B3%BB%E7%BB%9F/"},{"content":"重要 目前主流的网盘系统都支持WebDAV连接方式，在windows系统下链接WebDAV以及是很常见的事情，如果能在Linux下链接WebDAV变成本地磁盘，那么可以把部分文件放置在WebDAV空间，甚至还可以通过网页转成外链链接。\n1.简介 常用的文件共享协议有三种：FTP、Samba、WebDAV\nWebDAV 基于 HTTP 协议的通信协议，在广域网上共享文件有天然的优势，移动端文件管理APP也大多支持WebDAV协议。使用HTTPS还能保安全性。Apache和Nginx支持WebDAV，可作为WebDAV文件共享服务器软件。也可以使用专门的WebDAV软件部署。\nwebdav 是 GitHub 上开源的项目，基于 Go 语言实现，不仅跨平台，还支持 ARM 架构，可在㠌入式设备中部署 WebDAV 服务器。\n2. 操作 2.1 运行阿里云盘-webDAV 环境准备 1. 参数说明 变量名称 描述 示例 ALIYUNPAN_REFRESH_TOKEN RefreshToken 024534dbe2384807b24abfd1ab84fd7d ALIYUNPAN_AUTH_USER webdav登录用户名，随意设置，磁盘挂载的时候使用 admin ALIYUNPAN_AUTH_PASSWORD webdav登录密码，随意设置，磁盘挂载的时候使用 admin ALIYUNPAN_PAN_DIR 网盘文件夹的webdav服务根目录 / ALIYUNPAN_TRANSFER_URL_TYPE 上传下载链接类型：1-默认 2-阿里ECS环境(ECS必须是经典网络类型) 1 ALIYUNPAN_BLOCK_SIZE 上传数据块大小，单位为KB，默认为1024KB，建议范围1024KB~10240KB 10240 2. 获取refresh-token 3. https配置(可选) nginx配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 server { listen 443; server_name your.host.com; ssl on; root html; index index.html index.htm; ssl_certificate /path/to/your/file.pem; ssl_certificate_key /path/to/your/file.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; # webdav server location /{ root html; proxy_pass http://127.0.0.1:23077; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_redirect off; } } 部署 1. docker-run部署 1 2 3 4 5 6 7 docker run -d --name=aliyundisk \\ --restart=always -p 23077:23077 \\ -e TZ=\u0026#34;Asia/Shanghai\u0026#34; \\ -e ALIYUNPAN_REFRESH_TOKEN=\u0026#34;024534dbe2384807b24abfd1ab84fd7d\u0026#34; \\ -e ALIYUNPAN_AUTH_USER=\u0026#34;admin\u0026#34; \\ -e ALIYUNPAN_AUTH_PASSWORD=\u0026#34;admin\u0026#34; \\ -e ALIYUNPAN_PAN_DIR=\u0026#34;/\u0026#34; tickstep/aliyunpan-webdav:v0.1.4 2. docker-compose部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 version: \u0026#39;3\u0026#39; services: webdav: image: tickstep/aliyunpan-webdav:\u0026lt;tag\u0026gt; container_name: aliyunpan-webdav restart: always ports: - 23077:23077 environment: - TZ=Asia/Shanghai # refresh token用于登录 - ALIYUNPAN_REFRESH_TOKEN=b9123...13e66a1 # webdav 登录用户名 - ALIYUNPAN_AUTH_USER=admin # webdav 登录密码 - ALIYUNPAN_AUTH_PASSWORD=admin # 指定网盘文件夹作为webdav服务根目录 - ALIYUNPAN_PAN_DIR=/ # 上传下载链接类型：1-默认 2-阿里ECS环境(ECS必须是经典网络类型) - ALIYUNPAN_TRANSFER_URL_TYPE=1 # 上传数据块大小，单位为KB，默认为1024KB，建议范围1024KB~10240KB - ALIYUNPAN_BLOCK_SIZE=10240 2.2 挂载webdav 1. 安装davfs2工具 centos\n1 yum install davfs2 ubuntu\n1 apt install davfs2 2. 挂载磁盘 执行命令后，按提示输入用户名密码（ALIYUNPAN_AUTH_USER和ALIYUNPAN_AUTH_PASSWORD的值）\n1 2 mkdir /aliyun-disk mount -t davfs https://pan.cloud.com/dav /aliyun-disk 3. 设置开机自动挂载 编辑davfs2.conf配置文件，将use_locks的1改为0 1 vim /etc/davfs2/davfs2.conf 修改secrets文件，添加账号信息 普通用户可以修改此文件~/.davfs2/secrets\n1 vim /etc/davfs2/secrets 在底部添加账号信息，如\n1 https://pan.cloud.com/dav user password 添加开机挂载命令 在 /etc/rc.d/rc.local文件或者/etc/profile.d/aliyundisk.sh中追加下面内容\n开机自动运行的几种方法：\n/etc/rc.d/rc.local： 文件会在 Linux 系统各项服务都启动完毕之后再被运行\ncrontab @rebot: 任务在系统重启之后自动运行某个命令\nsystemd：适用systemd系统\n/etc/profile.d/xx.sh: /etc/profile会遍历/etc/profile.d/*.sh\n/etc/profile： 此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行. 并从/etc/profile.d目录的配置文件中搜集shell的设置。 /etc/bashrc: 为每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取（即每次新开一个终端，都会执行bashrc）。 ~/.bash_profile: 每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次。默认情况下,设置一些环境变量,执行用户的.bashrc文件。 ~/.bashrc: 该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该文件被读取。你可以在这里设置你的个性化终端了. ~/.bash_logout: 当每次退出系统(退出bash shell)时,执行该文件. 另外,/etc/profile中设定的变量(全局)的可以作用于任何用户,而~/.bashrc等中设定的变量(局部)只能继承 /etc/profile中的变量,他们是**”父子”关系**。 ~/.bash_profile: 是交互式、login 方式进入 bash 运行的。~/.bashrc 是交互式 non-login 方式进入 bash 运行的通常二者设置大致相同，所以通常前者会调用后者。 1 mount -t davfs http://127.0.0.1:23077 /aliyundisk/ 4. 逼坑 不能通过/etc/fstab的auto选项, 实现开机自动挂载\n1 http://127.0.0.1:23077 /aliyundisk/ davfs noauto,user 0 0 因为/etc/fstab在网络初始化之前执行，只有在建立网络连接之后才能装载webDAV共享，所以不能auto在/etc/fstab文件中使用该选项。自动挂载将失败。\n3. 可视化管理工具推荐 阿里云盘可视化管理工具-小白羊版\nReference 网络存储文件共享之WebDAV\nLinux配置WebDAV-server为共享存储\n阿里云盘命令行客户端，支持webdav文件服务\n阿里云盘可视化管理工具-小白羊版\n","description":"","id":30,"section":"posts","tags":["个人工具"],"title":"阿里云盘-WebDAV开机自动挂载","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2022-05-17-%E9%98%BF%E9%87%8C%E4%BA%91%E7%9B%98_webdav%E5%BC%80%E6%9C%BA%E8%87%AA%E5%8A%A8%E6%8C%82%E8%BD%BD/"},{"content":"重要 由于生产环境的函数服务需要编译go包，但内网无法访问互联网。所以需要搭建代理私仓，缓存第三方包。主要考虑的技术选型有两种: nexus和goproxy.\nnexus是能满足需求，但太重,并且go不支持认证,必须开启nexus的匿名模式。go-proxy功能比较简单。下面分别介绍nexus和goproxy的搭建方式，针对 不通场景进行选择。\nnexus搭建go私仓库 goproxy搭建go私仓库 Reference nexus搭建\ngoproxy 官方文档\n","description":"","id":31,"section":"posts","tags":["Go","Proxy","Nexus"],"title":"内网搭建goproxy私仓","uri":"https://hex-go.github.io/posts/golang/2022-05-07-%E5%86%85%E7%BD%91%E6%90%AD%E5%BB%BAgoproxy%E7%A7%81%E4%BB%93/"},{"content":"重要 最重要的事:\n1.简介 set 命令是 Bash 脚本的重要环节，却常常被忽视，导致脚本的安全性和可维护性出问题。此处记录基本用法。\n2.使用 set命令用来修改 Shell 环境的运行参数，也就是定制环境。\n顺便提一下，如果命令行下不带任何参数，直接运行set，会显示所有的环境变量和 Shell 函数\n常用的四个命令如下\nu, 忽略空变量 x, 调试 结果前打印命令 e, 发生错误，立即终止 o pipefail, 管道子命令发生错误，立即终止 2.1 忽略不存在变量 忽略 执行脚本 中 不存在的变量。\n1 set -u 等同于\n1 set -o nounset 2.2 在打印结果之前，先打印命令。 在运行结果之前，先输出执行的命令。\n1 set -x 等同于\n1 set -o xtrace 2.3 错误处理 Bash 命令执行失败，默认会继续执行后面的命令。\n通过下面写法，当command有非零返回值，脚本就会停止执行。防止错误累积\n1 command || exit 1 退出时，执行额外操作\n1 command || { echo \u0026#34;command failed\u0026#34;; exit 1; } 等同于\n1 if ! command; then echo \u0026#34;command failed\u0026#34;; exit 1; fi 等同于\n1 if [ \u0026#34;$?\u0026#34; -ne 0 ]; then echo \u0026#34;command failed\u0026#34;; exit 1; fi 2.4 命令依赖 command1执行成功，再执行command2。\n1 command1 \u0026amp;\u0026amp; command2 2.5 发生错误，立即终止 脚本只要发生错误，就终止执行。但对|管道失效，具体原因看 2.6 小节\n1 set -e 等同于\n1 set -o errexit 脚本后续命令，非空返回为执行成功。则需要临时关闭set -e，来让命令正常执行\n1 2 3 4 5 6 7 8 9 #!/usr/bin/env bash set -e echo \u0026#34;初始设置 set -e 并执行命令\u0026#34; ## 临时关闭 set -e set +e echo \u0026#34;执行正常返回为非空的命令\u0026#34; # 重新打开 set -e set -e 也可以通过command || true的方式解决\n1 2 3 4 5 6 #!/bin/bash set -e command || true echo bar 2.6 子命令失败，整个管道命令就失败，脚本就会终止执行。 管道命令，就是多个子命令通过管道运算符|组合成为一个大的命令。Bash会把最后一个子命令的返回值，作为整个命令的返回值。\n也就是说，只要最后一个子命令不失败，管道命令总是会执行成功，因此它后面命令依然会执行，set -e 就失效了。\n例如\n1 2 3 4 5 #!/usr/bin/env bash set -e # 由于下面`echo \u0026#34;test\u0026#34;`成功，命令永远不会中断 mc | echo \u0026#34;test\u0026#34; echo bar 改为如下写法，解决管道问题\n1 2 3 4 5 #!/usr/bin/env bash set -eo pipefail foo | echo a echo bar 总结 上面参数总会一起使用\nu, 忽略空变量 x, 调试 结果前打印命令 e, 发生错误，立即终止 o pipefail, 管道子命令发生错误，立即终止 比如\n1 set -euxo pipefail 等同于\n1 2 set -eux set -o pipefail 等同于\n1 bash -euxo pipefail script.sh Reference 官方手册\nBash脚本set命令教程-阮一峰\n","description":"","id":32,"section":"posts","tags":["Bash"],"title":"bash脚本set命令说明","uri":"https://hex-go.github.io/posts/bash/2022-03-30-bash%E8%84%9A%E6%9C%ACset%E5%91%BD%E4%BB%A4%E8%AF%B4%E6%98%8E/"},{"content":"重要 Featmap是一个用户故事映射工具，用于构建，计划和传达产品积压。\nFeatmap Picture\n环境说明 服务依赖 Postgresql\n个人部署记录\n安装 目录结构\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . ├── charts │ └── featmap │ ├── Chart.yaml │ ├── config │ │ └── conf.json # 配置文件： chart部署时， 运行环境的真实配置 │ ├── templates │ │ ├── configmap.yaml │ │ ├── deployment.yaml │ │ ├── _helpers.tpl │ │ ├── ingress.yaml │ │ └── svc.yaml │ └── values.yaml # chart值配置文件 ├── conf.json # 配置文件： 构建镜像时， 打进镜像的默认配置 ├── Dockerfile ├── Makefile └── README.md 1. 构建Docker镜像 1.1 Dockerfile 内容如下: 1 2 3 4 5 6 7 8 9 10 FROM self.registry.com/ubuntu:20.04 WORKDIR /opt/featmap COPY conf.json . ADD https://github.com/amborle/featmap/releases/download/v2.1.0/featmap-2.1.0-linux-amd64 /usr/local/bin/featmap RUN chmod 775 /usr/local/bin/featmap EXPOSE 5000 ENTRYPOINT [\u0026#34;featmap\u0026#34;] 其中配置文件内容conf.json如下:\n不支持环境变量，只能通过此配置文件修改环境配置\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;appSiteURL\u0026#34;: \u0026#34;https://localhost:5000\u0026#34;, \u0026#34;dbConnectionString\u0026#34;: \u0026#34;postgresql://gitea:gitea@pgsql-host:5432/postgres?sslmode=disable\u0026#34;, \u0026#34;jwtSecret\u0026#34;: \u0026#34;ChangeMeForProductionXXX\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;5000\u0026#34;, \u0026#34;emailFrom\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;smtpServer\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;smtpPort\u0026#34;: \u0026#34;587\u0026#34;, \u0026#34;smtpUser\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;smtpPass\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;environment\u0026#34;: \u0026#34;development\u0026#34; } 1.2 构建镜像 命令 镜像地址: self.registry.com/featmap:2.1.0\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 TAG := 2.1.0 IMAGE_PATH := self.registry.com/featmap IMAGE := $(IMAGE_PATH):$(TAG) .PHONY: docker-clean docker-clean: @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;docker clean\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; for i in $$(docker ps -a |grep $(IMAGE_PATH) |awk \u0026#39;{print$$1}\u0026#39;) ; do docker rm -f $$i ; done for i in $$(docker images |grep $(IMAGE_PATH) |awk \u0026#39;{print$$3}\u0026#39;) ; do docker rmi -f $$i ; done .PHONY: build build: docker-clean @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;docker build\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; docker build -t $(IMAGE) . 2. 部署 安装命令\n线上配置通过charts/featmap/config/conf.json修改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 TAG := 2.1.0 IMAGE_PATH := hub.icos.city/icos/icospaas/featmap IMAGE := $(IMAGE_PATH):$(TAG) INSTANCE := featmap CHART := charts/featmap NAMESPACE := default KUBECONFIG := /home/hex/.kube/config .PHONY: push push: build @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;docker push \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; docker push $(IMAGE) .PHONY: helm-uninstall helm-uninstall: @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;helm uninstall\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; helm --kubeconfig=$(KUBECONFIG) -n $(NAMESPACE) uninstall $(INSTANCE) .PHONY: helm-install helm-install: push @echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;helm install\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026#34; helm --kubeconfig=$(KUBECONFIG) -n $(NAMESPACE) install $(INSTANCE) $(CHART) ","description":"","id":33,"section":"posts","tags":["Devops","Featmap","Dockerfile","Chart"],"title":"FeatMap-UserStory地图服务配置和搭建","uri":"https://hex-go.github.io/posts/devops/2022-03-25-featmap-userstory%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%E5%92%8C%E6%90%AD%E5%BB%BA/"},{"content":"重要 最重要的事:\n1.简介 Reference RSA算法原理（一）\nRSA算法原理（二）\n","description":"","id":34,"section":"posts","tags":["计算机原理","面试","待完善"],"title":"RSA算法原理","uri":"https://hex-go.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/2021-11-09-rsa%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/"},{"content":"简介 算法（Algorithm）是指用来操作数据、解决程序问题的一组方法。对于同一个问题，\n使用不同的算法，也许最终得到的结果是一样的，但在过程中消耗的资源和时间却会有很大的区别。\n衡量算法性能优劣的度量：\n时间维度：是指执行当前算法所消耗的时间，我们通常用「时间复杂度」来描述。 空间维度：是指执行当前算法需要占用多少内存空间，我们通常用「空间复杂度」来描述。 大O符号表示法\n1. 时间复杂度 算法基本操作的重复执行次数为问题规模n的某个函数，也就是用时间频度T(n)表示。\n如果存在某个函数f(n)，使得当n趋于无穷大时，T(n)/f(n)的极限值是不为零的常数，\n那么f(n)是T(n)的同数量级函数，记作T(n)=O(f(n))，称O(f(n))为算法的渐进时间复杂度，简称为时间复杂度。\n1.1 概述 算法的渐进时间复杂度: T(n) = O(f(n))\nT(n): 表示时间频度\nf(n): 表示每行代码执行次数之和\nn : 表示着问题的规模\nO : 表示正比例关系\n常见的算法时间复杂度由小到大依次为：Ο(1)＜Ο(log n)＜Ο(n)＜Ο(nlog n)＜Ο(n2)＜Ο(n3)＜…＜Ο(2^n)＜Ο(n!)\n1.2 求解算法复杂度 求解算法复杂度分以下几个步骤：\n找出算法中的基本语句：算法中执行次数最多的语句就是基本语句，通常是最内层循环的循环体。 计算基本语句的执行次数的数量级：只需计算基本语句执行次数的数量级，即只要保证函数中的最高次幂正确即可，可以忽略所有低次幂和最高次幂的系数。这样能够简化算法分析，使注意力集中在最重要的一点上：增长率。 用大Ο表示算法的时间性能：将基本语句执行次数的数量级放入大Ο记号中。 其中用大O表示法通常有三种规则：\n用常数1取代运行时间中的所有加法常数； 只保留时间函数中的最高阶项； 如果最高阶项存在，则省去最高阶项前面的系数； 1.3 举例说明 常数阶O(1) 1 2 3 4 5 int i = 1; int j = 2; ++i; j++; int m = i + j; 线性阶O(n) 1 2 3 4 5 for(i=1; i\u0026lt;=n; ++i) { j = i; j++; } 对数阶O(logN) 1 2 3 4 5 int i = 1; while(i\u0026lt;n) { i = i * 2; } 线性对数阶O(nlogN) 1 2 3 4 5 6 7 8 for(m=1; m\u0026lt;n; m++) { i = 1; while(i\u0026lt;n) { i = i * 2; } } 平方阶O(n²) 1 2 3 4 5 6 7 8 for(x=1; i\u0026lt;=n; x++) { for(i=1; i\u0026lt;=n; i++) { j = i; j++; } } 立方阶O(n³)、K次方阶O(n^k) 1 三层、k层for循环嵌套 2. 空间复杂度 算法的渐进空间复杂度: S(n)=O(f(n))\nS(n): 表示空间复杂度\nf(n): 表示一个算法所需的存储空间\nn : 表示问题的规模\nO : 表示正比例关系\nO(1) 1 2 3 int i = 1; int j = 2; int k = 1 + 2; O(n) 1 2 3 4 5 6 int j = 0; int[] m = new int[n]; for (int i = 1; i \u0026lt;= n; ++i) { j = i; j++; } Reference 算法的时间与空间复杂度\nLeetCode0：学习算法必备知识：时间复杂度与空间复杂度的计算\n","description":"","id":35,"section":"posts","tags":["LeetCode"],"title":"算法的时间和空间复杂度说明","uri":"https://hex-go.github.io/posts/leetcode/2021-11-09-%E7%AE%97%E6%B3%95%E7%9A%84%E6%97%B6%E9%97%B4%E5%92%8C%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E8%AF%B4%E6%98%8E/"},{"content":"重要 环境说明 部署的external-dns包括以下组件:\nexternal-dns: k3s集群内部，kube-system命名空间 下载 etcd : k3s集群内部，paas命名空间 下载 coredns : k3s集群内部，paas命名空间 下载 external-dns 可以将ingress和external-service对象存储至etcd中，CoreDNS使用此etcd作为后端，解析所注册的服务。\n例如它解决了 registry，openldap、cassandra(headless) 、keycloak(loadbalancer) 这些服务的域名注册问题。\nexternal-dns可以通过设置coredns前缀,同时为不通的域名提供解析服务.\n部署 1. 部署 etcd 1.1 边缘使用local storage部署 在运行etcd的节点创建本地目录 1 mkdir \u0026#34;/opt/etcd-dns\u0026#34; 创建pv pv创建修改详情，参考etcd/chart/etcd-pv/README.md\n1 kubectl apply -f etcd/chart/etcd-pv/pv.yaml 部署etcd auth.rbac.enabled 设置为false, 不启用认证\nservice.type 设置为 LoadBalancer\nservice.loadBalancerIP 设置为\u0026quot;192.168.83.10\u0026quot;\npersistence.enable 设置为 true\npersistence.storageClass 设置为 paas-storage , 值与上一步创建pv时的sc一致\npersistence.size 设置为 8Gi , 值与上一步创建的pv大小一致\n1 helm install etcd etcd/chart/etcd -n paas 检测是否组成集群 1 etcdctl endpoint status --cluster -w table 2. 部署coredns 2.1 部署 chart配置说明 部署配置：\nservice.loadBalancerIP 设置dns服务的loadBalanceIP, 默认为 \u0026ldquo;192.168.83.5\u0026rdquo;\ncorefile相关配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 servers: - zones: - zone: . port: 53 plugins: # bugsize 由默认 512 设置为 1232 (loadBalance 只能代理TCP或UDP一种，此处coredns设置为UDP. # 为防止大数据记录数据超过512，走TCP协议,故将默认大小调大) - name: bufsize parameters: 1232 - name: errors # health 会启动一个监听 :8080/health 的服务 , 此chart中的 livenessProbe 检查此端口 - name: health configBlock: |- lameduck 5s # ready 会启动一个监听 :8181/ready 的服务 , 此chart中的 readinessProbe 检查此端口 - name: ready # # prometheus 会启动一个监听 :9153/metrics 的服务 , 此chart中的 serviceMonitor 检查此端口 - name: prometheus parameters: 0.0.0.0:9153 # 转发，配置上游DNS地址 - name: forward parameters: . 114.114.114.114 - name: log # 自定义 zone 配置，需要与下面 zonefile 对应 - name: file parameters: /etc/coredns/example.db deploy.org # adp租户 zone 配置， # 1. 设置 bufsize; 2. path 设置 /edge 取决与external-dns启动的设置，如果多个external-dns，则通过此处区分 # 2. endpoint 设置的地址为ETCD的LoadBalance IP和端口号 - zones: - zone: adp.icos.city port: 53 bufsize: 1232 plugins: - name: errors - name: log - name: etcd configBlock: |- path /edge endpoint http://192.168.83.10:2379 自定义zone配置\n1 2 3 4 5 6 7 zoneFiles: - filename: example.db domain: deploy.org contents: | deploy.org. IN SOA ns.deploy.org. root.deploy.org. 2015082541 7200 3600 1209600 3600 deploy.org. IN NS ns.deploy.org. license.deploy.org. IN TXT \u0026#34;QClDmn9IdX50gDN59UXNpb4oR733jsk05zLuCAkj0=\u0026#34; 部署 1 helm install coredns coredns/chart/coredns -n paas 3. 部署external-dns Deployment中的配置\nspec.template.spec.containers.[0].args\n--coredns-prefix=/edge/参数决定数据存储在etcd的目录前缀，此处不同可区分不同集群内的external-dns;\n而集群内部不同租户的服务，通过ingress中的租户名可以区分开\n部署\n1 kubectl apply -f external-dns.yaml 禁用节点DNS缓存 所有节点执行一下操作，注意IP地址设置正确\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 systemctl disable systemd-resolved systemctl stop systemd-resolved echo \u0026#39; network: bonds: bond0: addresses: - 192.168.82.11/23 gateway4: 192.168.82.1 interfaces: - ens3f0 - ens3f1 nameservers: addresses: - 192.168.83.5 search: [] parameters: mode: balance-rr ethernets: ens3f0: {} ens3f1: {} version: 2\u0026#39; \u0026gt; /etc/netplan/01-netcfg.yaml rm -rf /etc/resolv.conf echo \u0026#34;nameserver 192.168.83.5\u0026#34; \u0026gt; /etc/resolv.conf netplan apply 常用修改说明 license配置DNS-TXT记录说明 在zone为.的域的plugins参数增加name为file的参数，值为/etc/coredns/example.db deploy.org 1 2 3 4 5 6 7 servers: - zones: - zone: . port: 53 plugins: - name: file parameters: /etc/coredns/example.db deploy.org 在zoneFiles增加如下配置，license.deploy.org. IN TXT行的值为从QA获取的由私钥签名过的ou名Signature 1 2 3 4 5 6 7 zoneFiles: - filename: example.db domain: deploy.org contents: | deploy.org. IN SOA ns.deploy.org. root.deploy.org. 2015082541 7200 3600 1209600 3600 deploy.org. IN NS ns.deploy.org. license.deploy.org. IN TXT \u0026#34;QCUEsCx70xK2u9pdrm6y0hf4up8C9S44tvekF9LVODBPHbryRQGqh9dUyb8VcN11IlPXcl7hVdqC3qsIgYUo5/KBdNCX+edFYquOeKEyEfnkHRzoi8hjR6NIzOQoHh518EJClDmn9IdX50gDN59UXNpb4oR733jsk05zLuCAkj0=\u0026#34; 冒烟测试 集群中创建external-svc 1 2 3 4 5 6 7 8 9 10 11 12 echo \u0026#39; apiVersion: v1 kind: Service metadata: annotations: external-dns.alpha.kubernetes.io/hostname: reg.chebai.org name: reg-chebai-org namespace: paas spec: externalName: 10.90.0.11 type: ExternalName\u0026#39; \u0026gt; test-svc.yaml kubectl apply -f test-svc.yaml 检查 ETCD 中是否有正确写入的数据 1 2 etcdctl --prefix --keys-only=true get / # etcdctl --user=\u0026#34;root\u0026#34; --password=\u0026#34;OH4dQD4Cww\u0026#34; --prefix --keys-only=true get / 检查各个节点的测试数据域名解析 1.如果etcd中能查询到数据，但解析出错；则检查CoreDNS是否配置域adp.icos.city\n2.注意仔细看存储路径的prefix, 是否与CoreDNS中配置的保持一致\n1 nslookup reg.chebai.org \u0026lt;NODEIP\u0026gt; 或\n1 dig @192.168.83.5 reg.chebai.org Reference DNS相关 DNS之BIND使用小结(Forward转发)\nLinux系统解析域名的先后顺序files(/etc/hosts)OR dns(/etc/resolv.conf)\nresolv.conf(5) — Linux manual page\n/etc/resolv.conf 中的第二个nameserver未被 wget 拾取\n","description":"","id":36,"section":"posts","tags":["Kubernetes"],"title":"跨级群DNS方案-解析各集群ingress与custom-dns记录","uri":"https://hex-go.github.io/posts/kubernetes/2021-11-08-%E8%B7%A8%E7%BA%A7%E7%BE%A4dns%E6%96%B9%E6%A1%88-%E8%A7%A3%E6%9E%90%E5%90%84%E9%9B%86%E7%BE%A4ingress%E4%B8%8Ecustom-dns%E8%AE%B0%E5%BD%95/"},{"content":"重要 最重要的事:\n1.简介 seq: 序号，TCP连接中传送的字节流中的每个字节都按顺序编号。\nack: 确认号，是期望收到对方下一个报文的第一个数据字节的序号。\nSYN: 同步SYN，在连接建立时用来同步序号。当SYN=1，ACK=0，表明是连接请求报文，若同意连接，则响应报文中应该使SYN=1，ACK=1\nACK: 确认ACK，仅当ACK=1时，确认号字段才有效。TCP规定，在连接建立后所有报文的传输都必须把ACK置1；\nFIN: 终止FIN，用来释放连接。当FIN=1，表明此报文的发送方的数据已经发送完毕，并且要求释放；\n三次握手 过程：\nx= 随机生成序列号\ny= 随机生成序列号\n客户端[SYN_SENT ]\u0026mdash;-SYN=1,seq=x (请求连接)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt;[ ]服务端\n客户端[ ]\u0026lt;\u0026mdash;SYN=1,ACK=1,ack=x+1,seq=y(应答客户端SYN，并请求建立连接)\u0026ndash;\u0026gt;[SYN_RCVD ]服务端\n客户端[ESTABLISHED]\u0026ndash;ACK=1,ack=Y+1 (应答服务端SYN)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;[ESTABLISHED]服务端\n三次握手而非两次的原因：\n如果客户端发送请求连接-1，由于网络原因超时，客户端重试再次发出请求连接-2，此时正常建立连接并完成通信；\n之后网络回复请求连接-1再次送达服务端, 此时服务端响应的应答客户端SYN请求被返回客户端，此时客户端不会再\n发出应答服务端端SYN请求，server收不到确认请求，则不会建立连接。\n四次挥手 过程：\n断开过程由客户端或服务端任一方执行close来触发。TCP连接是全双工的，因此，每个方向都必须要单独进行关闭\nx=等于前面已经传送过来的数据的最后一个字节的序号加1\ny=自身序列号\nz=服务端释放的报文可能携带数据\n客户端[FIN_WAIT_1]\u0026mdash;-FIN=1,seq=x (client请求释放)\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;[ ]服务端\n客户端[FIN_WAIT_1]\u0026lt;\u0026mdash;ACK=1,ack=x+1,seq=y (释放确认报文)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;[CLOSE-WAIT ]服务端\n客户端[FIN_WAIT_2]\u0026lt;\u0026mdash;FIN=1,ACK=1,ack=y+1,seq=z (server请求释放)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;[LAST-ACK ]服务端\n客户端[TIME-WAIT ]\u0026mdash;-ACK=1,ack=z+1,seq=y+1 (最终释放确认报文)\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;[CLOSE ]服务端\n2∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。\n客户端[CLOSE]\n为什么客户端最后还要等待2MSL？\nMSL（Maximum Segment Lifetime）, 报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。\n第一，保证TCP协议的全双工连接能够可靠关闭保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，\n站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，\n应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，\n而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。\n第二，保证这次连接的重复数据段从网络中消失 防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。\n客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。\n这样新的连接中不会出现旧连接的请求报文。\n为什么建立连接是三次握手，关闭连接确是四次挥手呢？\n建立连接的时候，服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。\n而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，\n所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，\n因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。\nReference 两张动图-彻底明白TCP的三次握手与四次挥手\n","description":"","id":37,"section":"posts","tags":["计算机原理","面试","TCP"],"title":"TCP三次握手四次挥手备忘","uri":"https://hex-go.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/2021-11-05-tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E5%A4%87%E5%BF%98/"},{"content":"重要 最重要的事:\n1.简介 单向TLS加密\n流程： 浏览器 \u0026ndash;(request.明文)\u0026ndash;\u0026gt; 服务器 服务器 \u0026ndash;(response.明文)\u0026ndash;\u0026gt; 浏览器 服务器 \u0026ndash;(公钥.server)\u0026ndash;\u0026gt; 浏览器 浏览器 \u0026ndash;(request.密文-公钥加密)\u0026ndash;\u0026gt; 服务器 缺点：\n服务器发出的请求仍然是明文，即使用私钥加密，公钥是公开的，也相当于是明文 双向TLS加密\n流程： 浏览器 \u0026ndash;(request.明文)\u0026raquo;\u0026gt; 服务器 浏览器 \u0026laquo;(response.明文)\u0026ndash; 服务器 浏览器 \u0026laquo;(公钥.server)\u0026mdash;- 服务器 浏览器 \u0026ndash;(公钥.client)\u0026raquo;\u0026raquo; 服务器 浏览器 \u0026ndash;(request.密文-公钥.server加密)\u0026raquo;\u0026gt; 服务器 浏览器 \u0026laquo;(request.密文-公钥.client加密)\u0026mdash; 服务器 缺点：\n非对称机密给服务端和客户端性能带来巨大影响（加解密费时，费资源） 对称加密+非对称加密结合 随机数1= client random\n随机数2= server random\n随机数3= premaster secret\n流程：\n[ ]浏览器[随机数1 ] \u0026ndash;(随机数1.明文)\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt; [ ]服务器[私+公钥.server] [ ]浏览器[随机数1 ] \u0026laquo;(随机数2.明文)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- [随机数1+2 ]服务器[私+公钥.server] [ ]浏览器[随机数1+2 ] \u0026laquo;(公钥.server)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- [随机数1+2 ]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026ndash;(随机数3.密文-公钥.server加密)\u0026raquo;\u0026raquo; [随机数1+2 ]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026ndash;(finish.密文-随机数计算秘钥)\u0026raquo;\u0026raquo;\u0026raquo; [随机数1+2+3]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026laquo;(finish.密文-随机数计算秘钥)\u0026mdash;\u0026mdash; [随机数1+2+3]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026ndash;(request.密文-随机数计算秘钥)\u0026raquo;\u0026raquo;\u0026gt; [随机数1+2+3]服务器[私钥.server] [公钥.server]浏览器[随机数1+2+3] \u0026laquo;(response.密文-随机数计算秘钥)\u0026mdash;- [随机数1+2+3]服务器[私钥.server] 缺点：\n中间人攻击 数字证书 服务器上传公钥+名字 ca用这些信息计算hash,办法证书给服务器 服务器将证书发给浏览器验证 剩余证书签名、验证过程待完善\nReference 为了一个HTTPS，浏览器操碎了心\u0026hellip;\n","description":"","id":38,"section":"posts","tags":["计算机原理","面试","待完善"],"title":"Https流程说明","uri":"https://hex-go.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/2021-11-05-https%E6%B5%81%E7%A8%8B%E8%AF%B4%E6%98%8E/"},{"content":"重要 ChirpStack是一个开源的lora设备管理平台，其中ApplicationServer是设备管理页面，\n支持简单认证，也支持oauth2认证，但oauth2认证与正常的不太一样，可以简单总结为\n依靠sso做统一认证 本地数据库存储用户信息进行鉴权 优点： 依靠本地鉴权管理体系，更好跟local模式兼容。\n缺点： 无法统一在sso中进行权限分配。\nReference ","description":"","id":39,"section":"posts","tags":["Source Code"],"title":"ChirpStack-ApplicationServer[源码]-oidc认证流程","uri":"https://hex-go.github.io/posts/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/2021-03-01-chirpstack-applicationserver%E6%BA%90%E7%A0%81-oidc%E8%AE%A4%E8%AF%81%E6%B5%81%E7%A8%8B/"},{"content":"重要 入口函数 nuclio: pkg/processor/trigger/kafka/trigger.go k.consumerGroup.Consume函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func (k *kafka) Start(checkpoint functionconfig.Checkpoint) error { var err error k.consumerGroup, err = k.newConsumerGroup() if err != nil { return errors.Wrap(err, \u0026#34;Failed to create consumer\u0026#34;) } k.shutdownSignal = make(chan struct{}, 1) // start consumption in the background go func() { for { k.Logger.DebugWith(\u0026#34;Starting to consume from broker\u0026#34;, \u0026#34;topics\u0026#34;, k.configuration.Topics) // start consuming. this will exit without error if a rebalancing occurs err = k.consumerGroup.Consume(context.Background(), k.configuration.Topics, k) if err != nil { k.Logger.WarnWith(\u0026#34;Failed to consume from group, waiting before retrying\u0026#34;, \u0026#34;err\u0026#34;, errors.GetErrorStackString(err, 10)) time.Sleep(1 * time.Second) } else { k.Logger.DebugWith(\u0026#34;Consumer session closed (possibly due to a rebalance), re-creating\u0026#34;) } } }() return nil } sarama consume 函数sarama:consumer_group.go c.newSession函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 // Consume implements ConsumerGroup. func (c *consumerGroup) Consume(ctx context.Context, topics []string, handler ConsumerGroupHandler) error { // Ensure group is not closed select { case \u0026lt;-c.closed: return ErrClosedConsumerGroup default: } c.lock.Lock() defer c.lock.Unlock() // Quick exit when no topics are provided if len(topics) == 0 { return fmt.Errorf(\u0026#34;no topics provided\u0026#34;) } // Refresh metadata for requested topics if err := c.client.RefreshMetadata(topics...); err != nil { return err } // Init session sess, err := c.newSession(ctx, topics, handler, c.config.Consumer.Group.Rebalance.Retry.Max) if err == ErrClosedClient { return ErrClosedConsumerGroup } else if err != nil { return err } // loop check topic partition numbers changed // will trigger rebalance when any topic partitions number had changed go c.loopCheckPartitionNumbers(topics, sess) // Wait for session exit signal \u0026lt;-sess.ctx.Done() // Gracefully release session claims return sess.release(true) } 安装 使用 Reference ","description":"","id":40,"section":"posts","tags":["Source Code","Nuclio","待完善"],"title":"Nuclio[源码]-kafka-trigger流程","uri":"https://hex-go.github.io/posts/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/2021-02-23-nuclio%E6%BA%90%E7%A0%81-kafka-trigger/"},{"content":"重要 Kubernetes: 1.20.2\nPod 安全策略 1. 什么是PodSecurityPolicy？ Pod 安全策略（Pod Security Policy） 是集群级别的资源，它能够控制 Pod 规约 中与安全性相关的各个方面。 PodSecurityPolicy 对象定义了一组 Pod 运行时必须遵循的条件及相关字段的默认值，只有 Pod 满足这些条件 才会被系统接受。 Pod 安全策略允许管理员控制如下方面：\n2. 启用PodSecurityPolicy Pod 安全策略实现为一种可选（但是建议启用）的 准入控制器(admission-controllers)。 启用了准入控制器 即可强制实施 Pod 安全策略，不过如果没有授权认可策略之前即启用 准入控制器 将导致集群中无法创建任何 Pod。\n由于 Pod 安全策略 API（policy/v1beta1/podsecuritypolicy）是独立于准入控制器(admission-controllers)来启用的，对于现有集群而言，建议在启用准入控制器之前先添加策略并对其授权。\n3. 配置PodSecurityPolicy举例 3.1 创建PSP(PodSecurityPolicy) rke部署的集群会默认创建部分psp资源，比如default-psp\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 apiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: name: default-psp annotations: seccomp.security.alpha.kubernetes.io/allowedProfileNames: \u0026#39;*\u0026#39; spec: allowPrivilegeEscalation: true allowedCapabilities: - \u0026#39;*\u0026#39; fsGroup: rule: RunAsAny hostIPC: true hostNetwork: true hostPID: true hostPorts: - max: 65535 min: 0 privileged: true runAsUser: rule: RunAsAny seLinux: rule: RunAsAny supplementalGroups: rule: RunAsAny volumes: - \u0026#39;*\u0026#39; 3.2 RBAC授权 1 2 3 4 5 6 7 8 9 10 11 12 # 0. `default-psp`会在rke创建集群的时候自动创建 # 1. 创建role, 此角色可访问 `default-psp` 的psp # kubectl -n \u0026lt;namespace\u0026gt; create role \u0026lt;role-name\u0026gt; --verb=use --resource=podsecuritypolicy --resource-name=default-psp kubectl -n kube-ops create role psp:unprivileged --verb=use --resource=podsecuritypolicy --resource-name=default-psp # 2. 创建`rolebinding` # 在Namespace下会有一个默认账户`default` # Deployment创建的pod, 不指定`serviceAccountName`时，使用`default`账户，需要将`default`账户与创建的角色关联（特定用户声明参考Ingress-Nginx部署举例） # kubectl -n \u0026lt;Namespace\u0026gt; create rolebinding \u0026lt;Rolebinding-name\u0026gt; --role=\u0026lt;Role-name\u0026gt; --serviceaccount=\u0026lt;Namespace\u0026gt;:\u0026lt;ServiceAccount\u0026gt; kubectl -n kube-ops create rolebinding default:psp:unprivileged --role=psp:unprivileged --serviceaccount=kube-ops:default 3.3 创建Deployment 1 2 3 4 5 6 7 8 # 创建Deployment测试，一切正常 # kubectl create deployment \u0026lt;Deployment-name\u0026gt; --image=\u0026lt;ImagePath\u0026gt; -n \u0026lt;Namespace\u0026gt; kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 -n kube-ops # 查看，pod正常创建 root@hex-0001:~/# kubectl get pod -n kube-ops NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-57978f5f5d-dbkcm 0/1 ContainerCreating 0 12s 3.4 调试方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 创建失败时通过`Deployment`和`event`查看状态 # 1. describe Deployment root@lab-rke-hex-0001:~/bkp# kubectl describe deployment kubernetes-bootcamp -n kube-ops Name: kubernetes-bootcamp Namespace: kube-ops Selector: app=kubernetes-bootcamp Replicas: 1 desired | 0 updated | 0 total | 0 available | 1 unavailable StrategyType: RollingUpdate RollingUpdateStrategy: 25% max unavailable, 25% max surge Pod Template: Labels: app=kubernetes-bootcamp Containers: kubernetes-bootcamp: Image: gcr.io/google-samples/kubernetes-bootcamp:v1 Volumes: \u0026lt;none\u0026gt; Conditions: Type Status Reason ---- ------ ------ Progressing True NewReplicaSetCreated Available False MinimumReplicasUnavailable ReplicaFailure True FailedCreate OldReplicaSets: \u0026lt;none\u0026gt; NewReplicaSet: kubernetes-bootcamp-57978f5f5d (0/1 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 25s deployment-controller Scaled up replica set kubernetes-bootcamp-57978f5f5d to 1 # 2. get event root@lab-rke-hex-0001:~/bkp# kubectl get event -n kube-ops LAST SEEN TYPE REASON OBJECT MESSAGE 3m11s Warning FailedCreate replicaset/kubernetes-bootcamp-57978f5f5d Error creating: pods \u0026#34;kubernetes-bootcamp-57978f5f5d-\u0026#34; is forbidden: PodSecurityPolicy: unable to admit pod: [] 8m39s Normal ScalingReplicaSet deployment/kubernetes-bootcamp Scaled up replica set kubernetes-bootcamp-57978f5f5d to 1 4. IngressNginx部署举例 serviceAccount: ingress-nginx-admission 创建job:ingress-nginx-admission-patch和job: ingress-nginx-admission-create等 serviceAccount: ingress-nginx 创建Deployment:ingress-nginx-controller 所以需要将PodSecurityPolicy: default-psp给到两个账户serviceAccount: ingress-nginx和serviceAccount: ingress-nginx-admission\n操作如下：\n4.1 关联 PodSecurityPolicy: default-psp与serviceAccount: ingress-nginx Deployment中声明的serviceAccount如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: apps/v1 kind: Deployment metadata: labels: app.kubernetes.io/name: ingress-nginx name: ingress-nginx-controller spec: template: metadata: name: ingress-nginx-admission-create labels: app.kubernetes.io/name: ingress-nginx spec: containers: - name: create image: reg.chebai.org/kubernetes-ingress-controller/kube-webhook-certgen:v1.0.0 serviceAccountName: ingress-nginx-admission 创建rbac, 关联ServiceAccount与PodSecurityPolicy。\n1 2 3 4 5 6 7 8 9 10 # 0. `default-psp`会在rke部署集群的时候自动创建 # 1. 创建role `psp:unprivileged`, 此角色可访问psp `default-psp` # kubectl -n \u0026lt;namespace\u0026gt; create role \u0026lt;role-name\u0026gt; --verb=use --resource=podsecuritypolicy --resource-name=default-psp kubectl -n ingress-nginx create role psp:unprivileged --verb=use --resource=podsecuritypolicy --resource-name=default-psp # 2. 创建rolebinding `ingress-nginx:psp:unprivileged` # ingressNginx的Deployment创建的pod时，指定`serviceAccountName`为`ingress-nginx`。需要将`ingress-nginx`账户与创建的角色关联 # kubectl -n \u0026lt;Namespace\u0026gt; create rolebinding \u0026lt;Rolebinding-name\u0026gt; --role=\u0026lt;Role-name\u0026gt; --serviceaccount=\u0026lt;Namespace\u0026gt;:\u0026lt;ServiceAccount\u0026gt; kubectl -n ingress-nginx create rolebinding ingress-nginx:psp:unprivileged --role=psp:unprivileged --serviceaccount=ingress-nginx:ingress-nginx 4.2 关联 PodSecurityPolicy: default-psp与serviceAccount: ingress-nginx Job中声明的serviceAccount如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 apiVersion: batch/v1 kind: Job metadata: name: ingress-nginx-admission-patch annotations: \u0026#34;helm.sh/hook\u0026#34;: post-install,post-upgrade \u0026#34;helm.sh/hook-delete-policy\u0026#34;: before-hook-creation,hook-succeeded labels: app.kubernetes.io/name: ingress-nginx spec: template: metadata: name: ingress-nginx-admission-patch labels: app.kubernetes.io/name: ingress-nginx spec: containers: - name: patch image: reg.chebai.org/kubernetes-ingress-controller/kube-webhook-certgen:v1.0.0 serviceAccountName: ingress-nginx-admission 创建rbac, 关联ServiceAccount与PodSecurityPolicy。\n1 2 3 4 5 6 7 8 # 0. `default-psp`会在rke部署集群的时候自动创建 # 1. `psp:unprivileged`在上一步已创建 # 2. 创建rolebinding `ingress-nginx-admission:psp:unprivileged` # ingressNginx的Job创建的pod时，指定`serviceAccountName`为`ingress-nginx-admission`。需要将`ingress-nginx-admission`账户与创建的角色关联 # kubectl -n \u0026lt;Namespace\u0026gt; create rolebinding \u0026lt;Rolebinding-name\u0026gt; --role=\u0026lt;Role-name\u0026gt; --serviceaccount=\u0026lt;Namespace\u0026gt;:\u0026lt;ServiceAccount\u0026gt; kubectl -n ingress-nginx create rolebinding ingress-nginx-admission:psp:unprivileged --role=psp:unprivileged --serviceaccount=ingress-nginx:ingress-nginx-admission 4.2 helm 部署ingress-nginx 1 helm install ingress-nginx ingress-nginx/ -n ingress-nginx Reference Pod 安全策略\n","description":"","id":41,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes[PodSecurityPolicy]-使用说明","uri":"https://hex-go.github.io/posts/kubernetes/2021-02-18-kubernetespodsecuritypolicy-%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"},{"content":"重要 Kubernetes API弃用策略\nKubernetes 升级， 主要的API变化在v1.16\\v1., 具体说明如下：\nv1.16 变化\nv1.16版本将停止提供以下不推荐使用的API版本，而支持更新和更稳定的API版本：\nNetworkPolicy资源: 由extensions/v1beta1迁移至v1.8以来可用的networking.k8s.io/v1API。 PodSecurityPolicy资源: 由extensions/v1beta1迁移至v1.10以来可用的policy/v1beta1API。 DaemonSet资源: 由extensions/v1beta1和apps/v1beta2迁移至v1.9以来可用的apps/v1API。 spec.templateGeneration字段被删除。 spec.selector为必填项, 且在创建后是不变的。使用现有的tmplate labels作为selector无缝升级 spec.updateStrategy.type默认值为RollingUpdate（extensions/v1beta1默认值为OnDelete) Deployment资源: 由extensions/v1beta1 apps/v1beta1 apps/v1beta2迁移至v1.9以来可用的apps/v1API。 spec.rollbackTo字段被删除 spec.selector为必填项, 且在创建后是不变的。使用现有的tmplate labels作为selector无缝升级 spec.progressDeadlineSeconds默认值为600s(extensions/v1beta1默认值没有截止日期） spec.revisionHistoryLimit默认值为10(apps/v1beta1默认值为2，extensions/v1beta1中默认值为保留所有) maxSurge和maxUnavailable默认值为25％(extensions/v1beta1默认值为1) Statefulset资源: 由apps/v1beta1和apps/v1beta2迁移至v1.9以来可用的apps/v1API。 spec.selector为必填项, 且在创建后是不变的。使用现有的tmplate labels作为selector无缝升级 spec.updateStrategy.type默认值为RollingUpdate（extensions/v1beta1默认值为OnDelete) ReplicaSet资源: 由extensions/v1beta1 apps/v1beta1 apps/v1beta2迁移至v1.9以来可用的apps/v1API。 spec.selector为必填项, 且在创建后是不变的。使用现有的tmplate labels作为selector无缝升级 v1.22变化\nMutatingWebhookConfiguration和ValidatingWebhookConfiguration资源: 由admissionregistration.k8s.io/v1beta1迁移至v1.16以来可用的admissionregistration.k8s.io/v1 API\nwebhooks[*].failurePolicy 默认值 from Ignore to Fail webhooks[*].matchPolicy 默认值 from Exact to Equivalent webhooks[*].timeoutSeconds 默认值 from 30s to 10s webhooks[*].sideEffects 变为必填项 oneof None and NoneOnDryRun webhooks[*].admissionReviewVersions 变为必填项 webhooks[*].name 名称必须唯一 CustomResourceDefinition资源: 由apiextensions.k8s.io/v1beta1 迁移至v1.16以来可用的apiextensions.k8s.io/v1API。\nspec.scope 去除默认值 Namespaced，变为必须指定。 spec.version 去除，由 spec.versions 替换。 spec.validation 去除，由spec.versions[*].schema 替换。 spec.subresources 去除，由spec.versions[*].subresources 替换。 spec.additionalPrinterColumns 去除，由spec.versions[*].additionalPrinterColumns 替换。 spec.conversion.webhookClientConfig迁移至spec.conversion.webhook.clientConfig。 spec.conversion.conversionReviewVersions迁移至spec.conversion.webhook.conversionReviewVersions spec.versions[*].schema.openAPIV3Schema 为必填项, 并且必须为结构化schema。 spec.preserveUnknownFields: true 不被允许，必须通过schema中指定 x-kubernetes-preserve-unknown-fields: true additionalPrinterColumns 中, JSONPath 字段改为jsonPath (fixes #66531) APIService资源: 由apiregistration.k8s.io/v1beta1 迁移至v1.10以来可用的apiregistration.k8s.io/v1API。\nTokenReview资源: 由authentication.k8s.io/v1beta1 迁移至v1.6以来可用的authentication.k8s.io/v1API。\nLocalSubjectAccessReview、SelfSubjectAccessReview、SubjectAccessReview\n由authentication.k8s.io/v1beta1 迁移至v1.6以来可用的authentication.k8s.io/v1API。\nspec.group字段重命名为spec.groups(fix #32709) CertificateSigningRequest资源: 由certificates.k8s.io/v1beta1 迁移至v1.19以来可用的certificates.k8s.io/v1API。\n请求证书： spec.signerName为必填项(请参阅Kubernetes signers), 并且不允许通过。certificate.k8s.io/v1API创建对kubernetes.io/legacy-unknown的请求。 spec.usages为必填项、不可重复，并且只能包含已知用法。 颁发证书： status.condition不可重复。 status.conditions[*].status为必填项。 status.certificate 必须为PEM-encoded, 并且仅包含CERTIFICATE 块。 Lease资源: 由coordination.k8s.io/v1beta1 迁移至v1.14以来可用的coordination.k8s.io/v1API。\nIngress资源: 由extensions/v1beta1迁移至v1.19以来可用的networking.k8s.io/v1beta1API。\nspec.backend 字段名变为 spec.defaultBackend spec.rules[*].http.paths[*].backend.serviceName 字段变为 spec.rules[*].http.paths[*].backend.service.name spec.rules[*].http.paths[*].backend.servicePort 字段，值为数字变为 spec.rules[*].http.paths[*].backend.service.port.number spec.rules[*].http.paths[*].backend.servicePort 字段，值为字符串变为 spec.rules[*].http.paths[*].backend.service.port.name spec.rules[*].http.paths[*].pathType 为必填项，oneofPrefix, Exact, and ImplementationSpecific. ImplementationSpecific用来对应v1beta1. spec.rules[*].http.paths[*].backend.path为必填项，匹配所有路径值设置为/。 IngressClass资源: 由networking.k8s.io/v1beta1迁移至v1.19以来可用的networking.k8s.io/v1API。\nClusterRole, ClusterRoleBinding, Role, and RoleBinding 资源由rbac.authorization.k8s.io/v1beta1迁移至v1.8以来可用的rbac.authorization.k8s.io/v1API\nPriorityClass资源由scheduling.k8s.io/v1beta1迁移至v1.14以来可用的scheduling.k8s.io/v1API\nCSIDriver, CSINode, StorageClass, and VolumeAttachment 资源由storage.k8s.io/v1beta1迁移至storage.k8s.io/v1API\nCSIDriver在v1.19可用 CSINode在v1.17可用 StorageClass在v1.6可用 VolumeAttachment在v1.13可用 1.25变化\nEvent资源: 由events.k8s.io/v1beta1迁移至v1.19以来可用的events.k8s.io/v1API\ntype 仅限于 Normal 、 Warning involvedObject 被重命名为 regarding action, reason, reportingComponent, and reportingInstance 为必填项 eventTime 替换废弃的字段firstTimestamp series.lastObservedTime 替换废弃的字段lastTimestamp series.count 替换废弃的字段count reportingComponent 替换废弃的字段source.component reportingInstance 替换废弃的字段source.host RuntimeClass资源: 由node.k8s.io/v1beta1迁移至v1.20以来可用的node.k8s.io/v1API\nReference Kubernetes API弃用策略\n启用API迁移指南\n","description":"","id":42,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes[Release]-弃用API迁移说明(持续更新)","uri":"https://hex-go.github.io/posts/kubernetes/2021-02-18-kubernetesrelease-%E5%BC%83%E7%94%A8api%E8%BF%81%E7%A7%BB%E8%AF%B4%E6%98%8E/"},{"content":"重要 最重要的事: 主机换风扇，想尝试不装cpu散热使用。结果温度巨高。cpu使用率长时间标满（估计差一点就要断电保护了）。\n想查看温度，记录一下。\n1.简介 使用GUI工具Psensor，它允许你在Linux中监控硬件温度。用Psensor你可以：\n监控cpu和主板的温度 监控NVidia GPU的文档 监控硬盘的温度 监控风扇的速度 监控CPU的利用率 Psensor最新的版本同样提供了Ubuntu中的指示小程序，这样使得在Ubuntu中监控温度变得更加容易。你可以选择在面板的右上角显示温度。它还会在温度上过阈值后通知\n2. 安装 在安装Psensor前，你需要安装和配置lm-sensors，这是一个用于硬件监控的命令行工具。如果你想要测量磁盘温度，你还需要安装hddtemp。要安装这些工具，运行下面的这些命令:\n1 sudo apt-get install lm-sensors hddtemp 安装Psensor：\n1 sudo apt-get install psensor 3. 配置 在面板显示温度 1 # 启动 点击psensor, 进入Sensor Preferences. 在Application Indicator菜单下，选择你想要显示温度的组件并勾上Display sensor in the label选项。\n设置开机自启 进入Preferences-\u0026gt;Startup并选择Launch on session startup使每次启动时启动Psensor。\nReference pensor\n","description":"","id":43,"section":"posts","tags":["个人工具","Ubuntu"],"title":"Ubuntu--18.04-安装cpu温度显示工具","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2021-02-04-ubuntu18.04_%E5%AE%89%E8%A3%85cpu%E6%B8%A9%E5%BA%A6%E6%98%BE%E7%A4%BA%E5%B7%A5%E5%85%B7/"},{"content":"重要 阅读nuclio源码，分析nuclio平台中java由源码到服务启动的全过程。\n环境说明 nuclio: 1.4.17\nkubernetes: 1.15.3\n源码： 构建过程 有nuctl的build command往下查看调用\npkg/nuctl/command/build.go文件下，newBuildCommandeer函数内部调用了rootCommandeer.platform.CreateFunctionBuild\n走platform接口pkg/platform/platform.go，因为platform类型为kube，所以调用pkg/platform/kube/platform.go。\n其中kube的NewPlatform继承了pkg/platform/abstract/platform.go的实例，CreateFunctionBuild就在abstract/中具体定义的。\npkg/platform/abstract/platform.go文件下，CreateFunctionBuild函数内部，实例化了一个builder，并执行builder.Build函数。\npkg/processor/build/builder.go文件下：\nBuild 函数调用buildProcessorImage函数\nbuildProcessorImage 函数调用createProcessorDockerfile函数\ncreateProcessorDockerfile 函数调用getRuntimeProcessorDockerfileInfo函数\ngetRuntimeProcessorDockerfileInfo 函数调用resolveProcessorDockerfileInfo函数\nresolveProcessorDockerfileInfo 函数调用runtime.GetProcessorDockerfileInfo函数\n走runtime接口pkg/processor/build/runtime/runtime.go，\n因为runtime类型为java，所以调用pkg/processor/build/runtime/java/runtime.go。\npkg/processor/build/runtime/java/runtime.go中，有具体的GetProcessorDockerfileInfo定义（包含onbuild信息）。 resolveProcessorDockerfileInfo 函数调用GenerateDockerfileContents函数\nGenerateDockerfileContents 函数调用platform.GetOnbuildStages函数\nplatform接口pkg/platform/platform.go，GetOnbuildStages 具体定义在 pkg/platform/abstract/platform.go。\npkg/platform/abstract/platform.go文件下：\nGetOnbuildStages 函数内部调用ContainerBuilder.GetOnbuildStages函数。\nBuilderPusher接口pkg/containerimagebuilderpusher/containerimagebuilder.go，\n因为kind为kaniko，所以调用pkg/containerimagebuilderpusher/kaniko.go\npkg/containerimagebuilderpusher/kaniko.go文件下：\nGetOnbuildStages函数主要做以下操作\n将onbuildArtifacts转换为\u0026quot;FROM %s(artifact.Image) AS %s(artifact.Name)\u0026quot; \\n ARG NUCLIO_LABEL \\n ARG NUCLIO_ARCH\nGenerateDockerfileContents 函数调用platform.TransformOnbuildArtifactPaths函数\nplatform接口pkg/platform/platform.go，GetOnbuildStages 具体定义在 pkg/platform/abstract/platform.go。\nTransformOnbuildArtifactPaths 函数内部调用ContainerBuilder.GetOnbuildStages函数。\nBuilderPusher接口pkg/containerimagebuilderpusher/containerimagebuilder.go，\nTransformOnbuildArtifactPaths 具体定义在 pkg/containerimagebuilderpusher/kaniko.go\npkg/containerimagebuilderpusher/kaniko.go文件下：\nTransformOnbuildArtifactPaths 函数主要做以下操作\n将onbuildArtifacts转换为--from=%s(artifact.Name) %s(artifat.Path[x]) 从后向前推，构建function函数最终镜像的Dockerfile在pkg/processor/build/builder.go, 函数GenerateDockerfileContents。\n内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 // GenerateDockerfileContents return function docker file func (b *Builder) GenerateDockerfileContents(baseImage string, onbuildArtifacts []runtime.Artifact, imageArtifactPaths map[string]string, directives map[string][]functionconfig.Directive, healthCheckRequired bool) (string, error) { // now that all artifacts are in the artifacts directory, we can craft a Dockerfile dockerfileTemplateContents := `# Multistage builds {{ range $onbuildStage := .OnbuildStages }} {{ $onbuildStage }} {{ end }} # From the base image FROM {{ .BaseImage }} # Old(er) Docker support - must use all build args ARG NUCLIO_LABEL ARG NUCLIO_ARCH ARG NUCLIO_BUILD_LOCAL_HANDLER_DIR {{ if .PreCopyDirectives }} # Run the pre-copy directives {{ range $directive := .PreCopyDirectives }} {{ $directive.Kind }} {{ $directive.Value }} {{ end }} {{ end }} # Copy required objects from the suppliers {{ range $localArtifactPath, $imageArtifactPath := .OnbuildArtifactPaths }} COPY {{ $localArtifactPath }} {{ $imageArtifactPath }} {{ end }} {{ range $localArtifactPath, $imageArtifactPath := .ImageArtifactPaths }} COPY {{ $localArtifactPath }} {{ $imageArtifactPath }} {{ end }} {{ if .HealthcheckRequired }} # Readiness probe HEALTHCHECK --interval=1s --timeout=3s CMD /usr/local/bin/uhttpc --url http://127.0.0.1:8082/ready || exit 1 {{ end }} # Run the post-copy directives {{ range $directive := .PostCopyDirectives }} {{ $directive.Kind }} {{ $directive.Value }} {{ end }} # Run processor with configuration and platform configuration CMD [ \u0026#34;processor\u0026#34; ] ` onbuildStages, err := b.platform.GetOnbuildStages(onbuildArtifacts) if err != nil { return \u0026#34;\u0026#34;, errors.Wrap(err, \u0026#34;Failed to transform retrieve onbuild stages\u0026#34;) } // Transform `onbuildArtifactPaths` depending on the builder being used onbuildArtifactPaths, err := b.platform.TransformOnbuildArtifactPaths(onbuildArtifacts) if err != nil { return \u0026#34;\u0026#34;, errors.Wrap(err, \u0026#34;Failed to transform onbuildArtifactPaths\u0026#34;) } dockerfileTemplate, err := template.New(\u0026#34;singleStageDockerfile\u0026#34;). Parse(dockerfileTemplateContents) if err != nil { return \u0026#34;\u0026#34;, errors.Wrap(err, \u0026#34;Failed to create onbuildImage template\u0026#34;) } var dockerfileTemplateBuffer bytes.Buffer err = dockerfileTemplate.Execute(\u0026amp;dockerfileTemplateBuffer, \u0026amp;map[string]interface{}{ \u0026#34;BaseImage\u0026#34;: baseImage, \u0026#34;OnbuildStages\u0026#34;: onbuildStages, \u0026#34;OnbuildArtifactPaths\u0026#34;: onbuildArtifactPaths, \u0026#34;ImageArtifactPaths\u0026#34;: imageArtifactPaths, \u0026#34;PreCopyDirectives\u0026#34;: directives[\u0026#34;preCopy\u0026#34;], \u0026#34;PostCopyDirectives\u0026#34;: directives[\u0026#34;postCopy\u0026#34;], \u0026#34;HealthcheckRequired\u0026#34;: healthCheckRequired, }) if err != nil { return \u0026#34;\u0026#34;, errors.Wrap(err, \u0026#34;Failed to run template\u0026#34;) } dockerfileContents := dockerfileTemplateBuffer.String() return dockerfileContents, nil } b.platform.GetOnbuildStages(onbuildArtifacts)调用了platform接口下的功能。\nplatform说明如下:\npkg\\platform\\platform.go中定义接口 pkg\\platform\\types.go中定义数据结构 pkg\\platform\\factory\\factory.go为工厂函数，根据platform参数 local： 调用pkg\\platform\\local\\platform.go中的NewPlatform创建platform 实例 kube： 调用pkg\\platform\\kube\\platform.go中的NewPlatform创建platform 实例 pkg\\platform\\abstract\\platform.go为具体创建platform实例的。被local和kube下的NewPlatform调用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 pkg/platform ├── abstract │ ├── platform.go ├── config │ └── types.go ├── errors.go ├── factory │ └── factory.go ├── kube │ ├── platform.go │ ├── types.go ├── local │ ├── platform.go │ └── types.go ├── platform.go └── types.go 根据上面说明，函数执行了kube/下的platform.go，之后调用abstract/platform.go下的\n函数GetProcessorDockerfileInfo, pkg/processor/build/runtime/目录下，java/runtime.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (j *java) GetProcessorDockerfileInfo(onbuildImageRegistry string) (*runtime.ProcessorDockerfileInfo, error) { processorDockerfileInfo := runtime.ProcessorDockerfileInfo{} processorDockerfileInfo.BaseImage = \u0026#34;openjdk:9-jre-slim\u0026#34; // fill onbuild artifact artifact := runtime.Artifact{ Name: \u0026#34;java-onbuild\u0026#34;, Image: fmt.Sprintf(\u0026#34;%s/nuclio/handler-builder-java-onbuild:%s-%s\u0026#34;, onbuildImageRegistry, j.VersionInfo.Label, j.VersionInfo.Arch), Paths: map[string]string{ \u0026#34;/home/gradle/bin/processor\u0026#34;: \u0026#34;/usr/local/bin/processor\u0026#34;, \u0026#34;/home/gradle/src/wrapper/build/libs/nuclio-java-wrapper.jar\u0026#34;: \u0026#34;/opt/nuclio/nuclio-java-wrapper.jar\u0026#34;, }, } processorDockerfileInfo.OnbuildArtifacts = []runtime.Artifact{artifact} return \u0026amp;processorDockerfileInfo, nil } 调用关系\ncreateProcessorDockerfile: 调用 getRuntimeProcessorDockerfileInfo函数，生成content和DockerfilePath getRuntimeProcessorDockerfileInfo函数: 调用resolveProcessorDockerfileInfo函数收集processor的dockerfile信息 获取用户输入的指令FunctionConfig.Spec.Build.Directives，如果设置了command参数，则获取FunctionConfig.Spec.Build.Commands转换为指令并与构建过程的合并。 调用GenerateDockerfileContents函数，将第一步获取的内容转换为DockerfileContent。 resolveProcessorDockerfileInfo函数： 调用GetProcessorDockerfileInfo函数，获取默认的runtime。 调用getProcessorDockerfileBaseImage函数，a. 第一优先级FunctionConfig.Spec.Build.BaseImage；b. GetProcessorDockerfileInfo函数中格式为fmt.Sprintf(\u0026quot;%s/nuclio/handler-builder-java-onbuild:%s-%s\u0026quot;。 调用函数renderDependantImageURL 调用函数getProcessorDockerfileOnbuildImage 增加health-check组件 GetProcessorDockerfileInfo函数(meige)： 指定BaseImage和OnbuildArtifacts，其中OnbuildArtifacts包含onbuildImage和path。 GetProcessorDockerfileInfo -\u0026gt; resolveProcessorDockerfileInfo -\u0026gt; getRuntimeProcessorDockerfileInfo -\u0026gt; createProcessorDockerfile\n源码： 部署过程 Reference nuclio github\n","description":"","id":44,"section":"posts","tags":["Source Code","Nuclio","待完善"],"title":"Nuclio[源码]-java构建部署流程","uri":"https://hex-go.github.io/posts/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/2021-02-02-nuclio%E6%BA%90%E7%A0%81-java%E6%9E%84%E5%BB%BA%E9%83%A8%E7%BD%B2%E6%B5%81%E7%A8%8B/"},{"content":"重要 配置 Deployment中配置举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 spec: selector: matchLabels: app: {{ template \u0026#34;common.name\u0026#34; . }} replicas: {{ .Values.deploymentReplicas }} template: metadata: name: {{ template \u0026#34;common.name\u0026#34; . }} annotations: container.security.alpha.kubernetes.io/{{- template \u0026#34;common.name\u0026#34; . -}}: \u0026#34;runtime/default\u0026#34; labels: app: {{ template \u0026#34;common.name\u0026#34; . }} release: \u0026#34;{{ .Release.Name }}\u0026#34; spec: containers: {{- if .Values.filebeatSidecar }} - name: filebeat image: {{ $.Values.filebeat.image | quote }} volumeMounts: - name: log-data mountPath: /var/logs/app {{- if .Values.configMapEnable }} {{- range $i,$map := .Values.configMapList }} - name: {{ $map.name }} mountPath: {{ $map.mountPath | quote }} {{- if $map.subPath }} subPath: {{ $map.subPath }} {{- end }} {{- end }} {{- end }} {{- end }} - name: {{ template \u0026#34;common.containers.name\u0026#34; . }} image: \u0026#34;{{ .Values.global.imageRepositoryName }}/{{ .Values.imageRepository }}:{{.Chart.AppVersion}}\u0026#34; imagePullPolicy: {{ .Values.imagePullPolicy | quote }} Reference ","description":"","id":45,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes-使用sidecar配置filebeat收集容器日志","uri":"https://hex-go.github.io/posts/kubernetes/2021-01-27-kubernetes-%E4%BD%BF%E7%94%A8sidecar%E9%85%8D%E7%BD%AEfilebeat%E6%94%B6%E9%9B%86%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97/"},{"content":"重要 配置 Deployment中配置举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 spec: selector: matchLabels: app: {{ template \u0026#34;common.name\u0026#34; . }} replicas: {{ .Values.deploymentReplicas }} template: metadata: name: {{ template \u0026#34;common.name\u0026#34; . }} annotations: container.security.alpha.kubernetes.io/{{- template \u0026#34;common.name\u0026#34; . -}}: \u0026#34;runtime/default\u0026#34; labels: app: {{ template \u0026#34;common.name\u0026#34; . }} release: \u0026#34;{{ .Release.Name }}\u0026#34; spec: {{- if .Values.persistenceEnabled}} initContainers: - name: volume-permissions image: reg.chebai.org/paas/busybox:latest command: [\u0026#39;sh\u0026#39;, \u0026#39;-c\u0026#39;, \u0026#39;chmod -R 777 {{ .Values.volumeMounts.mountPath | quote }}\u0026#39;] volumeMounts: - mountPath: {{ .Values.volumeMounts.mountPath | quote }} name: {{ $.Values.serviceName }}-nfs {{- end }} Reference ","description":"","id":46,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes-使用初始化容器修改挂卷的权限","uri":"https://hex-go.github.io/posts/kubernetes/2021-01-27-kubernetes-%E4%BD%BF%E7%94%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%B9%E5%99%A8%E4%BF%AE%E6%94%B9%E6%8C%82%E5%8D%B7%E7%9A%84%E6%9D%83%E9%99%90/"},{"content":"重要 最重要的事:\n1.简介 华为云上s3使用手册\nReference AWS-使用authorization-header进行认证\nAWS-获取对象API\n","description":"","id":47,"section":"posts","tags":["Persistence"],"title":"S3-使用手册","uri":"https://hex-go.github.io/posts/persistence/2021-01-27-s3-%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/"},{"content":"重要 内网搭建nexus, 供nuclio构建go语言服务使用。\n由于go-proxy不支持认证，必须nexus启用匿名访问。\ngo1.14之后，引入sumdb验证。这个校验的概念是所有公共的包都会在官方的sumdb中存有一份校验值，以防止一些恶意劫持篡改的情况发生。\n但官方的sumdb地址为sum.golang.org(需要翻墙)，构建时连到这个地址去校验包会超时。\n配置 1. sumdb超时问题 配置国内sumdb库，export GOSUMDB=\u0026quot;sum.golang.google.cn\u0026quot;\n构建过程需要连接外网。\n关闭sumdb校验，export GOSUMDB=off\n不推荐，sumdb校验对安全来说，还是比较重要。\n2. GOPRIVATE跳过私有库 `go env -w GOPRIVATE=*.gitlab.com,*.gitee.com` 后续 由于nexus比较重，使用其搭建私仓又必需启用匿名访问。所以后期可以研究goproxy搭建私仓。\nGit-Hub goproxy\n搭建私有goproxy\nathens 搭建golang私有仓库\nReference Blog-go1.12与1.14之私服使用的差异与变化\nNexus-Document go repositories\n","description":"","id":48,"section":"posts","tags":["Persistence"],"title":"Nexus-搭建go私仓内网使用.md","uri":"https://hex-go.github.io/posts/persistence/2021-01-27-nexus-%E6%90%AD%E5%BB%BAgo%E7%A7%81%E4%BB%93%E5%86%85%E7%BD%91%E4%BD%BF%E7%94%A8.md/"},{"content":"重要 最重要的事: 通过postman的tests模块解析jwt，从而在Console查看claim的值。\n配置 在请求access-token的请求中，添加Tests脚本。请求示例如下\n1 2 3 4 5 6 7 curl --location --request POST \u0026#39;https://sso.icos.city/auth/realms/icos/protocol/openid-connect/token\u0026#39; \\ --header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ --data-urlencode \u0026#39;grant_type=password\u0026#39; \\ --data-urlencode \u0026#39;username=hexiang\u0026#39; \\ --data-urlencode \u0026#39;password=xxxxxx\u0026#39; \\ --data-urlencode \u0026#39;client_id=\u0026lt;client-id\u0026gt;\u0026#39; \\ --data-urlencode \u0026#39;client_secret=\u0026lt;client-secret\u0026gt;\u0026#39; 增加的Test脚本如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 let jsonData = pm.response.json(); // use whatever key in the response contains the jwt you want to look into. This example is using access_token let jwtContents = jwt_decode(jsonData.access_token); // Now you can set a postman variable with the value of a claim in the JWT pm.variable.set(\u0026#34;someClaim\u0026#34;, jwtContents.payload.someClaim); function jwt_decode(jwt) { var parts = jwt.split(\u0026#39;.\u0026#39;); // header, payload, signature let tokenContents={}; tokenContents.header = JSON.parse(atob(parts[0])); tokenContents.payload = JSON.parse(atob(parts[1])); tokenContents.signature = atob(parts[2]); // this just lets you see the jwt contents in the postman console. console.log(\u0026#34;Token Contents:\\n\u0026#34; + JSON.stringify(tokenContents, null, 2)); return tokenContents; } Reference Issue - 在Tests中解析jwt并显示claim\nStack Overflow - 在Tests中解析jwt并修改claim值\nStack Exchange - decoding-jwt-and-testing-results-in-postman\nPostman 文档 - Write Tests\n","description":"","id":49,"section":"posts","tags":["个人工具","Postman"],"title":"Postman使用Test解析jwt验证claim","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2021-01-27-postman%E4%BD%BF%E7%94%A8test%E8%A7%A3%E6%9E%90jwt%E9%AA%8C%E8%AF%81claim/"},{"content":"重要 最重要的事: PostgreSQL已安装postgis插件，给开发提供服务时，创建了数据库，并创建新的用户，用户只有关联数据库的所有权限。导致出现如下报错\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 登录 postgresql 客户端 psql -h \u0026#34;\u0026lt;PostgreSQL-Host|NoPort\u0026gt;\u0026#34; -U \u0026#34;\u0026lt;PostgreSQL-User\u0026gt;\u0026#34; -d \u0026#34;\u0026lt;PostgreSQL-Database\u0026gt;\u0026#34; # 查看支持的数据库类型, 未发现postgis支持的类型 \u0026gt; \\dT List of data types Schema | Name | Description --------+---------------+----------------------------------------------------------------------------------------- public | agg_count | public | box2df | public | gidx | public | spheroid | public | valid_detail | # 查看此数据库支持的插件 \u0026gt;\\dx List of installed extensions Name | Version | Schema | Description ---------+---------+------------+--------------------------------------------------------------------- plpgsql | 1.0 | pg_catalog | PL/pgSQL procedural language (1 rows) # 执行建库命令，报错类型不支持 \u0026gt;DROP TABLE IF EXISTS \u0026#34;public\u0026#34;.\u0026#34;test\u0026#34;; \u0026gt;CREATE TABLE \u0026#34;public\u0026#34;.\u0026#34;test\u0026#34; ( \u0026#34;id\u0026#34; varchar(50) COLLATE \u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34; NOT NULL, \u0026#34;name\u0026#34; varchar(255) COLLATE \u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;, \u0026#34;geometry\u0026#34; \u0026#34;public\u0026#34;.\u0026#34;geometry\u0026#34;, \u0026#34;type\u0026#34; int4, \u0026#34;parent_id\u0026#34; varchar(50) COLLATE \u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34; ); ERROR: type \u0026#34;public.geometry\u0026#34; does not exist LINE 4: \u0026#34;geometry\u0026#34; \u0026#34;public\u0026#34;.\u0026#34;geometry\u0026#34;, 原因 因为数据库没有启用postgis插件，需要执行以下命令\n1 CREATE EXTENSION postgis; 但由于启用插件需要全局管理员权限，因此需要用admin用户登录postgis, 并启用\u0026quot;\u0026ldquo;数据库的postgis插件\n1 2 3 4 5 # 赋予超级管理员权限 alter role user_name superuser; # 打开一个新的pgsql,执行命令`CREATE EXTENSION postgis;` # 收回超级管理员权限 alter role user_name nosuperuser Reference StackOverflow-只能用superuser创建extension\nStackOverflow-ERROR: type \u0026ldquo;public.geometry\u0026rdquo; does not exist\n","description":"","id":50,"section":"posts","tags":["Persistence"],"title":"PostgreSQL使用postgis插件涉及权限问题","uri":"https://hex-go.github.io/posts/persistence/2021-01-26-postgresql%E4%BD%BF%E7%94%A8postgis%E6%8F%92%E4%BB%B6%E6%B6%89%E5%8F%8A%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98/"},{"content":"重要 虽然louketo-proxy停止开发，转向oauth2proxy。但由于oauth2proxy功能太弱。不适用此场景。继续选用louketo-proxy实现。\n部署配置， 一共有三个组件（以nuclio举例）：\nkeycloak: 提供oauth2的认证源。在此处配置client、redirect_url、scope等 louketo-proxy: 作为proxy，代理所有走向nuclio的流量。与keycloak集成，没有权限的请求将被proxy拦截。 nuclio: 没有登录、授权的应用（一种faas平台）。 环境说明 keycloak: 10.0.2\nlouketo-proxy: v2.3.0\nnuclio: 1.5.12\n安装 louketo-proxy启动的ingress地址对用户开放，名字应为proxy后面服务的真实地址，如代理proxy服务，则需设置为faas.icos.city。\n1. 配置louketo-proxy client-id: 配置为keycloak服务中创建的client-name\nclient-secret: 配置为keycloak服务中创建的client, 点击credentials获取。\ndiscovery-url: 注意修改keycloak地址和realm名。\u0026lt;keycloak-address\u0026gt;/auth/realms/\u0026lt;realm-name\u0026gt;\nredirection-url: 认证完成后，返回的访问地址，即louketo-proxy的ingress地址。注意，不带oauth/callback。\nupstream-url: louketo-proxy 后面的真实应用地址。\nenable-refresh-tokens: 允许refresh-token刷新token。\n用户访问应用，会重定向到Keycloak。 那里获得授权代码。 前端louketo-proxy将此授权代码交换为access token、refresh token，\n这些token放在前端的cookie中。 当使用过期的access token调用后端时，refresh token将被解密并用于获取新的access token。\nrefresh token可以过期或无效。 当返回401时，前端应刷新页面，以便将用户重定向到Keycloak。\n更安全的做法是将token存储在redis中, 而不是存储在前端Cookie中。\nskip-upstream-tls-verify: 跳过证书校验\nskip-openid-provider-tls-verify: 跳过证书校验\nproxy的chart value.yaml如下：(proxy-chart文件)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #【----------------全局变量--------------------】 global: # # 镜像仓库名称 imageRepositoryName: reg.chebai.org #【----------------镜像配置--------------------】 # 镜像 imageRepository: paas/louketo-proxy #版本要求3位数,不写默认从.Chart.appVersion拿 #imageTag: 5.6.10 # 拉取镜像策略 imagePullPolicy: Always #容器启动命令和参数 containersCommand: {} containersArgs: \u0026#39;[ \u0026#34;--client-id=\u0026lt;client-id\u0026gt;\u0026#34;, \u0026#34;--client-secret=\u0026lt;client-secret\u0026gt;\u0026#34;, \u0026#34;--discovery-url=\u0026lt;keycloak-address\u0026gt;/auth/realms/\u0026lt;realm-name\u0026gt;\u0026#34;, \u0026#34;--enable-default-deny=true\u0026#34;, \u0026#34;--secure-cookie=false\u0026#34;, \u0026#34;--encryption-key=AgXa7xRcoClDEU0ZDSH4X0XhL5Qy2Z2j\u0026#34;, \u0026#34;--enable-json-logging=true\u0026#34;, \u0026#34;--enable-logging=true\u0026#34;, \u0026#34;--enable-request-id=true\u0026#34;, \u0026#34;--enable-security-filter=true\u0026#34;, \u0026#34;--http-only-cookie=true\u0026#34;, \u0026#34;--listen=0.0.0.0:8080\u0026#34;, \u0026#34;--preserve-host=true\u0026#34;, \u0026#34;--enable-logging\u0026#34;, \u0026#34;--redirection-url=http://faas.example.com\u0026#34;, \u0026#34;--upstream-url=http://nuclio-dashboard:8070\u0026#34;, \u0026#34;--skip-openid-provider-tls-verify\u0026#34;, \u0026#34;--skip-upstream-tls-verify\u0026#34;, \u0026#34;--resources=uri=/*|methods=GET,POST,DELETE,PUT,HEAD|roles=nuclio:viewer\u0026#34; ]\u0026#39; #【----------------服务配置--------------------】 #是否启动服务 serviceEnabled: true # 服务映射端口类型ClusterIP、NodePort serviceType: NodePort # 服务 serviceName: nuclio-proxy servicePorts: # 容器内端口 - port: 8080 protocol: \u0026#34;TCP\u0026#34; ingressEnabled: true ingressAnnotations: kubernetes.io/ingress.class: nginx ingressAddns: false ingressHosts: - host: faas domain: example.com paths: - path: / servicePort: 8080 2. 配置keycloak 配置client\n配置Scope\n也可以直接通过Mappers配置audience, ClientScope只是多封装了一层，好处是便于多个client共用。\n2.1 选择icosrealm \u0026ndash; 点击Client Scopes \u0026ndash; 点击Settings\nname: 设置名字为nuclio-service Protocol: 设置名字为openid-connect\n2.2 在Client Scope页面 \u0026ndash; 点击Mappers\nname: 设置名字为nuclio-audience Mapper Type: 设置为Audience Included Client: 输入nuclio，选择所要关联的client Add to access token: 将状态设置为ON 2.3 返回Clients页面 \u0026ndash; 点击nuclio client \u0026ndash; 选择Client Scopes标签页 \u0026ndash; 选择Setup\n在Available Client Scopes 中选择刚创建的nuclio-service \u0026ndash; 点击Add selected\n创建用户 并将\n3. 部署nuclio 将nuclio的集群外部访问都删除，比如ingress、nodeport等，用户只能通过代理访问nuclio-dashboard:8070服务。\n使用 遇到问题 error redirect_url报错： keycloak-client配置redirect_url 缺少oauth/callback,导致出现报错（keycloak端报错）\nkeycloak中需要设置为http://\u0026lt;nuclio.acme.com\u0026gt;/oauth/callback（也可以直接使用通配符，配置为http://\u0026lt;nuclio.acme.com\u0026gt;/*） louketo-proxy启动时配置为http://\u0026lt;nuclio.acme.com\u0026gt;/。 登录成功，但由于未配置audience字段aud，claim中的字段无法对应\n导致如下报错(louketo-proxy 端报错) 1 \u0026#39;aud\u0026#39; claim and \u0026#39;client_id\u0026#39; do not match 使用镜像supervisor启动，导致针对role的鉴权一直失败。 换成reg.chebai.org/paas/louketo-proxy:v1.0.0之后一切正常。\nkeycloak服务端，注销session，需要重新无痕模式打开新的窗口生效。 过期时间在生成accessToken时被服务端根据配置生成（服务端默认5分钟过期），并保存在cookie中。\n在无refreshToken干预的条件下，只有等过期时间（默认5分钟）结束才会过期，返回keycloak登录页面。\nnuclio会在请求header中x-nuclio-project-namespace: \u0026lt;namespace: eg. nuclio\u0026gt;,来区分不同命名空间下的function, 后期可以结合User Group，来进行租户划分和授权管理。 后续 nuclio使用louketo-proxy进行鉴权，多租户管理。\nReference gatekeeper git 仓库\ngatekeeper 用户手册\nKeycloak-gatekeeper: \u0026lsquo;aud\u0026rsquo; claim and \u0026lsquo;client_id\u0026rsquo; do not match\nKeycloak 文档 - Audience support\n参考，理解类似gatekeepr、oauth2proxy这类工具的实现\nOpen Policy Agent 文档\n","description":"","id":51,"section":"posts","tags":["Devops"],"title":"Keycloak-配置gatekeeper保护没有认证授权的应用功能","uri":"https://hex-go.github.io/posts/devops/2021-01-25-keycloak-%E9%85%8D%E7%BD%AEgatekeeper%E4%BF%9D%E6%8A%A4%E6%B2%A1%E6%9C%89%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83%E7%9A%84%E5%BA%94%E7%94%A8%E5%8A%9F%E8%83%BD/"},{"content":"重要 ingress controller 启用证书透传需要做两步操作\n部署IngressController时，需要增加参数--enable-ssl-passthrough 在ingress对象中设置annotation，值为nginx.ingress.kubernetes.io/ssl-redirect: \u0026quot;false\u0026quot; --enable-ssl-passthrough标志启用SSLPassthrough功能，​​此功能默认情况下处于禁用状态。\n环境说明 kubernetes 1.15.6\nnginx-ingress-controller:3.21.0\n配置 1. 获取chart 离线备份\n1 2 3 4 5 6 7 8 9 10 11 helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo update # 拉取 最新 版本chart # 建议拉取chart,而不是在线安装 helm pull ingress-nginx/ingress-nginx --version=3.21.0 # helm install helm install --name ingress-nginx --namespace ingress-nginx ingress-nginx-3.21.0.tgz helm install ingress-nginx ingress-nginx/ingress-nginx 2. 配置ingress-nginx,增加参数--enable-ssl-passthrough ingress-nginx的未在values文件中分离变量控制透传，需要改动template/controller-deployment.yaml#77： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 {{- if or (eq .Values.controller.kind \u0026#34;Deployment\u0026#34;) (eq .Values.controller.kind \u0026#34;Both\u0026#34;) -}} {{- include \u0026#34;isControllerTagValid\u0026#34; . -}} apiVersion: apps/v1 kind: Deployment metadata: name: {{ include \u0026#34;ingress-nginx.controller.fullname\u0026#34; . }} spec: revisionHistoryLimit: {{ .Values.revisionHistoryLimit }} minReadySeconds: {{ .Values.controller.minReadySeconds }} template: metadata: {{- if .Values.controller.podAnnotations }} annotations: {{- range $key, $value := .Values.controller.podAnnotations }} {{ $key }}: {{ $value | quote }} {{- end }} {{- end }} labels: {{- include \u0026#34;ingress-nginx.selectorLabels\u0026#34; . | nindent 8 }} app.kubernetes.io/component: controller {{- if .Values.controller.podLabels }} {{- toYaml .Values.controller.podLabels | nindent 8 }} {{- end }} spec: dnsPolicy: {{ .Values.controller.dnsPolicy }} containers: - name: controller {{- with .Values.controller.image }} image: \u0026#34;{{.repository}}:{{ .tag }}{{- if (.digest) -}} @{{.digest}} {{- end -}}\u0026#34; {{- end }} imagePullPolicy: {{ .Values.controller.image.pullPolicy }} {{- if .Values.controller.lifecycle }} lifecycle: {{ toYaml .Values.controller.lifecycle | nindent 12 }} {{- end }} args: - /nginx-ingress-controller - --enable-ssl-passthrough 3. 配置 ingress-object 的注解 创建的需要透传的ingress对象举例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: extensions/v1beta1 kind: Ingress metadata: annotations: nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; kubernetes.io/ingress.class: nginx creationTimestamp: \u0026#34;2020-08-18T07:35:48Z\u0026#34; name: paas-sample-ingress spec: rules: - host: paassample.icos.city http: paths: - backend: serviceName: paas-sample-svc servicePort: 80 path: / Reference IngressNginx设置SSL Passthrough\n","description":"","id":52,"section":"posts","tags":["Kubernetes","IngressController"],"title":"部署组件--IngressController启用证书透传","uri":"https://hex-go.github.io/posts/kubernetes/2021-01-22-%E9%83%A8%E7%BD%B2%E7%BB%84%E4%BB%B6--ingresscontroller%E5%90%AF%E7%94%A8%E8%AF%81%E4%B9%A6%E9%80%8F%E4%BC%A0/"},{"content":"重要 由于领导想通过代码量衡量外包的工作量，需要每周提供当前周的代码增量。\n规程中遇到以下问题：\n使用什么工具，cloc 如何统计最近一周代码增量 解决中文文件名导致cloc报错 环境说明 Ubuntu 18.04\n安装 版本较老，如果想使用最新版，参考此处安装\n1 sudo apt install cloc 使用 git 获取距今一周的 Commit ID --reverse : 将git log 倒序 -1 : 只取一行日志 --pretty=format:\u0026quot;%h\u0026quot;: 日志只输出commit-id 1 2 3 4 5 6 7 8 9 # 获取最近一周日志 date_str=$(date --date=\u0026#34;1 weeks ago\u0026#34; +\u0026#34;%Y-%m-%d\u0026#34;) logs=$(git log --after=\u0026#34;${date_str}\u0026#34; --pretty=format:\u0026#34;%h\u0026#34;) # --reverse 与 --pretty 一起使用未反转日志。以下命令会取最新的一次commit-id # commit_id=$(git log --after=\u0026#34;${date_str}\u0026#34; --reverse -1 --pretty=format:\u0026#34;%h\u0026#34;) # 获取最后一条commit-id 与 HEAD的差异 cloc --git --diff \u0026#34;${logs##*$\u0026#39;\\n\u0026#39;}\u0026#34; HEAD 如果git仓库中，存在中文，则有可能遇到以下报错 1 2 3 $ cloc --git --diff c9df9mf09df HEAD fatal: pathspec \u0026#39;\u0026#34;road/Road/\\346\\265\\213\\350\\257\\225\\345\\234\\271\\2.sql\u0026#34;\u0026#39; did not match any files Failed to create tarfile of files from git. at /usr/bin/cloc line 3811. 将中文名显示乱码问题解决，则能正常统计\n1 git config --global core.quotepath false Reference bash-date\ncloc\ngit中文显示乱码问题\n","description":"","id":53,"section":"posts","tags":["Devops","Cloc","Git","Date"],"title":"Git--中文名乱码导致cloc统计代码量出错","uri":"https://hex-go.github.io/posts/devops/2021-01-22-git--%E4%B8%AD%E6%96%87%E5%90%8D%E4%B9%B1%E7%A0%81%E5%AF%BC%E8%87%B4cloc%E7%BB%9F%E8%AE%A1%E4%BB%A3%E7%A0%81%E9%87%8F%E5%87%BA%E9%94%99/"},{"content":"重要 最重要的事: 操作记录\n1.简介 nuclio平台部署，需要一个镜像仓库提供两个功能\n构建时，提供build-base-image; 存储每个function构建后的结果镜像。 所以需要： 1. 部署带认证的registry； 2. 将基础依赖镜像(包括各个语言的build-handler镜像等)推送registry\n2.环境准备 获取, 基于\n此chart 修改的registry。\n离线chart\n3.部署 参数说明 prebaked-registry/values.yaml：\n变量 说明 secrets.htpasswd kaniko pull prebaked-registry时认证用的密码 生成prebaked-registry认证密码 1 docker run --entrypoint htpasswd registry:2 -Bbn icos 123456 部署prebaked-registry 把上一步生成的密码粘贴到 prebaked-registry/values.yaml secrets.htpasswd\n执行命令部署服务：\n1 2 kubectl create ns nuclio helm install prebaked-registry ./prebaked-registry/ -n nuclio 创建registry credentials secret 1 2 3 4 5 6 7 # 输入registry密码，同prebaked-registry保持一致 read -s mypassword # 注意修改 \u0026lt;user\u0026gt; kubectl -n nuclio create secret docker-registry registry-credentials --docker-username icos --docker-password $mypassword --docker-server prebaked-registry.nuclio:5000 --docker-email admin@icos.city # 注销变量 unset mypassword 4.使用 参考chart的Note内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 1. Get the application URL by running these commands: {{- if .Values.ingress.enabled }} {{- range .Values.ingress.hosts }} http{{ if $.Values.ingress.tls }}s{{ end }}://{{ . }}{{ $.Values.ingress.path }} {{- end }} {{- else if contains \u0026#34;NodePort\u0026#34; .Values.service.type }} export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services {{ template \u0026#34;docker-registry.fullname\u0026#34; . }}) export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT {{- else if contains \u0026#34;LoadBalancer\u0026#34; .Values.service.type }} NOTE: It may take a few minutes for the LoadBalancer IP to be available. You can watch the status of by running \u0026#39;kubectl get svc -w {{ template \u0026#34;docker-registry.fullname\u0026#34; . }}\u0026#39; export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ template \u0026#34;docker-registry.fullname\u0026#34; . }} -o jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].ip}\u0026#39;) echo http://$SERVICE_IP:{{ .Values.service.externalPort }} {{- else if contains \u0026#34;ClusterIP\u0026#34; .Values.service.type }} export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l \u0026#34;app={{ template \u0026#34;docker-registry.name\u0026#34; . }},release={{ .Release.Name }}\u0026#34; -o jsonpath=\u0026#34;{.items[0].metadata.name}\u0026#34;) echo \u0026#34;Visit http://127.0.0.1:8080 to use your application\u0026#34; kubectl -n {{ .Release.Namespace }} port-forward $POD_NAME 8080:5000 {{- end }} Reference Blog-private-docker-registry\nBlog-在k8s中部署registry\n","description":"","id":54,"section":"posts","tags":["Persistence","Registry","Kubernetes"],"title":"Registry--部署至k8s集群并使用","uri":"https://hex-go.github.io/posts/persistence/2021-01-22-registry--%E9%83%A8%E7%BD%B2%E8%87%B3k8s%E9%9B%86%E7%BE%A4%E5%B9%B6%E4%BD%BF%E7%94%A8/"},{"content":"重要 记同事一次奇葩问题拍错过程。\n环境说明 presto 服务部署在k8s集群内部，并与集成了集群外的kerbos认证。\n现象：\n集群内部访问presto一切正常，但集群外部访问会阻塞5分钟，之后访问正常。\n排错过程：\n抓包，抓client与kerbos之间包。发现客户端像DNS-Server发起了对域``的解析，返回的解析结果中包含36个主机IP,包大小超过了512字节，导致消息被截断，\n然后重新发起了TCP请求，但DNS-Server的TCP-53端口没有开放，客户端重试5分钟，超时。但presto还继续了后面正常的逻辑。\n造成问题原因：\n1. 集群外部使用DNS-Server,安全组中中开放了TCP-53，未开放UDP-53端口。\n导致问题难以定位原因：\n1. 之前主机较少，解析的包未超过512。集群内外状态皆正常。\n2. 集群内部使用的CoreDNS，TCP-53与UDP-53端口开放；但集群外部使用的外部的DNS-Server,安全组中只开放了TCP-53。\n3. 以为presto服务存在问题，只抓了客户端与presto之间的网路包。后期观察presto日志发现阻塞时，日志停留在与kerbos认证过程中。\n4. presto处理机制存在问题，即dns解析异常未做处理(比如抛错或退出)；未收到期望的解析结果仍走了后面正常逻辑，导致只是等待5分钟，但后续逻辑正常。\nReference 抓取的包文件可从此处获取\n包通过wireshark打开，如下：\nDNS使用TCP和UDP的53端口\n","description":"","id":55,"section":"posts","tags":["Kubernetes"],"title":"故障排查--ExternalDNS只开放UDP53不开放TCP53导致网络超时","uri":"https://hex-go.github.io/posts/kubernetes/2021-01-21-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5--externaldns%E5%8F%AA%E5%BC%80%E6%94%BEudp53%E4%B8%8D%E5%BC%80%E6%94%BEtcp53%E5%AF%BC%E8%87%B4%E7%BD%91%E7%BB%9C%E8%B6%85%E6%97%B6/"},{"content":"重要 1.简介 EOF是（END Of File）的缩写，表示自定义终止符。既然自定义，那么EOF就不是固定的，可以随意设置别名，在linux按ctrl-d 就代表EOF。\nEOF一般会配合cat能够多行文本输出。\n2. 用法说明 其用法如下：\n1 2 3 \u0026lt;\u0026lt;EOF #开始 .... #输入内容 EOF #结束 还可以自定义，比如自定义：\n1 2 3 4 5 #开始 \u0026lt;\u0026lt;ABC .... ## 结束 ABC 通过cat配合重定向能够生成文件并追加操作，在它之前先熟悉几个特殊符号\n\u0026lt;: 输入重定向\n\u0026gt;: 输出重定向\n\u0026gt;\u0026gt;: 输出重定向,进行追加,不会覆盖之前内容\n\u0026lt;\u0026lt;: 标准输入来自命令行的一对分隔号的中间内容\n例子1：\n1 2 3 cat \u0026lt;\u0026lt;EOF hello EOF 输出为：\n1 hello 我们知道cat的操作对象是文件，但是例1中cat的操作对象不是文件，而是用户输入；那么我们可以这样理解例1：先在文件file中输入“Hello”，再用cat file输出其中的内容。\n也就是说我们可以用一个文件来替代\u0026quot;\u0026laquo; EOF EOF\u0026quot;。\n反过来说，如果操作命令中的文件是输入对象，也可以用\u0026quot;\u0026laquo; EOF EOF\u0026quot;来替代的。\n例子2：\n1 2 3 4 5 6 7 8 9 10 11 12 ## 1. 创建1.txt文件，文件中有字段`abc` echo \u0026#34;abc\u0026#34; \u0026gt; 1.txt ## 2. 向文件1.txt输入覆盖内容（也可以：cat \u0026gt; 1.txt \u0026lt;\u0026lt;EOF） cat \u0026lt;\u0026lt;EOF \u0026gt; 1.txt 11 aa bb lol EOF ## \u0026#34;\u0026lt;\u0026lt; EOF EOF\u0026#34; 的作用是在命令执行过程中用户自定义输入，它类似于起到一个临时文件的作用，只是比使用文件更方便灵活。 3. cat \u0026lt;\u0026lt;EOF 与 cat \u0026lt;\u0026lt;-EOF 的区别 两个都是获取stdin，并在EOF处结束stdin，输出stdout。\n使用cat \u0026lt;\u0026lt;EOF时，输入完成后，需要在一个新的一行输入EOF结束stdin的输入。EOF必须顶行写，前面不能用制表符或者空格。\n使用cat \u0026lt;\u0026lt;-EOF时，分界符（EOF）所在行的开头部分的制表符（Tab）都将被去除。这可以解决由于脚本中的自然缩进产生的制表符。\n如果结束分解符EOF前有制表符或者空格，则EOF不会被当做结束分界符，只会继续被当做stdin来输入。所以会报如下报错\n1 2.sh: line 5: warning: here-document at line 1 delimited by end-of-file (wanted `EOF\u0026#39;) 脚本内容如下：\n1 2 3 4 5 #!/bin/bash cat \u0026lt;\u0026lt;EOF 你好，EOF！ EOF 正确写法如下 - 2种：\n1 2 3 4 5 6 7 8 ## 虽然最后的EOF前面有多个制表符和空格，但仍然会被当做结束分界符，表示stdin的结束。 #!/bin/bash cat \u0026lt;\u0026lt;EOF 你好，EOF！ EOF 1 2 3 4 5 6 7 8 #!/bin/bash ## 虽然最后的EOF前面有多个制表符和空格，但仍然会被当做结束分界符，表示stdin的结束。 cat \u0026lt;\u0026lt;-EOF 你好，EOF！ EOF ","description":"","id":56,"section":"posts","tags":["Bash"],"title":"shell基础之EOF的用法","uri":"https://hex-go.github.io/posts/bash/2021-01-14-shell%E5%9F%BA%E7%A1%80%E4%B9%8Beof%E7%9A%84%E7%94%A8%E6%B3%95/"},{"content":"重要 实现的状态\ngithub仓库走代理 内网仓库不走代理 1.简介 由于github仓库拉取缓慢，所以配置了代理； 但内网仓库拉取也走了代理，导致出现以下报错\n1 2 hex@hex-pc:~/example-repo$ git pull fatal: unable to access \u0026#39;https://git.service.rd/plugins/git/example-repo.git/\u0026#39;: gnutls_handshake() failed: The TLS connection was non-properly terminated. 解决办法(推荐) git是可以根据环境变量的配置，声明代理并将内网地址配置不走代理，实现此功能，但要注意格式。\n1 2 3 4 5 6 7 export https_proxy=http://127.0.0.1:10800/ export http_proxy=http://127.0.0.1:10800/ export all_proxy=socks://127.0.0.1:1088/ export ftp_proxy=http://127.0.0.1:10800 # 声明内网不走proxy的服务 声明域名作为通配，以空格分隔。 export no_proxy=\u0026#34;.service.rd .icos.city 127.0.0.1 localhost\u0026#34; 修改本地库-local配置 也可以针对仓库设置git config。可以设置本地库全局配置，也可以只设置单一远端。\n已有仓库,进入仓库目录下，并添加一个“空”代理（仓库级别）。 1 git config --local --add http.proxy \u0026#34;\u0026#34; 在仓库目录下\u0026lt;repo_path\u0026gt;/.git/config，会出现以下内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \u0026#34;origin\u0026#34;] url = https://git.service.rd/plugins/git/example.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \u0026#34;master\u0026#34;] remote = origin merge = refs/heads/master [http] proxy = 已有仓库，进入仓库目录下，添加一个”空“代理（固定remote级别）。 1 git config --local --add remote.\u0026lt;name\u0026gt;.proxy \u0026#34;\u0026#34; 执行下面命令查看\n1 git config --local --get remote.\u0026lt;name\u0026gt;.proxy 修改全局配置（只能针对单库） 修改 ~/.gitconfig文件，增加以下内容\n1 2 3 4 5 [http] sslVerify = true [http \u0026#34;https://git.service.rd/plugins/git/example-repo.git\u0026#34;] sslVerify = false ptoxy = ","description":"","id":57,"section":"posts","tags":["个人工具","Git"],"title":"GIT-配置proxy并忽略内网仓库","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-12-28-git-%E9%85%8D%E7%BD%AEproxy%E5%B9%B6%E5%BF%BD%E7%95%A5%E5%86%85%E7%BD%91%E4%BB%93%E5%BA%93/"},{"content":"重要 s3fs使用fuse挂载s3 bucket到Linux或Mac系统,并且支持在Docker容器内部以非特权用户挂载s3 bucket。\n安装s3fs 在容器内使用s3fs,需要在Docker镜像中安装s3fs,以下是主流发行版安装方法:\nDebian 9 and Ubuntu 16.04 or newer:\n1 sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL:\n1 2 sudo yum install epel-release sudo yum install s3fs-fuse 参数说明 /etc/fuse.conf文件中配置说明\nParameter Description Default user_allow_other 允许非root用户使用allow_other 挂载选项 no value 挂载选项说明\nParameter Description Default use_path_request_style 非AWS实现的S3服务,设置此参数,配合url使用 no value url S3服务的URL http://obs.cn-north-4.myhuaweicloud.com allow_other 允许非root用户挂载 no vaule 部署服务 通过fstab挂载\n1 2 3 4 echo ACCESS_KEY_ID:SECRET_ACCESS_KEY \u0026gt; ~/.passwd-s3fs sed -i \u0026#39;s/\\#user_allow_other/user_allow_other/g\u0026#39; /etc/fuse.conf mkdir /mnt/s3 rke-test /mnt/s3 fuse.s3fs _netdev,allow_other,use_path_request_style,url=http://obs.cn-north-4.myhuaweicloud.com / 0 0 通过命令挂载\n1 2 3 4 echo ACCESS_KEY_ID:SECRET_ACCESS_KEY \u0026gt; ~/.passwd-s3fs sed -i \u0026#39;s/\\#user_allow_other/user_allow_other/g\u0026#39; /etc/fuse.conf mkdir /mnt/s3 s3fs rke-test /mnt/s3 -o _netdev -o allow_other -o use_path_request_style -o url=http://obs.cn-north-4.myhuaweicloud.com 容器内命令挂载\n1 2 3 4 5 6 docker run -d --name ranger --cap-add mknod --cap-add sys_admin --security-opt apparmor:unconfined --device=/dev/fuse reg.chebai.org/paas/ranger:latest docker exec -it -u 1000 ranger bash echo ACCESS_KEY_ID:SECRET_ACCESS_KEY \u0026gt; ~/.passwd-s3fs sed -i \u0026#39;s/\\#user_allow_other/user_allow_other/g\u0026#39; /etc/fuse.conf mkdir /mnt/s3 s3fs rke-test /mnt/s3 -o _netdev -o allow_other -o use_path_request_style -o url=http://obs.cn-north-4.myhuaweicloud.com 测试 确定已成功挂载 1 mount | grep s3 复制文件到挂载点 1 cp file /mnt/s3 在华为云控制台检查bucket中是否存在该文件 常见问题 fuse: device not found, try \u0026lsquo;modprobe fuse\u0026rsquo; first\nk8s中，容器需要设置特权模式。否则会引起此报错\n启用此功能需要节点安装fuse组件么\n不需要，只需要容器安装s3fs，调用容器内的fuse组件。fuse是user-space的组件，只需要容器内安装。之后需要特权模式sys-admin。则能正常使用。\n用户空间文件系统FUSE工作原理\ns3fs: credentials file /root/.passwd-s3fs should not have others permissions.\n文件权限问题，为是s3认证信息保密，将权限由644改为600。chmod 600 ～/.passwd-s3fs。\n文件只读性能还可以，但一点有写操作，性能很差。\na服务修改了文件，会重新上传文件至s3，其他节点则是从s3同步下修改的文件。\nreference s3fs-fuse github\nfuse 概念扫盲\n","description":"","id":58,"section":"posts","tags":["Persistence"],"title":"S3fs-利用s3作为弹性文件存储方案","uri":"https://hex-go.github.io/posts/persistence/2020-11-18-s3fs-%E5%88%A9%E7%94%A8s3%E4%BD%9C%E4%B8%BA%E5%BC%B9%E6%80%A7%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88/"},{"content":"重要 mongodb的搭建主要分sharded-cluster,ha, single-node, 一个ha可以包含primary(1),secondary(0~2),ab\nmongodb使用偶数版本(稳定版本)。比如4.4.1， 而非奇数版本(开发版本)，比如4.3.0。具体详见mongodb versioning\nmongodb关于bitnami的sharded部署，普通用户的创建不能使用。因为\n1.简介 2.环境准备 3.部署 4.使用 Reference 官方文档\nmongodb官方文档-sharding\nmongodb官方文档-sharding部署\nmongodb官方文档-sharded-Cluster管理员文档\nmongodb官方文档-sharded-Cluster管理员文档v3版本\nmongodb官方文档-版本说明\nmongodb官方文档-Release Notes\n部署chart(注意，helm/charts下的mongodb和mongodb-replicaset已不再维护)\nmongodb-部署chart-Mongodb-sharded\n数据库初始化，需要等集群正确分片后执行\n(bitnami/mongodb-sharded)custom用户和数据库变量被忽略\n扫盲博客\n博客\u0026ndash;mongodb部署了解mongodb-sharded\n其他\n阿里云mongodb-sharding 注意事项\nPerformance Best Practices: Sharding\nWhat is MongoDB Sharding and the Best Practices?\nThe Basics of Sharding in MongoDB\n","description":"","id":59,"section":"posts","tags":["Persistence","Mongodb"],"title":"MongoDB-sharded集群搭建及维护使用","uri":"https://hex-go.github.io/posts/persistence/2020-11-13-mongodb-sharded%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E5%8F%8A%E7%BB%B4%E6%8A%A4%E4%BD%BF%E7%94%A8/"},{"content":"重要 环境说明 安装 使用 Reference ","description":"","id":60,"section":"posts","tags":["Go"],"title":"Go-Struct-tag深入理解[三]为struct设置参数校验validator","uri":"https://hex-go.github.io/posts/golang/2020-11-12-go-struct-tag%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E4%B8%89%E4%B8%BAstruct%E8%AE%BE%E7%BD%AE%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8Cvalidator/"},{"content":"重要 trivy用来扫描镜像的安全漏洞。如果用于生产环境，需要将漏洞库离线，安全人员将镜像的基础镜像或者buildpack的stack进行升级。之后再升级安全漏洞。\n将安全漏洞修复变成可计划，分期实施的过程。如果一直使用在线库，则不能采取存在漏洞立即删除的策略。\n环境说明 trivy version 0.4.4\n安装 使用 扫描镜像的命令\n采用server-client模式启动服务 trivy采取server-client模式，server端将漏洞库离线打在镜像内\n1. 获取离线漏洞库 在trivy版本Release时，会发布漏洞库\n下载连接\n参考issue\n或者选择执行命令下载\n1 trivy --download-db-only 2. 启动server端 server端命令如下\n\u0026ndash;token用于客户端与server连接时，认证使用。\n\u0026ndash;skip-update 跳过漏洞库更新\n1 trivy server -d --listen 0.0.0.0:4954 --skip-update --token mail2Uyu 3. 启动client端 client端命令如下\n\u0026ndash;cache-dir 声明缓存的路径\n\u0026ndash;severity 扫描的漏洞安全级别\n\u0026ndash;vuln-type 扫描的漏洞类型\n\u0026ndash;format 声明报告格式\n\u0026ndash;output 输出的日志位置\n\u0026ndash;ignore-unfixed 忽略未修复的漏洞\n1 2 3 4 5 6 7 8 trivy client --remote http://trivy-server.svc.com:4954 --token mail2Uyu \\ --cache-dir /root/.cache/trivy \\ --severity UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL \\ --vuln-type os \\ --ignore-unfixed \\ --format json \\ --output /root/.cache/reports/scan_report_984890059.json \\ ubuntu:20.04 使用 trivy 直接扫描 1 2 3 4 5 6 trivy --cache-dir /root/.cache/trivy \\ --severity CRITICAL \\ --vuln-type os \\ --format json \\ --output /root/.cache/reports/18.04.json \\ centos:centos7.8.2003 trivy 跳过 误报漏洞 在trivy命令执行的同级目录下， 创建.trivyignore文件。以类似下面内容配置忽略的漏洞\n1 2 3 4 5 6 $ cat .trivyignore # Accept the risk CVE-2018-14618 # No impact in our settings CVE-2019-1543 Reference 获取trivy漏洞库\n忽略特定的漏洞\ntrivy支持的os\nbug-使用厂商(比如. Redhat)提供的危险等级\nissue-不能使用非官方源装包(包括自制的包or国内源装包)\n","description":"","id":61,"section":"posts","tags":["Devops"],"title":"DevOps-trivy-镜像扫描汇总","uri":"https://hex-go.github.io/posts/devops/2020-11-06-devops-trivy-%E9%95%9C%E5%83%8F%E6%89%AB%E6%8F%8F%E6%B1%87%E6%80%BB/"},{"content":"重要 ingress-nginx对于暴露grpc的服务，要求必须tls加密。所以，要么ingress配置grpcs,在服务端自己管理证书；要么ingress配置grpc,在ingress配置统一管理证书。\n为便于运维管理证书，此处采用cert-manager统一在ingress配置中。自动生成证书，发布https服务。\n环境说明 使用 生成自签发CA证书，并保存在secret中(供cert-manager签发证书使用)； 配置cluster-issuer,和certificate，使生成Secret，保存证书、ca和私钥； 创建pod,service,ingress, ingress的tls配置使用第二步生成的Secret； 执行命令测试grpc端口是否暴露成功； 1 grpcurl -insecure test.icos.city:443 build.stack.fortune.FortuneTeller/Predict Reference 以上1.2步参考cert-manager相关内容\ncert-manager hex-博客\ncert-manager hex-github-示例项目\n第3,4部参考ingress-nginx的官方示例，\nIngressNginx官房GRPC示例\n第3,4部也可参考cert-manager的示例代码测试\ncert-manager hex-github-示例项目\n其他关于grpc的内容，需要参考此链接\ngrpc_github\ngrpc_go_quick_start\ngrpc python quick-start\ngrpc_java_quick-start\ningress-nginx-grpcExample\ningress-nginx-grpc-DOC\ningress-nginx-grocExampleImage\n","description":"","id":62,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes-ingress-nginx配置grpc服务","uri":"https://hex-go.github.io/posts/kubernetes/2020-11-06-kubernetes-ingress-nginx%E9%85%8D%E7%BD%AEgrpc%E6%9C%8D%E5%8A%A1/"},{"content":"重要 由于需要配置ingress-grpc,nginx-ingress要求tls加密。实现的方式有两种：一种在ingress注解grpcs,之后在pod控制证书；另一种在ingress配置tls。\n生产环境证书都是运维统一维护，舍弃第一种。所以调研cert-manager用来维护证书。\n此处cert-manager用来使用已给的ca为需要证书的服务生成证书、并使用.\n环境说明 K8S：1.15.6\nCertManager: 1.0.4\n部署cert-manager 两种方式：\n一种资源清单部署（install with regular manifests）\n另一种是helm-chart部署（install with helm）\n注意, 默认配置在certificate删除时,它所创建的secret不会被删除; 如果想要Secret同步被删除,需要在部署时指定参数--enable-certificate-owner-ref=true.\n1. 资源清单部署 由于工作环境使用的k8s环境版本为1.15.6，\u0026lt;1.16.\n1 2 # Kubernetes \u0026lt;1.16 kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.0.4/cert-manager-legacy.yaml 2. helm-chart部署 创建CRD资源 由于工作环境使用的k8s环境版本为1.15.6，创建crd时使用最新版本.\n1 kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.0.4/cert-manager.crds.yaml 获取chart部署 1 2 3 4 5 6 7 8 # 添加 chart-repo helm repo add jetstack https://charts.jetstack.io # 拉取 v1.0.4 版本chart # 建议拉取chart,而不是在线安装 helm pull jetstack/cert-manager --version=v1.0.4 # helm install helm install --name cert-manager --namespace cert-manager cert-manager-v1.0.4.tgz 检查安装 1 2 3 4 5 6 $ kubectl get pods --namespace cert-manager NAME READY STATUS RESTARTS AGE cert-manager-5c6866597-zw7kh 1/1 Running 0 2m cert-manager-cainjector-577f6d9fd7-tr77l 1/1 Running 0 2m cert-manager-webhook-787858fcdb-nlzsq 1/1 Running 0 2m 使用 cert-manager 可以从各种证书颁发机构获取证书，包括Let\u0026rsquo;s Encrypt、HashiCorp Vault、Venafi 和 私人PKI。\n由于服务不需要暴露公网，此处选用自签发CA(即私人PKI)方式签发证书：\n1. 创建ca并保存进集群，Secret:cert-manager:ca-key-pair 此处配置的是自签发证书，如果环境中需要更换成合法证书，需要运维在第二步时，根据真实证书创建Secret。\n生成自签发证书(ca.crt)和key(ca.key) 1 2 3 4 5 # Generate a CA private key openssl genrsa -out ca.key 2048 # Create a self signed Certificate, valid for 10yrs with the \u0026#39;signing\u0026#39; option set openssl req -x509 -new -nodes -key ca.key -subj \u0026#34;/CN=ICOS.CITY\u0026#34; -days 3650 -reqexts v3_req -extensions v3_ca -out ca.crt 创建Secret保存证书(命名空间: cert-manager; 资源类型: secret; 资源名称: ca-key-pair.)。 如果使用cluster-issuer，则需要将此secret保存至cert-manager命名空间；\n如果使用issuer,则需要在每个issuer所在命名空间创建此secret.\n此处以 cluster-issuer 配置\n1 kubectl create secret tls ca-key-pair --cert=ca.crt --key=ca.key --namespace=cert-manager 2. 创建 cluster-issuer, 内容如下(cluster-issuer.yaml)： 1 2 3 4 5 6 7 apiVersion: cert-manager.io/v1 kind: ClusterIssuer metadata: name: ca-clusterissuer spec: ca: secretName: ca-key-pair 执行下面命令创建\n1 kubectl create -f cluster-issuer.yaml 3. 创建certificate测试，内容如下(example-ca.yaml)： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 apiVersion: cert-manager.io/v1 kind: Certificate metadata: name: example-ca namespace: mars spec: # 创建名为`example-secret`的secret,保存`ca`与签发的证书. secretName: example-secret issuerRef: name: ca-clusterissuer kind: ClusterIssuer # 此处放的是服务集群内部访问地址， commonName: example.mars organization: - Example CA dnsNames: # 同namespace访问的服务地址 - example # 集群外部访问地址 - example.mars.icos.city 执行命令kubectl create -f example-ca.yaml\n查看证书和Secret\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 $ kubectl -n mars get certificate # 证书的状态 READY 为 True。 NAME READY SECRET AGE example-ca True example-secret 5d20h $ kubectl -n mars get secrets example-secret -o yaml # 回显的secret的 data.ca.crt, data.tls.crt, data.tls.key 都有证书或秘钥base64值。 apiVersion: v1 data: ca.crt: LS0tLS1C...EUtLS0tLQo= tls.crt: LS0tLS1C...RFLS0tLS0K tls.key: LS0tLS1C...0tLS0tCg== kind: Secret metadata: annotations: cert-manager.io/alt-names: test-cert.mars,test-cert.icos.city cert-manager.io/certificate-name: test-cert-ca cert-manager.io/common-name: icos.city cert-manager.io/issuer-kind: ClusterIssuer cert-manager.io/issuer-name: ca-clusterissuer # 在certificate中指定的 `spec.secretName` name: example-secret namespace: mars type: kubernetes.io/tls 4. 容器使用 集群中使用证书的场景有以下几个诉求：\n非https容器访问https容器，需要信任此自签证书。所以需要将ca.crt挂载到非https容器内部； 储存各个服务自身证书的secret中包含三部分，ca.crt,tls.crt,tls.key。 统一的平台部署应用到多个k8s集群，需要每个集群均部署cert-manager,并使用同一个ca。 所以采取以下实现。\n为每个服务均生成证书，至少包含同一集群内部访问和同一Namespace访问的证书。并挂载在/opt/tls/目录下。 如果服务有对外暴露，多加一个dnsName 为集群外部访问地址。 每个服务在固定的容器目录下，均有ca.crt,tls.crt,tls.key文件，只是访问https服务，则只使用ca.crt文件。 ca.crt是公用、一致的； tls.crt,tls.key是根据每个服务的服务名、ingress签发的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # Source: icossense-icosgrpc-service-xadit-001/templates/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: example-001 labels: app: example-001 chart: example-001-1.0.0 release: \u0026#34;RELEASE-NAME\u0026#34; heritage: \u0026#34;Helm\u0026#34; spec: selector: matchLabels: app: example-001 replicas: 1 template: metadata: name: example-001 labels: app: example-001 release: \u0026#34;RELEASE-NAME\u0026#34; spec: containers: - name: example-001 image: \u0026#34;hexpy/example-grpc:latest9\u0026#34; imagePullPolicy: \u0026#34;Always\u0026#34; securityContext: allowPrivilegeEscalation: true runAsNonRoot: true capabilities: drop: [\u0026#34;NET_ADMIN\u0026#34;, \u0026#34;SYS_TIME\u0026#34;,\u0026#34;CHOWN\u0026#34;,\u0026#34;SYS_ADMIN\u0026#34;] ports: - name: containerport-0 protocol: \u0026#34;TCP\u0026#34; containerPort: 7070 volumeMounts: - name: example-secret-mount mountPath: \u0026#34;/etc/tls\u0026#34; readOnly: true volumes: # 在此`deployment`中, `volumeMounts`中的`name`一致 - name: example-secret-mount secret: # 在`certificate`中`spec.secretName`设置的. secretName: example-secret Reference 官方文档\nchart\ngithub\n当证书被删除，Secret会被留下\n当证书被删除，Secret会被留下2\ngithub-示例项目\nAutomatic TLS certificates with cert-manager and ingress-nginx\n","description":"","id":63,"section":"posts","tags":["Kubernetes","CertManager"],"title":"Kubernetes-CertManager解决ingress-tls证书问题","uri":"https://hex-go.github.io/posts/kubernetes/2020-11-05-kubernetes-certmanager%E8%A7%A3%E5%86%B3ingress-tls%E8%AF%81%E4%B9%A6%E9%97%AE%E9%A2%98/"},{"content":"重要 环境说明 安装 使用 Reference golang 为struct设置默认值的四种方式\nhow-to-set-default-values-in-go-structs(stack overflow)\n为struct设置默认值的包\nvalidator包不支持也不打算支持default\nstruct 数据预处理包\n","description":"","id":64,"section":"posts","tags":["Go"],"title":"Go-Struct-tag深入理解[二]为struct设置default值","uri":"https://hex-go.github.io/posts/golang/2020-10-22-go-struct-tag%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E4%BA%8C%E4%B8%BAstruct%E8%AE%BE%E7%BD%AEdefault%E5%80%BC/"},{"content":"前言 Go 语言中Struct声明包含三部分: field_name, field_type, field_tag.\nfield_tag的作用:\n可以作为字段后额外的注释或者说明\n在反射场景下, reflect包中提供了操作tag的方法, tag的写法需要遵循一定规则.\n使用 Tag 书写规则 tag是一串字符串, 以空格分隔的key:\u0026quot;value\u0026quot;对.\nkey: 为非空字符串, 字符串不含控制字符\\空格\\引号\\冒号. value: 以双引号标记的字符串. 以:分隔,并且冒号前后不能有空格. 1 2 3 4 type Server struct { ServerName string `json: \u0026#34;server_name\u0026#34; gorm:\u0026#34;serverName\u0026#34; default:\u0026#34;example\u0026#34;` ServerIP string `json: \u0026#34;server_ip\u0026#34;` } reflect获取Tag值 StructTag提供了Get(key string) string方法来获取Tag，示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;reflect\u0026#34; \u0026#34;fmt\u0026#34; ) type Server struct { ServerName string `json: \u0026#34;server_name\u0026#34; gorm:\u0026#34;serverName\u0026#34; default:\u0026#34;example\u0026#34;` ServerIP string `json: \u0026#34;server_ip\u0026#34;` } func main() { s := Server{} st := reflect.TypeOf(s) fieldServerName := st.Field(0) fmt.Printf(\u0026#34;TAG-key=\u0026gt;json TAG-value=\u0026gt;%v\\n\u0026#34;, fieldServerName.Tag.Get(\u0026#34;json\u0026#34;)) fmt.Printf(\u0026#34;TAG-key=\u0026gt;default TAG-value=\u0026gt;%v\\n\u0026#34;, fieldServerName.Tag.Get(\u0026#34;default\u0026#34;)) fieldServerIp := st.Field(1) fmt.Printf(\u0026#34;TAG-key=\u0026gt;json TAG-value=\u0026gt;%v\\n\u0026#34;, fieldServerIp.Tag.Get(\u0026#34;json\u0026#34;)) } 程序输出如下：\n1 2 3 TAG-key=\u0026gt;json TAG-value=\u0026gt;server_name TAG-key=\u0026gt;default TAG-value=\u0026gt;example TAG-key=\u0026gt;json TAG-value=\u0026gt;server_ip Tag的作用 使用反射可以动态的给结构体成员赋值，正是因为有tag，在赋值前可以使用tag来决定赋值的动作。 比如，官方的encoding/json包，可以将一个JSON数据Unmarshal进一个结构体，此过程中就使用了Tag. 该包定义一些规则，只要参考该规则设置tag就可以将不同的JSON数据转换成结构体。\n总之：正是基于struct的tag特性，才有了诸如json数据解析、orm映射等等的应用。理解这个关系是至关重要的。或许，你可以定义另一种tag规则，来处理你特有的数据。\nTag使用举例 包 包中关于tag的规则 full example json https://godoc.org/encoding/json#Marshal \u0026ldquo;my_name,omitempty\u0026rdquo; 声明名字+可省略\n\u0026quot;,omitempty\u0026quot; 值为空则省略此字段\n\u0026ldquo;my_name\u0026rdquo; 在json中此字段的键\n\u0026quot;-\u0026quot; 字段始终省略 default https://github.com/creasty/defaults#usage gorm https://godoc.org/github.com/jinzhu/gorm https://www.cnblogs.com/zisefeizhu/p/12788017.html#%E7%BB%93%E6%9E%84%E4%BD%93%E6%A0%87%E8%AE%B0tags yaml https://godoc.org/gopkg.in/yaml.v2 xml https://godoc.org/encoding/xml Reference Go struct tag深入理解(华为)\nGo语言中的struct tag(知乎)\nWell known struct tags(golang wiki)\ngorm 结构体的相关标记\n","description":"","id":65,"section":"posts","tags":["Go"],"title":"Go-Struct-tag深入理解[一]StructTag规则说明","uri":"https://hex-go.github.io/posts/golang/2020-10-21-go-struct-tag%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E4%B8%80structtag%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"content":"重要 环境说明 安装 使用 Reference 官方博客-VaultPerformanceBenchmark\nGitHub-vault-benchmarking\nGoogleGroups - vaultTool\n","description":"","id":66,"section":"posts","tags":["Go"],"title":"Go-Vault-benchmark方案","uri":"https://hex-go.github.io/posts/golang/2020-09-23-go-vault-benchmark%E6%96%B9%E6%A1%88/"},{"content":"重要 环境说明 安装 使用 Reference Gin项目结构最佳实践\n在Golang尝试清洁架构\nThe Clean Architecture\n教程：使用 go 的 gin 和 gorm 框架来构建 RESTful API 微服务\n使用Gin构建Go Web应用程序和微服务\nHow to build a REST API with Golang using Gin and Gorm\n基于gin构建企业级 golang web 脚手架\n","description":"","id":67,"section":"posts","tags":["Go"],"title":"Go-Gin-项目结构最佳实践","uri":"https://hex-go.github.io/posts/golang/2020-09-22-go-gin-%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"},{"content":"重要 1. 目录操作 1.1 删除目录 删除目录下所有内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // Golang program to illustrate how to // remove all the files and directories // from the default directory package main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { // Remove all the directories and files // Using RemoveAll() function err := os.RemoveAll(\u0026#34;/Users/hex/Documents/go\u0026#34;) if err != nil { log.Fatal(err) } } 1.2 创建目录 级联创建所有目录 1 os.MkdirAll(\u0026#34;/tmp/\u0026#34;,FileMode) 1.3 创建临时目录 方法：\n调用io.ioutil包的 ioutil.TempDir方法 == == os包的 os.MkdirTemp方法\n作用：\n创建全局唯一的临时目录。但在使用完成后，需要自行删除此目录。\n参数：\n第一个dir参数如果不指定，则为os.TempDir()目录。如Linux下取$TMPDIR变量，变量空值则为/tmp目录。 ioutil.TempDir方法调用过程说明：\n在目录/tmp目录中创建一个名称以prefix开头的新目录 并返回新创建目录的路径 1 2 3 4 5 6 7 dir, err := ioutil.TempDir(\u0026#34;/tmp\u0026#34;, \u0026#34;prefix-\u0026#34;) if err != nil { log.Fatal(err) } defer os.RemoveAll(dir) fmt.Println(dir) // 例如目录名为 \u0026#34;/tmp/prefix-054003078/\u0026#34; 1.3.1 创建时间目录 1 2 3 // logsDir := os.path.Join(\u0026#34;/tmp\u0026#34;, time.Now().Format(\u0026#34;2006/01/02\u0026#34;)) logsDir := filepath.Join(\u0026#34;/tmp\u0026#34;, time.Now().Format(\u0026#34;2006/01/02\u0026#34;)) err := os.MkdirAll(logsDir, 666) 1.4 检查路径是否为目录 1 2 3 4 5 6 func IsDir(name string) bool { if info, err := os.State(name); err == nil { return info.IsDir() } return false } 1.5 打印当前目录 1 os.Getwd() //获取当前目录 1.6 文件目录拼接 1 2 os.path.join(\u0026#34;/tmp\u0026#34;, \u0026#34;/text.md\u0026#34;) 1.7 目录复制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 func CopyDir(srcPath, desPath string) error { //检查目录是否正确 if srcInfo, err := os.Stat(srcPath); err != nil { return err } else { if !srcInfo.IsDir() { return errors.New(\u0026#34;源路径不是一个正确的目录！\u0026#34;) } } if desInfo, err := os.Stat(desPath); err != nil { return err } else { if !desInfo.IsDir() { return errors.New(\u0026#34;目标路径不是一个正确的目录！\u0026#34;) } } if strings.TrimSpace(srcPath) == strings.TrimSpace(desPath) { return errors.New(\u0026#34;源路径与目标路径不能相同！\u0026#34;) } err := filepath.Walk(srcPath, func(path string, f os.FileInfo, err error) error { if f == nil { return err } //复制目录是将源目录中的子目录复制到目标路径中，不包含源目录本身 if path == srcPath { return nil } //生成新路径 destNewPath := strings.Replace(path, srcPath, desPath, -1) if !f.IsDir() { CopyFile(path, destNewPath) } else { if !FileIsExisted(destNewPath) { return MakeDir(destNewPath) } } return nil }) return err } 1.8 遍历目录下所有文件(不包含子目录) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /* 获取指定路径下的所有文件，只搜索当前路径，不进入下一级目录，可匹配后缀过滤（suffix为空则不过滤）*/ func ListDir(dir, suffix string) (files []string, err error) { files = []string{} _dir, err := ioutil.ReadDir(dir) if err != nil { return nil, err } suffix = strings.ToLower(suffix) //匹配后缀 for _, _file := range _dir { if _file.IsDir() { continue //忽略目录 } if len(suffix) == 0 || strings.HasSuffix(strings.ToLower(_file.Name()), suffix) { //文件后缀匹配 files = append(files, path.Join(dir, _file.Name())) } } return files, nil } 1.9 遍历目录下所有文件(包含子目录) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* 获取指定路径下以及所有子目录下的所有文件，可匹配后缀过滤（suffix为空则不过滤）*/ func WalkDir(dir, suffix string) (files []string, err error) { files = []string{} err = filepath.Walk(dir, func(fname string, fi os.FileInfo, err error) error { if fi.IsDir() { //忽略目录 return nil } if len(suffix) == 0 || strings.HasSuffix(strings.ToLower(fi.Name()), suffix) { //文件后缀匹配 files = append(files, fname) } return nil }) return files, err } 2. 文件操作 2.1 文件创建或追加内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { // ioutil包 创建文件 err := ioutil.WriteFile(\u0026#34;temp.txt\u0026#34;, []byte(\u0026#34;first line\\n\u0026#34;), 0644) if err != nil { log.Fatal(err) } // os包 Create方法 创建文件 f1, _ := os.Create(\u0026#34;./temp.txt\u0026#34;) defer f1.close() // os包 Openfile 读写打开文件 f2, _ := os.Openfile(\u0026#34;./temp.txt\u0026#34;, os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0666) defer f2.close() // 追加文件内容 file, err := os.OpenFile(\u0026#34;temp.txt\u0026#34;, os.O_APPEND|os.O_WRONLY, 0644) defer file.close() if err != nil { log.Println(err) } if _, err := file.WriteString(\u0026#34;second line\u0026#34;); err != nil { log.Fatal(err) } //Print the contents of the file data, err := ioutil.ReadFile(\u0026#34;temp.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(string(data)) } 2.2 创建临时文件 方法：\n调用io.ioutil包的 ioutil.TempFile方法[Go-旧版] == os包的 os.CreateTemp方法[ Go 1.17以上版本]\n作用：\n创建全局唯一的临时文件。但在使用完成后，需要自行删除此文件。\n参数：\n第一个dir参数如果不指定，则为os.TempDir()目录。如Linux下取$TMPDIR变量，变量空值则为/tmp目录。\n第二个参数pattern，在Go-1.11以后支持使用*占位符来制定随机串的位置，没有*则保持默认，再最后追加随机串。\nioutil.TempFile方法调用过程说明：\n在目录/tmp目录中以prefix开头的名称创建一个新文件 打开文件进行读写操作 并返回新创建临时文件对象*os.File 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 不指定随机串位置 file, err := ioutil.TempFile(\u0026#34;/tmp\u0026#34;, \u0026#34;prefix-\u0026#34;) if err != nil { log.Fatal(err) } defer os.Remove(file.Name()) fmt.Println(file.Name()) // 例如文件名为: \u0026#34;/tmp/prefix-054003078\u0026#34; // 指定随机串位置 file2, err2 := ioutil.TempFile(\u0026#34;/tmp\u0026#34;, \u0026#34;myname.*.go\u0026#34;) if err2 != nil { log.Fatal(err2) } defer os.Remove(file2.Name()) fmt.Println(file2.Name()) // 例如文件名为: \u0026#34;/tmp/myname.054003078.bat\u0026#34; 2.3 检查文件是否存在 1 2 3 4 5 6 7 func FileIsExisted(filename string) bool { existed := true if _, err := os.Stat(filename); os.IsNotExist(err){ existed = false } return existed } 2.4 重命名文件 1 os.Rename(\u0026#34;/tmp/1.md\u0026#34;, \u0026#34;tmp/2.md\u0026#34;) 2.5 复制文件 复制文件过程中一定要注意将原始文件的权限也要复制过去，否则可能会导致可执行文件不能执行等问题。\n2.5.1 使用io.Copy 方法简单，但是缺少灵活性。如果文件太大，不是一种很好的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func copy(src, dst string) (int64, error) { // 获取文件权限 sourceFileStat, err := os.Stat(src) if err != nil { return 0, err } perm := sourceFileStat.Mode() // 判断文件状态 if !perm.IsRegular() { return 0, fmt.Errorf(\u0026#34;%s is not a regular file\u0026#34;, src) } // 打开源文件 source, err := os.Open(src) if err != nil { return 0, err } defer source.Close() // 创建目标文件 // destination, err := os.Create(dst)\t//无法复制源文件的所有权限 //复制源文件的所有权限 destination, err := os.OpenFile(des, os.O_RDWR|os.O_CREATE|os.O_TRUNC, perm) if err != nil { return 0, err } defer destination.Close() // 拷贝 nBytes, err := io.Copy(destination, source) return nBytes, err 2.5.2 使用ioutil包WriteFile() 和 ReadFile() 一次性读取输入文件，然后再一次性写入目标文件。依然不是很高效的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func CopyFile(src, des string) (written int64, err error) { // 打开源文件 srcFile, err := os.Open(src) if err != nil { return 0, err } defer srcFile.Close() // 获取源文件的权限 fi, _ := srcFile.Stat() perm := fi.Mode() // 打开并读取源文件 input, err := ioutil.ReadFile(src) if err != nil { fmt.Println(err) return 0, err } // 创建并写入目标文件 err = ioutil.WriteFile(des, input, perm) if err != nil { fmt.Println(\u0026#34;Error creating\u0026#34;, destinationFile, err) return 0, err } return int64(len(input)), nil 2.5.3 使用os包Read() 和 Write() 使用buffer一块块地复制文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 func CopyFile(src string, des string, bufSize int) (written int64, err error) { if bufSize \u0026lt;= 0 { bufSize = 1*1024*1024 // buf大小1M } buf := make([]byte, bufSize) // 打开源文件 srcFile, err := os.Open(src) if err != nil { return 0, err } defer srcFile.Close() // 获取文件权限 fileInfo, _ := srcFile.Stat() perm := fileInfo.Mode() // 打开目标文件+原权限 destFile, err := os.OpenFile(des, os.O_RDWR|os.O_CREATE|os.O_TRUNC, perm) if err != nil { return 0, err } defer destFile.Close() count := 0 for { n, err := srcFile.Read(buf) if err != nil \u0026amp;\u0026amp; err != io.EOF { return err } if n == 0 { break } if wn, err := destFile.Write(buf[:n]); err != nil { return err } else{ count += wn } } return int64(count), nil } Reference path/filepath — 兼容操作系统的文件路径操作\nAppend to an existing file in Go (Golang)\n","description":"","id":68,"section":"posts","tags":["Go"],"title":"Go-Path-文件路径操作汇总","uri":"https://hex-go.github.io/posts/golang/2020-09-22-go-path-%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E6%93%8D%E4%BD%9C%E6%B1%87%E6%80%BB/"},{"content":"重要 环境说明 安装 使用 Reference hdfs golang client 非webhdfs\n","description":"","id":69,"section":"posts","tags":["Go"],"title":"Go-HDFS-操作hdfs文件系统","uri":"https://hex-go.github.io/posts/golang/2020-09-22-go-hdfs-%E6%93%8D%E4%BD%9Chdfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"content":"重要 环境说明 安装 使用 Reference 英伟达官方文档\ngpu-operator文档地址\ngpu-operator官方架构说明\ngpu-operator架构博客\ngpu-operator GitHub地址\ngpu-operator issue 在CentOS8部署失败\nCentOS 7.8 Support - GLIBC_2.27\nk8s-gpu-device-plugin\nGPU管理 和 DevicePlugin工作机制\nk8s-device-plugin dockerfile.centos7\n","description":"","id":70,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes-GPU-Operator部署centos7.8","uri":"https://hex-go.github.io/posts/kubernetes/2020-09-22-kubernetes-gpu-operator%E9%83%A8%E7%BD%B2centos7.8/"},{"content":"重要 删除切片中元素 Fast版本,改变顺序 此代码复制单个元素，元素长度增加, 运行时间不变。仍是复制单个元素的时间。\n1 2 3 4 5 6 7 8 9 a := []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;} i := 2 // Remove the element at index i from a. a[i] = a[len(a)-1] // Copy last element to index i. a[len(a)-1] = \u0026#34;\u0026#34; // Erase last element (write zero value). a = a[:len(a)-1] // Truncate slice. fmt.Println(a) // [A B E D] Slow版本,保持顺序 此代码复制len(a) - i - 1元素，元素长度增加, 运行时间呈线性增长。\n1 2 3 4 5 6 7 8 9 a := []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;} i := 2 // Remove the element at index i from a. copy(a[i:], a[i+1:]) // Shift a[i+1:] left one index. a[len(a)-1] = \u0026#34;\u0026#34; // Erase last element (write zero value). a = a[:len(a)-1] // Truncate slice. fmt.Println(a) // [A B D E] Reference Slice中删除元素的两种方式\nHow to delete an element from a Slice in Golang\n","description":"","id":71,"section":"posts","tags":["Go"],"title":"Go-Slice-切片操作汇总","uri":"https://hex-go.github.io/posts/golang/2020-09-22-go-slice-%E5%88%87%E7%89%87%E6%93%8D%E4%BD%9C%E6%B1%87%E6%80%BB/"},{"content":"重要 最重要的事:\n1.简介 Reference ubuntu出现\u0026quot;/dev/disk/by-uuid/xxxxxxxxx does not exist. Dropping to a shell \u0026ldquo;的恢复之路\nALERT! UUID=xxxxxxxxx does not exist. Dropping to a shell!\n卸载不能用的grub image\nhttps://askubuntu.com/questions/1273121/ubuntu-20-04-does-not-boot-after-kernel-grub-update\nhttps://askubuntu.com/questions/1273758/kernel-panic-after-update-from-16-04-lts-to-18-04-lts-virtual-machine-lubuntu\nhttps://www.reddit.com/r/zfs/comments/ilthfp/zfs_zvols_and_lvm_partitions_created_thru_libvirt/\n","description":"","id":72,"section":"posts","tags":["个人工具","Ubuntu"],"title":"Go-Ubuntu18.04-grub导致开机异常","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-09-22-ubuntu18.04_grub%E5%AF%BC%E8%87%B4%E5%BC%80%E6%9C%BA%E5%BC%82%E5%B8%B8/"},{"content":"重要 keycloak AccessToken验证过程\n1、解码 token（注意是解码，不是解密，因为token是不加密的，只是按照一定规则进行编码，并签名）。\n2、取得配置的 publickey（含 kid），或根据配置的keycloak地址和realm信息，调用keycloak的Rest接口（ /realms/{realm-name}/protocol/openid-connect/certs）查询publicKey(含kid)。\n3、从步骤2中得到的publicKey中，查找与步骤1中得到的kid匹配的publicKey。\n4、如果找不到对应的publicKey，则报异常：Didn\u0026rsquo;t find publicKey for specified kid。\n5、使用publicKey验证签名\n6、检查Token中的subject属性是否为空，为空则报异常：Subject missing in token\n7、检查配置realm url 与 token中的issuer是否匹配，不匹配则报异常：Invalid token issuer. Expected {realm url}, but was {issuer}\n7、检查token是否已过期，已过期，则报异常：Token is not active\ntoken 中的内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 { \u0026#34;exp\u0026#34;: 1600417728, # Expiration time Token过期时间 \u0026#34;iat\u0026#34;: 1600417428,\t# Issued at Token签发时间 \u0026#34;jti\u0026#34;: \u0026#34;541da01d-5fb8-4985-8ef7-9ebd6939c129\u0026#34;,\t# JWT ID \u0026#34;iss\u0026#34;: \u0026#34;http://192.168.10.240:8082/auth/realms/icos\u0026#34;,\t# Issuer 签发者 \u0026#34;aud\u0026#34;: [ \u0026#34;realm-management\u0026#34;, \u0026#34;keycloakos\u0026#34;, \u0026#34;account\u0026#34; ], \u0026#34;sub\u0026#34;: \u0026#34;605b699b-65b9-4f63-87ae-fd1f14ff45a7\u0026#34;,\t# Subject \u0026#34;typ\u0026#34;: \u0026#34;Bearer\u0026#34;, \u0026#34;azp\u0026#34;: \u0026#34;icosdeploy\u0026#34;, \u0026#34;session_state\u0026#34;: \u0026#34;9b6c82bf-785a-4975-98bb-d5b1f7c04c03\u0026#34;, \u0026#34;acr\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;realm_access\u0026#34;: { \u0026#34;roles\u0026#34;: [ \u0026#34;admin\u0026#34; ] }, \u0026#34;resource_access\u0026#34;: { \u0026#34;realm-management\u0026#34;: { \u0026#34;roles\u0026#34;: [ \u0026#34;query-groups\u0026#34; ] }, \u0026#34;keycloakos\u0026#34;: { \u0026#34;roles\u0026#34;: [ \u0026#34;admin\u0026#34; ] }, \u0026#34;account\u0026#34;: { \u0026#34;roles\u0026#34;: [ \u0026#34;view-profile\u0026#34; ] } }, \u0026#34;scope\u0026#34;: \u0026#34;openid profile email\u0026#34;, \u0026#34;email_verified\u0026#34;: false, \u0026#34;name\u0026#34;: \u0026#34;a dmin\u0026#34;, \u0026#34;groups\u0026#34;: [], \u0026#34;preferred_username\u0026#34;: \u0026#34;admin\u0026#34;,\t# 用户名 \u0026#34;given_name\u0026#34;: \u0026#34;a\u0026#34;, \u0026#34;family_name\u0026#34;: \u0026#34;dmin\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;admin@123.com\u0026#34; } 环境说明 安装 使用 Reference Go 使用keycloak进行jwt认证\nkeycloak bearer-only clients: why do they exist?\n在Keycloak中生成JWT令牌并获取公钥在第三方平台上验证JWT令牌\nKeycloak AccessToken 验证示例\n使用Keycloak和Spring Oauth2保护REST API\ngolang使用jwt做身份验证\nOAuth 2.0授权框架\nKeycloak adaptor for golang application (OIDC package)\ngithub OIDC Proxy\ngithub goth - 为编写身份验证提供了一种简单、干净和惯用的方法\n","description":"","id":73,"section":"posts","tags":["Go"],"title":"Go-Keycloak-BearerOnlyToken校验","uri":"https://hex-go.github.io/posts/golang/2020-09-22-go-keycloak-beareronlytoken%E6%A0%A1%E9%AA%8C/"},{"content":"重要 打算依托Tekton,作为工作流工具，将以下业务场景用task实现：\n镜像部署 源码构建+镜像部署 源码文件上传hdfs 微服务依赖关系 环境说明 k8s集群：\n安装 Tekton安装，通过官方GitHub仓库中的release.yaml文件部署服务。\n1 kubectl apply -f https://github.com/tektoncd/pipeline/releases/download/v0.16./release.yaml 使用 需要检查这几项, workspace\nReference 官方文档入口-select-version\nnuctl nuctl 是nuclio的客户端, nuctl使用时需要访问docker-daemon,\n1 2 3 4 $ nuctl get project --verbose 20.10.20 16:53:48.316 nuctl.platform (D) Using kubeconfig {\u0026#34;kubeconfigPath\u0026#34;: \u0026#34;/home/hex/.kube/config\u0026#34;} 20.10.20 16:53:48.324 tl.platform.docker.runner (D) Executing {\u0026#34;command\u0026#34;: \u0026#34;docker version\u0026#34;} 20.10.20 16:53:48.388 tl.platform.docker.runner (D) Command executed successfully {\u0026#34;output\u0026#34;: \u0026#34;Client: Docker Engine - Community\\n Version: 19.03.4\\n API version: 1.40\\n Go version: go1.12.10\\n Git commit: 9013bf583a\\n Built: Fri Oct 18 15:54:09 2019\\n OS/Arch: linux/amd64\\n Experimental: false\\n\\nServer: Docker Engine - Community\\n Engine:\\n Version: 19.03.4\\n API version: 1.40 (minimum version 1.12)\\n Go version: go1.12.10\\n Git commit: 9013bf583a\\n Built: Fri Oct 18 15:52:40 2019\\n OS/Arch: linux/amd64\\n Experimental: false\\n containerd:\\n Version: 1.2.10\\n GitCommit: b34a5c8af56e510852c35414db4c1f4fa6172339\\n runc:\\n Version: 1.0.0-rc8+dev\\n GitCommit: 3e425f80a8c931f88e6d94a8c831b9d5aa481657\\n docker-init:\\n Version: 0.18.0\\n GitCommit: fec3683\\n\u0026#34;, \u0026#34;stderr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;exitCode\u0026#34;: 0} 所以需要创建docker-in-docker的服务\ntask docker-in-docker\ndind issue\n构建镜像(kaniko) task kaniko\ntask之间传递数据(通过 result 配置) 传出result\n传出result \u0026ndash; task级别\n传出result \u0026ndash; pipe级别\n传入result \u0026ndash; task级别\n使用when做任务编排 任务编排 \u0026ndash; when\n使用runAfter做任务编排 任务编排 \u0026ndash; runAfter\nworkspace 工作空间使用\nauth Authorization at RunTime\n","description":"","id":74,"section":"posts","tags":["Go"],"title":"Go-Tekton使用-使用示例以及遇坑小记","uri":"https://hex-go.github.io/posts/golang/2020-09-16-go-tekton%E4%BD%BF%E7%94%A8-%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%E4%BB%A5%E5%8F%8A%E9%81%87%E5%9D%91%E5%B0%8F%E8%AE%B0/"},{"content":"引言 由于GitHub访问需要通过科学上网，因此需要配置git客户端通过proxy与github通信；但公司内网的git仓库不能走proxy，否则访问不通。因此需要查找git配置实现如下状态：\n所有github仓库走代理 所有内网仓库不走代理 现状 由于github仓库拉取缓慢，所以配置了代理； 但内网仓库拉取也走了代理，导致出现以下报错\n1 2 hex@hex-pc:~/example-repo$ git pull fatal: unable to access \u0026#39;https://git.service.rd/plugins/git/example-repo.git/\u0026#39;: gnutls_handshake() failed: The TLS connection was non-properly terminated. 办法一(推荐) git是可以根据环境变量的配置，声明代理并将内网地址配置不走代理，实现此功能，但要注意格式。\n1 2 3 4 5 6 7 export https_proxy=http://127.0.0.1:10800/ export http_proxy=http://127.0.0.1:10800/ export all_proxy=socks://127.0.0.1:1088/ export ftp_proxy=http://127.0.0.1:10800 # 声明内网不走proxy的服务 声明域名作为通配，以空格分隔。 export no_proxy=\u0026#34;.service.rd .local.domain 127.0.0.1 localhost\u0026#34; 方法二：修改本地库-local配置 也可以针对仓库设置git config。可以设置本地库全局配置，也可以只设置单一远端。\n进入仓库目录下，为当前仓库，添加一个“空”代理（仓库级别）。 1 git config --local --add http.proxy \u0026#34;\u0026#34; 在仓库目录下\u0026lt;repo_path\u0026gt;/.git/config，会出现以下内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \u0026#34;origin\u0026#34;] url = https://git.service.rd/plugins/git/example.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \u0026#34;master\u0026#34;] remote = origin merge = refs/heads/master [http] proxy = 进入仓库目录下，为名称为\u0026lt;name\u0026gt;的远端，添加一个”空“代理。 1 git config --local --add remote.\u0026lt;name\u0026gt;.proxy \u0026#34;\u0026#34; 执行下面命令查看\n1 git config --local --get remote.\u0026lt;name\u0026gt;.proxy 方法三：修改全局配置（只能针对单库） 修改 ~/.gitconfig文件，增加以下内容\n1 2 3 4 5 [http] sslVerify = true [http \u0026#34;https://git.service.rd/plugins/git/example-repo.git\u0026#34;] sslVerify = false ptoxy = ","description":"","id":75,"section":"posts","tags":["个人工具","Git"],"title":"科学上网（2） GIT配置proxy并忽略内网仓库","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-09-05-%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91-2_git%E9%85%8D%E7%BD%AEproxy%E5%B9%B6%E5%BF%BD%E7%95%A5%E5%86%85%E7%BD%91%E4%BB%93%E5%BA%93/"},{"content":"重要 环境说明 安装 使用 Reference ","description":"","id":76,"section":"posts","tags":["Go"],"title":"Go-fmt格式化IO","uri":"https://hex-go.github.io/posts/golang/2020-09-04-go-fmt%E6%A0%BC%E5%BC%8F%E5%8C%96io/"},{"content":"重要 defer语句是Go中一个非常有用的特性，可以将一个方法延迟到包裹defer的方法返回时执行，在实际应用中，defer可以充当其他语言中try…catch…的角色，\n也可以用来处理关闭文件句柄等收尾操作。\n1. defer使用 1.1 defer触发的时机 A \u0026ldquo;defer\u0026rdquo; statement invokes a function whose execution is deferred to the moment the surrounding function returns, either because the surrounding function executed a return statement, reached the end of its function body, or because the corresponding goroutine is panicking.\n官方文档指出，执行defer的时机为：\n包裹defer的函数返回时 包裹defer的函数执行到末尾时 所在的goroutine发生panic时 1.2 defer执行顺序 当一个方法中有多个defer时， defer会将要延迟执行的方法压栈，当defer被触发时，将所有压栈的方法出栈并执行。\n所以defer的执行顺序是LIFO的。\n例如\n1 2 3 4 5 6 7 8 9 10 11 func stackingDefers() { defer func() { fmt.Println(\u0026#34;1\u0026#34;) }() defer func() { fmt.Println(\u0026#34;2\u0026#34;) }() defer func() { fmt.Println(\u0026#34;3\u0026#34;) }() } 结果为：\n1 2 3 3 2 1 2. 坑 2.1 返回值是否匿名表现不同 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 匿名返回值 (int)，输出 0 func returnValues() int { var result int defer func() { result++ fmt.Println(\u0026#34;defer\u0026#34;) }() return result } // 命名返回值（result int）， 输出 1 // 因为return与defer是同时触发。 func namedReturnValues() (result int) { defer func() { result++ fmt.Println(\u0026#34;defer\u0026#34;) }() return result } 匿名返回执行顺序为：\n将result赋值给返回值(相当于， returnValue=result=0)；\n检查到defer，执行defer的语句，变量result值+1(result=1)；\n返回函数返回值，returnValue(returnValue=0)。\n命名返回值执行顺序为：\n返回值被声明为result； 检查到defer，执行defer的语句，变量result值+1(result=1)； 返回函数返回值，result(result=1)。 注意与python的浅拷贝区分开\n2.2 for循环中使用可能导致的性能问题 比如：\n1 2 3 4 5 6 func deferInLoops() { for i := 0; i \u0026lt; 100; i++ { f, _ := os.Open(\u0026#34;/etc/hosts\u0026#34;) defer f.Close() } } 此处defer f.Close()在创建文件对象后声明，看起来没有什么问题。但是和直接调用f.Close()相比，defer的执行存在着额外的开销。\ndefer会存在两方面的资源开销：\ndefer对其后需要的参数进行内存拷贝； 还需要对defer结构进行压栈出栈操作。 可以将f.Close()语句前的defer去掉，直接调用f.close()来减少大量defer导致的额外资源消耗。\n2.3 必须判断执行成功，再defer释放资源 如果获取资源的操作返回err参数：\n不使用defer, 可以选择忽略返回的err参数;\n使用defer进行延迟释放, 在使用defer之前先判断是否存在err。\n资源没有获取成功，对资源执行释放操作会导致释放方法执行报错。必须判断是否获取成功，再释放资源。\n正确写法：\n1 2 3 4 5 6 7 resp, err := http.Get(url) // 先判断操作是否成功 if err != nil { return err } // 如果操作成功，再进行Close操作 defer resp.Body.Close() 2.4 调用os.Exit时defer不会被执行 当发生panic时，所在goroutine的所有defer会被执行，但是当调用os.Exit()方法退出程序时，defer不会执行。\n下面例子中defer不会输出：\n1 2 3 4 5 6 func deferExit() { defer func() { fmt.Println(\u0026#34;defer\u0026#34;) }() os.Exit(0) } Reference Go语言中defer的一些坑\n","description":"","id":77,"section":"posts","tags":["Go"],"title":"Go-Defer说明","uri":"https://hex-go.github.io/posts/golang/2020-09-03-go-defer%E8%AF%B4%E6%98%8E/"},{"content":"重要 环境说明 安装 使用 Reference 内存内实现任务队列\n国外(原创)\n国内(第一抄)\n国内(第二)\n基于redis实现消息队列\nharbor-trivy-scanner\n原理\ngo语言并发\n","description":"","id":78,"section":"posts","tags":["Go"],"title":"Go-并发实践","uri":"https://hex-go.github.io/posts/golang/2020-09-03-go-%E5%B9%B6%E5%8F%91%E5%AE%9E%E8%B7%B5/"},{"content":"字符串常见操作有：\n字符串长度；\n求子串；\n是否存在某个字符或子串；\n子串出现的次数（字符串匹配）；\n字符串分割（切分）为[]string；\n字符串是否有某个前缀或后缀；\n字符或子串在字符串中首次出现的位置或最后一次出现的位置；\n通过某个字符串将[]string 连接起来；\n字符串重复几次；\n字符串中子串替换；\n大小写转换；\nTrim 操作；\n\u0026hellip;\nstring 类型可以看成是一种特殊的 slice 类型，因此获取长度可以用内置的函数 len；同时支持 切片 操作，因此，子串获取很容易。\n说明：这里说的String，指得是 rune 类型，即一个 UTF-8 字符（Unicode 代码点）。\n1. 正文 1.1 字符串长度 string 类型可以看成是一种特殊的 slice 类型，因此获取长度可以用内置的函数 len；同时支持 切片 操作，因此，子串获取很容易。\n1.2 字符串比较 1 2 3 4 5 // Compare 函数，用于比较两个字符串的大小，如果两个字符串相等，返回为 0。如果 a 小于 b ，返回 -1 ，反之返回 1 。不推荐使用这个函数，直接使用 == != \u0026gt; \u0026lt; \u0026gt;= \u0026lt;= 等一系列运算符更加直观。 func Compare(a, b string) int // EqualFold 函数，计算 s 与 t 忽略字母大小写后是否相等。 func EqualFold(s, t string) bool 示例：\n1 2 3 4 5 6 7 8 a := \u0026#34;gopher\u0026#34; b := \u0026#34;hello world\u0026#34; fmt.Println(strings.Compare(a, b)) fmt.Println(strings.Compare(a, a)) fmt.Println(strings.Compare(b, a)) fmt.Println(strings.EqualFold(\u0026#34;GO\u0026#34;, \u0026#34;go\u0026#34;)) fmt.Println(strings.EqualFold(\u0026#34;壹\u0026#34;, \u0026#34;一\u0026#34;)) 输出结果：\n1 2 3 4 5 -1 0 1 true false 1.3. 是否存在某个字符或子串 有三个函数做这件事：\n1 2 3 4 5 6 // 子串 substr 在 s 中，返回 true func Contains(s, substr string) bool // chars 中任何一个 Unicode 代码点在 s 中，返回 true func ContainsAny(s, chars string) bool // Unicode 代码点 r 在 s 中，返回 true func ContainsRune(s string, r rune) bool 这里对 ContainsAny 函数进行一下说明，看如下例子：\n1 2 3 4 5 fmt.Println(strings.ContainsAny(\u0026#34;team\u0026#34;, \u0026#34;i\u0026#34;)) fmt.Println(strings.ContainsAny(\u0026#34;failure\u0026#34;, \u0026#34;u \u0026amp; i\u0026#34;)) fmt.Println(strings.ContainsAny(\u0026#34;in failure\u0026#34;, \u0026#34;s g\u0026#34;)) fmt.Println(strings.ContainsAny(\u0026#34;foo\u0026#34;, \u0026#34;\u0026#34;)) fmt.Println(strings.ContainsAny(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;)) 输出结果：\n1 2 3 4 5 false true true false false 说明，第二个参数 chars 中任意一个字符（Unicode Code Point）如果在第一个参数 s 中存在，则返回 true。\n查看这三个函数的源码，发现它们只是调用了相应的 Index 函数（子串出现的位置），然后和 0 作比较返回 true 或 fale。如，Contains：\n1 2 3 func Contains(s, substr string) bool { return Index(s, substr) \u0026gt;= 0 } 关于 Index 相关函数的实现，我们后面介绍。\n1.3. 子串出现次数 ( 字符串匹配 ) 在数据结构与算法中，可能会讲解以下字符串匹配算法：\n朴素匹配算法 KMP 算法 Rabin-Karp 算法 Boyer-Moore 算法 \u0026hellip; 在 Go 中，查找子串出现次数(字符串模式匹配)，是通过 Rabin-Karp 算法实现的。Count 函数的签名如下：\n1 func Count(s, sep string) int 在 Count 函数中，处理了几种特殊情况，属于字符匹配预处理的一部分。要注意：当 sep 为空时，Count 的返回值是：utf8.RuneCountInString(s) + 1\n1 2 3 fmt.Println(strings.Count(\u0026#34;cheese\u0026#34;, \u0026#34;e\u0026#34;)) fmt.Println(len(\u0026#34;谷歌中国\u0026#34;)) fmt.Println(strings.Count(\u0026#34;谷歌中国\u0026#34;, \u0026#34;\u0026#34;)) 输出：\n1 2 3 3 12 5 Count 是计算子串在字符串中出现的无重叠的次数，比如：\n1 fmt.Println(strings.Count(\u0026#34;fivevev\u0026#34;, \u0026#34;vev\u0026#34;)) 输出：\n1 1 1.4. 字符串分割为[]string Strings包提供了六个三组函数：Fields 和 FieldsFunc、Split 和 SplitAfter、SplitN 和 SplitAfterN。\n1.4.1 Fields 和 FieldsFunc 这两个函数的签名如下：\n1 2 func Fields(s string) []string func FieldsFunc(s string, f func(rune) bool) []string Fields 用一个或多个连续的空格分隔字符串 s，返回子字符串的数组（slice）。如果字符串 s 只包含空格，则返回空列表 ([]string 的长度为 0）。其中，空格的定义是 unicode.IsSpace。\n常见间隔符包括：\u0026rsquo;\\t\u0026rsquo;, \u0026lsquo;\\n\u0026rsquo;, \u0026lsquo;\\v\u0026rsquo;, \u0026lsquo;\\f\u0026rsquo;, \u0026lsquo;\\r\u0026rsquo;, \u0026rsquo; \u0026lsquo;, U+0085 (NEL), U+00A0 (NBSP)\n由于是用空格分隔，因此结果中不会含有空格或空子字符串，例如：\n1 fmt.Printf(\u0026#34;Fields are: %q\u0026#34;, strings.Fields(\u0026#34; foo bar baz \u0026#34;)) 输出结果：\n1 Fields are: [\u0026#34;foo\u0026#34; \u0026#34;bar\u0026#34; \u0026#34;baz\u0026#34;] FieldsFunc 用这样的 Unicode 代码点 c 进行分隔：满足 f(c) 返回 true。该函数返回[]string。如果字符串 s 中所有的代码点 (unicode code points) 都满足 f(c) 或者 s 是空，则 FieldsFunc 返回空 slice。\n也就是说，我们可以通过实现一个回调函数来指定分隔字符串 s 的字符。比如上面的例子，我们通过 FieldsFunc 来实现：\n1 fmt.Println(strings.FieldsFunc(\u0026#34; foo bar baz \u0026#34;, unicode.IsSpace)) 实际上，Fields 函数就是调用 FieldsFunc 实现的：\n1 2 3 func Fields(s string) []string { return FieldsFunc(s, unicode.IsSpace) } 1.4.2. Split 和 SplitAfter、 SplitN 和 SplitAfterN 四个函数通过调用同一个内部函数实现：\n1 2 3 4 func Split(s, sep string) []string { return genSplit(s, sep, 0, -1) } func SplitAfter(s, sep string) []string { return genSplit(s, sep, len(sep), -1) } func SplitN(s, sep string, n int) []string { return genSplit(s, sep, 0, n) } func SplitAfterN(s, sep string, n int) []string { return genSplit(s, sep, len(sep), n) } 都调用了 genSplit 函数。\n这四个函数都是通过 sep 进行分割，返回[]string。如果 sep 为空，相当于分成一个个的 UTF-8 字符，如 ：\nSplit(\u0026quot;abc\u0026quot;,\u0026quot;\u0026quot;)，得到的是[a b c]。\nSplit(s, sep) 和SplitN(s, sep, -1)等价；\nSplitAfter(s, sep) 和 SplitAfterN(s, sep, -1) 等价。\nSplit 和 SplitAfter的区别是 Split 会将 s 中的 sep 去掉，而 SplitAfter 会保留 sep。\n1 2 fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;foo,bar,baz\u0026#34;, \u0026#34;,\u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.SplitAfter(\u0026#34;foo,bar,baz\u0026#34;, \u0026#34;,\u0026#34;)) 输出：\n1 2 [\u0026#34;foo\u0026#34; \u0026#34;bar\u0026#34; \u0026#34;baz\u0026#34;] [\u0026#34;foo,\u0026#34; \u0026#34;bar,\u0026#34; \u0026#34;baz\u0026#34;] 带 N 的方法可以通过最后一个参数 n 控制返回的结果中的 slice 中的元素个数：\n当 n \u0026lt; 0 时，返回所有的子字符串；\n当 n == 0 时，返回的结果是 nil；\n当 n \u0026gt; 0 时，表示返回的 slice 中最多只有 n 个元素；\n其中，最后一个元素不会分割，比如：\n1 fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.SplitN(\u0026#34;foo,bar,baz\u0026#34;, \u0026#34;,\u0026#34;, 2)) 输出：\n1 [\u0026#34;foo\u0026#34; \u0026#34;bar,baz\u0026#34;] 官方文档提供的例子，输出结果：\n1 2 3 4 fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;a,b,c\u0026#34;, \u0026#34;,\u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;a man a plan a canal panama\u0026#34;, \u0026#34;a \u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34; xyz \u0026#34;, \u0026#34;\u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;\u0026#34;, \u0026#34;Bernardo O\u0026#39;Higgins\u0026#34;)) 输出：\n1 2 3 4 [\u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34;] [\u0026#34;\u0026#34; \u0026#34;man \u0026#34; \u0026#34;plan \u0026#34; \u0026#34;canal panama\u0026#34;] [\u0026#34; \u0026#34; \u0026#34;x\u0026#34; \u0026#34;y\u0026#34; \u0026#34;z\u0026#34; \u0026#34; \u0026#34;] [\u0026#34;\u0026#34;] 1.5. 字符串是否有某个前缀或后缀 两个函数HasPrefix和HasSuffix：\n1 2 3 4 5 6 7 8 // s 中是否以 prefix 开始 func HasPrefix(s, prefix string) bool { return len(s) \u0026gt;= len(prefix) \u0026amp;\u0026amp; s[0:len(prefix)] == prefix } // s 中是否以 suffix 结尾 func HasSuffix(s, suffix string) bool { return len(s) \u0026gt;= len(suffix) \u0026amp;\u0026amp; s[len(s)-len(suffix):] == suffix } 如果 prefix 或 suffix 为 \u0026quot;\u0026quot; , 返回值总是 true。\n示例：\n1 2 3 4 5 6 fmt.Println(strings.HasPrefix(\u0026#34;Gopher\u0026#34;, \u0026#34;Go\u0026#34;)) fmt.Println(strings.HasPrefix(\u0026#34;Gopher\u0026#34;, \u0026#34;C\u0026#34;)) fmt.Println(strings.HasPrefix(\u0026#34;Gopher\u0026#34;, \u0026#34;\u0026#34;)) fmt.Println(strings.HasSuffix(\u0026#34;Amigo\u0026#34;, \u0026#34;go\u0026#34;)) fmt.Println(strings.HasSuffix(\u0026#34;Amigo\u0026#34;, \u0026#34;Ami\u0026#34;)) fmt.Println(strings.HasSuffix(\u0026#34;Amigo\u0026#34;, \u0026#34;\u0026#34;)) 输出结果：\n1 2 3 4 5 6 true false true true false true 1.6. 字符或子串在字符串中出现的位置 Index函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 在 s 中查找 sep 的第一次出现，返回第一次出现的索引 func Index(s, sep string) int // 在 s 中查找字节 c 的第一次出现，返回第一次出现的索引 func IndexByte(s string, c byte) int // chars 中任何一个 Unicode 代码点在 s 中首次出现的位置 func IndexAny(s, chars string) int // 查找字符 c 在 s 中第一次出现的位置，其中 c 满足 f(c) 返回 true func IndexFunc(s string, f func(rune) bool) int // Unicode 代码点 r 在 s 中第一次出现的位置 func IndexRune(s string, r rune) int // 有三个对应的查找最后一次出现的位置 func LastIndex(s, sep string) int func LastIndexByte(s string, c byte) int func LastIndexAny(s, chars string) int func LastIndexFunc(s string, f func(rune) bool) int 1.3小节Contain 相关的函数内部调用的是响应的 Index 函数。\nIndexFunc 举例：\n1 2 3 4 5 han := func(c rune) bool { return unicode.Is(unicode.Han, c) // 汉字 } fmt.Println(strings.IndexFunc(\u0026#34;Hello, world\u0026#34;, han)) fmt.Println(strings.IndexFunc(\u0026#34;Hello, 世界\u0026#34;, han)) 输出：\n1 2 -1 7 1.7. 字符串 JOIN 操作 Join函数 实现 字符串或数组连接 ：\n1 func Join(a []string, sep string) string 自己实现：\n使用了 bytes 包的 Buffer 类型，避免大量的字符串连接操作（因为 Go 中字符串是不可变的）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func Join(str []string, sep string) string { // 特殊情况应该做处理 if len(str) == 0 { return \u0026#34;\u0026#34; } if len(str) == 1 { return str[0] } buffer := bytes.NewBufferString(str[0]) for _, s := range str[1:] { buffer.WriteString(sep) buffer.WriteString(s) } return buffer.String() } 标准库的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func Join(a []string, sep string) string { if len(a) == 0 { return \u0026#34;\u0026#34; } if len(a) == 1 { return a[0] } n := len(sep) * (len(a) - 1) for i := 0; i \u0026lt; len(a); i++ { n += len(a[i]) } b := make([]byte, n) bp := copy(b, a[0]) for _, s := range a[1:] { bp += copy(b[bp:], sep) bp += copy(b[bp:], s) } return string(b) } 标准库的实现没有用 bytes 包，当然也不会简单的通过 + 号连接字符串。Go 中是不允许循环依赖的，标准库中很多时候会出现代码拷贝，而不是引入某个包。这里 Join 的实现方式挺好，我个人猜测，不直接使用 bytes 包，也是不想依赖 bytes 包（其实 bytes 中的实现也是 copy 方式）。\n简单使用示例：\n1 fmt.Println(Join([]string{\u0026#34;name=xxx\u0026#34;, \u0026#34;age=xx\u0026#34;}, \u0026#34;\u0026amp;\u0026#34;)) 输出结果:\n1 name=xxx\u0026amp;age=xx 1.8. 字符串重复几次 函数签名如下：\n1 func Repeat(s string, count int) string 将 s 重复 count 次，如果 count 为负数或返回值长度 len(s)*count 超出 string 上限会导致 panic，这个函数使用很简单：\n1 fmt.Println(\u0026#34;ba\u0026#34; + strings.Repeat(\u0026#34;na\u0026#34;, 2)) 输出结果：\n1 banana 1.9. 字符替换 1 func Map(mapping func(rune) rune, s string) string Map 函数，将 s 的每一个字符按照 mapping 的规则做映射替换，如果 mapping 返回值 \u0026lt;0 ，则舍弃该字符。该方法只能对每一个字符做处理，但处理方式很灵活，可以方便的过滤，筛选汉字等。\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 mapping := func(r rune) rune { switch { case r \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; r \u0026lt;= \u0026#39;Z\u0026#39;: // 大写字母转小写 return r + 32 case r \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; r \u0026lt;= \u0026#39;z\u0026#39;: // 小写字母不处理 return r case unicode.Is(unicode.Han, r): // 汉字换行 return \u0026#39;\\n\u0026#39; } return -1 // 过滤所有非字母、汉字的字符 } fmt.Println(strings.Map(mapping, \u0026#34;Hello你#￥%……\\n（\u0026#39;World\\n,好Hello^(\u0026amp;(*界gopher...\u0026#34;)) 输出结果：\n1 2 3 4 hello world hello gopher 1.10. 字符串子串替换 进行字符串替换时，考虑到性能问题，能不用正则尽量别用，应该用这里的函数。\n字符串替换的函数签名如下：\n1 2 3 4 5 // 用 new 替换 s 中的 old，一共替换 n 个。 // 如果 n \u0026lt; 0，则不限制替换次数，即全部替换 func Replace(s, old, new string, n int) string // 该函数内部直接调用了函数 Replace(s, old, new , -1) func ReplaceAll(s, old, new string) string 使用示例：\n1 2 3 fmt.Println(strings.Replace(\u0026#34;oink oink oink\u0026#34;, \u0026#34;k\u0026#34;, \u0026#34;ky\u0026#34;, 2)) fmt.Println(strings.Replace(\u0026#34;oink oink oink\u0026#34;, \u0026#34;oink\u0026#34;, \u0026#34;moo\u0026#34;, -1)) fmt.Println(strings.ReplaceAll(\u0026#34;oink oink oink\u0026#34;, \u0026#34;oink\u0026#34;, \u0026#34;moo\u0026#34;)) 输出：\n1 2 3 oinky oinky oink moo moo moo moo moo moo 如果我们希望一次替换多个，比如我们希望替换 This is \u0026lt;b\u0026gt;HTML\u0026lt;/b\u0026gt; 中的 \u0026lt; 和 \u0026gt; 为 \u0026amp;lt; 和 \u0026amp;gt;;，可以调用上面的函数两次。但标准库提供了另外的方法进行这种替换。\n1.11 大小写转换 1 2 3 4 func ToLower(s string) string func ToLowerSpecial(c unicode.SpecialCase, s string) string func ToUpper(s string) string func ToUpperSpecial(c unicode.SpecialCase, s string) string 大小写转换包含了 4 个相关函数，ToLower和ToUpper 用于大小写转换。ToLowerSpecial和ToUpperSpecial 可以转换特殊字符的大小写。 举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 fmt.Println(strings.ToLower(\u0026#34;HELLO WORLD\u0026#34;)) fmt.Println(strings.ToLower(\u0026#34;Ā Á Ǎ À\u0026#34;)) fmt.Println(strings.ToLowerSpecial(unicode.TurkishCase, \u0026#34;壹\u0026#34;)) fmt.Println(strings.ToLowerSpecial(unicode.TurkishCase, \u0026#34;HELLO WORLD\u0026#34;)) fmt.Println(strings.ToLower(\u0026#34;Önnek İş\u0026#34;)) fmt.Println(strings.ToLowerSpecial(unicode.TurkishCase, \u0026#34;Önnek İş\u0026#34;)) fmt.Println(strings.ToUpper(\u0026#34;hello world\u0026#34;)) fmt.Println(strings.ToUpper(\u0026#34;ā á ǎ à\u0026#34;)) fmt.Println(strings.ToUpperSpecial(unicode.TurkishCase, \u0026#34;一\u0026#34;)) fmt.Println(strings.ToUpperSpecial(unicode.TurkishCase, \u0026#34;hello world\u0026#34;)) fmt.Println(strings.ToUpper(\u0026#34;örnek iş\u0026#34;)) fmt.Println(strings.ToUpperSpecial(unicode.TurkishCase, \u0026#34;örnek iş\u0026#34;)) 输出结果:\n1 2 3 4 5 6 7 8 9 10 11 12 hello world ā á ǎ à 壹 hello world önnek iş önnek iş HELLO WORLD Ā Á Ǎ À // 汉字拼音有效 一 // 汉字无效 HELLO WORLD ÖRNEK IŞ ÖRNEK İŞ // 有细微差别 1.12. 标题处理 1 2 3 func Title(s string) string func ToTitle(s string) string func ToTitleSpecial(c unicode.SpecialCase, s string) string 标题处理包含 3 个相关函数，其中 Title 会将 s 每个单词的首字母大写，不处理该单词的后续字符。ToTitle 将 s 的每个字母大写。ToTitleSpecial 将 s 的每个字母大写，并且会将一些特殊字母转换为其对应的特殊大写字母。\n举个例子：\n1 2 3 4 5 6 7 8 9 fmt.Println(strings.Title(\u0026#34;hElLo wOrLd\u0026#34;)) fmt.Println(strings.ToTitle(\u0026#34;hElLo wOrLd\u0026#34;)) fmt.Println(strings.ToTitleSpecial(unicode.TurkishCase, \u0026#34;hElLo wOrLd\u0026#34;)) fmt.Println(strings.Title(\u0026#34;āáǎà ōóǒò êēéěè\u0026#34;)) fmt.Println(strings.ToTitle(\u0026#34;āáǎà ōóǒò êēéěè\u0026#34;)) fmt.Println(strings.ToTitleSpecial(unicode.TurkishCase, \u0026#34;āáǎà ōóǒò êēéěè\u0026#34;)) fmt.Println(strings.Title(\u0026#34;dünyanın ilk borsa yapısı Aizonai kabul edilir\u0026#34;)) fmt.Println(strings.ToTitle(\u0026#34;dünyanın ilk borsa yapısı Aizonai kabul edilir\u0026#34;)) fmt.Println(strings.ToTitleSpecial(unicode.TurkishCase, \u0026#34;dünyanın ilk borsa yapısı Aizonai kabul edilir\u0026#34;)) 输出结果：\n1 2 3 4 5 6 7 8 9 HElLo WOrLd HELLO WORLD HELLO WORLD Āáǎà Ōóǒò Êēéěè ĀÁǍÀ ŌÓǑÒ ÊĒÉĚÈ ĀÁǍÀ ŌÓǑÒ ÊĒÉĚÈ Dünyanın Ilk Borsa Yapısı Aizonai Kabul Edilir DÜNYANIN ILK BORSA YAPISI AIZONAI KABUL EDILIR DÜNYANIN İLK BORSA YAPISI AİZONAİ KABUL EDİLİR 1.13. 修剪 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 将 s 左侧和右侧中匹配 cutset 中的任一字符的字符去掉 func Trim(s string, cutset string) string // 将 s 左侧的匹配 cutset 中的任一字符的字符去掉 func TrimLeft(s string, cutset string) string // 将 s 右侧的匹配 cutset 中的任一字符的字符去掉 func TrimRight(s string, cutset string) string // 如果 s 的前缀为 prefix 则返回去掉前缀后的 string , 否则 s 没有变化。 func TrimPrefix(s, prefix string) string // 如果 s 的后缀为 suffix 则返回去掉后缀后的 string , 否则 s 没有变化。 func TrimSuffix(s, suffix string) string // 将 s 左侧和右侧的间隔符去掉。常见间隔符包括：\u0026#39;\\t\u0026#39;, \u0026#39;\\n\u0026#39;, \u0026#39;\\v\u0026#39;, \u0026#39;\\f\u0026#39;, \u0026#39;\\r\u0026#39;, \u0026#39; \u0026#39;, U+0085 (NEL) func TrimSpace(s string) string // 将 s 左侧和右侧的匹配 f 的字符去掉 func TrimFunc(s string, f func(rune) bool) string // 将 s 左侧的匹配 f 的字符去掉 func TrimLeftFunc(s string, f func(rune) bool) string // 将 s 右侧的匹配 f 的字符去掉 func TrimRightFunc(s string, f func(rune) bool) string 包含了 9 个相关函数用于修剪字符串。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 x := \u0026#34;!!!@@@你好,!@#$ Gophers###$$$\u0026#34; fmt.Println(strings.Trim(x, \u0026#34;@#$!%^\u0026amp;*()_+=-\u0026#34;)) fmt.Println(strings.TrimLeft(x, \u0026#34;@#$!%^\u0026amp;*()_+=-\u0026#34;)) fmt.Println(strings.TrimRight(x, \u0026#34;@#$!%^\u0026amp;*()_+=-\u0026#34;)) fmt.Println(strings.TrimSpace(\u0026#34; \\t\\n Hello, Gophers \\n\\t\\r\\n\u0026#34;)) fmt.Println(strings.TrimPrefix(x, \u0026#34;!\u0026#34;)) fmt.Println(strings.TrimSuffix(x, \u0026#34;$\u0026#34;)) f := func(r rune) bool { return !unicode.Is(unicode.Han, r) // 非汉字返回 true } fmt.Println(strings.TrimFunc(x, f)) fmt.Println(strings.TrimLeftFunc(x, f)) fmt.Println(strings.TrimRightFunc(x, f)) 输出结果：\n1 2 3 4 5 6 7 8 9 你好,!@#$ Gophers 你好,!@#$ Gophers###$$$ !!!@@@你好,!@#$ Gophers Hello, Gophers !!@@@你好,!@#$ Gophers###$$$ !!!@@@你好,!@#$ Gophers###$$ 你好 你好,!@#$ Gophers###$$$ !!!@@@你好 1.14. Replacer 类型 这是一个结构，没有导出任何字段，实例化通过 func NewReplacer(oldnew \u0026hellip;string) *Replacer 函数进行，其中不定参数 oldnew 是 old-new 对，即进行多个替换。如果 oldnew 长度与奇数，会导致 panic.\n示例：\n1 2 r := strings.NewReplacer(\u0026#34;\u0026lt;\u0026#34;, \u0026#34;\u0026amp;lt;\u0026#34;, \u0026#34;\u0026gt;\u0026#34;, \u0026#34;\u0026amp;gt;\u0026#34;) fmt.Println(r.Replace(\u0026#34;This is \u0026lt;b\u0026gt;HTML\u0026lt;/b\u0026gt;!\u0026#34;)) 输出结果：\n1 This is \u0026amp;lt;b\u0026amp;gt;HTML\u0026amp;lt;/b\u0026amp;gt;! 另外，Replacer 还提供了另外一个方法，它在替换之后将结果写入 io.Writer 中。\n1 func (r *Replacer) WriteString(w io.Writer, s string) (n int, err error) 1.15. Reader 类型 看到名字就能猜到，这是实现了 io 包中的接口。它实现了 io.Reader（Read 方法），io.ReaderAt（ReadAt 方法），io.Seeker（Seek 方法），io.WriterTo（WriteTo 方法），io.ByteReader（ReadByte 方法），io.ByteScanner（ReadByte 和 UnreadByte 方法），io.RuneReader（ReadRune 方法） 和 io.RuneScanner（ReadRune 和 UnreadRune 方法）。\nReader 结构如下：\n1 2 3 4 5 type Reader struct { s string // Reader 读取的数据来源 i int // current reading index（当前读的索引位置） prevRune int // index of previous rune; or \u0026lt; 0（前一个读取的 rune 索引位置） } 可见 Reader 结构没有导出任何字段，而是提供一个实例化方法：\n1 func NewReader(s string) *Reader 该方法接收一个字符串，返回的 Reader 实例就是从该参数字符串读数据。在后面学习了 bytes 包之后，可以知道 bytes.NewBufferString 有类似的功能，不过，如果只是为了读取，NewReader 会更高效。\n其他方法不介绍了，都是之前接口的实现，有兴趣的可以看看源码实现，大部分都是根据 i、prevRune 两个属性来控制。\n1.16. Builder 类型 1 2 3 4 type Builder struct { addr *Builder // of receiver, to detect copies by value buf []byte } 该类型实现了 io 包下的 Writer, ByteWriter, StringWriter 等接口，可以向该对象内写入数据，Builder 没有实现 Reader 等接口，所以该类型不可读，但提供了 String 方法可以获取对象内的数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 该方法向 b 写入一个字节 func (b *Builder) WriteByte(c byte) error // WriteRune 方法向 b 写入一个字符 func (b *Builder) WriteRune(r rune) (int, error) // WriteRune 方法向 b 写入字节数组 p func (b *Builder) Write(p []byte) (int, error) // WriteRune 方法向 b 写入字符串 s func (b *Builder) WriteString(s string) (int, error) // Len 方法返回 b 的数据长度。 func (b *Builder) Len() int // Cap 方法返回 b 的 cap。 func (b *Builder) Cap() int // Grow 方法将 b 的 cap 至少增加 n (可能会更多)。如果 n 为负数，会导致 panic。 func (b *Builder) Grow(n int) // Reset 方法将 b 清空 b 的所有内容。 func (b *Builder) Reset() // String 方法将 b 的数据以 string 类型返回。 func (b *Builder) String() string Builder 有 4 个与写入相关的方法，这 4 个方法的 error 都总是为 nil.\nBuilder 的 cap 会自动增长，一般不需要手动调用 Grow 方法。\nString 方法可以方便的获取 Builder 的内容。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 b := strings.Builder{} _ = b.WriteByte(\u0026#39;7\u0026#39;) n, _ := b.WriteRune(\u0026#39;夕\u0026#39;) fmt.Println(n) n, _ = b.Write([]byte(\u0026#34;Hello, World\u0026#34;)) fmt.Println(n) n, _ = b.WriteString(\u0026#34;你好，世界\u0026#34;) fmt.Println(n) fmt.Println(b.Len()) fmt.Println(b.Cap()) b.Grow(100) fmt.Println(b.Len()) fmt.Println(b.Cap()) fmt.Println(b.String()) b.Reset() fmt.Println(b.String()) 输出结果：\n1 2 3 4 5 6 7 8 3 12 15 31 32 31 164 7夕Hello, World你好，世界 Reference Go语言标准库\u0026ndash;strings\n","description":"","id":79,"section":"posts","tags":["Go"],"title":"Go-Strings-字符串操作汇总","uri":"https://hex-go.github.io/posts/golang/2020-09-02-go-strings-%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%93%8D%E4%BD%9C%E6%B1%87%E6%80%BB/"},{"content":"重要 环境说明 安装 使用 Reference go template href内容(\u0026amp;,=等)被转义 Go 语言标准库 text/template 包深入浅出\n","description":"","id":80,"section":"posts","tags":["Go"],"title":"Go-Template使用-使用示例以及遇坑小记","uri":"https://hex-go.github.io/posts/golang/2020-08-14-go-template%E4%BD%BF%E7%94%A8-%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%E4%BB%A5%E5%8F%8A%E9%81%87%E5%9D%91%E5%B0%8F%E8%AE%B0/"},{"content":"重要 环境说明 安装 使用 Reference ^^ Go by Example: JSON\n^^ How to use JSON with Go (best practices)\n^^ Json 解析复杂结构(interface{})\n^^ go json 实践中遇到的坑\nJson 不指定struct从interface{}取值(英文)\nJson 创建、解析、读写文件\nJson 创建、解析、读写文件\u0026ndash;英文版本\nJson 从API中解析\nHow to Parse a JSON Request Body in Go\ngolang解析创建复杂嵌套的json数据-峰云比较乱\nHow to Parse a JSON Request Body in Go\n","description":"","id":81,"section":"posts","tags":["Go"],"title":"Go-处理JSON-如何创建和解析复杂Json数据","uri":"https://hex-go.github.io/posts/golang/2020-08-14-go-%E5%A4%84%E7%90%86json-%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E5%92%8C%E8%A7%A3%E6%9E%90%E5%A4%8D%E6%9D%82json%E6%95%B0%E6%8D%AE/"},{"content":"重要 环境说明 安装 使用 Reference kubernetes1.9管中窥豹-CRD概念、使用场景及实例\n如何从零开始编写一个Kubernetes CRD\nk8s官网\u0026ndash;Custom Resources\nk8s官网\u0026ndash;使用CRD扩展k8s-API\n","description":"","id":82,"section":"posts","tags":["Kubernetes"],"title":"CRD-概念、使用场景、go示例","uri":"https://hex-go.github.io/posts/kubernetes/2020-08-13-crd-%E6%A6%82%E5%BF%B5%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AFgo%E7%A4%BA%E4%BE%8B/"},{"content":"重要 原理说明 kubernetes集群并采用Coredns进行解析，集群内部的服务都能通过内部域名进行访问。但是集群内部的coredns与物理机的dns解析不完全统一，\ncoredns不能解析物理机的hostname。k8s-coredns默认配置从本机/etc/resolv.conf获取上游DNS服务器的地址。\n有两种方式解决这个问题：\n搭建解析物理机地址的dns服务器，并作为上游dns服务配置给k8s的coredns。 通过coredns自带的hosts插件，手动添加自定义解析记录 配置 1. 配置外部dns服务器 搭建coredns服务参考coredns官网，此处只介绍k8s中dns服务器修改上游dns配置，有两种方式：\n修改/etc/resolv.conf中的nameserver nameserver地址换成自建的dns服务地址，默认监听53端口。\n1 nameserver 192.168.100.254 修改coredns配置文件 ConfigMap coredns 1 kubectl -n kube-system edit configmap coredns 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 apiVersion: v1 data: Corefile: | .:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa ttl 30 } prometheus :9153 proxy . 192.168.100.254 # 修改为上游dns服务地址,端口默认53 cache 30 loop reload loadbalance } kind: ConfigMap metadata: name: coredns namespace: kube-system 配置修改后，需要重启coredns服务\n查询coredns 的POD\n1 kubectl -n kube-system get pods -l k8s-app=kube-dns 删除 coredns 让 k8s 重新创建新的 coredns\n1 kubectl -n kube-system delete pod -l k8s-app=kube-dns 2. 通过hosts添加自定义DNS解析记录 coredns 自带 hosts 插件， 允许像配置 hosts 一样配置自定义 DNS 解析\n修改命名空间 kube-system 下的 configMap coredns\n1 kubectl edit configmap coredns -n kube-system 添加如下设置即可。\n1 2 3 4 5 6 hosts { 172.21.91.28 cache.redis 172.21.91.28 persistent.redis fallthrough } 修改后文件如下（根据kubernetes 安装方式不同，可能有些许差别）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 apiVersion: v1 data: Corefile: | .:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa ttl 30 } hosts { 10.10.0.10 reg.chebai.org 10.15.0.2 hub.icos.city fallthrough } prometheus :9153 forward . /etc/resolv.conf cache 30 loop reload loadbalance } kind: ConfigMap metadata: name: coredns namespace: kube-system 删除命名空间kube-system下的coredns pod，重启dns服务。\n3. 通过pod增加hostalias 以deployment修改举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: hostAliases: - ip: \u0026#34;192.168.100.106\u0026#34; hostnames: - \u0026#34;rancher.icos.city\u0026#34; containers: - env: - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace image: nginx name: nginx Reference 开发服务器 k8s 设置 自定义 dns解析\ncoredns 官网\n","description":"","id":83,"section":"posts","tags":["Kubernetes","Coredns"],"title":"Minikube--增加外部dns解析","uri":"https://hex-go.github.io/posts/kubernetes/2020-08-07-minikube--%E5%A2%9E%E5%8A%A0%E5%A4%96%E9%83%A8dns%E8%A7%A3%E6%9E%90/"},{"content":"重要 最重要的事:\nQv2ray开代理\n本人使用Qv2ray 设置系统代理 勾选SOCKS设置，并填写端口1088，UDP本地IP127.0.0.1。 设置docker代理配置 1 2 sudo mkdir -p /etc/systemd/system/docker.service.d/ sudo vim /etc/systemd/system/docker.service.d/http-proxy.conf 将以下内容填入文件http-proxy.conf\n1 2 3 4 5 [Service] Environment=\u0026#34;HTTP_PROXY=http://127.0.0.1:30388\u0026#34; Environment=\u0026#34;HTTPS_PROXY=http://127.0.0.1:30388\u0026#34; Environment=\u0026#34;ALL_PROXY=socks5://127.0.0.1:1088\u0026#34; Environment=\u0026#34;NO_PROXY=localhost,127.0.0.1,reg.chebai.org,icosdop.service.rd,hub.icos.city,registry.npm.taobao.org\u0026#34; 重启docker服务 1 2 root@:~# systemctl daemon-reload root@:~# systemctl restart docker 查看配置 1 2 systemctl show --property=Environment docker Environment=HTTP_PROXY=http://127.0.0.1:30388 HTTPS_PROXY=http://127.0.0.1:30388 ALL_PROXY=socks5://127.0.0.1:1088 NO_PROXY=localhost,127.0.0.1,reg.chebai.org,hub.icos.city,icosdop.service.rd docker pull 谷歌仓库镜像 1 2 3 4 5 6 7 8 9 10 root@:~# docker pull gcr.io/google_containers/pause-amd64:3.0 3.0: Pulling from google_containers/pause-amd64 a3ed95caeb02: Pull complete f11233434377: Pull complete Digest: sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 Status: Downloaded newer image for gcr.io/google_containers/pause-amd64:3.0 root@:~# docker images REPOSITORY TAG IMAGE ID CREATED SIZE stephenlu/pause-amd64 3.0 78ba6fae6829 3 weeks ago 747 kB gcr.io/google_containers/pause-amd64 3.0 99e59f495ffa 20 months ago 747 kB minikube启动k8s集群 1 minikube start 使用国内proxy启动 1 2 3 minikube start --registry-mirror=https://registry.docker-cn.com # 或 minikube start --vm-driver=none --registry-mirror=https://registry.docker-cn.com --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers 使用docker体验容器搬运镜像 官方体验虚拟机\n进入虚拟机，拉取gcr等墙外镜像。再推送至docker.io中\nReference docker使用代理pull gcr仓库镜像\ndocker官方文档设置HTTP/HTTPS Proxy\n遗留问题 docker 配置 no_proxy 无法使用 通配模式。\n","description":"","id":84,"section":"posts","tags":["个人工具","Docker","V2ray"],"title":"翻墙--docker拉取镜像","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-08-05-%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91-3_docker%E9%95%9C%E5%83%8F/"},{"content":"引言 如何在windows环境搭建环境，解决日常访问github的需求需要做到以下几步：\n获取代理工具（本文clash）与机场配置 配置浏览器，使浏览器可通过代理访问github等网站 通过代理工具，实现windows常见工具、软件翻墙 1. 代理工具配置 2. 浏览器配置 3. 常见工具 设置docker代理配置 1 2 sudo mkdir -p /etc/systemd/system/docker.service.d/ sudo vim /etc/systemd/system/docker.service.d/http-proxy.conf 将以下内容填入文件http-proxy.conf\n1 2 3 [Service] Environment=\u0026#34;ALL_PROXY=socks5://127.0.0.1:1088\u0026#34; NO_PROXY=localhost,127.0.0.1,reg.chebai.org,hub.icos.city,icosdop.service.rd,icos.city 重启docker服务 1 2 root@:~# systemctl daemon-reload root@:~# systemctl restart docker 查看配置 1 2 systemctl show --property=Environment docker Environment=ALL_PROXY=socks5://127.0.0.1:1080 NO_PROXY=localhost,127.0.0.1,reg.chebai.org,hub.icos.city,icosdop.service.rd,icos.city docker pull 谷歌仓库镜像 1 2 3 4 5 6 7 8 9 10 root@:~# docker pull gcr.io/google_containers/pause-amd64:3.0 3.0: Pulling from google_containers/pause-amd64 a3ed95caeb02: Pull complete f11233434377: Pull complete Digest: sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 Status: Downloaded newer image for gcr.io/google_containers/pause-amd64:3.0 root@:~# docker images REPOSITORY TAG IMAGE ID CREATED SIZE stephenlu/pause-amd64 3.0 78ba6fae6829 3 weeks ago 747 kB gcr.io/google_containers/pause-amd64 3.0 99e59f495ffa 20 months ago 747 kB minikube启动k8s集群 1 minikube start 使用国内proxy启动 1 2 3 minikube start --registry-mirror=https://registry.docker-cn.com # 或 minikube start --vm-driver=none --registry-mirror=https://registry.docker-cn.com --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers Reference docker使用代理pull gcr仓库镜像\ndocker官方文档设置HTTP/HTTPS Proxy\n遗留问题 docker 配置 no_proxy 无法使用 通配模式。\n","description":"","id":85,"section":"posts","tags":["个人工具","V2ray","Chrome","SwitchOmega","Clash"],"title":"科学上网","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-08-05-%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91-1_%E6%B5%8F%E8%A7%88%E5%99%A8/"},{"content":"重要 最近研究grafana与keycloak集成，能正常解决认证问题，但用户只会在grafana通过keycloak用户登录时，才会在grafana的数据库中创建用户。\n需要研究如何通过API触发此操作，为后续在grafana中给此用户授权做准备。grafana本身无此API，相近的功能Openldap与grafana用户同步也是在企业版。\n由此需要研究grafana源码，首选API实现，无法成功则研究API背后的逻辑，直接操作数据库实现。\n环境说明 grafana: v7.1.0\nkeycloak: 10.0.2\n安装 使用 Reference ","description":"","id":86,"section":"posts","tags":["Go"],"title":"Go-源码解读--grafana-v7.1.0","uri":"https://hex-go.github.io/posts/golang/2020-07-24-go-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB--grafana-v7.1.0/"},{"content":"重要 最近由于工作需求，需要统一调用各个系统的相同逻辑。并不想每集成一个服务就修改调用的代码，而是想实现插件机制。\n利用go包的init特性，将示例插件注册，并在主程序中调用。\n环境说明 代码结构如下：\n1 2 3 4 5 6 7 8 9 10 11 └── src └── test ├── main.go └── adaptor ├── init.go └── standard └── imports.go └── cls1 └── base.go └── cls2 └── base.go 项目代码\n使用 类工厂 具体文件: ./example-adaptor/adaptor/init.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package adaptor // 定义接口 type Adaptors interface { CreateUser(user string) (status bool, err error) DeleteUser(user string) (status bool, err error) Policies() (status bool, err error) } var ( // 插件字典 FactoryByName = make(map[string]func() Adaptors) ) // 注册插件 func Register(name string, factory func() Adaptors) { FactoryByName[name] = factory } 插件类 cls1 cls2 具体文件： adaptor/cls1/base.go 和 adaptor/cls2/base.go\n以cls1举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package cls1 import ( \u0026#34;example/adaptor\u0026#34; \u0026#34;fmt\u0026#34; ) // 定义 Cls1 type Cls1 struct { Name string } // 实现Class接口， 分别为 CreateUser DeleteUser Policies func (g *Cls1) CreateUser(user string) (status bool, err error) { fmt.Println(\u0026#34;Cls1 - create user: \u0026#34;, user) return true, nil } func (g *Cls1) DeleteUser(user string) (status bool, err error) { fmt.Println(\u0026#34;Cls1 - Delete user: \u0026#34;, user) return true, nil } func (g *Cls1) Policies() (status bool, err error) { fmt.Println(\u0026#34;Cls1 - get policies\u0026#34;) return true, nil } // 导入时注册插件的方法 func init() { // 导入包时 注册 cls1 adaptor.Register(\u0026#34;Cls1\u0026#34;, func() adaptor.Adaptors { return new(Cls1) }) } 导入包,实现插件自动注册到 Struct FactoryByName 具体文件： ./example-adaptor/adaptor/standard/imports.go\n1 2 3 4 5 6 7 package standard import ( // 统一导入， 触发init() 实现自动注册 _ \u0026#34;example/adaptor/cls1\u0026#34; // 匿名引用cls1包, 自动注册 _ \u0026#34;example/adaptor/cls2\u0026#34; // 匿名引用cls2包, 自动注册 ) 然后在项目入口文件处，导入adaptor/standard包即可\n1 2 3 4 5 6 7 8 9 10 11 package main import ( _ \u0026#34;example/adaptor/standard\u0026#34; // 统一导入，实现插件注册 \u0026#34;example/api\u0026#34; ) func main() { engine := api.Routers() _ = engine.Run(\u0026#34;:8887\u0026#34;) } 写新的插件 创建插件类\n创建包cls-new，并在包内做到这几件事： 创建 struct Cls-new 实现在adaptor中interface的方法 在init方法中注册 在adaptor/standard包处进行导入 文件路径: adaptor/standard/imports.go\n1 2 3 4 5 6 7 8 package standard import ( // 统一导入， 触发init() 实现自动注册 _ \u0026#34;example/adaptor/cls1\u0026#34; _ \u0026#34;example/adaptor/cls2\u0026#34; _ \u0026#34;example/adaptor/cls-new\u0026#34; ) Reference Useful Go语言工厂模式自动注册\n借鉴caddy插件机制博客\nGo-Plugin机制说明、简单示例\n","description":"","id":87,"section":"posts","tags":["Go"],"title":"Go-Module实现go语言的插件机制","uri":"https://hex-go.github.io/posts/golang/2020-07-23-go-module%E5%AE%9E%E7%8E%B0go%E8%AF%AD%E8%A8%80%E7%9A%84%E6%8F%92%E4%BB%B6%E6%9C%BA%E5%88%B6/"},{"content":"重要 生成自签发证书 生成CA根证书以及根证书私钥. output: ca.crt和 ca.key, pem格式. input ''\n1 2 3 4 5 # Generate a CA private key openssl genrsa -out ca.key 4096 # Create a self signed Certificate, valid for 10yrs with the \u0026#39;signing\u0026#39; option set openssl req -x509 -new -nodes -key ca.key -subj \u0026#34;/CN=company.COM\u0026#34; -days 3650 -reqexts v3_req -extensions v3_ca -out ca.crt 生成*.example.domain通配符证书私钥 output: example.domain.key, pem格式. input: ''\n1 openssl genrsa -out example.domain.key 4096 根据*.example.domain通配符证书私钥，生成证书请求文件(csr)example.domain.csr output: example.domain.csr, pem格式. input: example.domain.key.\n1 openssl req -new -sha256 -key example.domain.key -out example.domain.csr -subj \u0026#34;/CN=svc.example.domain\u0026#34; 根据证书请求文件通过根证书、根证书私钥签发证书。 output: example.domain.crt, pem格式. input: example.domain.csr和ca.crt和ca.key 以及配置文件example.domain.ini.\n其中，配置文件example.domain.ini的内容如下：\n1 2 3 4 5 [ ext ] subjectAltName = @dns [ dns ] DNS.1 = *.example.domain 执行下面命令：\n1 openssl x509 -req -in example.domain.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 3560 -out example.domain.crt -extfile example.domain.ini -extensions ext 生成k8s中的secret. output: k8s-secret example-certs, pem格式. input: example.domain.crt 和 example.domain.key pem格式.\n1 kubectl create secret tls example-certs --cert=example.domain.crt --key=example.domain.key Reference 概念说明\n生成证书\n","description":"","id":88,"section":"posts","tags":["Devops","证书"],"title":"PKI-自签发证书说明","uri":"https://hex-go.github.io/posts/devops/2020-07-08-pki-%E8%87%AA%E7%AD%BE%E5%8F%91%E8%AF%81%E4%B9%A6%E8%AF%B4%E6%98%8E/"},{"content":" 当下流行两种方式来为云原生应用提供后台服务： Operators和Open Services Broker API。本文比较两种技术，并针对性研究如何整合两者协同工作。\n运行在Kubernetes集群上的工作负载，需要访问许多相同的服务集。因此，Kubernetes社区构建了对OSBAPI规范，并创建了ServiceCatalog项目\n来提供Kubernetes集群内的服务市场。云计算服务API规范变成了OSBAPI(Open Service Broker API)。Operator是这一领域出现的新技术。\nOperators介绍 最近一段时间，Operator的人气飙升。原因很简单。Operators允许使用Kubernetes的开发人员直接使用Kubernetes集群中的托管服务。\n随后，Operator模式经常被用作构建符合OSBAPI的service broker的替代方案。\nOperator：\n是一组自定义资源定义(crd)，具有对其进行操作的自定义控制器。 重要 环境说明 安装 使用 Reference Operator和OSBAPI的最佳结合\n","description":"","id":89,"section":"posts","tags":["Kubernetes"],"title":"ServiceCatalog和Operator结合","uri":"https://hex-go.github.io/posts/kubernetes/2020-06-29-servicecatalog%E5%92%8Coperator%E7%BB%93%E5%90%88/"},{"content":"重要 问题：安全漏洞 CVE-2019-11245 容器中的进程默认以 root 用户权限运行，\nDocker默认不启用user namespace, 所有的容器共用一个内核，所以内核控制的 uid 和 gid 则仍然只有一套。\n如果容器内使用root用户，则容器内的进程与宿主机的root具有相同权限。会有很大的安全隐患，一旦容器有权限访问宿主机资源，则将具备宿主机root相同权限。\n相关链接 理解容器中的uid和gid(一)-Linux中的uid和gid.md\n理解容器中的uid和gid(二)-Docker容器中的uid和gid.md\n常见问题 1. pod中uid与宿主机冲突产生问题 因为一个原因：\n当pod设置runAsNoneroot，容器uid与宿主机uid一样，但username不一致时。会触发报错\nError: container has runAsNonRoot and image has non-numeric user (kong), cannot verify user is non-root\n原因待定位，现猜测 pod设置runAsNoneroot会获取容器uid,此时的user会变成宿主机的用户名，之后根据宿主机用户名在容器内获取uid时\n尽量要避免容器内的uid与宿主机的uid重复。所以建议在指定uid时，使用20000~65533的数值。\n3. 使用securityContext设置挂卷文件权限 当设置runAsNoneRoot后，往往会带来权限问题。比如有些私有云挂卷后，权限默认给的755权限。此时普通用户没有写权限，导致无法使用。所以需要\n总结 还有一种方式，解决uid未隔离导致的安全问题问题。但未做测试。\ndocker 开启user namespace隔离用户 隔离 docker 容器中的用户\nReference 理解 k8s 中 SecurityContext\nk8s文档\u0026ndash;为pod配置安全性上下文\n源码剖析\u0026ndash;SecurityContext\ndocker挂载volume的用户权限问题\nDocker mounting volume. Permission denied\nk8s挂载宿主机卷解决权限问题：securityContext fsgroup\n为非root用户启动的pod挂卷\nAdd ability to mount volume as user other than root\nVolumes are created in container with root ownership and strict permissions\nstack overflow k8s 设置挂卷的userGroup和文件权限\n","description":"","id":90,"section":"posts","tags":["Devops","Kubernetes","Docker"],"title":"Docker-理解容器中的uid和gid(二)-Kubernetes中使用uid","uri":"https://hex-go.github.io/posts/devops/2020-06-28-docker-%E7%90%86%E8%A7%A3%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9A%84uid%E5%92%8Cgid%E4%B8%89-kubernetes%E4%B8%AD%E7%9A%84uid%E5%92%8Cgid/"},{"content":"重要 最重要的事: 本文包括\n初始包安装； 安装翻墙软件； 安装docker； 安装Goland开发环境gvm+golang-1.13； 安装前端环境npm-nodejs-yarn； docker运行微信； 安装finalshell； 安装Goland并激活； 安装其他，postman、typora、git-client、docker-compose等； 初始包安装 必备工具\n1 sudo apt install openssh-server curl unrar net-tools 为Gland准备\n1 sudo apt-get install libcanberra-gtk-module openjdk-11-jre-headless 为前端和Golang编译安装\n1 sudo apt-get install curl git mercurial make binutils bison gcc build-essential 为搜狗输入法准备\n1 sudo apt-get install fcitx-bin fcitx-table 显卡驱动（draft） 卸载已存在驱动旧组件\n1 2 3 4 sudo apt-get purge nvidia* sudo apt-get autoremove # 删除/etc/apt/sources.list.d下的相关记录 sudo dpkg -P cuda-repo-ubuntu1404 下载驱动\n1 2 cd ~ wget http://us.download.nvidia.com/XFree86/Linux-x86_64/384.69/NVIDIA-Linux-x86_64-384.69.run 安装依赖\n1 2 3 4 5 6 7 8 # 用来编译驱动 sudo apt install build-essential # 用来支持32位系统(可选) sudo apt install gcc-multilib # 用来提供dkms支持 sudo apt install dkms # 带图形显示的系统必须装，但一般都装过了(因为你已经能看到桌面，说明已经装好了)。server版的机器不用装(可选) sudo apt install xorg xorg-dev 安装驱动\n1 sudo apt-get nvidia-375 nvidia-modprobe 安装配置翻墙软件 下载Qv2ray软件包 下载v2ray核心软件包 集成并配置订阅地址 chrome配置 安装配置Docker 卸载机器上docker组件 1 sudo apt-get remove docker docker-engine docker.io containerd runc 安装Docker 1 2 curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh 解决Docker命令和socket文件权限问题 1 2 3 4 5 6 # 将操作的用户加入docker组中 sudo usermod -aG docker ${USER} # 注销重新登录，或者执行下面命令来使改变生效 newgrp docker # 执行下面命令测试 docker run hello-world 配置国内镜像加速\n创建或修改 /etc/docker/daemon.json：\n1 2 3 4 5 6 7 8 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://1nj0zren.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;http://f1361db2.m.daocloud.io\u0026#34;, \u0026#34;https://registry.docker-cn.com\u0026#34; ] } 重启docker服务\n1 2 sudo systemctl daemon-reload sudo systemctl restart docker 执行docker info命令，查看配置是否已生效。\nGVM+Go1.13 安装GVM 如果下载超时的话，就尝试下搭个梯子。系统proxy不想配的话，就chrome配置好SwitchOMG，通过浏览器下载脚本。\n1 bash \u0026lt; \u0026lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) 安装go1.4 Go 1.5+从工具链中删除了C编译器，并用Go编写的代码替换了它们。 实现了自举。为了编译Go 1.5+，请确保先安装Go 1.4\n1 2 gvm install go1.4 -B gvm use go1.4 安装go1.13 1 2 export GOROOT_BOOTSTRAP=$GOROOT gvm intall go1.13 others 1 2 3 4 5 6 # 查看本地版本 gvm list # 查看所有版本 gvm listall # 卸载gvm和所有go gvm implode 前端环境 安装nvm 1 2 3 4 5 6 7 8 9 10 # 下载脚本并执行 curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.34.0/install.sh | bash # 使修改在当前回话生效 source ~/.profile # 检查nvm安装 nvm --version # list所有可用的nodejs版本(安装lts版本) nvm ls-remote # list所有已安装的nodejs nvm list 安装nodejs 1 2 3 4 5 6 7 nvm install 10.15 # select 安装的nodejs nvm use 10.15 # 检查 node -v npm -v 安装yarn，npm 1 2 3 4 5 6 7 8 9 npm i -g npm --registry https://registry.npm.taobao.org npm i -g yarn --registry https://registry.npm.taobao.org # 设置yarn yarn config set registry https://registry.npm.taobao.org -g yarn config set sass_binary_site http://cdn.npm.taobao.org/dist/node-sass -g # 设置npm export NVM_NODEJS_ORG_MIRROR=http://npm.taobao.org/mirrors/node npm config set registry https://registry.npm.taobao.org 运行微信 运行时有报错MIT-SHM，增加参数\u0026ndash;ipc=host解决问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 docker container run -d wechat \\ --device /dev/snd \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -v ${XDG_RUNTIME_DIR}/pulse/native:${XDG_RUNTIME_DIR}/pulse/native \\ -v $HOME:$HOME \\ -v $HOME/WeChatFiles:/WeChatFiles \\ -e DISPLAY=unix${DISPLAY} \\ -e XMODIFIERS=@im=fcitx \\ -e QT_IM_MODULE=fcitx \\ -e GTK_IM_MODULE=fcitx \\ -e AUDIO_GID=`getent group audio | cut -d: -f3` \\ -e VIDEO_GID=`getent group video | cut -d: -f3` \\ -e GID=`id -g` \\ -e UID=`id -u` \\ -e DPI=120 \\ --ipc=host \\ hoking007/wechat:latest 终端管理工具 \u0026ndash; FinalShell 一键安装\n安装路径/usr/lib/FinalShell/\n配置文件路径/home/$USER/.finalshell/\n1 2 3 4 rm -f finalshell_install_linux.sh wget www.hostbuf.com/downloads/finalshell_install_linux.sh chmod +x finalshell_install_linux.sh ./finalshell_install_linux.sh 安装配置Goland（draft） 下载安装包\n其他 安装最新git-client 1 2 3 4 5 6 7 8 9 sudo apt-add-repository ppa:git-core/ppa sudo apt-get update sudo apt-get install git # if `add-apt-repository` not found ## ubuntu 14.04 sudo apt-get install software-properties-common ## ubuntu 13.10 or earlier sudo apt-get install python-software-properties 安装最新docker-compose 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 1. remove the old version: ## If installed via apt-get sudo apt-get remove docker-compose ## If installed via curl sudo rm /usr/local/bin/docker-compose ## If installed via pip pip uninstall docker-compose # 2. install latest docker-compose VERSION=$(curl --silent https://api.github.com/repos/docker/compose/releases/latest | jq .name -r) DESTINATION=/usr/local/bin/docker-compose sudo curl -L https://github.com/docker/compose/releases/download/${VERSION}/docker-compose-$(uname -s)-$(uname -m) -o $DESTINATION sudo chmod 755 $DESTINATION 安装typora 1 sudo apt-get install typora 安装postman 通过软件中心安装。\n安装wps 通过软件中心安装。\nReference 显卡驱动\n安装NVIDIA驱动和CUDA在Linux上\n安装最新版NVIDIA驱动在Ubuntu上\nGVM+GO\nGVM-github\n安装golang的依赖-linux\nGVM安装go1.4报错\u0026quot;go: command not found\u0026quot;\nQv2ray\nQv2ray-git博客\n翻墙相关的git项目 new-pac\nDocker\n官方文档-在Ubuntu上安装Docker-Engine\n官方文档-在Ubuntu非root用户相关配置\nDocker hub 设置代理服务器\n前端\n使用nvm安装nodejs\napt安装nodejs并配置\n微信\n知乎-wine安装微信和QQ\n微信docker镜像-github\n微信docker镜像-github-高分屏显示问题\n微信docker镜像-github-MIT-SHM error solutions\n使用docker运行GUI工具\n使用docker运行GUI应用-stack-overflow\nGUI不工作\u0026ndash;报错MIT-SHM\n终端管理工具\nFinalShell官网-Linux安装\nFinalShell博客\u0026ndash;使用说明\nFinalShell博客\u0026ndash;建立隧道\ngotty+ssh/tmux实现web-xshell,并协同\n","description":"","id":91,"section":"posts","tags":["个人工具","Ubuntu","Docker","Go","GVM","Goland","Nodejs","Postman","Typora","Finalshell"],"title":"ubuntu18.04初始开发环境搭建","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-05-10-ubuntu18.04_%E5%88%9D%E5%A7%8B%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"content":"重要 最重要的事:\nGoTTY\u0026ndash;将终端共享为web应用 GoTTY是一个简单的命令行工具，可以将CLI工具转换为web应用程序\n使用场景：\n共享ssh gotty ssh 127.0.0.1 共享ssh，并共享session gotty -w tmux new -s test 共享docker，提供一个隔离的环境 gotty -w docker run -it --rm busybox Tmux\u0026ndash;终端多路复用器 通过tmux可以在一个终端上轻松地切换多个程序，分离它们(它们在后台运行)并重新连接到另一个终端.\n新建 session\n命令tmux new -s 如 tmux new -s \u0026lt;session-name\u0026gt;\n离开 session\n命令 tmux detach ； 快捷键 ctrl + b 然后 按 d\n查看 session 列表\n命令tmux ls ；快捷键操作 ctrl + b 然后 按s 列出所有的 session\n进入 session\n离开 session 之后，有时候我们还需要对某个 session 进行操作，这时候可以通过如下的操作：\ntmux attach -t \u0026lt;session-name\u0026gt;\n关闭 session\n如果需要关闭 session, 可以通过执行如下的命令即可：\ntmux kill-session -t \u0026lt;session-name\u0026gt;\n切换 session\n执行命令,可以从当前的 session 快速切换到另一个 session：\ntmux switch -t\n重命名 session\n命令tmux rename-session -t 快捷键 ctrl +d 然后 按$ 来重命名当前的session 。\n切换窗口\n在同一个会话的多个窗口之间可以通过如下快捷键进行切换:\n快捷键ctrl+b 然后 按p (previous的首字母) 切换到上一个window。\n快捷键ctrl+b 然后 按n (next的首字母) 切换到下一个window。\n快捷键ctrl+b 然后 按0 切换到0号window，依次类推，可换成任意窗口序号\n快捷键ctrl+b 然后 按w (windows的首字母) 列出当前session所有window，通过上、下键切换窗口\n快捷键ctrl+b 然后 按l (字母L的小写)相邻的window切换\n快捷键ctrl+b 然后 按\u0026amp;\n分屏\n快捷键ctrl+b 然后 按%， 垂直分屏\n快捷键ctrl+b 然后 按\u0026quot;， 水平分屏\n切换pane\n快捷键ctrl+b 然后 按o， 依次切换当前窗口下的各个pane。\n快捷键ctrl+b 然后 按Up|Down|Left|Right 根据按箭方向，选择切换到某个pane。\n快捷键ctrl+b 然后 按Space (空格键)， 对当前窗口下的所有pane重新排列布局，每按一次，换一种样式。\n快捷键ctrl+b 然后 按z ，最大化当前pane。再按一次后恢复。\n快捷键ctrl+b 然后 按x，关闭pane：\n帮助：\n快捷键ctrl+b 然后 按？\nReference ubuntu配置\nubuntu18.10给应用程序添加快捷键\nLinux 让终端走代理的几种方法\n[ubuntu18.04 ]\n安装工具，\u0026lsquo;Open in Terminal\u0026rsquo;\n常用工具使用\n破坏性测试工具：chaos-mesh\nKafaka客户端工具：kaf\nk8s切换集群、命名空间工具：kubectx 博客\nk8s自动合并kubeconfig工具： mergeKubeConfig\n完美替换terraform，支持Go和Python：pulumi\n终端共享为WEB应用：gotty\n终端共享为WEB应用：webtty\n终端多路复用器：tmux\nDevOPS工具：\n独立编译镜像(without connect to docker-daemon)工具: kaniko\n文件传输工具: croc\nLinux权限详解\n","description":"","id":92,"section":"posts","tags":["个人工具","GoTTY","Tmux","Ubuntu"],"title":"ubuntu系统配置+常用工具使用","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-04-23-ubuntu_18.04-%E4%BD%BF%E7%94%A8%E9%85%8D%E7%BD%AE%E6%8A%80%E5%B7%A7/"},{"content":"重要 记录常用的一些函数\n1. 字符串转int64 1 2 3 4 5 6 7 // Use the max value for signed 64 integer. http://golang.org/pkg/builtin/#int64 var s string = \u0026#34;9223372036854775807\u0026#34; i, err := strconv.ParseInt(s, 10, 64) if err != nil { panic(err) } fmt.Printf(\u0026#34;Hello, %v with type %s!\\n\u0026#34;, i, reflect.TypeOf(i)) 输出：\nHello, 9223372036854775807 with type int64!\n2. 最小化gormigrate 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 package main import ( \u0026#34;log\u0026#34; \u0026#34;gopkg.in/gormigrate.v1\u0026#34; \u0026#34;github.com/jinzhu/gorm\u0026#34; _ \u0026#34;github.com/jinzhu/gorm/dialects/sqlite\u0026#34; ) type Person struct { gorm.Model Name string } type Pet struct { gorm.Model Name string PersonID int } func main() { db, err := gorm.Open(\u0026#34;sqlite3\u0026#34;, \u0026#34;mydb.sqlite3\u0026#34;) if err != nil { log.Fatal(err) } if err = db.DB().Ping(); err != nil { log.Fatal(err) } db.LogMode(true) m := gormigrate.New(db, gormigrate.DefaultOptions, []*gormigrate.Migration{ { ID: \u0026#34;201608301400\u0026#34;, Migrate: func(tx *gorm.DB) error { return tx.AutoMigrate(\u0026amp;Person{}).Error }, Rollback: func(tx *gorm.DB) error { return tx.DropTable(\u0026#34;people\u0026#34;).Error }, }, { ID: \u0026#34;201608301430\u0026#34;, Migrate: func(tx *gorm.DB) error { return tx.AutoMigrate(\u0026amp;Pet{}).Error }, Rollback: func(tx *gorm.DB) error { return tx.DropTable(\u0026#34;pets\u0026#34;).Error }, }, }) err = m.Migrate() if err == nil { log.Printf(\u0026#34;Migration did run successfully\u0026#34;) } else { log.Printf(\u0026#34;Could not migrate: %v\u0026#34;, err) } } 3. 判断元素在Slice中 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package main import ( \u0026#34;fmt\u0026#34; ) func main() { items := []string{\u0026#34;A\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;3\u0026#34;} // Missing Example _, found := Find(items, \u0026#34;golangcode.com\u0026#34;) if !found { fmt.Println(\u0026#34;Value not found in slice\u0026#34;) } // Found example k, found := Find(items, \u0026#34;B\u0026#34;) if !found { fmt.Println(\u0026#34;Value not found in slice\u0026#34;) } fmt.Printf(\u0026#34;B found at key: %d\\n\u0026#34;, k) } // Find takes a slice and looks for an element in it. If found it will // return it\u0026#39;s key, otherwise it will return -1 and a bool of false. func Find(slice []string, val string) (int, bool) { for i, item := range slice { if item == val { return i, true } } return -1, false } Reference ","description":"","id":93,"section":"posts","tags":["Go"],"title":"Go-常用函数备忘","uri":"https://hex-go.github.io/posts/golang/2020-05-29-go-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%A4%87%E5%BF%98/"},{"content":"引言 Kubernetes 设计初衷是为模块化的云原生应用程序的部署、扩展和管理提供便捷性和灵活性。在 Kubernetes 的背后，有许多关键组件和接口，这些组件协同工作，以确保集群的正常运行。\n本文将重点介绍三个重要的 Kubernetes 接口：CRI、CNI 和 CSI，它们在容器运行时、网络和存储方面发挥着关键作用。\n1. 容器运行时接口（CRI） CRI（Container Runtime Interface）是k8s用于与容器运行时通信的主要协议。容器运行时负责管理和执行容器的生命周期，包括创建、启动、停止和销毁容器。\nCRI 通过定义一组 gRPC 服务和数据结构，使kubelet能够与各种容器运行时（如 Docker、Containerd 等）交互，无需重新编译集群组件。\nContainer Runtime 实现了CRI gRPC Server，包括RuntimeService和ImageService。该 gRPC Server 需要监听本地的Unix socket，而 kubelet 则作为gRPC Client运行。\n2. 容器网络接口（CNI） CNI（Container Network Interface）是k8s中负责处理容器网络配置的接口。在 Kubernetes 集群中，各个容器需要能够相互通信，而 CNI 就负责为容器配置网络。\nCNI 插件通过在容器创建、启动或停止时设置网络环境，使得容器能够正确地连接到集群网络。这种设计允许用户根据需要选择不同的网络解决方案，从而满足不同的网络需求。\n2.1 CNI设计考量 CNI 插件分配了命名空间隔离、流量和 IP 过滤等功能，而 Kubernetes Kube-Net 插件默认情况下不提供这些功能。假设开发人员想要实现这些高级网络功能。\n在这种情况下，他们必须使用带有容器网络接口（CNI）的 CNI 插件，以便更轻松地创建和管理网络。\n容器运行时必须在调用任何插件之前为容器创建一个新的网络命名空间。 然后，容器运行时必须确定这个容器应属于哪个网络，并为每个网络确定哪些插件必须被执行。 2.2 CNI网络模型 CNI 网络插件实现网络结构的网络模型分为两类：封装网络模型（例如 Virtual Extensible Lan，缩写是 VXLAN）或非封装网络模型（例如 Border Gateway Protocol，缩写是 BGP）。\n封装网络(encapsulated network) 封装信息由 Kubernetes worker 之间的 UDP 端口分发，交换如何访问 MAC 地址的网络控制平面信息。此类网络模型中常用的封装是 VXLAN、Internet 协议安全性 (IPSec) 和 IP-in-IP。\n封装网络在现有的 Kubernetes 集群节点三层（L3）网络拓扑之上创建了一个逻辑二层（L2）网络。通过这一模型，你能够为容器提供隔离的 L2 网络，无需进行路由分发。\n封装网络会带来少量的处理开销，并因覆盖封装（生成IP header）而增加 IP 包的大小。封装信息通过K8s-worker之间的 UDP 端口传输，交换着关于访问 MAC 地址的网络控制平面信息。\n在这类网络模型中，常见的封装方式包括 VXLAN、IPSec（Internet 协议安全性）和 IP-in-IP。\n简单来说，这种网络模型在 k8s-worker 之间生成了一种扩展网桥，连接了各个pod。\n如果偏向使用扩展 L2 网桥，则可以选择此网络模型。此网络模型对 Kubernetes worker 的 L3 网络延迟很敏感。如果数据中心位于不同的地理位置，请确保它们之间的延迟较低，以避免最终的网络分割。\n使用这种网络模型的 CNI 网络插件包括 Flannel、Canal、Weave 和 Cilium。默认情况下，Calico 不会使用此模型，但你可以对其进行配置。\n非封装网络(Unencapsulated Network) 此网络模型创建了一个 L3 网络，用于在容器之间进行数据包路由。这种模型并不创建隔离的 L2 网络，因此不会引起额外的开销。然而，这些优点的代价是，k8s-worker节点必须管理所有必要路由分发。\n该网络模型避免了使用 IP header 进行封装，而是通过k8s-worker之间的网络协议来传播路由信息，比如使用 BGP 协议，以实现 Pod 之间的连接。\n简单来说，这种网络模型在k8s-worker之间形成了一个扩展网络路由器，提供了连接 Pod 所需的信息。\n如果更偏好采用 L3 网络，则可以选择此网络模型。该模型在操作系统层面上为k8s-worker节点动态更新路由信息，对延迟不太敏感。\n使用这一网络模型的 CNI 网络插件包括 Calico 和 Cilium。Cilium 也能够通过这一模型进行配置，尽管这并非其默认模式。\n3. 容器存储接口（CSI） CSI（Container Storage Interface）是 Kubernetes 中处理容器存储的接口。CSI 使存储供应商能够开发插件，将各种存储系统集成到 Kubernetes 中。\n这些插件允许管理员在不影响应用程序的情况下管理存储，例如动态卷配置、快照和克隆操作。通过 CSI，Kubernetes 的存储管理变得更加灵活，能够适应不同的存储需求。\n总结：\nKubernetes 的成功在很大程度上得益于其丰富的接口体系，使得不同的组件能够协同工作，提供全面的容器编排解决方案。CRI、CNI 和 CSI 是 Kubernetes 中三个关键的接口，它们分别处理容器运行时、网络和存储方面的任务。\n理解这些接口如何工作以及它们的作用，有助于更好地管理和优化 Kubernetes 集群，从而更好地支持应用程序的部署和运行。\n参考文献 Understanding Kubernetes Interfaces: CRI, CNI, \u0026amp; CSI\nK8S-handbook\u0026ndash;容器存储接口\n","description":"","id":94,"section":"posts","tags":["Kubernetes","CNI","CSI","CRI"],"title":"K8S基石-理解k8s接口CRI、CNI、CSI","uri":"https://hex-go.github.io/posts/kubernetes/2020-05-29-k8s%E5%9F%BA%E7%9F%B3-%E7%90%86%E8%A7%A3k8s%E6%8E%A5%E5%8F%A3cricnicsi/"},{"content":"重要 环境说明 安装 使用 0. 校验kubeconfig可用性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import ( \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; clientcmdapi \u0026#34;k8s.io/client-go/tools/clientcmd/api\u0026#34; ) ## 解析kubeConfig文件， 校验 func (k *K8S) ParseConf(kubeConfig []byte) (Conf clientcmdapi.Config, err error) { var ( restConf clientcmd.ClientConfig ) if restConf, err = clientcmd.NewClientConfigFromBytes(kubeConfig); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not load kube Config : %s\u0026#34;, err.Error())) return } Conf, _ = restConf.RawConfig() return } 1. 初始化客户端clientSet 1.1 集群内初始化ClientSet 官方Example\n1.2 集群外初始化ClientSet 官方Example\n1.3 从字节流创建ClientSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package k8s import ( \u0026#34;k8s.io/client-go/rest\u0026#34; \u0026#34;k8s.io/client-go/kubernetes\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; clientcmdapi \u0026#34;k8s.io/client-go/tools/clientcmd/api\u0026#34; ) type K8S struct { clientSet *kubernetes.Clientset } // Connect - 初始化k8s客户端 func (k *K8S) Connect(kubeConfig []byte) (err error) { var ( restConf *rest.Config ) if restConf, err = clientcmd.RESTConfigFromKubeConfig(kubeConfig); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not load kube Config : %s\u0026#34;, err.Error())) return } // 生成client-set配置 if k.clientSet, err = kubernetes.NewForConfig(restConf); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not connect k8s : %s\u0026#34;, err.Error())) return } log.Info(\u0026#34;Successfully connected to k8s\u0026#34;) return } 1.4 创建Dynamic ClientSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package fleet import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;k8s.io/client-go/dynamic\u0026#34; \u0026#34;k8s.io/client-go/rest\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; ) type Crd struct { Client dynamic.Interface } // Connect 初始化Fleet客户端 func (i *Crd) Connect(kubeConfig []byte) (err error) { var ( restConf *rest.Config ) if restConf, err = clientcmd.RESTConfigFromKubeConfig(kubeConfig); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not load kube Config : %s\u0026#34;, err.Error())) return } if i.Client, err = dynamic.NewForConfig(restConf); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not connect FleetCrd-k8s : %s\u0026#34;, err.Error())) return } log.Info(\u0026#34;Successfully connected to FleetCrd\u0026#34;) return } 3. 根据Deployment|StatefulSet获取Pods 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import ( \u0026#34;k8s.io/api/apps/v1\u0026#34; coreV1 \u0026#34;k8s.io/api/core/v1\u0026#34; metaV1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/labels\u0026#34; ) func (k *K8S) PodGetByStatefulSet(namespace string, statefulSet v1.StatefulSet) ([]*coreV1.Pod, error) { var podList []*coreV1.Pod labelsMap := statefulSet.ObjectMeta.GetLabels() log.DebugF(\u0026#34;[Middleware-K8s] StatefulSet:Labels: %#v\u0026#34;, labelsMap) labelSets := labels.SelectorFromSet(labelsMap) options := metaV1.ListOptions{ LabelSelector: labelSets.String(), } podsClient := k.clientSet.CoreV1().Pods(namespace) pods, err := podsClient.List(context.TODO(), options) if err != nil { return nil, err } for _, pod := range pods.Items { log.DebugF(\u0026#34;[Middleware-K8s] Pod:Labels: %#v, pod_name=%s\u0026#34;, pod.ObjectMeta.GetLabels(), pod.ObjectMeta.Name) podList = append(podList, \u0026amp;pod) } return podList, err } 4. 根据Job获取Pods 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import ( batchV1 \u0026#34;k8s.io/api/batch/v1\u0026#34; coreV1 \u0026#34;k8s.io/api/core/v1\u0026#34; metaV1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/labels\u0026#34; ) func (k *K8S) PodGetByJob(namespace string, job batchV1.Job) ([]*coreV1.Pod, error) { var podList []*coreV1.Pod labelsMap := map[string]string{ \u0026#34;job-name\u0026#34;: job.ObjectMeta.Name, \u0026#34;controller-uid\u0026#34;: string(job.ObjectMeta.UID), } log.DebugF(\u0026#34;[Middleware-K8s] Jobs:Labels: %#v\u0026#34;, labelsMap) labelSets := labels.SelectorFromSet(labelsMap) options := metaV1.ListOptions{ LabelSelector: labelSets.String(), } podsClient := k.clientSet.CoreV1().Pods(namespace) pods, err := podsClient.List(context.TODO(), options) if err != nil { return nil, err } for _, pod := range pods.Items { log.DebugF(\u0026#34;[Middleware-K8s] Pod:Labels: %#v, pod_name=%s\u0026#34;, pod.ObjectMeta.GetLabels(), pod.ObjectMeta.Name) podList = append(podList, \u0026amp;pod) } return podList, err } 5. Dynamic-client-go操作CRD资源 以rancher fleet项目的CRD clusters.fleet.cattle.io举例\n完整的包引用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package fleet import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; fleet \u0026#34;github.com/rancher/fleet/pkg/apis/fleet.cattle.io/v1alpha1\u0026#34; \u0026#34;icosdeploy/pkg/api/log\u0026#34; metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1/unstructured\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime/schema\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime/serializer/yaml\u0026#34; \u0026#34;k8s.io/client-go/dynamic\u0026#34; \u0026#34;k8s.io/client-go/rest\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; ) 5.1 初始化ClientSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package fleet import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;k8s.io/client-go/dynamic\u0026#34; \u0026#34;k8s.io/client-go/rest\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; ) type Crd struct { Client dynamic.Interface } // Connect 初始化Fleet客户端 func (i *Crd) Connect(kubeConfig []byte) (err error) { var ( restConf *rest.Config ) if restConf, err = clientcmd.RESTConfigFromKubeConfig(kubeConfig); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not load kube Config : %s\u0026#34;, err.Error())) return } if i.Client, err = dynamic.NewForConfig(restConf); err != nil { log.Error(fmt.Sprintf(\u0026#34;Could not connect FleetCrd-k8s : %s\u0026#34;, err.Error())) return } log.Info(\u0026#34;Successfully connected to FleetCrd\u0026#34;) return } 5.2 Cluster CRD的查询、删除操作 资源定义\n1 2 3 4 5 var clusterCRD = schema.GroupVersionResource{ Group: \u0026#34;fleet.cattle.io\u0026#34;, Version: \u0026#34;v1alpha1\u0026#34;, Resource: \u0026#34;clusters\u0026#34;, } 上面的值在CRD``中获取\n1 2 3 4 5 6 7 8 9 10 11 12 13 spec: # group name to use for REST API: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt; # 对应 Group 字段的值 group: fleet.cattle.io # list of versions supported by this CustomResourceDefinition versions: # 对应 Version 字段的可选值 - name: v1alpha1 # ... names: # plural name to be used in the URL: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;/\u0026lt;plural\u0026gt; # 对应 Resource 字段的值 plural: clusters 5.2.1 List查询资源 如果资源对象不是Namespace隔离的，则不指定Namespace: i.Client.Resource(xxxCRD).List(context.TODO(), metav1.ListOptions{})\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func (i *Crd) ListClusters(namespace string) (clusters *fleet.ClusterList, err error) { list, err := i.Client.Resource(clusterCRD).Namespace(namespace).List(context.TODO(), metav1.ListOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err := json.Unmarshal(data, \u0026amp;clusters); err != nil { return nil, err } return clusters, nil } 5.2.2 Get查询资源详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func (i *Crd) GetCluster(namespace string, name string) (cluster *fleet.Cluster, err error) { list, err := i.Client.Resource(clusterCRD). Namespace(namespace).Get(context.TODO(), name, metav1.GetOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err := json.Unmarshal(data, \u0026amp;cluster); err != nil { return nil, err } return cluster, nil } 5.2.3 删除资源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (i *Crd) DelCluster(namespace string, name string) (err error) { deletePolicy := metav1.DeletePropagationForeground cluster, err := i.GetCluster(namespace, name) if err != nil { log.Error(err.Error()) return err } if cluster == nil { err = errors.New(fmt.Sprintf(\u0026#34;Cluster -- %s not exists\u0026#34;, name)) log.Error(err.Error()) return } err = i.Client.Resource(clusterCRD). Namespace(namespace).Delete(context.TODO(), name, metav1.DeleteOptions{PropagationPolicy: \u0026amp;deletePolicy}) if err != nil { return } return } 5.3 Token CRD的创建操作 资源定义\n1 2 3 4 5 var tokenCRD = schema.GroupVersionResource{ Group: \u0026#34;fleet.cattle.io\u0026#34;, Version: \u0026#34;v1alpha1\u0026#34;, Resource: \u0026#34;clusterregistrationtokens\u0026#34;, } 5.3.1 List查询资源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func (i *Crd) ListToken(namespace string) (tokenList *fleet.ClusterRegistrationTokenList, err error) { list, err := i.Client.Resource(tokenCRD).Namespace(namespace).List(context.TODO(), metav1.ListOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err = json.Unmarshal(data, \u0026amp;tokenList); err != nil { return nil, err } return tokenList, nil } 5.3.2 Get查询资源详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func (i *Crd) GetToken(namespace string, name string) (token *fleet.ClusterRegistrationToken, err error) { list, err := i.Client.Resource(tokenCRD).Namespace(namespace).Get(context.TODO(), name, metav1.GetOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err = json.Unmarshal(data, \u0026amp;token); err != nil { return nil, err } return token, nil } 5.3.3 创建资源 注意: yaml包一定要用 \u0026quot;k8s.io/apimachinery/pkg/runtime/serializer/yaml\u0026quot;， 否则想资源部分数据解析会报错\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 var CreateData = ` kind: ClusterRegistrationToken apiVersion: \u0026#34;fleet.cattle.io/v1alpha1\u0026#34; metadata: name: new-token namespace: fleet-local spec: ttl: 240h ` func (i *Crd) CreateToken(namespace string) (token *fleet.ClusterRegistrationToken, err error) { decoder := yaml.NewDecodingSerializer(unstructured.UnstructuredJSONScheme) obj := \u0026amp;unstructured.Unstructured{} gvk := schema.GroupVersionKind{ Group: \u0026#34;fleet.cattle.io\u0026#34;, Version: \u0026#34;v1alpha1\u0026#34;, Kind: \u0026#34;ClusterRegistrationToken\u0026#34;, } if _, _, err := decoder.Decode([]byte(CreateData), \u0026amp;gvk, obj); err != nil { return nil, err } one, err := i.Client.Resource(tokenCRD).Namespace(namespace).Create(context.TODO(), obj, metav1.CreateOptions{}) if err != nil { return nil, err } data, err := one.MarshalJSON() if err != nil { return nil, err } if err = json.Unmarshal(data, \u0026amp;token); err != nil { return nil, err } return token, nil } 5.4 GitRepo CRD的操作 资源定义\n1 2 3 4 5 var gitRepoCRD = schema.GroupVersionResource{ Group: \u0026#34;fleet.cattle.io\u0026#34;, Version: \u0026#34;v1alpha1\u0026#34;, Resource: \u0026#34;gitrepos\u0026#34;, } 5.4.1 List查询资源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func (i *Crd) ListGitRepo(namespace string) (repoList *fleet.GitRepoList, err error) { list, err := i.Client.Resource(gitRepoCRD).Namespace(namespace).List(context.TODO(), metav1.ListOptions{}) if err != nil { return nil, err } data, err := list.MarshalJSON() if err != nil { return nil, err } if err := json.Unmarshal(data, \u0026amp;repoList); err != nil { return nil, err } return repoList, nil } 6. 查看容器日志 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // PodLogs - pod logs func (k *K8S) PodLogs(namespace string, name string) (string, error) { podLogOpts := coreV1.PodLogOptions{} jobsClient := k.clientSet.CoreV1().Pods(namespace) result := jobsClient.GetLogs(name, \u0026amp;podLogOpts) podLogs, err := result.Stream(context.TODO()) if err != nil { log.ErrorF(\u0026#34;error in opening stream: %v\u0026#34;, err) return \u0026#34;\u0026#34;, err } defer podLogs.Close() buf := new(bytes.Buffer) _, err = io.Copy(buf, podLogs) if err != nil { log.ErrorF(\u0026#34;error in copy information from podLogs to buf: %v\u0026#34;, err) return \u0026#34;\u0026#34;, err } logs := buf.String() return logs, err } Reference 第一参考 client-go简介\nclient-go官方实例\u0026ndash;集群内client配置\nclient-go针对crd资源，代码生成器\nUnit test kubernetes client in Go\nDynamic-client-go操作CRD资源\n基于Dynamic-client, 开发第三方资源Informer和Controller\n","description":"","id":95,"section":"posts","tags":["Kubernetes","Client-go","Go"],"title":"k8S-使用client-go操作集群","uri":"https://hex-go.github.io/posts/kubernetes/2020-05-28-k8s-%E4%BD%BF%E7%94%A8client-go%E6%93%8D%E4%BD%9C%E9%9B%86%E7%BE%A4/"},{"content":"重要 开发过程中，需要解析helm-manifest获取到的各种资源的yaml。每个都写映射\n环境说明 helm 3 kubernetes-v1.15.6 安装 无\n使用 注意:\nk8s版本不同。，资源所在的api接口会有变化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 package k8s import ( \u0026#34;fmt\u0026#34; \u0026#34;heroku/pkg/api/log\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime\u0026#34; \u0026#34;k8s.io/client-go/kubernetes/scheme\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;strings\u0026#34; ) func ParseK8sYaml(fileR []byte) []runtime.Object { acceptedK8sTypes := regexp.MustCompile(`(Role|ClusterRole|RoleBinding|ClusterRoleBinding|ServiceAccount|Deployment|StatefulSet|Service|Ingress|HorizontalPodAutoscaler)`) fileAsString := string(fileR[:]) sepYamlfiles := strings.Split(fileAsString, \u0026#34;---\u0026#34;) retVal := make([]runtime.Object, 0, len(sepYamlfiles)) for _, f := range sepYamlfiles { if f == \u0026#34;\\n\u0026#34; || f == \u0026#34;\u0026#34; { // ignore empty cases continue } checkList := strings.Split(f, \u0026#34;#\u0026#34;) if len(checkList) \u0026gt; 10 { // ignore annotation resource log.Warn(fmt.Sprintf(\u0026#34;ignore annotation resource: %s\u0026#34;, f[:10])) continue } decode := scheme.Codecs.UniversalDeserializer().Decode obj, groupVersionKind, err := decode([]byte(f), nil, nil) if err != nil { log.Warn(fmt.Sprintf(\u0026#34;Error while decoding YAML object. Err was: %s\u0026#34;, err)) continue } log.Debug(fmt.Sprintf(\u0026#34;Helm-Manitest:--:%s\u0026#34;, groupVersionKind)) if !acceptedK8sTypes.MatchString(groupVersionKind.Kind) { log.Info(fmt.Sprintf(\u0026#34;The custom-roles configMap contained K8s object types which are not supported! Skipping object with type: %s\u0026#34;, groupVersionKind.Kind)) } else { retVal = append(retVal, obj) } } return retVal } func stringToFile(outDir string, aut model.Aut) (configFile string, err error) { filename := filepath.Join(outDir, \u0026#34;config\u0026#34;) var data = []byte(aut.K8sConf) err = ioutil.WriteFile(filename, data, 0666) if err != nil { return \u0026#34;\u0026#34;, errors.New(fmt.Sprintf(\u0026#34;k8s-config load to tmp Error : %s\u0026#34;, err.Error())) } return filename, nil } func Show(helmRelease string, aut model.Aut) (instances []runtime.Object, err error) { tmp, err := ioutil.TempDir(\u0026#34;\u0026#34;, \u0026#34;curator-\u0026#34;) if err != nil { return nil, errors.Wrapf(err, \u0026#34;Error while preparing temp Dir\u0026#34;) } defer os.RemoveAll(tmp) // clean up configPath, err := stringToFile(tmp, aut) if err != nil { return nil, err } log.Info(\u0026#34;Started Helm-show:\u0026#34;) args := []string{ \u0026#34;--kubeconfig\u0026#34;, configPath, \u0026#34;get\u0026#34;, \u0026#34;manifest\u0026#34;, helmRelease, \u0026#34;-n\u0026#34;, aut.Namespace, } stdout, err := utils.ExecCMD(\u0026#34;helm\u0026#34;, args) if err != nil { return nil, err } instances = k8s.ParseK8sYaml(stdout) return instances, err } Reference Support for parsing K8s yaml spec into client-go data structures\n","description":"","id":96,"section":"posts","tags":["Kubernetes","Go"],"title":"解析k8s-yaml成client-go中的data-structs","uri":"https://hex-go.github.io/posts/kubernetes/2020-05-25-%E8%A7%A3%E6%9E%90k8s-yaml%E6%88%90client-go%E4%B8%AD%E7%9A%84data-structs/"},{"content":"重要 最重要的事:\n1.安装软件 1.1 通过软件中心安装 Show Applications \u0026raquo; Search Ubuntu software center.\n1.2 安装.deb文件 所有安装deb文件的方式\n1.2.1 双击安装 双击.deb安装包，进入软件中心安装软件。\n1.2.2 dpkg命令安装 1 2 3 4 5 6 7 dpkg -i XXX.deb ## 如果您得到任何依赖项错误，请运行下面的命令。它将修复所有的错误 apt install -f ## 删除应用 dpkg -r packagename.deb ## 重新配置/修复deb安装 dpkg-reconfigure packagename 1.2.3 apt命令安装 1 2 3 ## 还有一种方法可以在Ubuntu系统上安装deb文件，apt-get工具。 sudo apt install ./name.deb 1.3 snap安装 ​ Canonical为在任何Linux发行版上安装应用程序提供了跨平台的解决方案。这是一个通用的包管理系统，它提供了在任何Linux系统上运行软件所需的所有依赖项和库。\n​ Ubuntu18.04之后都默认支持Snaps包。如果是Ubuntu 16.04和更老的版本环境，则在终端中运行以下命令来安装Snap包管理环境。\n1 sudo apt install snapd 执行以下命令，通过snap安装软件\n1 sudo snap install \u0026lt;package\u0026gt; 1.4 安装AppImage包 ​ Deb软件包和RPM文件格式分别用于在Debian或Ubuntu和基于Fedora / SUSE的Linux发行版上安装软件。 对于应用程序开发人员来说，存在一个问题，他们必须为各种Linux发行版维护多个软件包。 为了克服这个问题，AppImage出现了，它为所有Linux发行版提供了通用的软件包管理系统。\n​ AppImage文件格式类似于Windows系统中使用的.exe文件。但随着。AppImage格式，没有提取或安装，你删除AppImage，软件就会从Ubuntu中删除，双击AppImage就会运行该应用程序。\n运行软件包，只用通过下面三步：\n下载.appimage格式的软件包。 给次文件可执行权限。点击软件\u0026raquo;属性\u0026raquo;权限标签\u0026raquo;使其可执行，检查允许作为程序执行文件。 双击运行。 1.5 通过apt命令安装 ​ Ubuntu Linux上安装软件的另一种简单方法。就像从Ubuntu软件中心安装软件一样，命令行也类似于它。唯一不同的是Ubuntu软件中心是基于图形用户界面，apt命令是基于命令行界面。许多软件都提供了apt命令来安装软件 。\n​ 例如，Chromium浏览器有两种方式，Ubuntu软件中心和apt命令，可以在Ubuntu上安装它。如果你想安装它，那么去Ubuntu软件中心，通过关键字Chromium进行搜索，或者在终端中输入这个简单的apt命令。\n1 2 3 4 5 ## 创建应用 sudo apt install -y chromium-browser ## 删除应用 sudo apt chromium-browser 1.6 通过PPA安装应用 ​ PPA个人软件包存档是另一种简单的方式来安装软件在Ubuntu Linux。许多开发人员希望直接向最终用户提供他们的软件的最新版本。在这种情况下，PPA可以作为Ubuntu官方软件仓库使用，需要一个月的时间在Ubuntu软件中心包含任何尖端软件。所以很多Ubuntu用户可能不会等待那么长时间，而是可以使用PPA立即安装最新版本。\n举例：\n1 2 3 sudo add-apt-repository ppa:embrosyn/cinnamon sudo apt update sudo apt install cinnamon 注意，这里总共遵循了三个命令。第一个用于将PPA知识库添加到系统s源列表中，第二个用于更新软件列表的缓存，最后一个用于使用PPA apt命令安装特定的软件。\n2. 常用软件 免费的密码管理软件： Bitwarden\nRedis可视化工具： Redis Desktop Manager\nOpenLDAP可视化工具：\nReference ubuntu安装软件说明\n","description":"","id":97,"section":"posts","tags":["个人工具","Ubuntu","Appimage","Snap"],"title":"Ubuntu常见安装软件方式(ded、appimage、snap)说明.md","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-04-23-ubuntu_%E5%B8%B8%E8%A7%81%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%96%B9%E5%BC%8Fdedappimagesnap%E8%AF%B4%E6%98%8E/"},{"content":"重要 minikube 主要是镜像都在k8s.gcr.io上，需要设置proxy。\n环境说明 Ubuntu18.04 driver = docker 安装 1. 初始配置 验证机器支持虚拟化。执行下面命令，如果输出非空则说明支持。\n1 grep -E --color \u0026#39;vmx|svm\u0026#39; /proc/cpuinfo 2. 安装minikube 安装配置kubectl 1 2 3 4 5 6 7 # 下载最新版本 curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl # 配置 chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl # 检查安装 kubectl version --client 安装minikube\n1 2 3 4 5 6 7 8 # 下载最新版本 curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 # 配置 chmod +x minikube sudo install minikube /usr/local/bin/ # 检查安装 minikube start --driver=docker minikube status 使用 启动 由于在Ubuntu下，参数--image-mirror-country=cn存在bug，所以通过image-repository指定阿里的源进行安装。\n参数说明：\n参数 参数说明 值 \u0026ndash;driver 常用值说明：\nvirtualbx\u0026ndash;使用virtualbox\nvmware\u0026ndash;使用vmware\nnone: 在主机上而不是在虚拟机中运行Kubernetes组件。您需要运行Linux并安装Docker。\ndocker: Docker驱动程序允许您将Kubernetes安装到现有的Docker安装中。在Linux上，这并不需要启用虚拟化。\npodman: 在PodMan中运行k8s组件。需要安装podman. 使用\u0026quot;docker\u0026quot;，注意一些访问权限的问题。和局限性 \u0026ndash;registry-mirror 手动启动dockerd时，通过\u0026ndash;registry-mirror选项，或编辑/etc/docker/daemon.json并添加Registry-mirrors键和值，以使更改持久化。 \u0026ldquo;https://registry.docker-cn.com\u0026quot;国内registry-mirror \u0026ndash;image-repository 对gcr.io的访问权限有限时，指定拉取镜像的地址。例如registry.cn-hangzhou.aliyuncs.com/google_containers registry.cn-hangzhou.aliyuncs.com/google_containers \u0026ndash;kubernetes-version 指定k8s版本，如 \u0026lsquo;\u0026ndash;kubernetes-version=v1.19.6\u0026rsquo; \u0026ndash;vm-driver 废弃，使用--driver 代替 1 minikube start --driver=docker --kubernetes-version=\u0026#39;v1.19.6\u0026#39; --registry-mirror=https://registry.docker-cn.com --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers 停止 1 minikube stop 删除（清除本地数据） 1 minikube delete 常见问题 minikube start时报错缺包\nk8s-1.18.2以上版本需要依赖包 报错信息：\nExiting due to GUEST_MISSING_CONNTRACK: Sorry, Kubernetes 1.19.6 requires conntrack to be installed in root's path\n解决方案：\n1 sudo apt-get install -y conntrack Reference 备注 install minikube\nInstalling Kubernetes with Minikube\nminikube启动带参数--image-mirror-country=cn失败\nMinikube 安装踩坑记\n也可以考虑ubuntu出的microk8s\n","description":"","id":98,"section":"posts","tags":["Kubernetes"],"title":"Minikube本地启动","uri":"https://hex-go.github.io/posts/kubernetes/2020-04-20-minikube%E6%9C%AC%E5%9C%B0%E5%90%AF%E5%8A%A8/"},{"content":"重要 Kubernetes资料汇总\n环境说明 Reference 备注 Kubernetes-handbook(宋净超-jimmy Song)\nInstalling Kubernetes with Minikube\nminikube启动带参数--image-mirror-country=cn失败\nMinikube 安装踩坑记\n也可以考虑ubuntu出的microk8s\n","description":"","id":99,"section":"posts","tags":["Kubernetes"],"title":"Kubernetes资料汇总","uri":"https://hex-go.github.io/posts/kubernetes/2020-03-20-kubernetes%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/"},{"content":"重要 本文概述了使用Flask和Flask-restplus创建REST API所需的步骤。这些工具组合成一个框架，Swagger被整合在Flask-restplus中。\nAPI参数校验 格式化输出（Json） 生成交互式API文档 将python异常转化为Readable http响应。 API文档可导出Swagger格式，也可以导出为Postman-collection 1.简介 Flask: 轻量级的Python Web框架。\nFlask-RestPlus 使开发REST api变得快速和简单。它提供了足够的语法糖，使您的代码易于阅读和维护。它集成Swagger UI为API生成交互式文档。\n2.环境准备 git Virtualenv 建议python3，python2也可以正常工作 3. 运行Demo应用 下载示例代码 1 2 3 cd ~/work_space/ git clone https://github.com/hex-go/restplus-api-demo.git cd restplus-api-demo 构建运行的venv环境 1 2 3 virtualenv -p `which python3` venv source venv/bin/activate (venv) $ pip install -r requirements.txt 初始化应用，并启动 1 2 (venv) $ python setup.py develop (venv) $ python rest_api_demo/app.py 访问地址http://localhost:8888/api/，可以查看API文档如下:\n4. 使用 4.1 HelloWorld举例 1 2 3 4 5 6 7 8 9 10 11 12 13 from flask import Flask from flask_restplus import Resource, Api app = Flask(__name__) # Create a Flask WSGI application api = Api(app) # Create a Flask-RESTPlus API @api.route(\u0026#39;/hello\u0026#39;) # Create a URL route to this resource class HelloWorld(Resource): # Create a RESTful resource def get(self): # Create GET endpoint return {\u0026#39;hello\u0026#39;: \u0026#39;world\u0026#39;} if __name__ == \u0026#39;__main__\u0026#39;: app.run(debug=True) # Start a development server 4.2应用目录结构规划 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ├── api # │ ├── blog # Blog-related API directory │ │ ├── business.py # │ │ ├── endpoints # API namespaces and REST methods │ │ │ ├── categories.py # │ │ │ └── posts.py # │ │ ├── parsers.py # Argument parsers │ │ └── serializers.py # Output serializers │ └── restplus.py # API bootstrap file ├── app.py # Application bootstrap file ├── database # │ └── models.py # Definition of SQLAlchemy models ├── db.sqlite # └── settings.py # Global app settings Rest API 定义放在文件rest_api_demo/api/restplus.py\nFlask app 的配置和实例化放在文件rest_api_demo/app.py\n重点注意的是app.py文件的initialize_app函数：\n1 2 3 4 5 6 7 8 9 10 def initialize_app(flask_app): configure_app(flask_app) blueprint = Blueprint(\u0026#39;api\u0026#39;, __name__, url_prefix=\u0026#39;/api\u0026#39;) api.init_app(blueprint) api.add_namespace(blog_posts_namespace) api.add_namespace(blog_categories_namespace) flask_app.register_blueprint(blueprint) db.init_app(flask_app) Blueprint 注册/apiURL前缀的路由；这样就可以通过前缀区分不同部分或不同版本的api。 add_namespace api本身也分为多个namespace， 每个ns都有自己的URL-prefix，在/api/blog/endpoints目录下配置。 4.3 定义 API api=namespace+resource+method\nrest_api_demo/api/blog/endpoints/categories.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ns = api.namespace(\u0026#39;blog/categories\u0026#39;, description=\u0026#39;Operations related to blog categories\u0026#39;) # # @ns.route(\u0026#39;/\u0026#39;) # class CategoryCollection(Resource): # # def get(self): # 1. Retrieve a list of categories \u0026#34;\u0026#34;\u0026#34;Returns list of blog categories.\u0026#34;\u0026#34;\u0026#34; # curl -X GET \u0026#39;http://localhost:8888/api/blog/categories/\u0026#39; return get_all_categories() # # @api.response(201, \u0026#39;Category successfully created.\u0026#39;) # def post(self): # 2. Create a new category \u0026#34;\u0026#34;\u0026#34;Creates a new blog category.\u0026#34;\u0026#34;\u0026#34; # POST \u0026#39;http://localhost:8888/api/blog/categories/\u0026#39; create_category(request.json) # return None, 201 # # # @ns.route(\u0026#39;/\u0026lt;int:id\u0026gt;\u0026#39;) # @api.response(404, \u0026#39;Category not found.\u0026#39;) # class CategoryItem(Resource): # # def get(self, id): # 3. Retrieve category with ID 1 \u0026#34;\u0026#34;\u0026#34;Returns details of a category.\u0026#34;\u0026#34;\u0026#34; # GET \u0026#39;http://localhost:8888/api/blog/categories/1\u0026#39; return get_category(id) # # @api.response(204, \u0026#39;Category successfully updated.\u0026#39;) # def put(self, id): # 4. Update the category with ID 1 \u0026#34;\u0026#34;\u0026#34;Updates a blog category.\u0026#34;\u0026#34;\u0026#34; # PUT \u0026#39;http://localhost:8888/api/blog/categories/1\u0026#39; update_category(id, request.json) # return None, 204 # # @api.response(204, \u0026#39;Category successfully deleted.\u0026#39;) # def delete(self, id): # 5. Delete the category with ID 1 \u0026#34;\u0026#34;\u0026#34;Deletes blog category.\u0026#34;\u0026#34;\u0026#34; # DELETE \u0026#39;http://localhost:8888/api/blog/categories/1\u0026#39; delete_category(id) # return None, 204 # api.namespace() 创建某个URL-prefix的namespace， 其中description的内容会在api文档中。 @ns.route() 将URLs与函数绑定，可以指定路径参数。比如@ns.route('/\u0026lt;int:id\u0026gt;')。string:(default),path:,int:,float:,uuid: 每个Resource 都是一个类，类包含的方法与http-method对应。包括：get, post, put, delete, patch, options, head. @api.response 声明每个方法的返回状态码+信息 上面代码生成的api文档页面如下图：\nSwagger UI文档还包括一个可以设置参数的表单。如果需要一个请求体，它的格式可以指定。 点击Try it out！按钮，将会给后端服务发请求，并显示response信息。\n4.4 参数+method校验 上面提到了在path中用\u0026lt;\u0026gt;传参，下面介绍:\nrequest请求中传参(?xx=xxx) headers中传参(\u0026ndash;heads HOST=xxx) form表单中(in request body)\n所以需要用到RequestParser对象，可以通过函数add_argument()来声明参数以及参数的类型。 4.4.1 通用配置 rest_api_demo/api/blog/parsers.py\n1 2 3 4 5 6 from flask_restplus import reqparse pagination_arguments = reqparse.RequestParser() pagination_arguments.add_argument(\u0026#39;page\u0026#39;, type=int, required=False) pagination_arguments.add_argument(\u0026#39;per_page\u0026#39;, type=int, required=False, choices=[5, 10, 20, 30, 40, 50], default=10) 然后通过装饰器@api.expect，将这个parser与方法绑定。\nrest_api_demo/api/blog/endpoints/posts.py\n1 2 3 4 5 6 @ns.route(\u0026#39;/\u0026#39;) class PostsCollection(Resource): @api.expect(pagination_arguments, validate=True) def get(self): ... 配置了参数校验后，Swagger-UI会显示一个form表单来校验参数。\n参数校验可以通过@api.expect的参数validate来启用或关闭。(分别在每个方法上做设置) 全局启用/关闭 app.config['RESTPLUS_VALIDATE'] = True。(在开发时，debug使用) 4.4.2 add_argument参数说明 type allowed value： int,str,bool.\nlocation 声明参数在哪儿, allowed value： headers, form, json\u0026hellip;\n1 2 3 parser.add_argument(\u0026#39;args1\u0026#39;, location=\u0026#39;headers\u0026#39;) parser.add_argument(\u0026#39;args2\u0026#39;, location=\u0026#39;form\u0026#39;) parser.add_argument(\u0026#39;args2\u0026#39;, location=\u0026#39;json\u0026#39;) action 多值参数 1 parser.add_argument(\u0026#39;args1\u0026#39;, type=int, action=\u0026#39;append\u0026#39;, required=True) choise 可选值 1 pagination_arguments.add_argument(\u0026#39;pages\u0026#39;, choices=[5, 10, 20, 30, 40, 50]) 4.5 json对象的值校验和说明 4.5.1 通用配置 通过api.model()列出所有期望的字段来定义对象的格式。每个字段都有一个关联的类型(e.g. String, Integer, DateTime)\nrest_api_demo/api/blog/serializers.py\n1 2 3 4 5 6 7 8 9 10 from flask_restplus import fields from rest_api_demo.api.restplus import api blog_post = api.model(\u0026#39;Blog post\u0026#39;, { \u0026#39;id\u0026#39;: fields.Integer(description=\u0026#39;The unique identifier of a blog post\u0026#39;), \u0026#39;title\u0026#39;: fields.String(required=True, description=\u0026#39;Article title\u0026#39;), \u0026#39;body\u0026#39;: fields.String(required=True, description=\u0026#39;Article content\u0026#39;), \u0026#39;status\u0026#39;: fields.String(required=True, enum=[\u0026#39;DRAFT\u0026#39;, \u0026#39;PUBLISHED\u0026#39;, \u0026#39;DELETED\u0026#39;]), \u0026#39;pub_date\u0026#39;: fields.DateTime, }) 将定义的校验model绑定给指定的Resource, 通过@api.expect(blog_post)\n1 2 3 4 5 6 7 @ns.route(\u0026#39;/\u0026#39;) class BlogPostCollection(Resource): @api.response(201, \u0026#39;Blog post successfully created.\u0026#39;) @api.expect(blog_post) def post(self): ... 4.5.2 fields参数说明 公共参数选项： required: True/False是否必填项; default: 该字段的默认值; description: 该字段说明(会在SwaggerUI中显示); example: 字段值示例(会在SwaggerUI中显示); 更具体的校验参数选项 字符串类型(包括String)： min_length 和 max_length: 字符串最大或最小长度。\npattern: 正则表达式。\n举例(字符串长度5\u0026lt;=len\u0026lt;=200, 必填, 正则: 小写字母+数字+符号\u0026rsquo;-\u0026rsquo;)：\n1 \u0026#39;slug\u0026#39;: fields.String(required=True, pattern=\u0026#39;^[a-z0-9-]+$\u0026#39;, min_length=5, max_length=200) 数字类型(包括Integer,Float,Fixed,Arbitrary)： min 和 max: 该字段最大值或最小值, 包括边界值, 即 min\u0026lt;value\u0026lt;max; exclusiveMin and exclusiveMax: 该字段最大值或最小值, 但不包过边界值, 即 exclusiveMin\u0026lt;value\u0026lt;exclusiveMax; multiple: 该字段必须是多值; 嵌套类型配置 API-model的一个字段可以使用另一个API-model作为它的期望值。然后提供一个JSON对象作为该字段的有效值。 1 \u0026#39;details\u0026#39;: fields.Nested(blog_post_details) API-model的一个字段是一个值列表，甚至是一个嵌套对象列表。 1 2 \u0026#39;item_ids\u0026#39;: fields.List(fields.Integer), \u0026#39;items\u0026#39;: fields.List(fields.Nested(blog_post)) Model继承 相似的API-model可以使用继承来扩展带有其他字段的API-model的定义。在下面的示例中，父类：通用分页API模型pagination，子类：更具体的博客文章分页page_of_blog_posts。使用api.inherit()方法继承父类。\n1 2 3 4 5 6 7 8 9 10 pagination = api.model(\u0026#39;A page of results\u0026#39;, { \u0026#39;page\u0026#39;: fields.Integer(description=\u0026#39;Number of this page of results\u0026#39;), \u0026#39;pages\u0026#39;: fields.Integer(description=\u0026#39;Total number of pages of results\u0026#39;), \u0026#39;per_page\u0026#39;: fields.Integer(description=\u0026#39;Number of items per page of results\u0026#39;), \u0026#39;total\u0026#39;: fields.Integer(description=\u0026#39;Total number of results\u0026#39;), }) page_of_blog_posts = api.inherit(\u0026#39;Page of blog posts\u0026#39;, pagination, { \u0026#39;items\u0026#39;: fields.List(fields.Nested(blog_post)) }) 4.6 处理输出json对象 可以根据上文提的 API-model定义，通过方法@api.marshal_with(model)将生成一个与model定义相同的json对象返回。值对应可以是两种方式：\n被装饰函数返回一个object，object具有跟model中字段名相同的属性; 被装饰函数返回一个dict，dict具有跟model中字段名相同的key; 例如，方法返回与API-model具有相同字段的SQLAlchemy ORM对象。\nrest_api_demo/api/blog/endpoints/categories.py\n1 2 3 4 5 6 7 8 9 10 @ns.route(\u0026#39;/\u0026lt;int:id\u0026gt;\u0026#39;) @api.response(404, \u0026#39;Category not found.\u0026#39;) class CategoryItem(Resource): @api.marshal_with(category_with_posts) def get(self, id): \u0026#34;\u0026#34;\u0026#34; Returns a category with a list of posts. \u0026#34;\u0026#34;\u0026#34; return Category.query.filter(Category.id == id).one() 如果返回值是list, 使用装饰器@api.marshal_list_with(model).\nattribute: 显式声明值来自于函数返回对象的哪个字段;\n1 \u0026#39;firstName\u0026#39;: fields.String(attribute=\u0026#39;first_name\u0026#39;), 通过attribute参数，可以提取嵌套在对象结构深处的值:\n1 \u0026#39;firstName\u0026#39;: fields.String(attribute=\u0026#39;user.first_name\u0026#39;), 更复杂的情形, 使用lambda函数提取值:\n1 \u0026#39;fullName\u0026#39;: fields.String(attribute=lambda x: \u0026#39;{} {}\u0026#39;.format(x.first_name, x.last_name)), 4.7 处理Errors 通过函数api.abort()抛出异常\n1 api.abort(code=400, message=\u0026#34;Sorry, Dave. I\u0026#39;m afraid I can\u0026#39;t do that.\u0026#34;) 如果没有显式地自己处理错误，Flask将捕获异常并将其转换为一个HTTP 500错误页面。\n通过装饰器@api.errorhandler重写默认的错误处理函数\nrest_api_demo/api/restplus.py\n1 2 3 4 @api.errorhandler(NoResultFound) def database_not_found_error_handler(e): log.warning(traceback.format_exc()) return {\u0026#39;message\u0026#39;: \u0026#39;A database result was required but none was found.\u0026#39;}, 404 Flask debug模式下，上面default_error_handler不会生效。异常只会触发Werkzeug interactive debugger页面。\n4.8 重置数据库 如果删除数据库db.sqlite文件或只是想将数据库重置为空状态，可以在Python控制台中输入以下命令。\n1 2 3 4 5 6 \u0026gt;\u0026gt;\u0026gt; from rest_api_demo.app import initialize_app, app \u0026gt;\u0026gt;\u0026gt; from rest_api_demo.database import reset_database \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; initialize_app(app) \u0026gt;\u0026gt;\u0026gt; with app.app_context(): ... reset_database() Reference Rest API Design Rulebook\nflask-restplus stable文档\napi export to Postman\napi export to PostMan\n","description":"","id":100,"section":"posts","tags":["Python","RestAPI","Flask","Swagger","Web Develop"],"title":"Python-RestAPI使用Flask、Flask-RestPlus","uri":"https://hex-go.github.io/posts/python/20200110-python-restapi%E4%BD%BF%E7%94%A8flaskswaggeruiflask-restplus/"},{"content":"重要 定义共享库 目录结构 1 2 3 4 5 6 7 8 9 10 11 12 (root) +- src # Groovy source files | +- org | +- foo | +- Bar.groovy # for org.foo.Bar class +- vars | +- foo.groovy # for global \u0026#39;foo\u0026#39; variable | +- foo.txt # help for \u0026#39;foo\u0026#39; variable +- resources # resource files (external libraries only) | +- org | +- foo | +- bar.json # static helper data for org.foo.Bar src目录: Java 源目录结构。当执行流水线时，该目录被添加到类路径下。\nvars目录: 定义Pipeline中使用的全局变量。 *.groovy文件名=variable-name, *.txt该变量说明文档，内容可以是 Markdown 等，但扩展名必须为txt)。\nresources目录: 目录允许从外部库中使用libraryResource加载有关的非 Groovy 文件\njenkins配置 全局共享库 全局可用 需要 Overall/RunScripts 权限配置这些库，权限过大，不安全。\nManage Jenkins » Configure System » Global Pipeline Libraries\nJenkinsFile引用共享库 勾选 Load implicitly, 可直接引用共享库中变量方法； 不勾选，则需要使用@Library显式引用。 1 2 3 4 5 @Library(\u0026#39;my-shared-library\u0026#39;) _ /* Using a version specifier, such as branch, tag, etc */ @Library(\u0026#39;my-shared-library@1.0\u0026#39;) _ /* Accessing multiple libraries with one statement */ @Library([\u0026#39;my-shared-library\u0026#39;, \u0026#39;otherlib@abc1234\u0026#39;]) _ 编写Pipeline-lib steps 共享库：\n1 2 3 4 5 6 7 8 // src/org/foo/Zot.groovy package org.foo; def checkOutFrom(repo) { git url: \u0026#34;git@github.com:jenkinsci/${repo}\u0026#34; } return this jenkinsFile中引用:\n1 2 def z = new org.foo.Zot() z.checkOutFrom(repo) vars 1 2 3 4 5 6 7 8 vars/log.groovy def info(message) { echo \u0026#34;INFO: ${message}\u0026#34; } def warning(message) { echo \u0026#34;WARNING: ${message}\u0026#34; } 1 2 3 4 5 Jenkinsfile @Library(\u0026#39;utils\u0026#39;) _ log.info \u0026#39;Starting\u0026#39; log.warning \u0026#39;Nothing to do!\u0026#39; Reference jenkins 共享库官方文档\n","description":"","id":101,"section":"posts","tags":["Devops","Jenkins","JenkinsFile","Pipeline"],"title":"jenkins-pipeline-lib使用","uri":"https://hex-go.github.io/posts/devops/2020-01-09-jenkins-pipeline-lib%E4%BD%BF%E7%94%A8/"},{"content":"重点 DN 是一条LDAP记录项的名字，并作为唯一标识。可以理解成uuid，具体格式像： \u0026ldquo;cn=admin,dc=service,dc=corp\u0026rdquo; 1.概念 LDAP：Lightweight Directory Access Protocol，轻量目录访问协议。 LDAP服务是一个为只读（查询、浏览、搜索）访问而优化的非关系型数据库，呈树状结构组织数据。 LDAP主要用做用户信息查询（如邮箱、电话等）或对各种服务访问做后台认证以及用户数据权限管控。 名词解释：\nDC: domain component一般为公司名，例如：dc=163,dc=com\nOU: organization unit为组织单元，最多可以有四级，每级最长32个字符，可以为中文\nCN: common name为用户名或者服务器名，最长可以到80个字符，可以为中文\nDN: distinguished name为一条LDAP记录项的名字，有唯一性，例如：dc:\u0026ldquo;cn=admin,ou=developer,dc=163,dc=com\u0026rdquo;\n图形示例:\n2.安装 2.1docker 安装 openldap官方镜像-Github ldap-account-manager Docker-hub 1 2 3 4 5 6 7 8 9 10 11 12 # 拉取镜像 docker pull osixia/openldap # 启动容器 docker run \\ -p 389:389 \\ --name openldap \\ --restart=always \\ --env LDAP_ORGANISATION=\u0026#34;sotemalltest\u0026#34; \\ --env LDAP_DOMAIN=\u0026#34;sotemalltest.com\u0026#34; \\ --env LDAP_ADMIN_PASSWORD=\u0026#34;redhat\u0026#34; \\ --detach osixia/openldap 说明：\n389端口：默认ldap服务是使用389端口 LDAP_ORGANISATION 表示ldap的机构组织 LDAP_DOMAIN 配置LDAP域 LDAP_ADMIN_PASSWORD 配置LDAP管理员(admin)的密码 默认用登陆用户名admin 如果是Windows用户，建议使用ldapadmin， 这样就省去安装管理ldap的服务，如果使用Ubuntu，建议还是装一个管理服务，毕竟Ubuntu下的管理ldap工具都太原始了，还不如命令来的好用。\n1 2 3 4 5 6 7 8 9 10 11 12 # 拉取ldap account manager镜像 docker pull ldapaccountmanager/lam # 启动容器 docker run -d \\ --restart=always \\ --name ldap-account-manager \\ -p 80:80 \\ --link openldap:ldap-host \\ --env PHPLDAPADMIN_LDAP_HOSTS=ldap-host \\ --env PHPLDAPADMIN_HTTPS=false \\ --detach ldapaccountmanager/lam 说明：\n--link这里连接到OpenLDAP容器并起了一个别名ldap-host PHPLDAPADMIN_LDAP_HOSTS这里直接通过别名指向OpenLDAP容器，这样不需要写死IP地址 PHPLDAPADMIN_HTTPS不使用443协议 --restart=always加入此参数是防止系统重启了容器未启动。(docker服务开机启动) 2.2Kubernetes 安装 获取chart:\ngithub地址: https://github.com/helm/charts.git\n文件路径: charts-stable-openldap\n1 helm install --name=openldap openldap 具体详细配置，参考该chart readme文件。\n3.使用 3.1Docker 版使用 访问ldap-account-manager,打开网页访问： http://IP\n点击上图3号位置，配置lam。如下图所示，点击Edit server profiles\n提示输入Lam密码，默认密码lam，可自行修改。登录后如下图做相应修改:\n修改一下默认的管理员帐号：\n接下来是修改默认创建的两个组，这两个会在首次登陆系统时提示创建\n保存后，登陆系统\n提示创建默认的组:\nlam详细使用 参考博客ldap account manager 使用\nReference 运维吧-ldap1-openldap部署及管理维护\n运维吧-ldap2-SVN集成openldap\n运维吧-ldap3-GitLab集成OpenLDAP认证\n运维吧-ldap4-Jenkins集成OpenLDAP认证\nldap-jenkins\nldap-grafana\nlam 使用说明\n","description":"","id":102,"section":"posts","tags":["Devops","LDAP","Deployment"],"title":"LDAP部署手册","uri":"https://hex-go.github.io/posts/devops/2020-01-08-ldap%E9%83%A8%E7%BD%B2%E6%89%8B%E5%86%8C/"},{"content":"运行环境\npython环境: python3.7\n安装包\n1 pip install ldap3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 #!/usr/bin/python # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; @Time : 2019/11/14 5:37 PM @Author : Hex @File : ldapBaseApi.py @Software: PyCharm # ApiDocument: https://ldap3.readthedocs.io/ # https://ldap3.readthedocs.io/tutorial_operations.html# \u0026#34;\u0026#34;\u0026#34; # import sys # reload(sys) # sys.setdefaultencoding(\u0026#39;utf8\u0026#39;) from ldap3 import Server, Connection, SUBTREE, ALL_ATTRIBUTES from ldap3.core.exceptions import LDAPBindError from ldap3 import MODIFY_REPLACE from ldap3.utils.dn import safe_rdn from rest_framework.exceptions import APIException class LDAP(object): def __init__(self, host, port, user, password, base_dn): dn = \u0026#34;cn=%s,%s\u0026#34; % (user, base_dn) self.server = Server(host=host, port=port) self.base_dn = base_dn self.__conn = Connection(self.server, dn, password, auto_bind=True) def add_ou(self, ou, oid): \u0026#34;\u0026#34;\u0026#34; 参考: https://ldap3.readthedocs.io/tutorial_operations.html#create-an-entry 添加oy :param ou: \u0026#39;ou=测试部,dc=domain,dc=com\u0026#39; 或者 \u0026#39;ou=测试子部门,ou=测试部,dc=domain,dc=com\u0026#39; :param oid: 部门id保存至st中 :return: \u0026#34;\u0026#34;\u0026#34; return self.__conn.add(ou, \u0026#39;organizationalUnit\u0026#39;, {\u0026#34;st\u0026#34;: oid}) def add_user(self, userid, username, mobile, mail, title, ou_dn, gidnumber=501, alias=None): \u0026#34;\u0026#34;\u0026#34; 参考: https://ldap3.readthedocs.io/tutorial_operations.html#create-an-entry :param userid: \u0026#34;linan\u0026#34; :param username: \u0026#34;姓名\u0026#34; cn=姓名 :param mobile: :param mail: \u0026#34;xxx@domain.com\u0026#34; :param title: :param ou_dn: \u0026#34;ou=运维中心,dc=domain,dc=com\u0026#34; :param gidnumber: 501 默认用户组 :return: \u0026#34;\u0026#34;\u0026#34; l = self.__conn objectclass = [\u0026#39;top\u0026#39;, \u0026#39;person\u0026#39;, \u0026#39;inetOrgPerson\u0026#39;, \u0026#39;posixAccount\u0026#39;] add_dn = \u0026#34;cn=%s,%s\u0026#34; % (username, ou_dn) # 也可以随机生成,我先随便写一个值，这个需要自己定义规则 password = \u0026#39;%s@qwe\u0026#39; % userid uidNumber = \u0026#39;%s\u0026#39; % userid.strip(\u0026#34;xxx\u0026#34;) # 添加用户 s = l.add(add_dn, objectclass, {\u0026#39;mobile\u0026#39;: mobile, \u0026#39;sn\u0026#39;: userid, \u0026#39;mail\u0026#39;: mail, \u0026#39;userPassword\u0026#39;: password, \u0026#39;title\u0026#39;: title, \u0026#39;uid\u0026#39;: username, \u0026#39;gidNumber\u0026#39;: gidnumber, \u0026#39;uidNumber\u0026#39;: uidNumber, \u0026#39;homeDirectory\u0026#39;: \u0026#39;/home/users/%s\u0026#39; % userid, \u0026#39;loginShell\u0026#39;: \u0026#39;/bin/bash\u0026#39; }) return s def get_oudn_by_st(self, st, base_dn=None): \u0026#34;\u0026#34;\u0026#34; 根据 st值 获取组织dn 参考: https://ldap3.readthedocs.io/tutorial_searches.html :param base_dn: :param st: 部门id :return: entry \u0026#34;\u0026#34;\u0026#34; if not base_dn: base_dn = self.base_dn # 查询ou 中 返回的信息 attribute 包含 st status = self.__conn.search(base_dn, \u0026#39;(objectclass=organizationalUnit)\u0026#39;, attributes=[\u0026#34;st\u0026#34;]) if status: flag = False for i in self.__conn.entries: if st: if st in i.entry_attributes_as_dict[\u0026#34;st\u0026#34;]: return i else: return False else: return False def get_object_classes_info(self, objec_classes): \u0026#34;\u0026#34;\u0026#34; 获取 Ldap中 object_classes的必要参数以及其他信息 参考: https://ldap3.readthedocs.io/tutorial_searches.html :param objec_classes: objec_classes :return: \u0026#34;\u0026#34;\u0026#34; print(self.server.schema.object_classes[objec_classes]) def get_userdn_by_mail(self, mail, base_dn=None): \u0026#34;\u0026#34;\u0026#34; 通过邮箱地址，获取用户dn。部分没有邮箱地址的用户被忽略，不能使用ldap认证 参考: https://ldap3.readthedocs.io/tutorial_searches.html :param mail: :param base_dn: :return: \u0026#34;\u0026#34;\u0026#34; if not base_dn: base_dn = self.base_dn status = self.__conn.search(base_dn, search_filter=\u0026#39;(mail={})\u0026#39;.format(mail), search_scope=SUBTREE, attributes=ALL_ATTRIBUTES, ) if status: flag = False for i in self.__conn.entries: # print(i.entry_dn) return i else: return False else: return False def get_userdn_by_args(self, base_dn=None, **kwargs): \u0026#34;\u0026#34;\u0026#34; 参考: https://ldap3.readthedocs.io/tutorial_searches.html 获取用户dn, 通过 args 可以支持多个参数: get_userdn_by_args(mail=\u0026#34;xxx@domain.com\u0026#34;, uid=\u0026#34;姓名\u0026#34;) 会根据 kwargs 生成 search的内容，进行查询: 多个条件是 \u0026amp; and查询 返回第一个查询到的结果, 建议使用唯一标识符进行查询 这个函数基本可以获取所有类型的数据 :param base_dn: :param kwargs: :return: \u0026#34;\u0026#34;\u0026#34; search = \u0026#34;\u0026#34; for k, v in kwargs.items(): search += \u0026#34;(%s=%s)\u0026#34; % (k, v) if not base_dn: base_dn = self.base_dn if search: search_filter = \u0026#39;(\u0026amp;{})\u0026#39;.format(search) else: search_filter = \u0026#39;\u0026#39; status = self.__conn.search(base_dn, search_filter=search_filter, search_scope=SUBTREE, attributes=ALL_ATTRIBUTES ) if status: return self.__conn.entries else: return False def authenticate_userdn_by_mail(self, mail, password): \u0026#34;\u0026#34;\u0026#34; 验证用户名密码 通过邮箱进行验证密码 :param mail: :param password: :return: \u0026#34;\u0026#34;\u0026#34; entry = self.get_userdn_by_mail(mail=mail) if entry: bind_dn = entry.entry_dn try: Connection(self.server, bind_dn, password, auto_bind=True) return True except LDAPBindError: return False else: print(\u0026#34;user: %s not exist! \u0026#34; % mail) return False def update_user_info(self, user_dn, action=MODIFY_REPLACE, **kwargs): \u0026#34;\u0026#34;\u0026#34; :param dn: 用户dn 可以通过get_userdn_by_args，get_userdn_by_mail 获取 :param action: MODIFY_REPLACE 对字段原值进行替换 MODIFY_ADD 在指定字段上增加值 MODIFY_DELETE 对指定字段的值进行删除 :param kwargs: 要进行变更的信息内容 uid userPassword mail sn gidNumber uidNumber mobile title :return: \u0026#34;\u0026#34;\u0026#34; allow_key = \u0026#34;uid userPassword mail sn gidNumber uidNumber mobile title\u0026#34;.split(\u0026#34; \u0026#34;) update_args = {} for k, v in kwargs.items(): if k not in allow_key: msg = \u0026#34;字段: %s, 不允许进行修改, 不生效\u0026#34; % k print(msg) return False update_args.update({k: [(action, [v])]}) print(update_args) status = self.__conn.modify(user_dn, update_args) return status def update_user_cn(self, user_dn, new_cn): \u0026#34;\u0026#34;\u0026#34; 修改cn dn: cn=用户,ou=运维部,ou=研发中心,dc=domain,dc=com rdn就是 cn=用户 Example: from ldap3.utils.dn import safe_rdn safe_rdn(\u0026#39;cn=b.smith,ou=moved,ou=ldap3-tutorial,dc=demo1,dc=freeipa,dc=org\u0026#39;) [cn=b.smith] :param dn: :param new_cn: :return: \u0026#34;\u0026#34;\u0026#34; s = self.__conn.modify_dn(user_dn, \u0026#39;cn=%s\u0026#39; % new_cn) return s def update_ou(self, dn, new_ou_dn): \u0026#34;\u0026#34;\u0026#34; 更换所在的OU :param dn: 要进行变动的DN :param new_ou_dn: 新的OU DN :return: \u0026#34;\u0026#34;\u0026#34; rdn = safe_rdn(dn) print(rdn) s = self.__conn.modify_dn(dn, rdn[0], new_superior=new_ou_dn) return s def delete_dn(self, dn): \u0026#34;\u0026#34;\u0026#34; 要进行删除的DN :param dn: :return: \u0026#34;\u0026#34;\u0026#34; # 如果不是以cn开头的需要清理(删除) sub-link if not dn.startswith(\u0026#34;cn\u0026#34;): # 获取dn 下所有 sub Person DN 进行删除 allUserEntry = self.get_userdn_by_args(base_dn=dn, objectClass=\u0026#34;Person\u0026#34;) if allUserEntry: for userentry in allUserEntry: self.__conn.delete(userentry.entry_dn) print(\u0026#34;deleting ou %s and delete sub Person DN: %s\u0026#34; % (dn, userentry.entry_dn)) # 获取dn 下所有 sub OU进行删除 allOuEntry = self.get_userdn_by_args(base_dn=dn, objectClass=\u0026#34;organizationalUnit\u0026#34;) if allOuEntry: for ouEntry in reversed(allOuEntry): s = self.__conn.delete(ouEntry.entry_dn) print(\u0026#34;deleting ou %s and delete sub organizationalUnit DN: %s\u0026#34; % (dn, ouEntry.entry_dn)) else: s = self.__conn.delete(dn) # print(self.__conn.result) return s if __name__ == \u0026#39;__main__\u0026#39;: ldap_config = { \u0026#39;host\u0026#39;: \u0026#34;10.12.0.23\u0026#34;, \u0026#39;port\u0026#39;: 32616, \u0026#39;base_dn\u0026#39;: \u0026#39;dc=service,dc=corp\u0026#39;, \u0026#39;user\u0026#39;: \u0026#39;admin\u0026#39;, \u0026#39;password\u0026#39;: \u0026#39;xxxxxx\u0026#39;, } ldapObj = LDAP(**ldap_config) # 同步企业微信 组织架构 to Ldap # 同步企业微信 User To ldap # ------------------------------- # 删除DN, 对DN下的 sub 进行递归删除 # s = ldapObj.get_oudn_by_st(\u0026#34;1\u0026#34;) # status = ldapObj.delete_dn(s.entry_dn) # print(status) # ------------------------------- # 验证用户密码 # s = ldapObj.authenticate_userdn_by_mail(\u0026#34;linan@domain.com\u0026#34;, \u0026#34;xxx9999@qwe\u0026#34;) # - ----------------------------- # 添加用户 # s = ldapObj.add_user(\u0026#34;xxx9999\u0026#34;, \u0026#34;李南\u0026#34;, \u0026#34;190283812\u0026#34;, \u0026#34;linan@domain.com\u0026#34;, \u0026#34;运维\u0026#34;, # ou_dn=\u0026#34;ou=运维中心,dc=domain,dc=com\u0026#34;) # -------------------------------- # 查询 ou st 组id # s = obj.get_oudn_by_st(st=\u0026#34;1\u0026#34;) # -------------------------------- # 添加OU # obj.add_ou(\u0026#34;ou=总部,dc=domain,dc=com\u0026#34;, 1) # obj.add_ou(\u0026#34;ou=研发中心,ou=总部,dc=domain,dc=com\u0026#34;, 2) # -------------------------------- # 查询用户是否存在 - 通过 mail 获取用户 dn_entry # ldapObj.get_userdn_by_mail(mail=\u0026#34;linan@domain.com\u0026#34;) # -------------------------------- # 根据 参数 查询用户DN data = [dn_entry, ...] ，多个参数为 \u0026amp; # data = ldapObj.get_userdn_by_args(cn=\u0026#34;李南\u0026#34;,mail=\u0026#34;xxxx\u0026#34;) # -------------------------------- # 对指定dn 进行参数修改 多个参数可以一起修改 # s = ldapObj.update_user_info(data[0].entry_dn, userPassword=\u0026#34;123456\u0026#34;) # -------------------------------- # 对指定DN 变更 OU-DN # s = ldapObj.update_user_ou(data[0].entry_dn, s.entry_dn) # -------------------------------- # 对指定DN 修改CN名称 # ldapObj.update_cn(data[0].entry_dn,new_cn=\u0026#34;李南男\u0026#34;) # -------------------------------- # 获取objectClass 详细信息 # ldapObj.get_object_classes_info(\u0026#34;organizationalUnit\u0026#34;) # ldapObj.get_object_classes_info(\u0026#34;posixAccount\u0026#34;) # ldapObj.get_object_classes_info(\u0026#34;inetOrgPerson\u0026#34;) # ldapObj.get_object_classes_info(\u0026#34;person\u0026#34;) # 没有邮箱地址的用户: s = ldapObj.get_userdn_by_args(ou=\u0026#34;Product\u0026#34;) data = ldapObj.get_userdn_by_args(base_dn=s[0].entry_dn, objectclass=\u0026#34;inetOrgPerson\u0026#34;) for i in data: print(i.entry_dn) print(s) ","description":"","id":103,"section":"posts","tags":["Python","LDAP"],"title":"LDAP-Python 操作库","uri":"https://hex-go.github.io/posts/python/20200108-ldap-python%E6%93%8D%E4%BD%9C%E5%BA%93/"},{"content":"重点 如果使用multi-pipeline， 则在---之后不能跟注释。而且multi-pipeline之间的无法共通数据，每个新的pipeline就是一个完全新的环境。 能在DockerFile中处理的，就不要放在drone中处理。 同一Pipeline不同step可以相互引用生成的文件，不同Pipeline完全独立。都是重新的目录，新的clone文件。 Drone Pipeline的构建命令都是在一个容器中去执行的，比如要使用Helm来部署应用，就需要容器有helm，并能够目标Kubernetes集群联通。一种方式：可以自己做一个镜像，把 helm 命令和连接集群的配置文件都内置到里面去，但这样不是很灵活，不具有通用性。另一种方法： Drone 的插件机制，使用插件配置。 示例 go项目 项目 go代码： 下面是用go-web框架gin创建一个简单的 web 服务，在 GitHub 上创建一个名为 drone-demo 的代码仓库，Clone 到本地，添加名为 main.go 的文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/sirupsen/logrus\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/health\u0026#34;, func(c *gin.Context) { c.JSON(http.StatusOK, gin.H { \u0026#34;health\u0026#34;: true, }) }) if err := r.Run(\u0026#34;:8080\u0026#34;); err != nil { logrus.WithError(err).Fatal(\u0026#34;Couldn\u0026#39;t listen\u0026#34;) } } 服务监听在 8080 端口，提供了一个简单的/health路由，返回一个简单的 JSON 消息表示应用状态状态，本地我们使用的是 go1.11.4 版本，所以可以通过 Go Modules 来管理应用的依赖，在项目目录下面执行 mod init：\n1 go mod init dronek8s 项目DockerFile： 生产环境，建议在DockerFile中多阶段构建来将项目的构建和打包工作放在同一个 Dockerfile， 此处为了研究Drone的Pipeline使用，将两步分开。\n在项目根目录下面创建 Dockerfile 文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 FROM alpine WORKDIR /home # 修改alpine源为阿里云 RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g\u0026#39; /etc/apk/repositories \u0026amp;\u0026amp; \\ apk update \u0026amp;\u0026amp; \\ apk upgrade \u0026amp;\u0026amp; \\ apk add ca-certificates \u0026amp;\u0026amp; update-ca-certificates \u0026amp;\u0026amp; \\ apk add --update tzdata \u0026amp;\u0026amp; \\ rm -rf /var/cache/apk/* COPY demo-app /home/ ENV TZ=Asia/Shanghai EXPOSE 8080 ENTRYPOINT ./demo-app 构建结果文件demo-app拷贝到镜像中去执行来构建镜像，手动构建生成该文件命令是在根目录下面执行 go build 命令：\n1 2 3 4 5 # build CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o demo-app # docker image docker build -t hex/drone-demo . 项目 .drone.yml 项目根目录下创建一个名为.drone.yml文件，文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 kind: pipeline name: default steps: - name: linter image: golang:latest environment: GOPROXY: https://mirrors.aliyun.com/goproxy/ commands: - go get -u github.com/golangci/golangci-lint/cmd/golangci-lint - golangci-lint run - name: build image: golang:latest environment: GOPROXY: https://mirrors.aliyun.com/goproxy/ commands: - CGO_ENABLED=0 go build -o demo-app - name: docker image: plugins/docker settings: repo: hex/drone-demo use_cache: true username: from_secret: docker_username password: from_secret: docker_password tags: - latest when: event: push branch: master - name: deploy image: quay.io/ipedrazas/drone-helm environment: STABLE_REPO_URL: https://mirror.azure.cn/kubernetes/charts/ SERVICE_ACCOUNT: tiller API_SERVER: from_secret: api_server KUBERNETES_TOKEN: from_secret: kubernetes_token KUBERNETES_CERTIFICATE: from_secret: kubernetes_ca settings: client-only: true wait: true recreate_pods: true chart: ./helm release: drk8d values_files: [\u0026#34;./helm/my-values.yaml\u0026#34;] namespace: kube-ops 说明:\nlinter: 在golang:latest镜像中执行任务commands中的命令 build: 在golang:latest镜像中执行任务commands中的命令 docker: 使用官方插件plugins/docker，该镜像可以指定Dockerfile 的路径，镜像的tag，以及镜像仓库的用户名和密码。\n此处用户名密码通过secret的方式传入。该secret可以通过drone-cli创建，也可以Drone网页配置。 deploy: 使用官方插件drone-helm\nDrone 的插件页面找到和 Helm 相关的插件：http://plugins.drone.io/ipedrazas/drone-helm/，这个插件的基本用法如下: 1 2 3 4 5 6 7 8 9 pipeline: helm_deploy: image: quay.io/ipedrazas/drone-helm skip_tls_verify: true chart: ./charts/my-chart release: ${DRONE_BRANCH} values: secret.password=${SECRET_PASSWORD},image.tag=${TAG} prefix: STAGING namespace: development 上面Pipeline相当于：\n1 helm upgrade --install ${DRONE_BRANCH} ./charts/my-chart --namespace development --set secret.password=${SECRET_PASSWORD},image.tag=${TAG} helm连接Kubernetes集群可以通过API_SERVER、KUBERNETES_TOKEN、KUBERNETES_CERTIFICATE 三个环境变量来指定。\nAPI_SERVER就是集群的APIServer服务地址；KUBERNETES_TOKEN获取通过创建一个 ServiceAccount，去绑定一个的集群角色权限(比如cluster-admin)，然后获取ServiceAccount 对应的TOKEN。比如我们 Helm 的服务端 Tiller 服务对应的 ServiceAccount，我们可以这样来获取：\n1 2 3 4 $ kubectl -n kube-system get secrets | grep tiller tiller-token-z4f6k kubernetes.io/service-account-token 3 115d $ kubectl get secret tiller-token-z4f6k -o jsonpath={.data.token} -n kube-system | base64 --decode eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.xxxxx.jO7vEZCzLbtBg 证书信息同样可以通过上面的 secret 来获取：\n1 kubectl get secret tiller-token-z4f6k -o jsonpath={.data.ca\\\\.crt} -n kube-system 注意： 证书信息不需要用 base64 解码。\nnode项目 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 workspace: base: /data/apps/opt path: web-im pipeline: restore-cache: image: drillster/drone-volume-cache restore: true mount: - node_modules - tag volumes: - /data/apps/opt/web-im:/cache build: image: node:7.8 privileged: true commands: - npm run build - mkdir -p publish/demo/javascript - cp -r demo/images publish/demo - cp -r demo/stylesheet publish/demo - cp -r demo/javascript/dist publish/demo/javascript/ - cp -r demo/javascript/src publish/demo/javascript/ - mkdir publish/sdk - cp -r sdk/dist publish/sdk - cp -r sdk/src publish/sdk - cp sdk/*.* publish/sdk - cp -r webrtc publish - cp favicon.ico publish/ - cp index.html publish/ - cp CHANGELOG.md publish/ - cp package.json publish/ - cp webpack.config.js publish/ - cp README.md publish/ - cp .babelrc publish/ - cp -rf publish image/docker/webim/webim - echo \u0026#39;build success\u0026#39; when: branch: [ dev, online ] dockerize-latest: image: plugins/docker environment: - DOCKER_LAUNCH_DEBUG=true debug: true repo: docker-registry-cn.easemob.com/kubernetes/im/webim tags: latest registry: docker-registry-cn.easemob.com secrets: [ docker_username, docker_password ] dockerfile: image/docker/webim/Dockerfile context: image/docker/webim/ when: branch: dev deploy-latest: image: docker-registry-cn.easemob.com/kubernetes/im/webim-deploy:latest pull: true environment: - DOCKER_LAUNCH_DEBUG=true - TAG=latest secrets: [ ssh_key, jumpserver_host, jumpserver_port, sandbox_host ] debug: true when: branch: dev dockerize-online: image: plugins/docker environment: - DOCKER_LAUNCH_DEBUG=true debug: true repo: docker-registry-cn.easemob.com/kubernetes/im/webim tags: ${DRONE_COMMIT:0:7} registry: docker-registry-cn.easemob.com secrets: [ docker_username, docker_password ] dockerfile: image/docker/webim/Dockerfile context: image/docker/webim/ when: branch: online deploy-online: image: docker-registry-cn.easemob.com/kubernetes/im/webim-online:latest pull: true environment: - DOCKER_LAUNCH_DEBUG=true - TAG=${DRONE_COMMIT:0:7} secrets: [ ssh_key, jumpserver_host, jumpserver_port, online_host ] debug: true when: branch: online rollback-online: image: docker-registry-cn.easemob.com/kubernetes/im/webim-rollback:latest pull: true environment: - DOCKER_LAUNCH_DEBUG=true secrets: [ ssh_key, jumpserver_host, jumpserver_port, online_host ] debug: true when: branch: rollback rebuild-cache: image: drillster/drone-volume-cache rebuild: true mount: - node_modules - tag volumes: - /data/apps/opt/web-im:/cache notify: image: drillster/drone-email port: 25 secrets: [ plugin_host, plugin_from, plugin_username, plugin_password ] when: status: [ failure, success ] Reference ","description":"","id":104,"section":"posts","tags":["Devops","Drone","Pipeline","Dockerfile"],"title":"Drone-Pipeline使用举例","uri":"https://hex-go.github.io/posts/devops/2020-01-07-drone-pipeline%E4%BD%BF%E7%94%A8%E4%B8%BE%E4%BE%8B/"},{"content":"重点 能在DockerFile中做的，比如多阶段构建，就在Dockerfile中做。不能在Jenkinsfile中做太多特例化的事情，否则不好管理迁移。 如果有时间，可以做一个简单的ui来配置生成Jenkinsfile，这样就可以省去开发人员学习JenkinsFile的成本。也可以增加限制，把控标准。 JenkinsFile 文档目录 拉代码 代码构建 构建+推送镜像 推送初始化脚本 推送chart 1 拉取代码 1 2 3 stage(\u0026#39;Check out\u0026#39;) { checkout scm } 1.1 镜像版本控制 \u0026ndash; {ver} master \u0026ndash;\u0026gt; latest\nrelease \u0026ndash;\u0026gt; stable\nTAG \u0026ndash;\u0026gt; 保持不变\n1 2 3 4 5 6 name_list = \u0026#34;$JOB_NAME\u0026#34;.split(\u0026#39;/\u0026#39;) def ver = name_list[1] def ver_map = [\u0026#34;master\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;release\u0026#34;: \u0026#34;stable\u0026#34;] if(ver_map.containsKey(ver)){ ver = ver_map.get(ver) } 1.2 镜像版本控制 \u0026ndash; {ver} 举例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 jenkins配置的job名为 \u0026#39;paas-devops-ui\u0026#39; 选择 master 分支构建 $JOB_NAME : paas-devops-ui/master name_list : [\u0026#39;paas-devops-ui\u0026#39;, \u0026#39;master\u0026#39;] ver : \u0026#39;master\u0026#39; job : \u0026#39;paas-devops-ui\u0026#39; job_list : [\u0026#39;paas\u0026#39;, \u0026#39;devops\u0026#39;, \u0026#39;ui\u0026#39;] project : paas job_size : 2 img_list : [\u0026#39;devops\u0026#39;, \u0026#39;ui\u0026#39;] img : devops-ui ver : \u0026#39;latest\u0026#39; (重赋值) tag : \u0026#34;reg.service.com/paas/devops-ui:latest\u0026#34; script_dir : paas/devops-ui/latest slug_dir : /tmp/paas/devops-ui/latest slug_file : /tmp/paas/devops-ui/latest/slug.tgz 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 name_list = \u0026#34;$JOB_NAME\u0026#34;.split(\u0026#39;/\u0026#39;) def ver = name_list[1] def job = name_list[0] job_list = \u0026#34;$job\u0026#34;.split(\u0026#39;-\u0026#39;) def project = job_list[0] job_size = job_list.size()-1 img_list = [] for(x in (1..job_size)){ img_list.add(job_list[x]) } def img = img_list.join(\u0026#39;-\u0026#39;) def ver_map = [\u0026#34;master\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;release\u0026#34;: \u0026#34;stable\u0026#34;] if(ver_map.containsKey(ver)){ ver = ver_map.get(ver) } def tag = \u0026#34;reg.service.com/\u0026#39;${ project }\u0026#39;/\u0026#39;${ img }\u0026#39;:\u0026#39;${ ver }\u0026#39;\u0026#34; // def tag = \u0026#34;reg.service.com\u0026#34;+\u0026#34;/\u0026#34;+project+\u0026#39;/\u0026#39;+img+\u0026#39;:\u0026#39;+ver def script_dir= project+\u0026#39;/\u0026#39;+img+\u0026#39;/\u0026#39;+ver def slug_dir = \u0026#34;/tmp/\u0026#39;${script_dir}\u0026#39;\u0026#34; def slug_file = \u0026#34;\u0026#39;${slug_dir}\u0026#39;/slug.tgz\u0026#34; 2. 代码构建 2.1 mvn项目构建 1 2 3 4 5 6 7 def mvnHome = tool \u0026#39;maven_3_5_4\u0026#39; stage(\u0026#39;Build\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn clean package -DskipTests=true\u0026#34; } } 2.2 Node项目构建 1 2 3 4 5 6 7 8 9 10 11 12 13 def nodeHome = tool \u0026#39;NodeJS_8.12\u0026#39; stage(\u0026#39;Build\u0026#39;) { withEnv([\u0026#34;PATH+NODE=${ nodeHome }/bin\u0026#34;]) { dir(\u0026#39;devops_ui\u0026#39;){ sh \u0026#39;npm install\u0026#39; sh \u0026#34;${ng_cmd}\u0026#34; } dir(\u0026#39;devops_ui/devops\u0026#39;){ sh \u0026#39;npm install\u0026#39; } } } 3. Build+Push 镜像 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def script_dir= project+\u0026#39;/\u0026#39;+img+\u0026#39;/\u0026#39;+ver def slug_dir = \u0026#34;/tmp/\u0026#39;${script_dir}\u0026#39;\u0026#34; def slug_file = \u0026#34;\u0026#39;${slug_dir}\u0026#39;/slug.tgz\u0026#34; stage(\u0026#39;Docker build\u0026#39;) { // 创建存放代码slug包的目录 sh(\u0026#34;mkdir -p \u0026#39;${ slug_dir }\u0026#39;\u0026#34;) // 在DevopsUI目录，将当前文件夹除去.git src 的所有内容打成 slug.tgz包 // 目录结构为： /tmp/{project}/{img}/{ver}/slug.tgz dir(\u0026#39;devops_ui\u0026#39;){ sh(\u0026#34;tar -z --exclude=\u0026#39;.git\u0026#39; --exclude=\u0026#39;src\u0026#39; -cf \u0026#39;${slug_file}\u0026#39; .\u0026#34;) } // 将/tmp/{project}/{img}/{ver}/slug.tgz 拷贝到 Dockerfile 同级 sh(\u0026#34;cp ${slug_file} .\u0026#34;) // docker构建 sh(\u0026#34;docker build -t ${tag} .\u0026#34;) // 推送镜像 sh(\u0026#34;docker push ${tag}\u0026#34;) } 4. 推送初始化脚本 项目根目录下如果没有/deploy/install.sh, 那么说明该项目不需要初始化脚本，跳过。\n1 2 3 4 5 6 7 8 9 stage(\u0026#39;Send script\u0026#39;) { def exists = fileExists \u0026#39;./deploy/install.sh\u0026#39; if (exists) { sh(\u0026#34;tar -zcvf deploy.tgz deploy/\u0026#34;) sh(\u0026#34;curl -v -u username:password -X POST \u0026#39;http://nexus.service.com/service/rest/v1/components?repository=paasinstall\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: multipart/form-data\u0026#39; -F \u0026#39;raw.directory=${script_dir}\u0026#39; -F \u0026#39;raw.asset1=@deploy.tgz;type=application/x-compressed-tar\u0026#39; -F \u0026#39;raw.asset1.filename=deploy.tgz\u0026#39;\u0026#34;) } else { println \u0026#34;File doesn\u0026#39;t exist\u0026#34; } } 5. 推送chart 1 2 3 4 5 6 7 stage(\u0026#39;Send Helm\u0026#39;) { def gitUrl = \u0026#39;https://git.service.com/plugins/git/paas/charts.git\u0026#39; def gitCredentialsId = \u0026#39;4116a55e-8551-46b7-b864-xxxxxxxxxxxx\u0026#39; git credentialsId: \u0026#34;${ gitCredentialsId }\u0026#34;, url: \u0026#34;${ gitUrl }\u0026#34; helm package \u0026#39;\u0026#39; curl -X POST \u0026#34;http://dop.service.com/service/rest/v1/components?repository=market\u0026#34; -H \u0026#34;accept: application/json\u0026#34; -H \u0026#34;Content-Type: multipart/form-data\u0026#34; -F \u0026#34;helm.asset=@monitor-1.2.1.tgz;type=application/x-compressed-tar\u0026#34; } 6. 清理环境 1 2 3 4 5 6 7 8 9 stage(\u0026#39;Cleanup\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn -Dmaven.test.failure.ignore clean\u0026#34; } sh(\u0026#34;docker rmi ${tag}\u0026#34;) sh(\u0026#34;rm -f ${slug_file}\u0026#34;) sh \u0026#34;rm -rf *\u0026#34; sh \u0026#34;rm -rf .git\u0026#34; } 项目个性化需求 前端命令 如果job名末尾为-onlyapi ng命令为 ng build -c=onlyApi\n否则 ng命令为 ng build --prod\n1 2 3 4 5 6 7 8 9 10 11 12 13 def nodeHome = tool \u0026#39;NodeJS_8.12\u0026#39; def label = \u0026#34;$project\u0026#34;.split(\u0026#39;-\u0026#39;)[-1] def ng_cmd = \u0026#34;ng build --prod\u0026#34; def ng_map = [\u0026#34;onlyapi\u0026#34;: \u0026#34;ng build -c=onlyApi\u0026#34;] if(ng_map.containsKey(label)){ ng_cmd = ng_map.get(label) } withEnv([\u0026#34;PATH+NODE=${ nodeHome }/bin\u0026#34;]) { sh \u0026#39;npm install\u0026#39; sh \u0026#34;${ng_cmd}\u0026#34; } 在某个目录下执行命令 1 2 3 4 //例 在 **.git/devops_ui 目录下 执行编译命令 dir(\u0026#39;devops_ui/devops\u0026#39;){ sh \u0026#39;npm install\u0026#39; } 完整示例 node 项目 jenkinsFile:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 node { currentBuild.result = \u0026#34;SUCCESS\u0026#34; def ng_cmd = \u0026#34;ng build --prod\u0026#34; def nodeHome = tool \u0026#39;NodeJS_8.12\u0026#39; def ng_map = [\u0026#34;onlyapi\u0026#34;: \u0026#34;ng build -c=onlyApi\u0026#34;] if(ng_map.containsKey(label)){ ng_cmd = ng_map.get(label) } name_list = \u0026#34;$JOB_NAME\u0026#34;.split(\u0026#39;/\u0026#39;) //eg : \u0026#39;devops-api/master\u0026#39; --\u0026gt; [\u0026#39;devops-api\u0026#39;, \u0026#39;master\u0026#39;] def ver = name_list[1] //eg : \u0026#39;master\u0026#39; def job = name_list[0] //eg : \u0026#39;devops-api\u0026#39; job_list = \u0026#34;$job\u0026#34;.split(\u0026#39;-\u0026#39;) //eg : \u0026#39;devops-api\u0026#39; --\u0026gt; [\u0026#39;devops\u0026#39;, \u0026#39;api\u0026#39;] def project = job_list[0] //eg : \u0026#39;devops\u0026#39; job_size = job_list.size()-1 img_list = [] for(x in (1..job_size)){ img_list.add(job_list[x]) } def img = img_list.join(\u0026#39;-\u0026#39;) def ver_map = [\u0026#34;master\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;release\u0026#34;: \u0026#34;stable\u0026#34;] if(ver_map.containsKey(ver)){ ver = ver_map.get(ver) } def tag = \u0026#34;reg.service.com/\u0026#39;${ project }\u0026#39;/\u0026#39;${ img }\u0026#39;:\u0026#39;${ ver }\u0026#39;\u0026#34; // def tag = \u0026#34;reg.service.com\u0026#34;+\u0026#34;/\u0026#34;+project+\u0026#39;/\u0026#39;+img+\u0026#39;:\u0026#39;+ver def script_dir= project+\u0026#39;/\u0026#39;+img+\u0026#39;/\u0026#39;+ver def slug_dir = \u0026#34;/tmp/\u0026#39;${script_dir}\u0026#39;\u0026#34; def slug_file = \u0026#34;\u0026#39;${slug_dir}\u0026#39;/slug.tgz\u0026#34; try { stage(\u0026#39;Check out\u0026#39;) { checkout scm } stage(\u0026#39;Cleanup-before\u0026#39;) { withEnv([\u0026#34;PATH+NODE=${ nodeHome }/bin\u0026#34;]) { // sh \u0026#39;npm prune\u0026#39; sh \u0026#34;rm -rf devops_ui/node_modules\u0026#34; sh \u0026#34;rm -rf devops_ui/package-lock.json\u0026#34; sh \u0026#34;rm -rf devops_ui/devops/node_modules\u0026#34; sh \u0026#34;rm -rf devops_ui/devops/package-lock.json\u0026#34; } } stage(\u0026#39;Build\u0026#39;) { withEnv([\u0026#34;PATH+NODE=${ nodeHome }/bin\u0026#34;]) { dir(\u0026#39;devops_ui\u0026#39;){ sh \u0026#39;npm install\u0026#39; sh \u0026#34;${ng_cmd}\u0026#34; } dir(\u0026#39;devops_ui/devops\u0026#39;){ sh \u0026#39;npm install\u0026#39; } } } stage(\u0026#39;Docker build\u0026#39;) { sh(\u0026#34;mkdir -p \u0026#39;${ slug_dir }\u0026#39;\u0026#34;) dir(\u0026#39;devops_ui\u0026#39;){ sh(\u0026#34;tar -z --exclude=\u0026#39;.git\u0026#39; --exclude=\u0026#39;src\u0026#39; -cf \u0026#39;${slug_file}\u0026#39; .\u0026#34;) } sh(\u0026#34;cp ${slug_file} .\u0026#34;) sh(\u0026#34;docker build -t ${tag} .\u0026#34;) sh(\u0026#34;docker push ${tag}\u0026#34;) } stage(\u0026#39;Send script\u0026#39;) { def exists = fileExists \u0026#39;./deploy/install.sh\u0026#39; if (exists) { sh(\u0026#34;tar -zcvf deploy.tgz deploy/\u0026#34;) sh(\u0026#34;curl -v -u username:password -X POST \u0026#39;http://nexus.service.com/service/rest/v1/components?repository=paasinstall\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: multipart/form-data\u0026#39; -F \u0026#39;raw.directory=${script_dir}\u0026#39; -F \u0026#39;raw.asset1=@deploy.tgz;type=application/x-compressed-tar\u0026#39; -F \u0026#39;raw.asset1.filename=deploy.tgz\u0026#39;\u0026#34;) } else { println \u0026#34;File doesn\u0026#39;t exist\u0026#34; } } stage(\u0026#39;Send Helm\u0026#39;) { def gitUrl = \u0026#39;https://git.service.com/plugins/git/paas/devops-api.git\u0026#39; def gitCredentialsId = \u0026#39;4116a55e-8551-46b7-b864-xxxxxxxxxxxx\u0026#39; git credentialsId: \u0026#34;${ gitCredentialsId }\u0026#34;, url: \u0026#34;${ gitUrl }\u0026#34; curl -X POST \u0026#34;http://dop.service.com/service/rest/v1/components?repository=market\u0026#34; -H \u0026#34;accept: application/json\u0026#34; -H \u0026#34;Content-Type: multipart/form-data\u0026#34; -F \u0026#34;helm.asset=@monitor-1.2.1.tgz;type=application/x-compressed-tar\u0026#34; } stage(\u0026#39;Cleanup\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn -Dmaven.test.failure.ignore clean\u0026#34; sh(\u0026#34;docker rmi ${tag}\u0026#34;) sh(\u0026#34;rm -f ${slug_file}\u0026#34;) sh \u0026#34;rm -rf *\u0026#34; sh \u0026#34;rm -rf .git\u0026#34; } } } catch (err) { currentBuild.result = \u0026#34;FAILURE\u0026#34; throw err } } DockerFile:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 FROM reg.service.com/paas/node:8.12 # Create app directory RUN mkdir -p /usr/src/app # Bundle app source ADD ./devops_ui/slug.tgz /usr/src/app WORKDIR /usr/src/app/devops_ui ENV NODE_ENV dev CMD [\u0026#34;/usr/src/app/devops_ui/start.sh\u0026#34;] EXPOSE 8080 # Build image # docker build -t devops-api:v1 . #image save #docker save d38ea8888a73 -o ~/work/thirdCode/paas/devops-api.tar #docker images|grep none|awk \u0026#39;{print \u0026#34;docker rmi -f \u0026#34; $3}\u0026#39;|sh # docker rm -f $(docker ps -q -a) #tar zcvf devops.tgz devops # Run docker # docker run -e SYSTEMCONFIG=\u0026#39;{\u0026#34;port\u0026#34;:\u0026#34;8080\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;http://49.4.93.173:32090\u0026#34;}\u0026#39; -p 8080:8080 devops_ui:v1 #数据格式 http://localhost:8080/api/products/seed #{ # \u0026#34;port\u0026#34;:\u0026#34;8080\u0026#34;, # \u0026#34;url\u0026#34;:\u0026#34;http://49.4.93.173:32090\u0026#34; #} maven 项目 jenkinsFile:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 node { currentBuild.result = \u0026#34;SUCCESS\u0026#34; def mvnHome = tool \u0026#39;maven_3_5_4\u0026#39; name_list = \u0026#34;$JOB_NAME\u0026#34;.split(\u0026#39;/\u0026#39;) //eg : \u0026#39;devops-api/master\u0026#39; --\u0026gt; [\u0026#39;devops-api\u0026#39;, \u0026#39;master\u0026#39;] def ver = name_list[1] //eg : \u0026#39;master\u0026#39; def job = name_list[0] //eg : \u0026#39;devops-api\u0026#39; job_list = \u0026#34;$job\u0026#34;.split(\u0026#39;-\u0026#39;) //eg : \u0026#39;devops-api\u0026#39; --\u0026gt; [\u0026#39;devops\u0026#39;, \u0026#39;api\u0026#39;] def project = job_list[0] //eg : \u0026#39;devops\u0026#39; job_size = job_list.size()-1 img_list = [] for(x in (1..job_size)){ img_list.add(job_list[x]) } def img = img_list.join(\u0026#39;-\u0026#39;) def ver_map = [\u0026#34;master\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;release\u0026#34;: \u0026#34;stable\u0026#34;] if(ver_map.containsKey(ver)){ ver = ver_map.get(ver) } def tag = \u0026#34;reg.service.com/\u0026#39;${ project }\u0026#39;/\u0026#39;${ img }\u0026#39;:\u0026#39;${ ver }\u0026#39;\u0026#34; // def tag = \u0026#34;reg.service.com\u0026#34;+\u0026#34;/\u0026#34;+project+\u0026#39;/\u0026#39;+img+\u0026#39;:\u0026#39;+ver def script_dir= project+\u0026#39;/\u0026#39;+img+\u0026#39;/\u0026#39;+ver def slug_dir = \u0026#34;/tmp/\u0026#39;${script_dir}\u0026#39;\u0026#34; def slug_file = \u0026#34;\u0026#39;${slug_dir}\u0026#39;/slug.tgz\u0026#34; try { stage(\u0026#39;Check out\u0026#39;) { checkout scm } stage(\u0026#39;Build\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn clean package -DskipTests=true\u0026#34; //执行mvn命令 } } stage(\u0026#39;Docker build\u0026#39;) { sh(\u0026#34;mkdir -p \u0026#39;${ slug_dir }\u0026#39;\u0026#34;) sh(\u0026#34;tar -z --exclude=\u0026#39;.git\u0026#39; --exclude=\u0026#39;src\u0026#39; -cf \u0026#39;${slug_file}\u0026#39; .\u0026#34;) sh(\u0026#34;cp ${slug_file} .\u0026#34;) sh(\u0026#34;docker build -t ${tag} .\u0026#34;) sh(\u0026#34;docker push ${tag}\u0026#34;) } stage(\u0026#39;Send script\u0026#39;) { def exists = fileExists \u0026#39;./deploy/install.sh\u0026#39; if (exists) { sh(\u0026#34;tar -zcvf deploy.tgz deploy/\u0026#34;) sh(\u0026#34;curl -v -u admin:admin123 -X POST \u0026#39;http://nexus.service.com/service/rest/v1/components?repository=paasinstall\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: multipart/form-data\u0026#39; -F \u0026#39;raw.directory=${script_dir}\u0026#39; -F \u0026#39;raw.asset1=@deploy.tgz;type=application/x-compressed-tar\u0026#39; -F \u0026#39;raw.asset1.filename=deploy.tgz\u0026#39;\u0026#34;) } else { println \u0026#34;File doesn\u0026#39;t exist\u0026#34; } } stage(\u0026#39;Send Helm\u0026#39;) { def gitUrl = \u0026#39;https://git.service.com/plugins/git/paas/charts.git\u0026#39; def gitCredentialsId = \u0026#39;4116a55e-8551-46b7-b864-xxxxxxxxxxxx\u0026#39; git credentialsId: \u0026#34;${ gitCredentialsId }\u0026#34;, url: \u0026#34;${ gitUrl }\u0026#34; curl -X POST \u0026#34;http://dop.service.com/service/rest/v1/components?repository=market\u0026#34; -H \u0026#34;accept: application/json\u0026#34; -H \u0026#34;Content-Type: multipart/form-data\u0026#34; -F \u0026#34;helm.asset=@monitor-1.2.1.tgz;type=application/x-compressed-tar\u0026#34; } stage(\u0026#39;Cleanup\u0026#39;) { withEnv([\u0026#34;PATH+MAVEN=${ mvnHome }/bin\u0026#34;]) { sh \u0026#34;mvn -Dmaven.test.failure.ignore clean\u0026#34; } sh(\u0026#34;docker rmi ${tag}\u0026#34;) sh(\u0026#34;rm -f ${slug_file}\u0026#34;) sh \u0026#34;rm -rf *\u0026#34; sh \u0026#34;rm -rf .git\u0026#34; } } catch (err) { currentBuild.result = \u0026#34;FAILURE\u0026#34; throw err } } DockerFile:\n1 2 3 4 5 6 7 8 FROM reg.service.com/paas/jrunner:1.0.0 ENV LANG C.UTF-8 RUN set -x; \\ { \\ echo [program:customer-profile]; \\ echo command=/runner/init start web; \\ autorestart=true; \\ } \u0026gt; /etc/supervisor/conf.d/customer-profile.conf ","description":"","id":105,"section":"posts","tags":["Devops","Jenkins","Pipeline"],"title":"Jenkins-Pipeline使用举例","uri":"https://hex-go.github.io/posts/devops/2020-01-07-jenkins-pipeline%E4%BD%BF%E7%94%A8%E4%B8%BE%E4%BE%8B/"},{"content":"重要 Gogs 支持 本地认证+LDAP认证 模式。 Gogs 要求LDAP中的DN必须具备mail属性。 配置 使用安装时配置的管理帐号登陆gogs系统，点击头像进入管理面板—\u0026gt;认证管理源—\u0026gt;添加新的源,根据自己的ldap配置填入即可。\n这里就是一个绑定帐号，配置过gitlab的也差不多，也是需要一个帐号来获取ldap 帐号树的信息.\n说明:\n非必填项都未做配置\n认证名称: 必填项, 随意填写。 安全协议: 不加密。 主机地址: 此处部署k8s中，用的主机名。如果虚拟机部署可以填IP。 主机端口: ldap服务端口。 绑定DN: 绑定的dn，此处绑定的admi账号。 绑定密码: 上面dn的密码。 用户搜索基准: 从ou=Product往下查找匹配用户 用户过滤规则: dn的属性objectClass=posixAccount \u0026amp; uid=用户登录输入的用户名 邮箱属性: 由于Gogs要求邮箱属性必填，所以ldap创建的用户条目，必须具备mail属性。此处填写mail属性的键名 该授权认证将作为默认登录源: 勾选该配置。Gogs支持本地认证+ldap认证。比jenkins强太多了。 Reference Gogs 集成 LDAP\n","description":"","id":106,"section":"posts","tags":["Devops","LDAP","Gogs"],"title":"Gogs集成LDAP","uri":"https://hex-go.github.io/posts/devops/2020-01-06-gogs%E9%9B%86%E6%88%90ldap/"},{"content":"重要 ldap创建两个groupjenkins-admin和jenkins-manager。并分别将用户admin， operator各自分配到两个组下。（ldapadmin工具操作用户分配组: 在用户条目上右键View\\Edit Group Membership，选择要加入的组。 配置之前备份一下config.xml配置文件，方便出错恢复。文件地址/var/lib/jenkins_home/config.xml。 Jenkins一旦集成LDAP认证就无法使用本地认证。因此在保存ldap配置之前多测试下ldap连接，否则配置错误就无法登录jenkins，参考后面，解决错误配置ldap，导致无法登录问题。 Jenkins 的root DN和User search base需要重点注意。 配置jenkins-ldap 0. LDAP准备 添加jenkins相关的测试账户和组\n在group这个ou里面创建2个组，名为jenkins-admin,jenkins-manager。 在ou=people下面创建4个账户，名为admin,test01,test02,test03,配置好邮箱和密码。 在三个组上面添加对应的用户， jenkins-admin组添加admin， jenkins-manager组添加operator用户\n最终组织图如下： 1. jenkins插件安装 使用LDAP认证需要安装LDAP插件，安装插件有两种方法：\n方法一：后台插件管理里直接安装\n优点：简单方便，不需要考虑插件依赖问题 缺点：因为网络等各种问题安装不成功\n安装方法：登录Jenkins \u0026ndash;\u0026gt; 系统管理 \u0026ndash;\u0026gt; 插件管理 \u0026ndash;\u0026gt; 可选插件 \u0026ndash;\u0026gt; 搜索LDAP \u0026ndash;\u0026gt; 选中 \u0026ndash;\u0026gt; 直接安装 \u0026ndash;\u0026gt; 安装完成重启 如果安装失败，网上也有说在插件管理 \u0026ndash;\u0026gt; 高级 \u0026ndash;\u0026gt; 升级站点里替换URL为https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json，但替换了之后依然没有成功，最后还是使用方法二安装成功\n方法二：官网下载安装文件后台上传\n优点：一定可以安装成功的 缺点：麻烦，要去官网找插件并解决依赖\n插件下载地址：https://updates.jenkins-ci.org/download/plugins/ 安装方法：官网下载插件 \u0026ndash;\u0026gt; 登录Jenkins \u0026ndash;\u0026gt; 系统管理 \u0026ndash;\u0026gt; 插件管理 \u0026ndash;\u0026gt; 高级 \u0026ndash;\u0026gt; 上传插件 \u0026ndash;\u0026gt; 选择文件 \u0026ndash;\u0026gt; 上传 \u0026ndash;\u0026gt; 安装完成后重启\n上传插件安装可能会失败，大部分都是提示你当前插件依赖某些插件，只需要下载全部依赖插件，按照顺序上传安装即可，LDAP插件安装完成后，所有依赖的插件如下：\n2. 配置LDAP认证 登录Jenkins \u0026ndash;\u0026gt; 系统管理 \u0026ndash;\u0026gt; 全局安全配置\n访问控制选择“LDAP”，Server输入LDAP服务器地址，有其他配置可以点击“Advanced Server Configuration\u0026hellip;”\n说明：\nroot DN：这里的root DN只是指搜索的根，并非LDAP服务器的root dn。由于LDAP数据库的数据组织结构类似一颗大树，而搜索是递归执行的，理论上，我们如果从子节点（而不是根节点）开始搜索，因为缩小了搜索范围那么就可以获得更高的性能。这里的root DN指的就是这个子节点的DN，当然也可以不填，表示从LDAP的根节点开始搜索 User search base：这个配置也是为了缩小LDAP搜索的范围，例如Jenkins系统只允许ou为Admin下的用户才能登陆，那么你这里可以填写ou=Admin，这是一个相对的值，相对于上边的root DN，例如你上边的root DN填写的是dc=domain,dc=com，那么user search base这里填写了ou=Admin，那么登陆用户去LDAP搜索时就只会搜索ou=Admin,dc=domain,dc=com下的用户 User search filter：这个配置定义登陆的“用户名”对应LDAP中的哪个字段，如果你想用LDAP中的uid作为用户名来登录，那么这里可以配置为uid={0}（{0}会自动的替换为用户提交的用户名），如果你想用LDAP中的mail作为用户名来登录，那么这里就需要改为mail={0}。在测试的时候如果提示你user xxx does not exist，而你确定密码输入正确时，就要考虑下输入的用户名是不是这里定义的这个值了 Group search base：参考上边User search base解释 Group search filter：这个配置允许你将过滤器限制为所需的objectClass来提高搜索性能，也就是说可以只搜索用户属性中包含某个objectClass的用户，这就要求你对你的LDAP足够了解，一般我们也不配置 Group membership：没配置，没有详细研究 Manager DN：这个配置在你的LDAP服务器不允许匿名访问的情况下用来做认证，通常DN为cn=admin,dc=domain,dc=com这样 Manager Password：上边配置dn的密码 Display Name LDAP attribute：配置用户的显示名称，一般为显示名称就配置为uid，如果你想显示其他字段属性也可以这里配置，例如mail Email Address LDAP attribute：配置用户Email对应的字段属性，一般没有修改过的话都是mail，除非你用其他的字段属性来标识用户邮箱，这里可以配置 Enable Cache: 当你的LDAP数据量很大或者LDAP服务器性能较差时，可以开启缓存，配置缓存条数和过期时间，那么在过期时间内新请求优先查找本地缓存认证，认证通过则不会去LDAP服务器请求，以减轻LDAP服务器的压力。 配置完成后，不要立刻保存，点击``Test LDAP Settings`验证配置的准确性。\n这里输入的用户名就是你上边配置的User search filter里定义的LDAP中的属性, 本文配置的是uid 密码就是LDAP的密码\n3. 配置ldap分组认证 操作步骤: 选择 jenkins -\u0026gt; 系统管理-\u0026gt; 全局安全设置 -\u0026gt; 访问控制 -\u0026gt; ldap -\u0026gt; 授权策略，选择安全矩阵授权策略。\n备注 解决错误配置ldap，导致无法登录问题 为方便用户管理，想通过ldap集中式认证，接入harbor， Gogs， Gitlab， Jenkins，省去每个系统分别创建账号，并管理的问题。但Jenkins集成LDAP配置不当导致Jenkins无法登陆。下面是解决办法：\n首先在配置LDAP之前，可以先备份配置文件/var/lib/jenkins_home/config.xml， ldap的配置只会影响这个文件，可以在无法登录时，重新还原该文件，并重启jenkins服务. 如果没有备份该文件，也可以手动修改已变化的部分。在config.xml配置文件中找到这段关于ldap认证的信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;securityRealm class=\u0026#34;hudson.security.LDAPSecurityRealm\u0026#34; plugin=\u0026#34;ldap@1.20\u0026#34;\u0026gt; \u0026lt;disableMailAddrexxxesolver\u0026gt;false\u0026lt;/disableMailAddrexxxesolver\u0026gt; \u0026lt;configurations\u0026gt; \u0026lt;jenkins.security.plugins.ldap.LDAPConfiguration\u0026gt; \u0026lt;server\u0026gt;ldap://XXXXXX.com:389\u0026lt;/server\u0026gt; \u0026lt;rootDN\u0026gt;dc=XXXXXX,dc=com\u0026lt;/rootDN\u0026gt; \u0026lt;inhibitInferRootDN\u0026gt;false\u0026lt;/inhibitInferRootDN\u0026gt; \u0026lt;userSearchBase\u0026gt;\u0026lt;/userSearchBase\u0026gt; \u0026lt;userSearch\u0026gt;uid={0}\u0026lt;/userSearch\u0026gt; \u0026lt;groupMembershipStrategy class=\u0026#34;jenkins.security.plugins.ldap.FromGroupSearchLDAPGroupMembershipStrategy\u0026#34;\u0026gt; \u0026lt;filter\u0026gt;cn=jenkins\u0026lt;/filter\u0026gt; \u0026lt;/groupMembershipStrategy\u0026gt; \u0026lt;managerDN\u0026gt;uid=jarry,ou=People,dc=XXXXXX,dc=com\u0026lt;/managerDN\u0026gt; \u0026lt;managerPasswordSecret\u0026gt;{AQAAABAAAAAQWfZrb7qoIjeM=}\u0026lt;/managerPasswordSecret\u0026gt; \u0026lt;displayNameAttributeName\u0026gt;uid\u0026lt;/displayNameAttributeName\u0026gt; \u0026lt;mailAddressAttributeName\u0026gt;mail\u0026lt;/mailAddressAttributeName\u0026gt; \u0026lt;ignoreIfUnavailable\u0026gt;false\u0026lt;/ignoreIfUnavailable\u0026gt; \u0026lt;extraEnvVars class=\u0026#34;linked-hash-map\u0026#34;\u0026gt; \u0026lt;entry\u0026gt; \u0026lt;string\u0026gt;\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;\u0026lt;/string\u0026gt; \u0026lt;/entry\u0026gt; \u0026lt;/extraEnvVars\u0026gt; \u0026lt;/jenkins.security.plugins.ldap.LDAPConfiguration\u0026gt; \u0026lt;/configurations\u0026gt; \u0026lt;userIdStrategy class=\u0026#34;jenkins.model.IdStrategy$CaseInsensitive\u0026#34;/\u0026gt; \u0026lt;groupIdStrategy class=\u0026#34;jenkins.model.IdStrategy$CaseInsensitive\u0026#34;/\u0026gt; \u0026lt;disableRolePrefixing\u0026gt;true\u0026lt;/disableRolePrefixing\u0026gt; \u0026lt;/securityRealm\u0026gt; 上面的配置不当无法通过ldap认证，jenkins也无法正常登陆。可以把上面一段替换成以下内容：\n1 2 3 4 \u0026lt;securityRealm class=\u0026#34;hudson.security.HudsonPrivateSecurityRealm\u0026#34;\u0026gt; \u0026lt;disableSignup\u0026gt;false\u0026lt;/disableSignup\u0026gt; \u0026lt;enableCaptcha\u0026gt;false\u0026lt;/enableCaptcha\u0026gt; \u0026lt;/securityRealm\u0026gt; Reference Jenkins ldap配置不当导致无法登录\n运维吧-ldap4-Jenkins集成OpenLDAP认证\nldap-jenkins\n","description":"","id":107,"section":"posts","tags":["Devops","Jenkins","LDAP"],"title":"jenkins集成LDAP","uri":"https://hex-go.github.io/posts/devops/2020-01-06-jenkins%E9%9B%86%E6%88%90ldap/"},{"content":"申请Github OAuth Application Github OAuth Application是为了授权Drone Server读取Github信息。\n参考连接\n部署drone+mysql+nginx 部署的组件\nDrone-server (中央Drone服务器) Drone-agent (接受来自中央Drone服务器的指令以执行构建Pipeline) Mysql (Drone默认的数据存储是sqlite3, 本次部署改用mysql) Nginx (使用Nginx来做对外服务代理) Reference:\nDrone安装官方文档 Drone集成GitHub官方文档 DockerHub Mysql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 version: \u0026#34;3.7\u0026#34; services: nginx: image: nginx:alpine container_name: drone_nginx ports: - \u0026#34;80:80\u0026#34; restart: always networks: - dronenet mysql: image: mysql:5.7 restart: always container_name: drone_mysql environment: - MYSQL_ROOT_PASSWORD=root_password - MYSQL_DATABASE=drone - MYSQL_USER=drone - MYSQL_PASSWORD=drone_password networks: - dronenet volumes: - /path/to/conf/my.cnf:/etc/mysql/my.cnf:rw - /path/to/data:/var/lib/mysql/:rw - /path/to/logs:/var/log/mysql/:rw drone-server: image: drone/drone:1.0.0-rc.5 #不要用latest,latest并非稳定版本 container_name: drone-server networks: - dronenet volumes: - ${DRONE_DATA}:/var/lib/drone/:rw - /var/run/docker.sock:/var/run/docker.sock:rw restart: always environment: - DRONE_DEBUG=true - DRONE_DATABASE_DATASOURCE=drone:drone_password@tcp(drone_mysql:3306)/drone?parseTime=true #mysql配置，要与上边mysql容器中的配置一致 - DRONE_DATABASE_DRIVER=mysql - DRONE_GITHUB_SERVER=https://github.com - DRONE_GITHUB_CLIENT_ID=${Your-Github-Client-Id} #Github Client ID - DRONE_GITHUB_CLIENT_SECRET=${Your-Github-Client-Secret} #Github Client Secret - DRONE_RUNNER_CAPACITY=2 - DRONE_RPC_SECRET=YOU_KEY_ALQU2M0KdptXUdTPKcEw #RPC秘钥 - DRONE_SERVER_PROTO=http\t#这个配置决定了你激活时仓库中的webhook地址的proto - DRONE_SERVER_HOST=dronetest.qloud.com - DRONE_USER_CREATE=username:hex,admin:true #管理员账号，一般是你github用户名 drone-agent: image: drone/agent:1.0.0-rc.5 container_name: dronetest_agent restart: always networks: - dronenet depends_on: - drone-server #依赖drone_server，并在其后启动 volumes: - /var/run/docker.sock:/var/run/docker.sock:rw environment: - DRONE_RPC_SERVER=http://drone-server:8000\t#drone用的http请求包，url一定要写上协议才能支持 - DRONE_RPC_SECRET=YOU_KEY_ALQU2M0KdptXUdTPKcEw #RPC秘钥，与drone_server中的一致 - DRONE_DEBUG=true networks: dronenet: 执行以下命令，创建容器、网络\n1 docker-compose up -d 修改Nginx配置\n1 docker exec -it nginx ash 容器内执行以下命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 vim /etc/nginx/conf.d/drone.conf server { listen 80; server_name drone.qloud.com; location / { proxy_pass http://drone-server:8000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } nginx -s reload 使用 创建仓库，并保证仓库中存在.drone.yml文件; 访问drone服务， 并刷新。找到刷新出的新项目,点击active; 查看webhook中是否多出drone的webhook记录； 手动出发，看是否出发Drone构建过程。 注意：\n1. 如果文件名要自定义，需要再drone active的设置里修改成自定义的名字， 负责会发生正常事件触发drone时失败，返回状态码与信息均为N/A\n2. Drone 的编写总体符合yaml格式, 但要注意，第一个构建步骤之前是不能加注释的, 否则会报错\n举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 pipeline: restore-cache: image: drillster/drone-volume-cache restore: true mount: - ./node_modules volumes: # Mount the cache volume, needs \u0026#34;Trusted\u0026#34; | https://docs.drone.io/administration/user/admins/ # DRONE_USER_CREATE=username:{alicfeng},admin:true # source path {/tmp/cache/composer need to mkdir on server} - /tmp/cache/node_modules:/cache build-tests: image: node:latest commands: - node -v \u0026amp;\u0026amp; npm -v - npm install -g cnpm --registry=https://registry.npm.taobao.org - cnpm install - npm run build rebuild-cache: image: drillster/drone-volume-cache rebuild: true mount: - ./node_modules volumes: - /tmp/cache/node_modules:/cache sit-deploy: image: appleboy/drone-ssh host: $host username: $username password: $password port: $port command_timeout: 300s script: # sit env deploy shell script list - cd /www/code.samego.com/ - git pull - git pull - cnpm install -ddd - npm run build -ddd prod-deploy: image: appleboy/drone-ssh host: $host username: $username password: $password port: $port command_timeout: 300s script: # prod env deploy shell script list # todo awaiting extend to deploy | main scp - node -v \u0026amp;\u0026amp; npm -v - cd /www/code.samego.com/ - git pull - cnpm install -ddd - npm run build -ddd when: event: - push branch: - prod mail-notify: image: drillster/drone-email from: $from host: smtp.163.com username: $username password: $password port: 465 subject: CICD fail notify recipients: - a@test.com when: status: [ failure ] Reference Drone CI for GitHub\nDrONE CD for k8s\n","description":"","id":108,"section":"posts","tags":["Devops","Drone","CI/CD","Deployment","Docker"],"title":"GitHub-drone-dockercompose","uri":"https://hex-go.github.io/posts/devops/2020-01-06-github-drone-dockercompose/"},{"content":"写在前面 最重要的事: 可以提供java\\node\\python\\docker-image\\chart的仓储服务，但对镜像仓库的支持不足，不如harbor，helm-chart也值相当于原始文件存储的级别。\n1.简介 2.环境准备 3.部署 1 2 docker volume create --name nexus-data docker run -d -p 8081:8081 --name nexus -v nexus-data:/nexus-data sonatype/nexus3:3.20.1 4.使用 Reference nexus hub.docker 说明\n","description":"","id":109,"section":"posts","tags":["Persistence","Devops","Nexus"],"title":"提供健全的私仓服务-Nexus","uri":"https://hex-go.github.io/posts/persistence/2020-01-03-%E6%8F%90%E4%BE%9B%E5%81%A5%E5%85%A8%E7%9A%84%E7%A7%81%E4%BB%93%E6%9C%8D%E5%8A%A1-nexus/"},{"content":"写在前面 最重要的事: 备份一定要包含恢复脚本，一个不可恢复的备份就是脏数据！！！\n简介 Restic是一个用Go语言编写，安全且高效的备份客户端。它可以将本地文件备份到许多不同的后端存储库，例如本地目录，SFTP服务器或对象存储服务。公司由于Git-Server跑在本地办公网络,需要提供一个异地定期备份的方案,备份数据要求加密存储。选定CronTab+Restic+MinIO备份至华为云虚拟机上。\n获取Restic并在对象存储服务上初始化存储库。 准备要备份的文件，并将文件备份到存储库。 配置CronTab，自动执行备份以获取每小时快照，并在必要时自动精简旧快照。 环境准备 Restic可执行文件\nMinIO信息获取\n访问秘钥: AWS_ACCESS_KEY_ID 秘钥: AWS_SECRET_ACCESS_KEY 服务器URL: RESTIC_REPOSITORY Bucket名称: RESTIC_REPOSITORY RESTIC_PASSWORD定义Restic将用于加密备份的密码。此加密发生在本地，因此可以备份到不受信环境的异地服务器，并将其复制到安全备份的地方。可以通过KeyPass软件，或者通过openSSL命令:\n1 openssl rand -base64 24 环境准备过程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 1. Get Restic bin-file cd ~ curl -LO https://github.com/restic/restic/releases/download/v0.9.6/restic_0.9.6_linux_amd64.bz2 # Extract Here bzip2 -dk restic* # Set file cp restic* /usr/local/bin/restic chmod +x /usr/local/bin/restic # test restic version # 2. set Environments to access MinIO-bucket export AWS_ACCESS_KEY_ID=\u0026#34;minio-access-key\u0026#34; export AWS_SECRET_ACCESS_KEY=\u0026#34;minio-secret-key\u0026#34; export RESTIC_REPOSITORY=\u0026#34;s3:\u0026lt;server-url|eg=http://127.0.0.1:9000\u0026gt;/\u0026lt;bucket-name|eg=restic-git\u0026gt;/\u0026#34; export RESTIC_PASSWORD=\u0026#34;\u0026lt;a-strong-password|eg=j8CGOSdz8ibUYK137wtYdVsRoGUp\u0026gt;\u0026#34; 1. 初始化存储库 1 restic init 2. 准备备份文件 备份服务为内部开发服务, docker-run 跑在虚拟机上.所以做如下准备:\n服务的镜像文件 服务的数据文件 服务恢复脚本 3. crontab设置定时备份 最近24小时备份,7天备份,12月备份\n1 2 /usr/local/bin/restic backup -q ./restic-jenkins /usr/local/bin/restic forget -q --prune --keep-hourly 24 --keep-daily 30 --keep-monthly 12 restic 操作备查 1 2 3 4 5 6 7 8 # backup restic backup --tag data /opt/bkp_dir # show snapshots restic snapshots # restore restic restore \u0026lt;snapshot-id\u0026gt; --target /opt/restore-data Reference Restic备份对象存储服务器\n示例参考\n","description":"","id":110,"section":"posts","tags":["Persistence","Restic"],"title":"服务数据备份方案-Restic","uri":"https://hex-go.github.io/posts/persistence/2020-01-02-%E6%9C%8D%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E6%96%B9%E6%A1%88-restic/"},{"content":"摘要 对象存储服务可以用来存储各类文件，公司前端项目中的图片存储采用的是OSS，也采取过Minio+Restic给虚拟机服务提供定期异地加密备份方案。小记对minio服务的理解。\nMinIo简介 MinIO是一款基于Go语言的高性能对象存储服务，基于Apache License v2.0开源协议。在Github上已有19K+Star。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。\nMinIo可以单机或分布式模式运行。单机Minio服务存在单点故障，通常仅用于测试环境。分布式Minio将多块硬盘（甚至在不同的机器上）组成一个对象存储服务。由于硬盘分布在不同的节点上，分布式Minio避免了单点故障。如果是一个N节点的分布式Minio,只要有N/2节点在线，数据就是安全的。不过你需要至少有N/2+1个节点 Quorum 来创建新的对象。\n分布式模式与单机模式搭建的流程基本一样，Minio服务基于命令行传入的参数自动切换成单机模式还是分布式模式。启动一个分布式Minio实例，你只需要把硬盘位置做为参数传给minio server命令即可，然后，需要在所有其它节点运行同样的命令。\nMinio服务器将监控数据通过无须认证的端点暴露出来\n健康检查侦测：存活侦测（/minio/health/live），就绪侦测（/minio/health/ready）\nPrometheus侦测：/minio/prometheus/metrics\n安装及部署 1. Docker运行MinIo单点模式 MinIO 需要持久化配置(容器内: /root/.minio)和应用数据(容器内: /data)。传递的参数/data是数据存储目录，如果不存在会在容器启动时在容器的文件系统中创建。\n1 2 3 4 5 docker pull minio/minio docker run -p 9000:9000 --name minio \\ -v /mnt/data:/data \\ -v /mnt/config:/root/.minio \\ minio/minio server /data 2. Docker-compose运行MinIo分布式模式 分布式MinIO可以通过Docker Compose或者Swarm mode进行部署,本文docker-compose部署.\nDocker-Compose部署 Docker-swarm 节点规划 单个主机，多容器部署 多主机，多容器部署 优缺点 可以让快速的在机器上快速使用分布式MinIO，非常适合开发\\测试环境 提供了更健壮,生产级别的部署.但生产环境更建议部署到k8s中 Docker Compose允许定义和运行单主机，多容器Docker应用程序。使用Compose，可以使用Compose文件来配置MinIO服务。 然后，使用单个命令，您可以通过你的配置创建并启动所有分布式MinIO实例。 分布式MinIO实例将部署在同一主机上的多个容器中。 适合创建基于分布式MinIO的开发，测试环境。\n在Docker Compose上部署分布式MinIO,请下载docker-compose.yaml到你的当前工作目录。执行下面命令：\n1 2 3 4 5 6 7 8 # 1. Get docker-compose.yaml wget https://raw.githubusercontent.com/minio/minio/master/docs/orchestration/docker-compose/docker-compose.yaml # 2. pull image docker-compose pull # 3. container create \u0026amp; up docker-compose up Docker compose file中的MinIO服务使用的端口是9001到9004。\n3. Kubernetes-Helm MinIO生产环境更建议部署再kubernetes,不建议使用Swarm.而且\nMinIO Helm Chart部署MinIO。 Kubernetes MinIO参考示例 ，通过.yaml文件部署MinIO。 3.1前提条件 部署环境检查\n默认standaline模式下，需要开启Beta API的Kubernetes 1.4+。 distributed 模式，需要开启Beta API的Kubernetes 1.5+。 底层支持PV provisioner。 helm安装病配置完成。 3.2使用Helm Chart 部署 1 helm install --name=minio --namespace paas stable/minio 3.3分布式节点规划： 分布式Minio单租户存在最少4个盘最多32个盘的限制。只要遵守分布式Minio的限制，可以组合不同的节点和每个节点几块盘。比如，可以使用2个节点，每个节点4块盘，也可以使用4个节点，每个节点两块盘，诸如此类。 多个节点的存储容量和就是分布式Minio的存储容量。 mode：Minio服务器运行模式(standalone或distributed) replicas：节点数(仅适用于distributed模式).4 \u0026lt;= x \u0026lt;= 32,默认为4 3.4冒烟测试 1 2 3 4 5 6 7 8 9 # curl curl http://\u0026lt;service-name:9000\u0026gt;/minio/health/live curl http://\u0026lt;service-name:9000\u0026gt;/minio/health/ready # mc client mc config host add \u0026lt;ALIAS\u0026gt; \u0026lt;ENDPOINT\u0026gt; \u0026lt;ACCESS-KEY\u0026gt; \u0026lt;SECRET-KEY\u0026gt; mc ls \u0026lt;ALIAS\u0026gt; mc mb \u0026lt;ALIAS\u0026gt;/testbucket mc ls \u0026lt;ALIAS\u0026gt; 使用 (未完待续)\nReference Docker Compose 部署 MinIO\nKubernetes 部署 MinIO\nChart 获取\n","description":"","id":111,"section":"posts","tags":["Persistence","MinIO"],"title":"对象存储服务-Minio","uri":"https://hex-go.github.io/posts/persistence/2020-01-02-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1-minio/"},{"content":"重要 提前说明 开发人员提交代码到 Gitlab 代码仓库 通过 Gitlab 配置的 Jenkins Webhook 触发 Pipeline 自动构建 Jenkins 触发构建构建任务，根据 Pipeline 脚本定义分步骤构建 先进行代码静态分析，单元测试 然后进行 Maven 构建（Java 项目） 根据构建结果构建 Docker 镜像 推送 Docker 镜像到 Harbor 仓库 触发更新服务阶段，使用 Helm 安装/更新 Release 查看服务是否更新成功。 部署Jenkins chart地址: https://github.com/helm/charts/tree/master/stable/jenkins\n1 helm install --name jenkins stable/jenkins 1.后端服务容器化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 FROM maven:3.6-alpine as BUILD COPY src /usr/app/src COPY pom.xml /usr/app RUN mvn -f /usr/app/pom.xml clean package -Dmaven.test.skip=true FROM openjdk:8-jdk-alpine ENV LANG en_US.UTF-8 ENV LANGUAGE en_US:en ENV LC_ALL en_US.UTF-8 ENV TZ=Asia/Shanghai RUN mkdir /app WORKDIR /app COPY --from=BUILD /usr/app/target/polls-0.0.1-SNAPSHOT.jar /app/polls.jar EXPOSE 8080 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-Djava.security.egd=file:/dev/./urandom\u0026#34;, \u0026#34;-jar\u0026#34;,\u0026#34;/app/polls.jar\u0026#34;] 页面打包到一个jar文件build-container-/usr/app/target/polls-0.0.1-SNAPSHOT.jar 将上面jar文件添加到 jdk-container-/app/polls.jar目录 2. 前段服务容器化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 FROM node:alpine as BUILD WORKDIR /usr/src/app RUN mkdir -p /usr/src/app ADD . /usr/src/app RUN npm install \u0026amp;\u0026amp; \\ npm run build FROM nginx:1.15.10-alpine COPY --from=BUILD /usr/src/app/build /usr/share/nginx/html ADD nginx.conf /etc/nginx/conf.d/default.conf 页面打包到一个build目录build-container-/usr/src/app/build 将上面目录添加到 nginx-container-/usr/share/nginx/html目录 3. Jenkins task配置 在 Pipeline 中去自定义Slave Pod中所需要用到的容器模板，需要什么镜像只需要在Slave Pod Template中声明即可，不需要安装了所有工具的Slave镜像。\n首先Jenkins 中 kubernetes 配置，Jenkins -\u0026gt; 系统管理 -\u0026gt; 系统设置 -\u0026gt; 云 -\u0026gt; Kubernetes区域\n新建一个名为polling-app-server类型为流水线(Pipeline)的任务：\n勾选触发远程构建的触发器，其中令牌我们可以随便写一个字符串，然后记住下面的 URL，将 JENKINS_URL 替换成 Jenkins 的地址,我们这里的地址就是：http://jenkins.qikqiak.com/job/polling-app-server/build?token=server321\n在下面的流水线区域，可以选择Pipeline script，测试流水线脚本。正常配置选择Pipeline script from SCM，就是从代码仓库中通过Jenkinsfile文件获取Pipeline script脚本定义，选择 SCM 来源为Git。配置仓库地址http://git.qikqiak.com/course/polling-app-server.git，由于是在一个 Slave Pod 中去进行构建，所以如果使用 SSH 的方式去访问 Gitlab 代码仓库的话就需要频繁的去更新 SSH-KEY，所以直接采用用户名和密码的形式来访问：\n在Credentials区域点击添加按钮添加我们访问 Gitlab 的用户名和密码：\n配置用于构建的分支，如果所有的分支需要进行构建，将Branch Specifier区域留空即可，一般情况下，只有不同的环境对应的分支才需要构建，比如 master、develop、test 等，平时开发的 feature 或者 bugfix 的分支没必要频繁构建，下图只配置 master 和 develop 两个分支用户构建：\n然后前往 Gitlab 中配置项目polling-app-server Webhook，settings -\u0026gt; Integrations，填写上面得到的 trigger 地址：\n保存后，可以直接点击Test -\u0026gt; Push Event测试是否可以正常访问 Webhook 地址，这里需要注意的是我们需要配置下 Jenkins 的安全配置，否则这里的触发器没权限访问 Jenkins，系统管理 -\u0026gt; 全局安全配置：取消防止跨站点请求伪造，勾选上匿名用户具有可读权限：\n如果测试出现了Hook executed successfully: HTTP 201则证明 Webhook 配置成功了，否则就需要检查下 Jenkins 的安全配置是否正确了。\n4. JenkinsFile Clone 代码 -\u0026gt; 代码静态分析 -\u0026gt; 单元测试 -\u0026gt; Maven 打包 -\u0026gt; Docker 镜像构建/推送 -\u0026gt; Helm 更新服务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def label = \u0026#34;slave-${UUID.randomUUID().toString()}\u0026#34; podTemplate(label: label, containers: [ containerTemplate(name: \u0026#39;maven\u0026#39;, image: \u0026#39;maven:3.6-alpine\u0026#39;, command: \u0026#39;cat\u0026#39;, ttyEnabled: true), containerTemplate(name: \u0026#39;docker\u0026#39;, image: \u0026#39;docker\u0026#39;, command: \u0026#39;cat\u0026#39;, ttyEnabled: true), containerTemplate(name: \u0026#39;kubectl\u0026#39;, image: \u0026#39;hex/kubectl\u0026#39;, command: \u0026#39;cat\u0026#39;, ttyEnabled: true), containerTemplate(name: \u0026#39;helm\u0026#39;, image: \u0026#39;hex/helm\u0026#39;, command: \u0026#39;cat\u0026#39;, ttyEnabled: true) ], volumes: [ hostPathVolume(mountPath: \u0026#39;/root/.m2\u0026#39;, hostPath: \u0026#39;/var/run/m2\u0026#39;), hostPathVolume(mountPath: \u0026#39;/home/jenkins/.kube\u0026#39;, hostPath: \u0026#39;/root/.kube\u0026#39;), hostPathVolume(mountPath: \u0026#39;/var/run/docker.sock\u0026#39;, hostPath: \u0026#39;/var/run/docker.sock\u0026#39;) ]) { node(label) { def myRepo = checkout scm def gitCommit = myRepo.GIT_COMMIT def gitBranch = myRepo.GIT_BRANCH stage(\u0026#39;单元测试\u0026#39;) { echo \u0026#34;测试阶段\u0026#34; } stage(\u0026#39;代码编译打包\u0026#39;) { container(\u0026#39;maven\u0026#39;) { echo \u0026#34;打码编译打包阶段\u0026#34; } } stage(\u0026#39;构建 Docker 镜像\u0026#39;) { container(\u0026#39;docker\u0026#39;) { echo \u0026#34;构建 Docker 镜像阶段\u0026#34; } } stage(\u0026#39;运行 Kubectl\u0026#39;) { container(\u0026#39;kubectl\u0026#39;) { echo \u0026#34;查看 K8S 集群 Pod 列表\u0026#34; sh \u0026#34;kubectl get pods\u0026#34; } } stage(\u0026#39;运行 Helm\u0026#39;) { container(\u0026#39;helm\u0026#39;) { echo \u0026#34;查看 Helm Release 列表\u0026#34; sh \u0026#34;helm list\u0026#34; } } } } /root/.m2 挂载为了maven构建添加缓存，否则每次构建重新下载依赖，太慢。 ~/.kube 挂载为了让kubectl和helm访问 Kubernetes 集群。 /var/run/docker.sock 挂载为了docker客户端与Docker Daemon通信，构建镜像。 label标签的定义 使用 、UUID生成随机字符串，让Slave Pod每次的名称不一样，不会被固定在一个Pod上面了，而且有多个构建任务的时候就不会存在等待的情况. Reference k8s-deploy jenkins 动态slaves\njenkins pipeline 部署k8s应用\njenkin Blue Ocean 使用\njenkins-pipeline to k8s\n","description":"","id":112,"section":"posts","tags":["Devops","Jenkins","JenkinsFile","Gitlab","Kubernetes","Docker"],"title":"基于Jenkins、gitlab、docker、helm和Kubernetes的CI/CD","uri":"https://hex-go.github.io/posts/devops/2019-12-31-%E5%9F%BA%E4%BA%8Ejenkinsgitlabdockerhelm%E5%92%8Ckubernetes%E7%9A%84ci-cd/"},{"content":"重要 Drone登录的账号需要在Gogs设置为管理员，他俩兄弟的账密是互通的 Gogs的仓库会自动同步到Drone上，此时，需要在Drone开启激活该项目才能正常运行，激活后能在Gogs仓库WeHooks多一个记录。 Drone默认读取的配置文件名为项目根下.drone.yml，如果仓库内文件名不是。需要再Drone-setting中做修改。 正文 CI / CD( 持续集成 / 持续部署 )方案是DevOps中不可或缺的流程之一，本文简单介绍选择 Gogs + Drone 通过docker compose部署。\n主机名 gitLab + jenkins Gogs + Drone NUM 成熟度 GitLab是一个非常成熟的git工具之一，同时Jenkins也是非常成熟的CICD组件，功能非常强大。 性能高，并且简单易用 1 语言技术栈 GitLab是使用Ruby编写的，Jenkins更是了不起，使用Java来编写的，项目整体比较膨大，同时它们对硬件、CPU等开销比较高 Drone、Gogs皆是使用Go语言来编写构建，在整体的语言性能与内存开销算是有一定的优势 2 Drone是一种基于容器技术的持续交付系统。Drone使用简单的YAML配置文件（docker-compose的超集）来定义和执行Docker容器中的Pipelines。Drone与流行的源代码管理系统无缝集成，包括GitHub，GitHub Enterprise，Gogs，Bitbucket等。\n镜像说明 drone升级使用1.0.0-rc6版本，此版本并非稳定版本，推荐使用1版本甚至是0.8.6更稳定的版本。1.0后的版本较之前而言，配置更加灵活、优化版本，同时界面也变化了。drone\n环境准备 使用的前提，必须符合以下条件\n系统安装了Docker，同时要安装了Docker编排工具docker-compose 主流的x64位系统，Linux、Mac、Window等 安装了git版本控制工具 安装 安装非常简单，拉取docker-compose.yml编排文件，基于Docker环境自动构建即可！\ndocker-compose: https://github.com/alicfeng/gogs-drone-docker.git/deployment/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 version: \u0026#34;2\u0026#34; services: gogs: container_name: gogs image: gogs/gogs:0.11.91 ports: - 3000:3000 - 10022:22 volumes: - ./data/gogs/data:/data environment: - TZ=Asia/Shanghai restart: always networks: - dronenet drone-server: image: drone/drone:1.6.1 container_name: drone-server ports: - 8000:80 volumes: - /var/run/docker.sock:/var/run/docker.sock - ./data/drone/:/var/lib/drone environment: - DRONE_OPEN=true - DRONE_SERVER_HOST=drone-server:8000 - DRONE_DEBUG=true - DRONE_GIT_ALWAYS_AUTH=false - DRONE_GOGS=true - DRONE_GOGS_SKIP_VERIFY=false - DRONE_GOGS_SERVER={http://gogs:3000} - DRONE_PROVIDER=gogs - DRONE_SERVER_PROTO=http - DRONE_RPC_SECRET=7b4eb5caee376cf81a2fcf7181e66175 - DRONE_USER_CREATE=username:alic,admin:true - DRONE_DATABASE_DATASOURCE=/var/lib/drone/drone.sqlite - DRONE_DATABASE_DRIVER=sqlite3 - TZ=Asia/Shanghai restart: always networks: - dronenet drone-agent: image: drone/agent:1.6.1 container_name: drone-agent depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_RPC_SERVER={docker-server:8000} - DRONE_RPC_SECRET=7b4eb5caee376cf81a2fcf7181e66175 - DRONE_RUNNER_CAPACITY=2 - DRONE_DEBUG=true - TZ=Asia/Shanghai restart: always nginx: image: nginx:alpine container_name: drone_nginx ports: - \u0026#34;80:80\u0026#34; restart: always networks: - dronenet networks: dronenet: 执行以下命令，创建容器、网络\n1 docker-compose up -d 修改Nginx配置\n1 docker exec -it nginx ash 容器内执行以下命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 vim /etc/nginx/conf.d/drone.conf server { listen 80; server_name drone.qloud.com; location / { proxy_pass http://drone-server:8000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } nginx -s reload 运行 docker-runner\n1 2 3 4 5 6 7 8 9 10 11 docker run -d \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -e DRONE_RPC_PROTO=http \\ -e DRONE_RPC_HOST=10.8.3.206:8000 \\ -e DRONE_RPC_SECRET=7b4eb5caee376cf81a2fcf7181e66175 \\ -e DRONE_RUNNER_CAPACITY=2 \\ -e DRONE_RUNNER_NAME=${HOSTNAME} \\ -p 3002:3000 \\ --restart always \\ --name docker-runner \\ drone/drone-runner-docker:1 使用 每当分支的代码更新的时候，Gogs会动过钩子同步通知Drone，而Drone收到通知后根据.drone.yml配置执行命令。\n通过git clone分支代码到容器里面 单元测试, 代码静态检查 编译代码，构建可执行文件 build image镜像，发布到Registry 部署至生产环境 发送邮件等通知信息，这里还有很多插件，比如微信、钉钉、电报等 价值源于技术，技术源于分享\nReference Nginx代理\n","description":"","id":113,"section":"posts","tags":["Devops","CI/CD","Drone","Gogs","Docker"],"title":"gogs-drone-dockercompose","uri":"https://hex-go.github.io/posts/devops/2019-12-30-gogs-drone-dockercompose/"},{"content":" 计算机原理 网络 dns bgp 证书 ssl 编译原理 编程思想 linux ","description":"","id":114,"section":"posts","tags":["计算机原理"],"title":"Tree","uri":"https://hex-go.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/20191230-tree/"},{"content":" kubernetes源码阅读 Docker源码 flask源码 DBaas源码 ","description":"","id":115,"section":"posts","tags":["Source Code"],"title":"k8s源码阅读","uri":"https://hex-go.github.io/posts/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/20191229-k8s%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"content":"有待准备完善的博客计划：\npersistence: minio restic mongodb redis kafka postgresql dbaas consul vault nomad ElasticSearch zookeeper rook-ceph GlusterFS Kubernetes 监控 prometheus grafana promethus operator k8s deployment k8s Resource详解 k8s 源码阅读 knative faas k8s operator ambassador istio consul-connect gloo Devops docker jenkins gitlab gogs drone pipeline join with k8s 自动化工具 ansible terraform 个人工具 Pycharm Postman SecureCRT Git 在线json数据结构定义[Golang]。 Python 代码块 jinjia2 gitClient chartmuseum api apscheduler socket-client + socket-server 架构 Raft-gossip分布式python实现 设计模式 算法实现 部署 venv docker Golang 架构 Raft-gossip分布式Golang实现 vue 计算机原理 网络 dns bgp 证书 ssl 编译原理 编程思想 linux ","description":"","id":116,"section":"posts","tags":["Next"],"title":"下一步研究方向","uri":"https://hex-go.github.io/posts/%E6%8F%90%E4%B8%8A%E6%97%A5%E7%A8%8B/20191229-%E4%B8%8B%E4%B8%80%E6%AD%A5%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/"},{"content":"{% note success %} 不错的备查资料 {% endnote %}\n超详细备查(利于排查概念模糊点)\nGo语言入门教程，Golang入门教程（非常详细）\n超级实用\nGo语言标准库》The Golang Standard Library by Example\nGolang设计模式\u0026ndash;k8s源码为例\nGlang设计模式\u0026ndash;概念+示例\nGo by Example\ngo社区知识图谱\ngo语言的leetcode刷题\nThe Way To Go-ZH_CN\n交互式go工具\u0026ndash;lgo\n容器的top\u0026ndash;ctop\ndocker和docker-compose的终端UI\n","description":"","id":118,"section":"posts","tags":["Go"],"title":"Golang学习资料","uri":"https://hex-go.github.io/posts/golang/2019-12-29-golang%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/"},{"content":"SecureCRT/SecureFX 8.5.4安装使用 1. 下载 官网下载地址\n直接到官网上下载即可，下载过程可能会提示要先注册，直接注册，然后再下载。\n我直接下载的是最新版secureCRT+secureFX的合体包：scrt-sfx-8.5.4-1942.ubuntu16-64.x86_64.deb\n2.安装 sudo dpkg -i scrt-sfx-8.5.4-1942.ubuntu16-64.x86_64.deb\n如果安装过程中因为缺少依赖而安装失败，只需要通过命令：apt-get install -f即可完成依赖的安装。\n3.破解 破解文件下载：https://share.weiyun.com/5Mc38uB 密码：yetp32\nsecureCRT破解\n1 2 # /usr/bin/SecureCRT 路径如果不知道,请自行find sudo perl securecrt_forgeek_crack.pl /usr/bin/SecureCRT 打开SecureCRT，会弹出配置存放路径，点OK，跳出激活界面，还有30天过期什么的。\na. 点Enter License Data，跳出一个文本框，不用输任何东西!!! 直接点下一步 b. 他肯定报错，说license无效，不用管， c. 点左下角的 Enter Licence Manually, 然后要求输入各种信息，照着上面命令执行完的output信息复制粘贴上去就行。下面是举例: Name:REIZ Company:Toyota Serial Number: 请复制卡号 03-52-039026 License Key:请复制密码 AAS4RS X1MU15 G9S6WV VTA5TV ACXK55 1JKW75 8R8Z5Z PK4FXJ Issue Date: 08-08-2088 SecureFX破解\n1 sudo perl securefx_forgeek_crack.pl /usr/bin/SecureFX 打开SecureFX，参考SecureCRT激活步骤.\nReference linux破解资源\nWindows破解资源\n","description":"","id":119,"section":"posts","tags":["Ubuntu","个人工具","SSH"],"title":"Ubuntu18.04安装SecureCRT.","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-12-26-ubuntu_18.04%E5%AE%89%E8%A3%85securecrt/"},{"content":"前言 博客 评论系统 技术选型：\nDisqus 国内无法访问。 gitment很久没有维护、更新。 选用Gitalk 评论插件。 Gitalk 说明 Gitalk 的界面和功能：\ngitalk 使用 Github 帐号登录，界面干净整洁，且支持 MarkDown语法。\n正文 1. 获取 Token Gitalk 需要一个 Github Application，点击这里申请。\n填写下面参数：\n点击创建，获取 Client ID 和 Client Secret 之后填入 博客配置 Gitalk 部分\n2. 博客配置 博客配置文件source/_data/next.yml，增加以下配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026lt;!-- Gitalk start --\u0026gt; {% if site.gitalk.enable %} \u0026lt;!-- Link Gitalk 的脚本 --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://unpkg.com/gitalk/dist/gitalk.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/gitalk@latest/dist/gitalk.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;div id=\u0026#34;gitalk-container\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; var gitalk = new Gitalk({ // gitalk的主要参数 clientID: `Github Application clientID`, clientSecret: `Github Application clientSecret`, repo: `存储评论 issue 的 Github 仓库名（一般设置为 GitHub Page 的仓库名）`, owner: \u0026#39;Github 用户名\u0026#39;, admin: [\u0026#39;Github 用户名\u0026#39;], id: \u0026#39;页面的唯一标识。gitalk会根据这个标识，自动创建issue的标签\u0026#39;, }); gitalk.render(\u0026#39;gitalk-container\u0026#39;); \u0026lt;/script\u0026gt; {% endif %} \u0026lt;!-- Gitalk end --\u0026gt; 主要参数配置如下：\n1 2 3 4 5 6 clientID: `Github Application clientID`, clientSecret: `Github Application clientSecret`, repo: `Github 仓库名`,//存储评论 issue 的 Github 仓库名（建议直接用 GitHub Page 的仓库名） owner: \u0026#39;Github 用户名\u0026#39;, admin: [\u0026#39;Github 用户名\u0026#39;], //这个仓库的管理员，可以有多个，数组表示 id: \u0026#39;window.location.pathname\u0026#39;, //页面的唯一标识。gitalk 会根据这个标识，自动创建issue的标签，使用页面的相对路径作为标识 其他参数说明见官方文档 。比如，增加 全屏遮罩 的参数。\n1 distractionFreeMode: true, 结语 遗留问题\nGitalk 需要点开每篇文章的页面，进行初始化issue创建。解决方案参考 自动初始化 Gitalk 和 Gitment 评论。\n","description":"","id":120,"section":"posts","tags":["Hexo"],"title":"为博客添加 Gitalk 评论插件","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-06-23-hexo_%E4%B8%BA%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0gitalk%E8%AF%84%E8%AE%BA%E6%8F%92%E4%BB%B6/"},{"content":"简化命令行交互, 简化应用程序部署语法 1. Kubectl 自动补全 kubectl 工具本身支持自动补全,只需要简单设置一下即可\n1 2 3 echo \u0026#34;source \u0026lt;(kubectl completion bash)\u0026#34; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 如果没有安装bash-completion, 按如下命令安装\n1 2 apt update apt install bash-completion 2. 自定义 kubectl get 输出 kubectl get 相关资源，默认输出为 kubectl 内置，一般我们也可以使用-o json/-o jsonpath=''或者-o yaml查看其完整的资源信息。但是很多时候，我们需要关心的信息并不全面，因此我们需要自定义输出的列，那么可以使用 go-template 来进行实现。\ngo-template 是 golang 的一种模板，可以参考 template 的相关说明。\n比如仅仅想要查看获取的 pods 中的各个 pod 的 uid，则可以使用以下命令：\n1 kubectl get pods --all-namespaces -o go-template=\u0026#39;{{range .items}}{{.metadata.uid}} {{end}}\u0026#39; 比如使用 jsonpath 获取数据\n1 2 export ISTIO_PILOT_PORT=$(kubectl get -n istio-system service istio-ingressgateway -o jsonpath=\u0026#39;{.spec.ports[?(@.name==\u0026#34;tcp-pilot-grpc-tls\u0026#34;)].nodePort}\u0026#39;) echo ${ISTIO_PILOT_PORT} 3. k8s强制删除提示 Terminating 的namespace a. 首先尝试强制删除参数 1 kubectl delete namespace example-ns -force --grace-period=0 b. 如果不能删除，则采取以下方法 1 kubectl edit namespace example-ns 将其中spec.finalizers的值删除，也可以设置为[]。保存退出后，namespace就会被删除。\n1 2 3 4 5 6 7 8 9 10 11 apiVersion: v1 kind: Namespace metadata: finalizers: - controller.cattle.io/namespace-auth name: mars spec: finalizers: - kubernetes status: phase: Active 思路：\n命名空间无法删除通常是因为还有资源在使用这个命名空间，执行kubectl delete namespace xxx 时候，虽然显示deleted，但是命令夯死。我们可以查看资源使用情况：\n1 kubectl api-resources --namespaced=true -o name | xargs -n 1 kubectl get --show-kind --ingore-not-found -n xxxx Reference Kubernetes 的奇技淫巧\n删除一直处于terminating状态的namespace\n","description":"","id":121,"section":"posts","tags":["Kubernetes","运维笔记"],"title":"kubectl 小技巧","uri":"https://hex-go.github.io/posts/kubernetes/2019-12-13-k8s%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"content":"下载补丁文件 补丁文件地址：\n下载补丁文件后放置到任一目录下,建议放在pycharm安装目录, egg: /home/hex/apps/pycharm-2018.3.6/\n修改pycharm文件,安装目录bin下 pycharm64.vmoptions 和 pycharm.vmoptions, 文件末尾追加一下内容 1 2 # 格式为 -javaagent:补丁的文件地址 -javaagent:/home/hex/apps/pycharm-2018.3.6/JetbrainsCrack-release-enc.jar 启动pycharm, 输入如下 Activation code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ThisCrackLicenseId-{ “licenseId”:”1”, “licenseeName”:”Hex”, “assigneeName”:”Hex”, “assigneeEmail”:”892120992@qq.com”, “licenseRestriction”:””, “checkConcurrentUse”:false, “products”:[ {“code”:”II”,”paidUpTo”:”2099-12-31”}, {“code”:”DM”,”paidUpTo”:”2099-12-31”}, {“code”:”AC”,”paidUpTo”:”2099-12-31”}, {“code”:”RS0”,”paidUpTo”:”2099-12-31”}, {“code”:”WS”,”paidUpTo”:”2099-12-31”}, {“code”:”DPN”,”paidUpTo”:”2099-12-31”}, {“code”:”RC”,”paidUpTo”:”2099-12-31”}, {“code”:”PS”,”paidUpTo”:”2099-12-31”}, {“code”:”DC”,”paidUpTo”:”2099-12-31”}, {“code”:”RM”,”paidUpTo”:”2099-12-31”}, {“code”:”CL”,”paidUpTo”:”2099-12-31”}, {“code”:”PC”,”paidUpTo”:”2099-12-31”} ], “hash”:”2911276/0”, “gracePeriodDays”:7, “autoProlongated”:false} ","description":"","id":122,"section":"posts","tags":["Python","Pycharm","个人工具"],"title":"Pycharm2018 破解","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-12-13-pycharm_%E7%A0%B4%E8%A7%A3/"},{"content":"配置pycharm 同步代码至docker容器 参考连接\n容器配置 22端口暴露： 1 docker run --name chartbackend -d -p 5556:5555 -p8022:22 reg.qloudhub.com/qloudpaas/chartbackend:latest4 安装配置ssh服务 1 2 3 4 5 6 7 # Ubuntu 16.04 apt install openssh-server sed -i\u0026#39;s/PermitRootLogin prohibit-password/PermitRootLogin yes/\u0026#39; /etc/ssh/sshd_config # sed \u0026#39;s@sessions*requireds*pam_loginuid.so@session optional pam_loginuid.so@g\u0026#39; -i /etc/pam.d/sshd # echo \u0026#34;export VISIBLE=now\u0026#34; \u0026gt;\u0026gt; /etc/profile service ssh restart 设置容器用户名密码 1 2 3 passwd # 查看用户 whoami pycharm配置 add sftp server PyCharm Tools \u0026gt; Deployment \u0026gt; Configuration\nset project interpreter use sftp\u0026rsquo;s 点击 PyCharm 的 File \u0026gt; Setting \u0026gt; Project \u0026gt; Project Interpreter 右边的设置按钮新建一个项目的远程解释器：\n","description":"","id":123,"section":"posts","tags":["Python","Pycharm","个人工具"],"title":"Pycharm配置Sftp远程开发","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2020-05-13-pycharm_%E9%85%8D%E7%BD%AEsftp%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91/"},{"content":"1. ubuntu 18.04 install Ansible software-properties-common package installed. This software will make it easier to manage this and other independent software repositories:\n1 2 apt update apt install software-properties-common Then add the Ansible PPA by typing the following command:\n1 apt-add-repository ppa:ansible/ansible install Ansible\n1 2 apt update apt install ansible 2. config ssh access to ansible-hosts 3. ansible 注意 ansible 主机需要安装 pip install netaddr，因为 playbook 依赖 ansible 主机需要安装 apt install sshpass ，因为使用密码连接 ansible 主机需要安装 apt install zip unzip 因为 playbook 需要解压文件 ansible 主机需要配置 ansible 的host_key_checking(/etc/ansible/ansible.cfg)为False，因为所有主机都是第一次连接，还没有主机指纹在known_hosts中，需要忽略 4. 测试Ansible-Hosts连通性方法 vi /etc/ansible/hosts追加以下内容，IP地址即为要测试的机器 1 2 [test] 10.8.2.95 ansible_ssh_user=root ansible_ssh_pass=Qloud@123 docker_registry=true 执行以下命令，用ping模块进行测试。test为上面为hosts配置的主机组名字。 1 ansible -i /etc/ansible/hosts test -m ping 5. Ansible 的一些约定 inventory 主机清单\n-i参数指定主机清单。例如ansible-playbook -i inventory.py nomad.yaml\n1.1 静态inventory，通过静态配置文件inventory.json配置。\n1.2 动态inventory，通过动态生成脚本inventory.py生成。\nroles目录必须与playbook文件同级，并且文件夹名必须为roles。playbook文件中通过roles下的各个文件夹名字引用role\n例如\n1 2 3 4 5 6 - name: install mirrors and initialization hosts: all roles: # roles/ - yum-mirrors # |-- yum-mirrors/ - initialization # |-- initializations/ - docker-registry # |-- docker-registry/ 单个role目录结构说明。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . ├── install_nginx.yml # playbook 文件和 roles 目录应该处于平级目录 └── roles # 存放所有角色的的目录 └── nginx # nginx 角色 │ ├── defaults # 设定默认变量 │ │ └── main.yml │ ├── files # 存放由 copy 或 script 模块等调用的文件 │ │ └── index.html │ ├── handlers # 触发器任务 │ │ └── main.yml │ ├── meta # 定义当前角色的特殊设定及其依赖关系 │ ├── tasks # 定义任务，它是 role 的基本元素 │ │ └── main.yml │ ├── templates # templates 模块查找所需要模板文件的目录 │ │ └── nginx.conf.j2 │ └── vars # 定义变量 │ └── main.yml └── php # php 角色 └── ... playbook文件的定义中，优先级: role \u0026gt; task; 如果task-A必须要在某role-B之前执行，需要将task-A封装为role-A，放到role-B之前。\ntask中常用的模块\n模块名称 作用 ping 检查指定节点机器是否还能连通 command 执行命令模块，可以不填，是ansible默认的模块，命令中无法使用变量，管道。 shell 启动一个子shell执行命令，执行的命令中有管道或者变量，就需要使用shell模块。 script 将本机的shell脚本在被管理主机运行 copy 将本机复制文件到远程位置 service 用于控制远程主机的服务 cron 用于管理定时任务 file 用于远程主机上的文件操作 yum 使用yum包管理器来管理软件包 user、group user、goup分别请求：useradd、userdel、usermod；groupadd、groupdel、groupmod filesystem 在块设备上创建文件系统 get_url 下载文件 synchronize 同步文件模块 Reference Install Ansible on Ubuntu 18.04\n官方文档\n中文文档\nansible Ad-Hoc命令集\n金恒博客\n","description":"记录Ansible使用，包括环境准备、注意事项与操作记录","id":124,"section":"posts","tags":["Ansible","运维笔记","Python"],"title":"简记 Ansible 使用","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-12-13-ansible_%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"},{"content":"环境准备 1. install nvm 1 2 3 4 5 6 # refrence (https://hackernoon.com/how-to-install-node-js-on-ubuntu-16-04-18-04-using-nvm-node-version-manager-668a7166b854) curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.34.0/install.sh | bash bash install_nvm.sh source ~/.profile nvm --version nvm ls-remote 2. install nodejs 1 2 3 4 nvm install 10.15 nvm use 10.15 node -v npm -v 3. install+set yarn 1 2 3 4 npm i -g npm --registry https://registry.npm.taobao.org npm i -g yarn --registry https://registry.npm.taobao.org # set yarn use taobao proxy yarn config set registry https://registry.npm.taobao.org 4. install hexo 1 2 3 4 5 6 7 # install pkg yarn install # 安装包 npm install hexo-generator-searchdb --save npm install -g hexo-cli npm install -g hexo@3.9.0 使用说明 1. 本地调试 1 2 3 4 5 6 7 # local start hexo g ## 启动服务 hexo s ## 清理 hexo clean 2. 创建博客 1 2 3 4 5 6 7 8 9 10 11 12 # 创建博客（TITLE 不能带空格，不能加特殊字符） hexo new devops --path devops/ TITLE # 创建草稿 hexo new draft hexo常用命令备忘录 # 本机预览草稿 hexo S --draft # 将草稿发布为正式文章 hexo P hexo常用命令备忘录 # 或者 将草稿 以 bash 的布局发布(不支持--path参数知道目录，文件会保存在_post目录下，只能手动移动到相应子文件夹下) hexo publish bash hexo常用命令备忘录 配置文件 ./_config.yml\n./themes/next/_config.yml\n./source/_data/next.yml\n常见配置 1. 放图片或文件下载 本网站挂载\nhexo在构建成静态页面时，会将目录./source/images/下的内容全部拷贝至./public/images/目录。而public目录为网站根目录。 所以需要以下操作：\n将文件或照片放至./source/images/目录下 在md文件中，图片通过![例子](/images/\u0026lt;相对source/images目录的路径\u0026gt;)或\u0026lt;img src=\u0026quot;/images/\u0026lt;相对source/images目录的路径\u0026gt;\u0026quot; width=\u0026quot;80%\u0026quot;\u0026gt;\n文件通过[例子-文件](/images/\u0026lt;相对source/images目录的路径\u0026gt;) hexo构建后的静态网页会将source目录下的文件夹(除_data/, _drafts, posts)放至 根目录下，所以可以通过绝对路径索引。\n第三方工具挂载 使用chrome插件微博图床工具上传图片 将url放至md文件中例如![xxx图片](https://hex-cdn.oss-cn-hangzhou.aliyuncs.com/old/yNuAgl.jpg) 遗留问题 计划迁移 hugo, 遗留以下问题 暂不处理\nlocal-search设置\nCDN加速\n国内字体\n参考 Hexo生成Post: post、page、draft\nHexo文章保存为草稿\nHexo+Github博客搭建小白教程\n","description":"记录hexo的环境准备、常用命令、常规配置。","id":125,"section":"posts","tags":["个人工具","Hexo","Blog"],"title":"hexo常用命令备忘录","uri":"https://hex-go.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/2019-06-22-hexo_%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%E5%BD%95/"},{"content":"云原生，目前坐标西安。刚毕业两三年用Python做安全平台开发。18年入SRE岗，接触Kubernetes、devops、云原生，打开新世界大门。19年开始将Golang作为主要语言，成为一名Gopher。\n22年初集成优秀开源项目、开发创新平台。语言学习以及平台框架都渐入佳境。喜欢瞎折腾感兴趣的开源项目。本站主要作为工作和学习生活中的备忘录。\n三个方向\ngo的运行底层原理 （为什么） go的设计模式 （怎么写） 算法 （上魔法） 领域\n存储 网络 运行时 Learn more on GitHub.\n","description":"大胆假设 小心求证 认真做事 严谨做人","id":126,"section":"page","tags":null,"title":"关于","uri":"https://hex-go.github.io/page/about/"},{"content":" 如果要反馈本站存在的问题，敬请在评论区留言，或发送邮件联系我，亦可在 GitHub 上提交 Issue。\n站点概况 本站采用了 Hugo 静态博客框架，主题为 Zzo，托管在 Github page。除此之外，评论、统计等功能使用了以下服务：\n评论系统：Gitalk 访客统计：LeanCloud + 谷歌分析 静态资源：阿里云对象存储. 建站简史 记录工作、备忘.\n","description":"","id":127,"section":"page","tags":null,"title":"本站概览","uri":"https://hex-go.github.io/page/site/"},{"content":" 希望我们，都成为拥有好奇心与想象力的人，都是不断发现更大世界的有趣人类。\n{% tabs leisure %}\n1. 书目 1.1 在读书目 深入理解计算机系统. Randal E.Bryant / David O\u0026rsquo;Hallaron. 2016 1.2 已读书目 Docker从入门到实战 黄靖钧. 2017 算法图解. [美] Aditya · Bhargava. 2017 码农翻身. 刘欣. 2018 2. 优秀的开源项目 2.1 Kubernetes source-code-reading-notes k8s源码阅读笔记\n主要专注 k8s 云原生实践，包括但不限于 docker、kubernetes、promethus、istio、knative、service mesh、serverless 等。 2.2 Python psf/requests pallets/flask 2.3 Go hashicorp/raft Golang implementation of the Raft consensus protocol\nGolang implementation of the Raft consensus protocol kubernetes/kubernetes kafka-operator automate provisioning, management, autoscaling and operations of Apache Kafka clusters deployed to K8s. *keycloak A OpenID / Keycloak Proxy service 2.4 云原生 koderover/zadig 七牛云的一款面向开发者设计的云原生持续交付(Continuous Delivery)产品，具备高可用 CI/CD 能力，提供云原生运行环境，支持开发者本地联调、微服务并行构建和部署、集成测试等 2.5 其他 HelloGitHub 分享 GitHub 上有趣、入门级的开源项目\n各种语言的开源项目、让生活变得更美好的工具、书籍、学习笔记、教程等。通过这些项目你将学习到更多编程知识、提高自己的编程技巧、发现编程的乐趣。 awesomeAwesome lists\nAwesome lists about all kinds of interesting topics 3. 站点收藏夹 自己经常访问的一些站点收藏，涵盖技术工具向、学术向等各方向站点。\n3.1 学术 Websites for Economic Study \u0026amp; Research Top Journals in Economics 3.2 技术工具 GitHub Netlify 腾讯云 LeanCloud 国际版 WolframAlpha SM 公共图床 {% endtabs %}\n","description":"","id":128,"section":"page","tags":null,"title":"分享","uri":"https://hex-go.github.io/page/share/"},{"content":" 感觉内容不错的博客\n封尘网 [python ldap jenkins k8s docker]-[详细]\n阳明的博客 [DevOps Kubernetes]-[详细+深入]\nljchen\u0026rsquo;s Notes [consul istio Kubernetes]-[详细]\n田飞雨 [Kubernetes 源码阅读]-[详细]\n煎鱼 [gin 使用 example]-[详细]\nHuangHuang的博客 [python go 云原生 安全 镜像优化]-[详细]\n通过 k8s-ClientGo 的Dynamic.interface包操作CRD资源，发现此博客。后面了解技术栈也是云原生、go、python，故收藏。以下博客打算有时间细读\nGo: 关于锁（mutex）的一些使用注意事项 一个在容器外用 tcpdump 命令对容器内的网络请求抓包的方法 网络负载均衡器的类别和功能介绍 通过编写自定义内置函数的方式扩展 OPA/Rego 运行时 使用 Alpine 作为基础镜像时可能会遇到的常见问题的解决方法 shellless 容器、binaryless 容器以及 distroless 容器 当有多个可用的 Pod Security Policy 时 k8s 的 PSP 选择策略 gobpf 使用示例：使用 perf event 保存数据 健康检查功能相关的一些备忘 tcpdump 常用操作 面向信仰编程 [编译原理 操作系统 Go语言设计与实现 数据结构]-[详细] 大牛，通过Go语言设计与实现发现大牛对底层原理讲的很好。先收藏，后持续学习，记录学习新的博客。以下内容打算花时间细读\nGo语言设计与实现 为什么这么设计系列文章 云原生驿站 [云原生技术]-[详细] b站接触到小伙子的视频，刚毕业达到这水平。深受刺激\u0026hellip;\n","description":"","id":129,"section":"page","tags":null,"title":"小伙伴们","uri":"https://hex-go.github.io/page/friend/"}]